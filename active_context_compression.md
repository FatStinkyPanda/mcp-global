To successfully manage a codebase of millions of lines with agents restricted to 16,000 tokens (approx. 2-3 standard code files), you cannot rely on "remembering" the code. You must instead rely on navigation and structured external state.The architectural solution is to treat the 16k window not as a storage drive, but as a "workbench." An agent only puts on the workbench exactly what it needs for the immediate 5-minute task, then clears it off for the next one.Here is the specific architecture to make this work autonomously:1. The "External Brain" Architecture (Graph RAG)Standard "vector search" (RAG) is insufficient for code because it finds similar words, not logical connections. If an agent changes a function in auth.py, it needs to know that login.py breaks, even if they don't share similar words.Implement a Knowledge Graph: Before the agents start, run a script (using tools like tree-sitter) to map the codebase into a graph database (like Neo4j or a simple NetworkX JSON).What it stores: Function A -> calls -> Function B.Why this saves tokens: When an agent asks, "Where is the user login logic?", the Orchestrator queries the graph and returns only the file paths: ["/src/auth/login.py", "/src/models/user.py"]. The agent then reads only those two files, staying well under 16k tokens.2. The "Skeleton" View (Context Compression)An agent rarely needs to see the implementation of every function to understand how to use it.Technique: Generate "Skeleton Files" (or interface files) that contain only class names, function signatures, and docstrings, replacing the body code with ... or pass.Result: A 5,000-line file becomes 200 lines. The Orchestrator uses these skeletons to plan high-level architecture changes without blowing its context limit. It only requests the "full" file when it needs to write actual code lines.3. The "State File" (The Anchor)Since your system is autonomous and always running, the biggest risk is the agents getting lost in a loop or forgetting the "Grand Plan." You must decouple the "Project Status" from the "Agent Memory."Create a project_state.json: This file lives in the root of your repo and acts as the "Save Game" file. It is the only thing the Orchestrator reads at the start of every cycle.Structure:JSON{
  "global_goal": "Refactor database to PostgreSQL",
  "completed_milestones": ["Created schema", "Migrated user table"],
  "current_active_task": "Update connection string in config.py",
  "known_bugs": ["Login timeout in test_auth.py"],
  "next_step_queue": ["Run migration script", "Update documentation"]
}
Workflow:Orchestrator wakes up, reads project_state.json (500 tokens).Decides the next move.Spins up a Worker Agent, giving it only the specific instructions for that move.Worker finishes, updates project_state.json, and terminates.Orchestrator repeats.4. The "Memoization" Log (Learning from Mistakes)With a small context, agents will make the same mistake twice (e.g., "I forgot we are using Python 3.12, not 3.10").Solution: Maintain a lessons_learned.md file.Mechanism: Every time an agent's code fails a test or build, the error and the fix are summarized into a one-line "rule" and appended to this file.Injection: This file is universally injected into the system prompt of every agent. Since itâ€™s a list of high-value warnings, it is worth the token cost (e.g., "Note: Do not use os.path; use pathlib").Summary: The 3-Tier Context StrategyTo manage millions of lines with 16k tokens, you divide memory into three tiers:TierComponentLimitContentTier 1 (Hot)Active Window16k TokensThe 1-2 files currently being edited + the immediate error log.Tier 2 (Warm)Project State~2k Tokensproject_state.json + lessons_learned.md (The "Consciousness").Tier 3 (Cold)Knowledge GraphInfiniteThe map of where everything is. Agents query this; they never load it.A useful deep dive into exactly how these context windows saturate and why "stuffing" them with irrelevant code (like entire files) degrades agent performance is covered here: