{"d46e50ee5b1c_file": {"id": "d46e50ee5b1c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\test_bad_code.py", "content": "\"\"\"Test file with code quality issues.\"\"\"\n\n# Missing docstrings, poor naming, unused imports\nimport json\nimport os\nimport sys\n\ndef a(x,y):\n    z = x + y\n    return z\n\nclass b:\n    def __init__(self):\n        pass\n", "chunk_type": "file", "line_start": 1, "line_end": 15, "language": "python", "name": "test_bad_code.py"}, "d46e50ee5b1c_func_a": {"id": "d46e50ee5b1c_func_a", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\test_bad_code.py", "content": "def a(x,y):\n    z = x + y\n    return z", "chunk_type": "function", "line_start": 8, "line_end": 10, "language": "python", "name": "a"}, "d46e50ee5b1c_func___init__": {"id": "d46e50ee5b1c_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\test_bad_code.py", "content": "    def __init__(self):\n        pass", "chunk_type": "function", "line_start": 13, "line_end": 14, "language": "python", "name": "__init__"}, "d46e50ee5b1c_class_b": {"id": "d46e50ee5b1c_class_b", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\test_bad_code.py", "content": "class b:\n    def __init__(self):\n        pass", "chunk_type": "class", "line_start": 12, "line_end": 14, "language": "python", "name": "b"}, "4669868943fd_file": {"id": "4669868943fd_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\test_hook_enforcement.py", "content": "\"\"\"\nTest file to verify MCP hook enforcement.\n\"\"\"\n\ndef test_function():\n    \"\"\"Simple test function.\"\"\"\n    return \"MCP hooks are working!\"\n\nif __name__ == \"__main__\":\n    print(test_function())\n", "chunk_type": "file", "line_start": 1, "line_end": 11, "language": "python", "name": "test_hook_enforcement.py"}, "4669868943fd_func_test_function": {"id": "4669868943fd_func_test_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\test_hook_enforcement.py", "content": "def test_function():\n    \"\"\"Simple test function.\"\"\"\n    return \"MCP hooks are working!\"", "chunk_type": "function", "line_start": 5, "line_end": 7, "language": "python", "name": "test_function"}, "3fcc313cfefc_file": {"id": "3fcc313cfefc_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\test_normal_commit.py", "content": "\"\"\"Test normal commit with all MCP checks.\"\"\"\n\n\ndef test_function() -> str:\n    \"\"\"Test function with proper documentation and type hints.\"\"\"\n    return \"This commit will pass all MCP quality gates\"\n\n\nif __name__ == \"__main__\":\n    print(test_function())\n", "chunk_type": "file", "line_start": 1, "line_end": 11, "language": "python", "name": "test_normal_commit.py"}, "3fcc313cfefc_func_test_function": {"id": "3fcc313cfefc_func_test_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\test_normal_commit.py", "content": "def test_function() -> str:\n    \"\"\"Test function with proper documentation and type hints.\"\"\"\n    return \"This commit will pass all MCP quality gates\"", "chunk_type": "function", "line_start": 4, "line_end": 6, "language": "python", "name": "test_function"}, "c6042ec4f725_file": {"id": "c6042ec4f725_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Agent Collaboration Layer (ACL)\nEnables secure, bidirectional communication and presence tracking between AI agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport socket\nimport sys\nimport time\n\n# Configuration - Shared with NSync\nWINDOWS_NSYNC = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\")\nLINUX_NSYNC = Path(\"/home/p4nd4pr0t0c01/Projects/NSync\")\n\ndef get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC\n\ndef get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir\n\ndef get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox\n\ndef get_hostname():\n    return socket.gethostname()\n\nclass AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.lo", "chunk_type": "file", "line_start": 1, "line_end": 216, "language": "python", "name": "agent_comms.py"}, "c6042ec4f725_func_get_nsync_path": {"id": "c6042ec4f725_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC", "chunk_type": "function", "line_start": 18, "line_end": 19, "language": "python", "name": "get_nsync_path"}, "c6042ec4f725_func_get_comms_dir": {"id": "c6042ec4f725_func_get_comms_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir", "chunk_type": "function", "line_start": 21, "line_end": 25, "language": "python", "name": "get_comms_dir"}, "c6042ec4f725_func_get_mailbox_dir": {"id": "c6042ec4f725_func_get_mailbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox", "chunk_type": "function", "line_start": 27, "line_end": 31, "language": "python", "name": "get_mailbox_dir"}, "c6042ec4f725_func_get_hostname": {"id": "c6042ec4f725_func_get_hostname", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def get_hostname():\n    return socket.gethostname()", "chunk_type": "function", "line_start": 33, "line_end": 34, "language": "python", "name": "get_hostname"}, "c6042ec4f725_func_send_message": {"id": "c6042ec4f725_func_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def send_message(recipient: str, msg_type: str, content: dict):\n    \"\"\"Sends an encrypted-in-transit message via NSync mailbox.\"\"\"\n    mailbox = get_mailbox_dir()\n    msg_id = int(time.time() * 1000)\n    msg_file = mailbox / f\"{recipient}_{get_hostname()}_{msg_id}.json\"\n\n    payload = {\n        \"id\": msg_id,\n        \"from\": get_hostname(),\n        \"to\": recipient,\n        \"type\": msg_type,\n        \"content\": content,\n        \"timestamp\": time.time()\n    }\n\n    with open(msg_file, \"w\") as f:\n        json.dump(payload, f, indent=2)\n    print(f\"[COMMS] Message sent to {recipient}: {msg_type}\")\n\n    # Trigger NSync to propagate the message\n    try:\n        mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n        subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n    except:\n        pass\n    return msg_file", "chunk_type": "function", "line_start": 72, "line_end": 97, "language": "python", "name": "send_message"}, "c6042ec4f725_func_listen_for_messages": {"id": "c6042ec4f725_func_listen_for_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def listen_for_messages():\n    \"\"\"Polls for messages addressed to this host.\"\"\"\n    mailbox = get_mailbox_dir()\n    hostname = get_hostname()\n\n    messages = []\n    for f in mailbox.glob(f\"{hostname}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            # Mark as read/processed by deleting\n            f.unlink()\n        except Exception as e:\n            print(f\"[WARN] Failed to read message {f}: {e}\")\n\n    return messages", "chunk_type": "function", "line_start": 99, "line_end": 115, "language": "python", "name": "listen_for_messages"}, "c6042ec4f725_func_show_status": {"id": "c6042ec4f725_func_show_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def show_status():\n    \"\"\"Displays local and remote agent status.\"\"\"\n    local = AgentPresence.update()\n    print(\"--- Local Agent Priority ---\")\n    print(f\"Host:   {local['hostname']}\")\n    print(f\"Status: {local['status']}\")\n    print(f\"Task:   {local['current_task']}\")\n    print(f\"Sync:   {local['last_seen']}\")\n\n    print(\"\\n--- Remote Agents ---\")\n    remotes = AgentPresence.get_remote_status()\n    if not remotes:\n        print(\"No remote agents detected yet.\")\n    for host, data in remotes.items():\n        age = time.time() - data['timestamp']\n        active_str = \"[ACTIVE]\" if age < 60 else \"[OFFLINE/STALE]\"\n        print(f\"Host:   {host} {active_str}\")\n        print(f\"Status: {data['status']}\")\n        print(f\"Task:   {data['current_task']}\")\n        print(f\"Last heartbeat: {int(age)}s ago\")\n        print(\"-\" * 20)", "chunk_type": "function", "line_start": 117, "line_end": 137, "language": "python", "name": "show_status"}, "c6042ec4f725_func_show_help": {"id": "c6042ec4f725_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def show_help():\n    print(\"MCP Agent Collaboration Layer (ACL)\")\n    print(\"Usage: mcp comms <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  status                Check local and remote agent presence\")\n    print(\"  send <host> <type> <msg> Send a message to a specific agent\")\n    print(\"  listen                Poll and display unread messages\")\n    print(\"  ping <host>           Quick verification of remote agent life\")\n    print(\"  heartbeat <status> <task> Update local presence info\")\n    print(\"  collaborate           Enter autonomous agent-to-agent team mode\")", "chunk_type": "function", "line_start": 139, "line_end": 148, "language": "python", "name": "show_help"}, "c6042ec4f725_func_autonomous_loop": {"id": "c6042ec4f725_func_autonomous_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def autonomous_loop():\n    \"\"\"Autonomous execution loop for AI agents.\"\"\"\n    hostname = get_hostname()\n    print(f\"[AUTONOMOUS] Agent {hostname} entered collaboration mode.\")\n    AgentPresence.update(\"active\", \"autonomous collaboration\")\n\n    try:\n        while True:\n            msgs = listen_for_messages()\n            for m in msgs:\n                print(f\"\\n[RECEIVED] From: {m['from']} | Type: {m['type']}\")\n                print(f\"Content: {m['content']}\")\n\n                # If it's a task, execute it and report back\n                if m['type'] == \"task\" or m['type'] == \"instruction\":\n                    task_text = m['content'].get('text', '')\n                    print(f\"[EXEC] Starting task: {task_text}\")\n                    # In a real scenario, the agent would use the LLM to process this.\n                    # For now, we simulate acknowledgment.\n                    send_message(m['from'], \"ack\", {\"text\": f\"Task received and processing: {task_text}\"})\n\n            time.sleep(5)", "chunk_type": "function", "line_start": 150, "line_end": 175, "language": "python", "name": "autonomous_loop"}, "c6042ec4f725_func_main": {"id": "c6042ec4f725_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"status\":\n        show_status()\n    elif cmd == \"send\" and len(args) >= 3:\n        send_message(args[0], args[1], {\"text\": \" \".join(args[2:])})\n    elif cmd == \"listen\":\n        msgs = listen_for_messages()\n        if not msgs:\n            print(\"No new messages.\")\n        for m in msgs:\n            print(f\"\\n[FROM: {m['from']}] [TYPE: {m['type']}]\")\n            print(f\"Content: {m['content']}\")\n    elif cmd == \"ping\" and args:\n        remotes = AgentPresence.get_remote_status()\n        if args[0] in remotes:\n            age = time.time() - remotes[args[0]]['timestamp']\n            if age < 60:\n                print(f\"[OK] {args[0]} is ALIVE (Age: {int(age)}s)\")\n                return 0\n        print(f\"[FAIL] {args[0]} is UNREACHABLE or STALE\")\n        return 1\n    elif cmd == \"heartbeat\" and len(args) >= 2:\n        AgentPresence.update(args[0], args[", "chunk_type": "function", "line_start": 177, "line_end": 212, "language": "python", "name": "main"}, "c6042ec4f725_func_update": {"id": "c6042ec4f725_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data", "chunk_type": "function", "line_start": 39, "line_end": 57, "language": "python", "name": "update"}, "c6042ec4f725_func_get_remote_status": {"id": "c6042ec4f725_func_get_remote_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.load(pf)\n                except:\n                    pass\n        return remote_status", "chunk_type": "function", "line_start": 60, "line_end": 70, "language": "python", "name": "get_remote_status"}, "c6042ec4f725_class_AgentPresence": {"id": "c6042ec4f725_class_AgentPresence", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\agent_comms.py", "content": "class AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n       ", "chunk_type": "class", "line_start": 36, "line_end": 70, "language": "python", "name": "AgentPresence"}, "dcddc93ae137_file": {"id": "dcddc93ae137_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\mcp.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Tools Runner\n================\nSingle entry point for all MCP AI enhancement tools.\n\nWorks correctly regardless of:\n- How it's invoked (relative path, absolute path, symlink)\n- Current working directory\n- Installation location in project\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\nimport importlib\n\n# =============================================================================\n# CRITICAL: Resolve the ACTUAL location of this script\n# =============================================================================\n\ndef get_package_root():\n    \"\"\"\n    Get the absolute path to the mcp-global-rules directory.\n    Handles symlinks, relative paths, and various invocation methods.\n    \"\"\"\n    # Method 1: Use __file__ (works in most cases)\n    if '__file__' in dir():\n        script_path = Path(__file__).resolve()\n        return script_path.parent\n\n    # Method 2: Use sys.argv[0] (when __file__ isn't available)\n    if sys.argv:\n        script_path = Path(sys.argv[0]).resolve()\n        if script_path.name == 'mcp.py':\n            return script_path.parent\n\n    # Method 3: Search common locations\n    cwd = Path.cwd()\n\n    # Check if mcp-global-rules is in current directory\n    if (cwd / 'mcp-global-rules' / 'mcp.py').exists():\n        return cwd / 'mcp-global-rules'\n\n    # Check if we're inside mcp-global-rules\n    if (cwd / 'mcp.py').exists() and (cwd / 'scripts').exists():\n        return cwd\n\n    # Check parent directories\n    for parent in cwd.parents:\n        if (parent / 'mcp-global-rules' / 'mcp.py').exists():\n            return parent / 'mcp-global-rules'\n\n    return None\n\n\n# Get MCP root and add to path\nMCP_ROOT = get_package_root()\n\nif MCP_ROOT is None:\n    print(\"[FAIL] Cannot find mcp-global-rules directory\")\n    print(\"Make sure you're running from a project with mcp-global-rules installed\")\n    sys.exit(1)\n\n# Add MCP root to path for imports\nif str(MCP_ROOT) not in sys.path:\n    sys.path.insert(0, str(MCP_ROOT))\n\n# Sto", "chunk_type": "file", "line_start": 1, "line_end": 252, "language": "python", "name": "mcp.py"}, "dcddc93ae137_func_get_package_root": {"id": "dcddc93ae137_func_get_package_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\mcp.py", "content": "def get_package_root():\n    \"\"\"\n    Get the absolute path to the mcp-global-rules directory.\n    Handles symlinks, relative paths, and various invocation methods.\n    \"\"\"\n    # Method 1: Use __file__ (works in most cases)\n    if '__file__' in dir():\n        script_path = Path(__file__).resolve()\n        return script_path.parent\n\n    # Method 2: Use sys.argv[0] (when __file__ isn't available)\n    if sys.argv:\n        script_path = Path(sys.argv[0]).resolve()\n        if script_path.name == 'mcp.py':\n            return script_path.parent\n\n    # Method 3: Search common locations\n    cwd = Path.cwd()\n\n    # Check if mcp-global-rules is in current directory\n    if (cwd / 'mcp-global-rules' / 'mcp.py').exists():\n        return cwd / 'mcp-global-rules'\n\n    # Check if we're inside mcp-global-rules\n    if (cwd / 'mcp.py').exists() and (cwd / 'scripts').exists():\n        return cwd\n\n    # Check parent directories\n    for parent in cwd.parents:\n        if (parent / 'mcp-global-rules' / 'mcp.py')", "chunk_type": "function", "line_start": 24, "line_end": 56, "language": "python", "name": "get_package_root"}, "dcddc93ae137_func_show_help": {"id": "dcddc93ae137_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\mcp.py", "content": "def show_help():\n    \"\"\"Show help message.\"\"\"\n    print(\"\"\"\nMCP AI Enhancement Tools (48 Commands)\n=======================================\n\nUsage: python3 mcp-global-rules/mcp.py <command> [args...]\n\nCode Quality:\n    review [path] [--strict]    Code review automation\n    docs [path] [--write]       Generate missing docstrings\n    test [path]                 Generate pytest test stubs\n    deadcode [path]             Find unused code\n    fix [path] [--safe --apply] Auto-fix issues\n\nAnalysis:\n    deps [path]                 Dependency analysis\n    profile [path]              Performance/complexity\n    security [path]             Security audit\n    errors [path]               Error handling\n    architecture [path]         Architecture validation\n\nIntelligence:\n    context \"query\" [path]      Smart context extraction\n    find \"query\" [path]         Natural language search\n    refactor [path]             Suggest refactorings\n\nIndexes:\n    index-all                   Full reindex (all 7)\n   ", "chunk_type": "function", "line_start": 75, "line_end": 137, "language": "python", "name": "show_help"}, "dcddc93ae137_func_main": {"id": "dcddc93ae137_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\mcp.py", "content": "def main():\n    \"\"\"Main entry point.\"\"\"\n    if len(sys.argv) < 2 or sys.argv[1] in ('help', '-h', '--help'):\n        show_help()\n        return 0\n\n    command = sys.argv[1]\n    args = sys.argv[2:]\n\n    if command not in COMMANDS:\n        print(f\"[FAIL] Unknown command: {command}\")\n        show_help()\n        return 1\n\n    module_name = COMMANDS[command]\n\n    try:\n        # Import the module\n        module = importlib.import_module(f'scripts.{module_name}')\n\n        # Update sys.argv for the module\n        sys.argv = [f'scripts/{module_name}.py'] + args\n\n        if hasattr(module, 'main'):\n            return module.main() or 0\n        else:\n            print(f\"[FAIL] Module {module_name} has no main function\")\n            return 1\n\n    except ImportError as e:\n        print(f\"[FAIL] Could not import {module_name}: {e}\")\n        print(f\"MCP_ROOT: {MCP_ROOT}\")\n        print(f\"sys.path: {sys.path[:3]}\")\n        return 1\n    except Exception as e:\n        print(f\"[FAIL] Error running {comma", "chunk_type": "function", "line_start": 209, "line_end": 247, "language": "python", "name": "main"}, "fd91577c8591_file": {"id": "fd91577c8591_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\model_manager.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Model Priority Manager\nManages model selection based on user preference and availability.\nPriority 1: Gemini 3 Flash\nPriority 2: Claude Opus (Latest/4.5 Thinking)\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\n# Configuration Path\nCONFIG_PATH = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules/model_preferences.json\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules/model_preferences.json\")\n\nDEFAULT_PRIORITY = [\n    \"Gemini 3 Flash\",\n    \"Claude Opus (4.5 Thinking)\",\n    \"GPT-4o\"\n]\n\ndef get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n\ndef save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)\n\ndef get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])\n\ndef switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]\n\ndef main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n", "chunk_type": "file", "line_start": 1, "line_end": 73, "language": "python", "name": "model_manager.py"}, "fd91577c8591_func_get_preferences": {"id": "fd91577c8591_func_get_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\model_manager.py", "content": "def get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}", "chunk_type": "function", "line_start": 23, "line_end": 27, "language": "python", "name": "get_preferences"}, "fd91577c8591_func_save_preferences": {"id": "fd91577c8591_func_save_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\model_manager.py", "content": "def save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)", "chunk_type": "function", "line_start": 29, "line_end": 31, "language": "python", "name": "save_preferences"}, "fd91577c8591_func_get_current_model": {"id": "fd91577c8591_func_get_current_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\model_manager.py", "content": "def get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])", "chunk_type": "function", "line_start": 33, "line_end": 35, "language": "python", "name": "get_current_model"}, "fd91577c8591_func_switch_model": {"id": "fd91577c8591_func_switch_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\model_manager.py", "content": "def switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]", "chunk_type": "function", "line_start": 37, "line_end": 52, "language": "python", "name": "switch_model"}, "fd91577c8591_func_main": {"id": "fd91577c8591_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\model_manager.py", "content": "def main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n        save_preferences(prefs)\n        print(\"[MODEL] Preferences reset to defaults.\")\n    return 0", "chunk_type": "function", "line_start": 54, "line_end": 69, "language": "python", "name": "main"}, "f51c15910e25_file": {"id": "f51c15910e25_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\config\\loop_config.py", "content": "\"\"\"\nAuto-Dev Loop Configuration\n===========================\nWARNING: THIS FILE CONTROLS AN INFINITE AUTONOMOUS LOOP.\n\nRules:\n1. ONLY the USER is allowed to change this file.\n2. AI Agents must NEVER modify this file.\n3. If set to True, the system will trigger a new development cycle after every commit.\n\nTo stop the loop, set ENABLE_AUTO_LOOP = False manually.\n\"\"\"\n\n# START USER CONFIGURATION\nENABLE_AUTO_LOOP = True\n# END USER CONFIGURATION\n", "chunk_type": "file", "line_start": 1, "line_end": 17, "language": "python", "name": "loop_config.py"}, "c71eaafaef63_file": {"id": "c71eaafaef63_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\config\\__init__.py", "content": "\"\"\"\nConfiguration Package\n=====================\n\"\"\"\n", "chunk_type": "file", "line_start": 1, "line_end": 5, "language": "python", "name": "__init__.py"}, "349bf5d14377_file": {"id": "349bf5d14377_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Agent Collaboration Layer (ACL)\nEnables secure, bidirectional communication and presence tracking between AI agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport socket\nimport subprocess\nimport sys\nimport time\n\n# Configuration - Shared with NSync\nWINDOWS_NSYNC = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\")\nLINUX_NSYNC = Path(\"/home/p4nd4pr0t0c01/Projects/NSync\")\n\ndef get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC\n\ndef get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir\n\ndef get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox\n\ndef get_telegram_inbox_dir() -> Path:\n    inbox = get_comms_dir() / \"telegram_inbox\"\n    if not inbox.exists():\n        inbox.mkdir(parents=True, exist_ok=True)\n    return inbox\n\ndef get_hostname():\n    # Allow override for specifically identifying the IDE agent session\n    identity = os.environ.get(\"AGENT_IDENTITY\")\n    if identity:\n        return identity\n    return socket.gethostname()\n\nclass AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        exc", "chunk_type": "file", "line_start": 1, "line_end": 364, "language": "python", "name": "agent_comms.py"}, "349bf5d14377_func_get_nsync_path": {"id": "349bf5d14377_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC", "chunk_type": "function", "line_start": 19, "line_end": 20, "language": "python", "name": "get_nsync_path"}, "349bf5d14377_func_get_comms_dir": {"id": "349bf5d14377_func_get_comms_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir", "chunk_type": "function", "line_start": 22, "line_end": 26, "language": "python", "name": "get_comms_dir"}, "349bf5d14377_func_get_mailbox_dir": {"id": "349bf5d14377_func_get_mailbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox", "chunk_type": "function", "line_start": 28, "line_end": 32, "language": "python", "name": "get_mailbox_dir"}, "349bf5d14377_func_get_telegram_inbox_dir": {"id": "349bf5d14377_func_get_telegram_inbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_telegram_inbox_dir() -> Path:\n    inbox = get_comms_dir() / \"telegram_inbox\"\n    if not inbox.exists():\n        inbox.mkdir(parents=True, exist_ok=True)\n    return inbox", "chunk_type": "function", "line_start": 34, "line_end": 38, "language": "python", "name": "get_telegram_inbox_dir"}, "349bf5d14377_func_get_hostname": {"id": "349bf5d14377_func_get_hostname", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_hostname():\n    # Allow override for specifically identifying the IDE agent session\n    identity = os.environ.get(\"AGENT_IDENTITY\")\n    if identity:\n        return identity\n    return socket.gethostname()", "chunk_type": "function", "line_start": 40, "line_end": 45, "language": "python", "name": "get_hostname"}, "349bf5d14377_func_send_message": {"id": "349bf5d14377_func_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def send_message(recipient: str, msg_type: str, content: dict):\n    \"\"\"Sends an encrypted-in-transit message via NSync mailbox.\"\"\"\n    mailbox = get_mailbox_dir()\n    msg_id = int(time.time() * 1000)\n    msg_file = mailbox / f\"{recipient}_{get_hostname()}_{msg_id}.json\"\n\n    payload = {\n        \"id\": msg_id,\n        \"from\": get_hostname(),\n        \"to\": recipient,\n        \"type\": msg_type,\n        \"content\": content,\n        \"timestamp\": time.time()\n    }\n\n    with open(msg_file, \"w\") as f:\n        json.dump(payload, f, indent=2)\n    print(f\"[COMMS] Message sent to {recipient}: {msg_type}\")\n\n    # Trigger NSync to propagate the message\n    try:\n        mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n        subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n    except:\n        pass\n    return msg_file", "chunk_type": "function", "line_start": 83, "line_end": 108, "language": "python", "name": "send_message"}, "349bf5d14377_func_listen_for_messages": {"id": "349bf5d14377_func_listen_for_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def listen_for_messages():\n    \"\"\"Polls for messages addressed to this host.\"\"\"\n    mailbox = get_mailbox_dir()\n    hostname = get_hostname()\n\n    messages = []\n    for f in mailbox.glob(f\"{hostname}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            # Mark as read/processed by deleting\n            f.unlink()\n        except Exception as e:\n            print(f\"[WARN] Failed to read message {f}: {e}\")\n\n    return messages", "chunk_type": "function", "line_start": 110, "line_end": 126, "language": "python", "name": "listen_for_messages"}, "349bf5d14377_func_listen_for_telegram_messages": {"id": "349bf5d14377_func_listen_for_telegram_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def listen_for_telegram_messages():\n    \"\"\"Polls for Telegram messages. Background agents wait for Antigravity priority.\"\"\"\n    inbox = get_telegram_inbox_dir()\n    hostname = get_hostname()\n    agent_identity = os.getenv(\"AGENT_IDENTITY\", hostname)  # Use AGENT_IDENTITY if set, else hostname\n\n    messages = []\n\n    # Priority 1: Messages directly for me (based on AGENT_IDENTITY)\n    for f in inbox.glob(f\"{agent_identity}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            f.unlink()\n        except: pass\n\n    # Skip fallback logic if I AM Antigravity (I already checked)\n    if agent_identity.lower() == \"antigravity\":\n        return messages\n\n    # Priority 2: Fallback for Antigravity (Background Agents only)\n    # Background agents (Quasar/wizardpanda) only take Antigravity messages if stale\n    for f in inbox.glob(\"Antigravity_*.json\"):\n        try:\n            # Check how old the message is\n ", "chunk_type": "function", "line_start": 128, "line_end": 181, "language": "python", "name": "listen_for_telegram_messages"}, "349bf5d14377_func_notify_user_telegram": {"id": "349bf5d14377_func_notify_user_telegram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def notify_user_telegram(text: str):\n    \"\"\"Sends a notification back to the user via the Telegram Bridge.\"\"\"\n    # The bridge will watch this directory for outgoing alerts\n    outbox = get_comms_dir() / \"telegram_outbox\"\n    if not outbox.exists():\n        outbox.mkdir(parents=True, exist_ok=True)\n\n    msg_id = int(time.time() * 1000)\n    msg_file = outbox / f\"out_{msg_id}.json\"\n\n    with open(msg_file, \"w\") as f:\n        json.dump({\"text\": text, \"from\": get_hostname(), \"timestamp\": time.time()}, f, indent=2)\n    print(f\"[COMMS] Notification queued for Telegram: {text[:50]}...\")", "chunk_type": "function", "line_start": 183, "line_end": 195, "language": "python", "name": "notify_user_telegram"}, "349bf5d14377_func_show_status": {"id": "349bf5d14377_func_show_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def show_status():\n    \"\"\"Displays local and remote agent status.\"\"\"\n    hostname = get_hostname()\n    presence_file = get_comms_dir() / f\"{hostname}.json\"\n    local = {}\n    if presence_file.exists():\n        with open(presence_file, \"r\") as f:\n            local = json.load(f)\n    else:\n        local = AgentPresence.update() # Create if missing\n\n    print(\"--- Local Agent Priority ---\")\n    print(f\"Host:   {local.get('hostname', hostname)}\")\n    print(f\"Status: {local.get('status', 'unknown')}\")\n    print(f\"Task:   {local.get('current_task', 'unknown')}\")\n    print(f\"Sync:   {local.get('last_seen', 'unknown')}\")\n\n    print(\"\\n--- Remote Agents ---\")\n    remotes = AgentPresence.get_remote_status()\n    if not remotes:\n        print(\"No remote agents detected yet.\")\n    for host, data in remotes.items():\n        age = time.time() - data['timestamp']\n        active_str = \"[ACTIVE]\" if age < 60 else \"[OFFLINE/STALE]\"\n        print(f\"Host:   {host} {active_str}\")\n        print(f\"Status: {da", "chunk_type": "function", "line_start": 197, "line_end": 225, "language": "python", "name": "show_status"}, "349bf5d14377_func_show_help": {"id": "349bf5d14377_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def show_help():\n    print(\"MCP Agent Collaboration Layer (ACL)\")\n    print(\"Usage: mcp comms <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  status                Check local and remote agent presence\")\n    print(\"  send <host> <type> <msg> Send a message to a specific agent\")\n    print(\"  listen                Poll and display unread messages\")\n    print(\"  ping <host>           Quick verification of remote agent life\")\n    print(\"  heartbeat <status> <task> Update local presence info\")\n    print(\"  collaborate           Enter autonomous agent-to-agent team mode\")", "chunk_type": "function", "line_start": 227, "line_end": 236, "language": "python", "name": "show_help"}, "349bf5d14377_func_handle_telegram_instruction": {"id": "349bf5d14377_func_handle_telegram_instruction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def handle_telegram_instruction(text):\n    \"\"\"Parses telegram text and tries to execute as an MCP command or route to Antigravity.\"\"\"\n    print(f\"[EXEC] Parsing Telegram Task: {text}\")\n\n    # Check if this is the \"Antigravity\" agent (IDE session)\n    # If so, send to Antigravity automation instead of running MCP commands\n    hostname = get_hostname().lower()\n    agent_identity = os.getenv(\"AGENT_IDENTITY\", \"\").lower()\n\n    # Route to Antigravity IDE automation if AGENT_IDENTITY is set to \"Antigravity\"\n    if agent_identity == \"antigravity\":\n        try:\n            # Import antigravity automation module\n            antigravity_path = Path(__file__).resolve().parent / \"antigravity_automation.py\"\n            if antigravity_path.exists():\n                import importlib.util\n                spec = importlib.util.spec_from_file_location(\"antigravity_automation\", antigravity_path)\n                ag_module = importlib.util.module_from_spec(spec)\n                spec.loader.exec_module(ag_m", "chunk_type": "function", "line_start": 238, "line_end": 294, "language": "python", "name": "handle_telegram_instruction"}, "349bf5d14377_func_autonomous_loop": {"id": "349bf5d14377_func_autonomous_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def autonomous_loop():\n    \"\"\"Autonomous execution loop for AI agents.\"\"\"\n    hostname = get_hostname()\n    print(f\"[AUTONOMOUS] Agent {hostname} entered collaboration mode.\")\n    AgentPresence.update(\"active\", \"autonomous collaboration\")\n\n    try:\n        while True:\n            msgs = listen_for_messages()\n            for m in msgs:\n                print(f\"\\n[RECEIVED] From: {m['from']} | Type: {m['type']}\")\n                if m['type'] == \"task\" or m['type'] == \"instruction\":\n                    task_text = m['content'].get('text', '')\n                    result = handle_telegram_instruction(task_text)\n                    send_message(m['from'], \"result\", {\"text\": result})\n\n            # Check for Telegram instructions\n            t_msgs = listen_for_telegram_messages()\n            for tm in t_msgs:\n                print(f\"\\n[TELEGRAM] Instruction received: {tm['text']}\")\n                result = handle_telegram_instruction(tm['text'])\n                notify_user_telegram(f\"Result f", "chunk_type": "function", "line_start": 296, "line_end": 323, "language": "python", "name": "autonomous_loop"}, "349bf5d14377_func_main": {"id": "349bf5d14377_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"status\":\n        show_status()\n    elif cmd == \"send\" and len(args) >= 3:\n        send_message(args[0], args[1], {\"text\": \" \".join(args[2:])})\n    elif cmd == \"listen\":\n        msgs = listen_for_messages()\n        if not msgs:\n            print(\"No new messages.\")\n        for m in msgs:\n            print(f\"\\n[FROM: {m['from']}] [TYPE: {m['type']}]\")\n            print(f\"Content: {m['content']}\")\n    elif cmd == \"ping\" and args:\n        remotes = AgentPresence.get_remote_status()\n        if args[0] in remotes:\n            age = time.time() - remotes[args[0]]['timestamp']\n            if age < 60:\n                print(f\"[OK] {args[0]} is ALIVE (Age: {int(age)}s)\")\n                return 0\n        print(f\"[FAIL] {args[0]} is UNREACHABLE or STALE\")\n        return 1\n    elif cmd == \"heartbeat\" and len(args) >= 2:\n        AgentPresence.update(args[0], args[", "chunk_type": "function", "line_start": 325, "line_end": 360, "language": "python", "name": "main"}, "349bf5d14377_func_update": {"id": "349bf5d14377_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data", "chunk_type": "function", "line_start": 50, "line_end": 68, "language": "python", "name": "update"}, "349bf5d14377_func_get_remote_status": {"id": "349bf5d14377_func_get_remote_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.load(pf)\n                except:\n                    pass\n        return remote_status", "chunk_type": "function", "line_start": 71, "line_end": 81, "language": "python", "name": "get_remote_status"}, "349bf5d14377_class_AgentPresence": {"id": "349bf5d14377_class_AgentPresence", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_comms.py", "content": "class AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n       ", "chunk_type": "class", "line_start": 47, "line_end": 81, "language": "python", "name": "AgentPresence"}, "6d199201a5af_file": {"id": "6d199201a5af_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Autonomous Agent Launcher\nEnsures the mcp comms collaborate loop stays running in the background.\nAuto-restarts on failure.\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport subprocess\nimport sys\nimport time\n\nimport signal\n\nPID_FILE = Path(\"/tmp/agent_launcher.pid\") if os.name != 'nt' else Path(os.environ.get('TEMP', 'C:/Temp')) / \"agent_launcher.pid\"\n\ndef is_already_running():\n    if PID_FILE.exists():\n        try:\n            with open(PID_FILE, \"r\") as f:\n                pid = int(f.read().strip())\n            # Check if process exists\n            if os.name != 'nt':\n                os.kill(pid, 0)\n            else:\n                # Windows check\n                subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {pid}\"], capture_output=True, check=True)\n            return True\n        except:\n            PID_FILE.unlink(missing_ok=True)\n    return False\n\ndef write_pid():\n    with open(PID_FILE, \"w\") as f:\n        f.write(str(os.getpid()))\n\ndef get_mcp_py():\n    script_dir = Path(__file__).resolve().parent\n    mcp_py = script_dir.parent / \"mcp.py\"\n    return str(mcp_py)\n\ndef run_collaboration():\n    mcp_py = get_mcp_py()\n    script_dir = Path(__file__).resolve().parent\n    telegram_bridge_py = script_dir / \"telegram_bridge.py\"\n    telegram_config = script_dir / \"telegram_config.json\"\n\n    print(f\"[LAUNCHER] Starting autonomous collaboration loop...\")\n\n    t_process = None\n\n    while True:\n        try:\n            # Check/Start Telegram Bridge if configured\n            if telegram_config.exists():\n                if t_process is None or t_process.poll() is not None:\n                    action = \"Starting\" if t_process is None else \"Restarting\"\n                    print(f\"[LAUNCHER] Telegram configuration found. {action} Bridge...\")\n                    t_process = subprocess.Popen([sys.executable, str(telegram_bridge_py)], shell=False)\n\n            # Run mcp comms collaborate\n            process = subprocess.Popen([sys.executable, mcp_p", "chunk_type": "file", "line_start": 1, "line_end": 97, "language": "python", "name": "agent_launcher.py"}, "6d199201a5af_func_is_already_running": {"id": "6d199201a5af_func_is_already_running", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def is_already_running():\n    if PID_FILE.exists():\n        try:\n            with open(PID_FILE, \"r\") as f:\n                pid = int(f.read().strip())\n            # Check if process exists\n            if os.name != 'nt':\n                os.kill(pid, 0)\n            else:\n                # Windows check\n                subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {pid}\"], capture_output=True, check=True)\n            return True\n        except:\n            PID_FILE.unlink(missing_ok=True)\n    return False", "chunk_type": "function", "line_start": 18, "line_end": 32, "language": "python", "name": "is_already_running"}, "6d199201a5af_func_write_pid": {"id": "6d199201a5af_func_write_pid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def write_pid():\n    with open(PID_FILE, \"w\") as f:\n        f.write(str(os.getpid()))", "chunk_type": "function", "line_start": 34, "line_end": 36, "language": "python", "name": "write_pid"}, "6d199201a5af_func_get_mcp_py": {"id": "6d199201a5af_func_get_mcp_py", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def get_mcp_py():\n    script_dir = Path(__file__).resolve().parent\n    mcp_py = script_dir.parent / \"mcp.py\"\n    return str(mcp_py)", "chunk_type": "function", "line_start": 38, "line_end": 41, "language": "python", "name": "get_mcp_py"}, "6d199201a5af_func_run_collaboration": {"id": "6d199201a5af_func_run_collaboration", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def run_collaboration():\n    mcp_py = get_mcp_py()\n    script_dir = Path(__file__).resolve().parent\n    telegram_bridge_py = script_dir / \"telegram_bridge.py\"\n    telegram_config = script_dir / \"telegram_config.json\"\n\n    print(f\"[LAUNCHER] Starting autonomous collaboration loop...\")\n\n    t_process = None\n\n    while True:\n        try:\n            # Check/Start Telegram Bridge if configured\n            if telegram_config.exists():\n                if t_process is None or t_process.poll() is not None:\n                    action = \"Starting\" if t_process is None else \"Restarting\"\n                    print(f\"[LAUNCHER] Telegram configuration found. {action} Bridge...\")\n                    t_process = subprocess.Popen([sys.executable, str(telegram_bridge_py)], shell=False)\n\n            # Run mcp comms collaborate\n            process = subprocess.Popen([sys.executable, mcp_py, \"comms\", \"collaborate\"], shell=False)\n\n            # Monitoring loop\n            while process.poll() is None:\n      ", "chunk_type": "function", "line_start": 43, "line_end": 85, "language": "python", "name": "run_collaboration"}, "d353debcc3b3_file": {"id": "d353debcc3b3_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity IDE Automation Bridge\nAutomates typing messages into the Antigravity IDE chat interface using Playwright.\n\nThis module integrates with telegram_bridge.py and agent_comms.py to enable\nTelegram \u2192 Antigravity \u2192 Telegram message flow.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Optional\nimport json\nimport os\nimport sys\nimport time\n\n# Playwright will be imported dynamically to handle installation\ntry:\n    from playwright.sync_api import sync_playwright, Page, Browser, TimeoutError as PlaywrightTimeoutError\n    PLAYWRIGHT_AVAILABLE = True\nexcept ImportError:\n    PLAYWRIGHT_AVAILABLE = False\n    print(\"[WARNING] Playwright not installed. Run: pip install playwright && playwright install chromium\")\n\n# MCP Path Resolution\nSCRIPTS_DIR = Path(__file__).resolve().parent\nsys.path.append(str(SCRIPTS_DIR))\n\ntry:\n    import agent_comms\nexcept ImportError:\n    agent_comms = None\n\n\nclass AntigravityBridge:\n    \"\"\"Manages automation of Antigravity IDE chat interface.\"\"\"\n\n    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")\n\n    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigravity is an Electron app, so we'll use Playwright's Chromium DevTools Protocol\n  ", "chunk_type": "file", "line_start": 1, "line_end": 525, "language": "python", "name": "antigravity_automation.py"}, "d353debcc3b3_func_handle_antigravity_message": {"id": "d353debcc3b3_func_handle_antigravity_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def handle_antigravity_message(message_text: str) -> str:\n    \"\"\"\n    Main handler for processing Telegram messages destined for Antigravity.\n\n    Args:\n        message_text: The instruction from Telegram\n\n    Returns:\n        str: The response from Antigravity agent\n    \"\"\"\n    print(f\"[ANTIGRAVITY] Processing message: {message_text}\")\n\n    bridge = AntigravityBridge()\n\n    try:\n        response = bridge.send_message_to_agent(message_text, timeout_seconds=60)\n\n        if response:\n            return response\n        else:\n            return \"[ERROR] Failed to get response from Antigravity. Ensure the IDE is running with remote debugging enabled.\"\n\n    finally:\n        bridge.close()", "chunk_type": "function", "line_start": 436, "line_end": 459, "language": "python", "name": "handle_antigravity_message"}, "d353debcc3b3_func_install_playwright": {"id": "d353debcc3b3_func_install_playwright", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def install_playwright():\n    \"\"\"Helper function to install Playwright if needed.\"\"\"\n    import subprocess\n\n    print(\"[INFO] Installing Playwright...\")\n    try:\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"playwright\"], check=True)\n        subprocess.run([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\"], check=True)\n        print(\"[OK] Playwright installed successfully\")\n        return True\n    except Exception as e:\n        print(f\"[FAIL] Failed to install Playwright: {e}\")\n        return False", "chunk_type": "function", "line_start": 462, "line_end": 474, "language": "python", "name": "install_playwright"}, "d353debcc3b3_func_test_connection": {"id": "d353debcc3b3_func_test_connection", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def test_connection():\n    \"\"\"Test the connection to Antigravity IDE.\"\"\"\n    print(\"=== Antigravity Connection Test ===\")\n\n    if not PLAYWRIGHT_AVAILABLE:\n        print(\"[INFO] Playwright not available. Attempting to install...\")\n        if install_playwright():\n            print(\"[INFO] Please restart this script after installation completes.\")\n            return\n\n    bridge = AntigravityBridge()\n\n    if bridge.connect_to_antigravity():\n        print(\"[OK] Successfully connected to Antigravity IDE\")\n\n        # Test sending a simple message\n        test_msg = \"Hello! This is a test message from the Telegram bridge.\"\n        print(f\"\\n[TEST] Sending test message: {test_msg}\")\n\n        response = bridge.send_message_to_agent(test_msg, timeout_seconds=30)\n\n        if response:\n            print(f\"\\n[SUCCESS] Received response:\\n{response}\")\n        else:\n            print(\"\\n[FAIL] No response received\")\n    else:\n        print(\"[FAIL] Could not connect to Antigravity\")\n        print(\"\\n", "chunk_type": "function", "line_start": 477, "line_end": 511, "language": "python", "name": "test_connection"}, "d353debcc3b3_func___init__": {"id": "d353debcc3b3_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")", "chunk_type": "function", "line_start": 38, "line_end": 54, "language": "python", "name": "__init__"}, "d353debcc3b3_func_connect_to_antigravity": {"id": "d353debcc3b3_func_connect_to_antigravity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigravity is an Electron app, so we'll use Playwright's Chromium DevTools Protocol\n        to connect to the existing instance.\n\n        Returns:\n            bool: True if successfully connected, False otherwise\n        \"\"\"\n        if not PLAYWRIGHT_AVAILABLE:\n            print(\"[FAIL] Playwright is not installed.\")\n            return False\n\n        try:\n            self.playwright = sync_playwright().start()\n\n            # Antigravity IDE typically runs on a CDP endpoint\n            # We need to find the CDP debugging port\n            # Default for Electron apps is often http://localhost:9222\n\n            # Try common debugging ports for Electron apps\n            debugging_ports = [9222, 9223, 9224, 8315, 8316]\n\n            for port in debugging_ports:\n                try:\n                    cdp_url = f\"http://localhost:{port}\"\n                    pr", "chunk_type": "function", "line_start": 56, "line_end": 127, "language": "python", "name": "connect_to_antigravity"}, "d353debcc3b3_func_verify_workspace": {"id": "d353debcc3b3_func_verify_workspace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def verify_workspace(self) -> bool:\n        \"\"\"\n        Verifies that Antigravity is open in the correct workspace directory.\n\n        Returns:\n            bool: True if in correct workspace, False otherwise\n        \"\"\"\n        if not self.page:\n            return False\n\n        try:\n            # Check if title bar or status bar shows the correct workspace path\n            # Method 1: Check window title\n            title = self.page.title()\n            workspace_name = str(self.workspace_path.name)\n\n            print(f\"[DEBUG] Window title: {title}\")\n            print(f\"[DEBUG] Expected workspace: {workspace_name} or {self.workspace_path}\")\n\n            if workspace_name in title or str(self.workspace_path) in title:\n                print(f\"[OK] Antigravity is in correct workspace: {workspace_name}\")\n                return True\n\n            # Method 2: Execute JavaScript to get workspace path from VS Code API\n            try:\n                current_workspace = self.page.evaluate(", "chunk_type": "function", "line_start": 129, "line_end": 180, "language": "python", "name": "verify_workspace"}, "d353debcc3b3_func_open_workspace": {"id": "d353debcc3b3_func_open_workspace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def open_workspace(self) -> bool:\n        \"\"\"\n        Opens the correct workspace directory in Antigravity.\n\n        Returns:\n            bool: True if workspace opened successfully, False otherwise\n        \"\"\"\n        if not self.page:\n            return False\n\n        try:\n            print(f\"[INFO] Opening workspace: {self.workspace_path}\")\n\n            # First, press Escape to close any open dialogs\n            self.page.keyboard.press(\"Escape\")\n            time.sleep(0.5)\n\n            # Click \"Open Folder\" button if on Launchpad\n            try:\n                open_folder_button = self.page.query_selector('text=\"Open Folder\"')\n                if open_folder_button:\n                    print(\"[INFO] Clicking 'Open Folder' button on Launchpad\")\n                    open_folder_button.click()\n                    time.sleep(2)\n                else:\n                    # Try keyboard shortcut: Ctrl+K Ctrl+O\n                    print(\"[INFO] Using Ctrl+K Ctrl+O to open folder\")\n    ", "chunk_type": "function", "line_start": 182, "line_end": 245, "language": "python", "name": "open_workspace"}, "d353debcc3b3_func_send_message_to_agent": {"id": "d353debcc3b3_func_send_message_to_agent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def send_message_to_agent(self, message: str, timeout_seconds: int = 30) -> Optional[str]:\n        \"\"\"\n        Types a message into Antigravity's agent chat interface and retrieves the response.\n\n        Args:\n            message: The message text to send\n            timeout_seconds: Maximum time to wait for response\n\n        Returns:\n            str: The agent's response, or None if failed\n        \"\"\"\n        if not self.page:\n            if not self.connect_to_antigravity():\n                return None\n\n        try:\n            # Click the \"Open Agent Manager\" button to open the agent panel\n            print(\"[INFO] Looking for 'Open Agent Manager' button...\")\n            try:\n                # Try to find and click the Open Agent Manager button\n                agent_button = self.page.query_selector('text=\"Open Agent Manager\"')\n                if agent_button and agent_button.is_visible():\n                    print(\"[INFO] Clicking 'Open Agent Manager' button...\")\n              ", "chunk_type": "function", "line_start": 247, "line_end": 420, "language": "python", "name": "send_message_to_agent"}, "d353debcc3b3_func_close": {"id": "d353debcc3b3_func_close", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def close(self):\n        \"\"\"Cleanup resources.\"\"\"\n        if self.browser:\n            try:\n                self.browser.close()\n            except:\n                pass\n        if self.playwright:\n            try:\n                self.playwright.stop()\n            except:\n                pass", "chunk_type": "function", "line_start": 422, "line_end": 433, "language": "python", "name": "close"}, "d353debcc3b3_class_AntigravityBridge": {"id": "d353debcc3b3_class_AntigravityBridge", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "class AntigravityBridge:\n    \"\"\"Manages automation of Antigravity IDE chat interface.\"\"\"\n\n    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")\n\n    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigrav", "chunk_type": "class", "line_start": 35, "line_end": 433, "language": "python", "name": "AntigravityBridge"}, "6efea09de937_file": {"id": "6efea09de937_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "\"\"\"\nAPI Documentation Generator\n===========================\nGenerate OpenAPI specs and markdown docs from Flask/FastAPI code.\n\nUsage:\n    python api_docs.py [path] [--output api.md]\n    python -m scripts.api_docs src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Any\nimport ast\nimport json\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass APIEndpoint:\n    \"\"\"An API endpoint definition.\"\"\"\n    path: str\n    method: str\n    function_name: str\n    file_path: Path\n    line_number: int\n    docstring: Optional[str] = None\n    parameters: List[Dict[str, Any]] = field(default_factory=list)\n    request_body: Optional[Dict[str, Any]] = None\n    responses: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass APIDocumentation:\n    \"\"\"Complete API documentation.\"\"\"\n    title: str = \"API Documentation\"\n    version: str = \"1.0.0\"\n    endpoints: List[APIEndpoint] = field(default_factory=list)\n\n    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"openapi\": \"3.0.0\",\n            \"info\": {\n                \"title\": self.title,\n                \"version\": self.version\n          ", "chunk_type": "file", "line_start": 1, "line_end": 400, "language": "python", "name": "api_docs.py"}, "6efea09de937_func_analyze_file": {"id": "6efea09de937_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "def analyze_file(path: Path) -> List[APIEndpoint]:\n    \"\"\"Analyze a file for API endpoints.\"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return []\n\n    endpoints = []\n\n    # Detect framework\n    source = ''.join(source_lines)\n\n    if 'flask' in source.lower() or 'Flask' in source:\n        extractor = FlaskRouteExtractor(path, source_lines)\n        extractor.visit(tree)\n        endpoints.extend(extractor.endpoints)\n\n    if 'fastapi' in source.lower() or 'FastAPI' in source:\n        extractor = FastAPIRouteExtractor(path, source_lines)\n        extractor.visit(tree)\n        endpoints.extend(extractor.endpoints)\n\n    return endpoints", "chunk_type": "function", "line_start": 299, "line_end": 326, "language": "python", "name": "analyze_file"}, "6efea09de937_func_generate_api_docs": {"id": "6efea09de937_func_generate_api_docs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "def generate_api_docs(\n    root: Path,\n    title: str = \"API Documentation\",\n    exclude_patterns: List[str] = None\n) -> APIDocumentation:\n    \"\"\"Generate API documentation for a project.\"\"\"\n    docs = APIDocumentation(title=title)\n\n    Console.info(f\"Scanning {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        endpoints = analyze_file(path)\n        docs.endpoints.extend(endpoints)\n\n    Console.info(f\"Found {len(docs.endpoints)} API endpoints\")\n\n    return docs", "chunk_type": "function", "line_start": 329, "line_end": 348, "language": "python", "name": "generate_api_docs"}, "6efea09de937_func_main": {"id": "6efea09de937_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"API Documentation Generator\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n    output_format = 'markdown'\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n        if arg == '--json':\n            output_format = 'json'\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    docs = generate_api_docs(path)\n\n    if len(docs.endpoints) == 0:\n        Console.warn(\"No API endpoints found (Flask/FastAPI)\")\n        return 0\n\n    if output_format == 'json':\n        content = json.dumps(docs.to_openapi(), indent=2)\n    else:\n        content = docs.to_markdown()\n\n    if output_file:\n        with open(output_fi", "chunk_type": "function", "line_start": 351, "line_end": 395, "language": "python", "name": "main"}, "6efea09de937_func_to_openapi": {"id": "6efea09de937_func_to_openapi", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"openapi\": \"3.0.0\",\n            \"info\": {\n                \"title\": self.title,\n                \"version\": self.version\n            },\n            \"paths\": paths\n        }", "chunk_type": "function", "line_start": 48, "line_end": 75, "language": "python", "name": "to_openapi"}, "6efea09de937_func_to_markdown": {"id": "6efea09de937_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Convert to markdown documentation.\"\"\"\n        lines = [\n            f\"# {self.title}\",\n            \"\",\n            f\"**Version:** {self.version}\",\n            \"\",\n            \"## Endpoints\",\n            \"\",\n        ]\n\n        # Group by path\n        by_path: Dict[str, List[APIEndpoint]] = {}\n        for ep in self.endpoints:\n            if ep.path not in by_path:\n                by_path[ep.path] = []\n            by_path[ep.path].append(ep)\n\n        for path, endpoints in sorted(by_path.items()):\n            lines.append(f\"### `{path}`\")\n            lines.append(\"\")\n\n            for ep in endpoints:\n                lines.append(f\"#### {ep.method} `{path}`\")\n                lines.append(\"\")\n                lines.append(f\"**Handler:** `{ep.function_name}`\")\n                lines.append(f\"**Source:** `{ep.file_path}:{ep.line_number}`\")\n                lines.append(\"\")\n\n                if ep.docstring:\n                    lines.append(ep.docstrin", "chunk_type": "function", "line_start": 77, "line_end": 119, "language": "python", "name": "to_markdown"}, "6efea09de937_func___init__": {"id": "6efea09de937_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []", "chunk_type": "function", "line_start": 227, "line_end": 230, "language": "python", "name": "__init__"}, "6efea09de937_func_visit_Assign": {"id": "6efea09de937_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        # Detect Flask app = Flask(__name__)\n        if isinstance(node.value, ast.Call):\n            if isinstance(node.value.func, ast.Name):\n                if node.value.func.id == 'Flask':\n                    for target in node.targets:\n                        if isinstance(target, ast.Name):\n                            self._app_names.add(target.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 133, "line_end": 141, "language": "python", "name": "visit_Assign"}, "6efea09de937_func_visit_FunctionDef": {"id": "6efea09de937_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 232, "line_end": 234, "language": "python", "name": "visit_FunctionDef"}, "6efea09de937_func_visit_AsyncFunctionDef": {"id": "6efea09de937_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 236, "line_end": 238, "language": "python", "name": "visit_AsyncFunctionDef"}, "6efea09de937_func__check_decorators": {"id": "6efea09de937_func__check_decorators", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _check_decorators(self, node):\n        for decorator in node.decorator_list:\n            endpoint = self._parse_fastapi_decorator(decorator, node)\n            if endpoint:\n                self.endpoints.append(endpoint)", "chunk_type": "function", "line_start": 240, "line_end": 244, "language": "python", "name": "_check_decorators"}, "6efea09de937_func__parse_flask_decorator": {"id": "6efea09de937_func__parse_flask_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _parse_flask_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.route('/path', methods=['GET'])\n        if isinstance(decorator, ast.Call):\n            if isinstance(decorator.func, ast.Attribute):\n                if decorator.func.attr == 'route':\n                    path = self._get_path_arg(decorator)\n                    methods = self._get_methods_arg(decorator)\n                    if path:\n                        for method in methods:\n                            return APIEndpoint(\n                                path=path,\n                                method=method,\n                                function_name=func_node.name,\n                                file_path=self.path,\n                                line_number=func_node.lineno,\n                                docstring=ast.get_docstring(func_node),\n                                parameters=self._extract_params(path),\n                                responses={\"200\": {\"descripti", "chunk_type": "function", "line_start": 157, "line_end": 191, "language": "python", "name": "_parse_flask_decorator"}, "6efea09de937_func__get_path_arg": {"id": "6efea09de937_func__get_path_arg", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _get_path_arg(self, call: ast.Call) -> Optional[str]:\n        if call.args and isinstance(call.args[0], ast.Constant):\n            return call.args[0].value\n        return None", "chunk_type": "function", "line_start": 265, "line_end": 268, "language": "python", "name": "_get_path_arg"}, "6efea09de937_func__get_methods_arg": {"id": "6efea09de937_func__get_methods_arg", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _get_methods_arg(self, call: ast.Call) -> List[str]:\n        for keyword in call.keywords:\n            if keyword.arg == 'methods':\n                if isinstance(keyword.value, ast.List):\n                    return [\n                        elt.value.upper() if isinstance(elt, ast.Constant) else 'GET'\n                        for elt in keyword.value.elts\n                    ]\n        return ['GET']", "chunk_type": "function", "line_start": 198, "line_end": 206, "language": "python", "name": "_get_methods_arg"}, "6efea09de937_func__extract_params": {"id": "6efea09de937_func__extract_params", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _extract_params(self, path: str, func_node) -> List[Dict]:\n        \"\"\"Extract parameters from path and function signature.\"\"\"\n        params = []\n\n        # Path parameters: {id}\n        for match in re.findall(r'\\{(\\w+)\\}', path):\n            params.append({\n                \"name\": match,\n                \"in\": \"path\",\n                \"required\": True,\n                \"schema\": {\"type\": \"string\"}\n            })\n\n        # Query parameters from function args\n        skip = {'request', 'response', 'db', 'session'}\n        path_params = {p['name'] for p in params}\n\n        for arg in func_node.args.args:\n            if arg.arg not in skip and arg.arg not in path_params:\n                params.append({\n                    \"name\": arg.arg,\n                    \"in\": \"query\",\n                    \"required\": arg.annotation is not None,\n                    \"schema\": {\"type\": \"string\"}\n                })\n\n        return params", "chunk_type": "function", "line_start": 270, "line_end": 296, "language": "python", "name": "_extract_params"}, "6efea09de937_func__parse_fastapi_decorator": {"id": "6efea09de937_func__parse_fastapi_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _parse_fastapi_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.get(\"/path\"), @router.post(\"/path\")\n        if isinstance(decorator, ast.Call):\n            if isinstance(decorator.func, ast.Attribute):\n                if decorator.func.attr in self.METHODS:\n                    path = self._get_path_arg(decorator)\n                    if path:\n                        return APIEndpoint(\n                            path=path,\n                            method=decorator.func.attr.upper(),\n                            function_name=func_node.name,\n                            file_path=self.path,\n                            line_number=func_node.lineno,\n                            docstring=ast.get_docstring(func_node),\n                            parameters=self._extract_params(path, func_node)\n                        )\n\n        return None", "chunk_type": "function", "line_start": 246, "line_end": 263, "language": "python", "name": "_parse_fastapi_decorator"}, "6efea09de937_class_APIEndpoint": {"id": "6efea09de937_class_APIEndpoint", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "class APIEndpoint:\n    \"\"\"An API endpoint definition.\"\"\"\n    path: str\n    method: str\n    function_name: str\n    file_path: Path\n    line_number: int\n    docstring: Optional[str] = None\n    parameters: List[Dict[str, Any]] = field(default_factory=list)\n    request_body: Optional[Dict[str, Any]] = None\n    responses: Dict[str, Any] = field(default_factory=dict)", "chunk_type": "class", "line_start": 28, "line_end": 38, "language": "python", "name": "APIEndpoint"}, "6efea09de937_class_APIDocumentation": {"id": "6efea09de937_class_APIDocumentation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "class APIDocumentation:\n    \"\"\"Complete API documentation.\"\"\"\n    title: str = \"API Documentation\"\n    version: str = \"1.0.0\"\n    endpoints: List[APIEndpoint] = field(default_factory=list)\n\n    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"o", "chunk_type": "class", "line_start": 42, "line_end": 119, "language": "python", "name": "APIDocumentation"}, "6efea09de937_class_FlaskRouteExtractor": {"id": "6efea09de937_class_FlaskRouteExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "class FlaskRouteExtractor(ast.NodeVisitor):\n    \"\"\"Extract routes from Flask applications.\"\"\"\n\n    METHODS = {'get', 'post', 'put', 'delete', 'patch', 'options', 'head'}\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []\n        self._app_names: set = set()\n\n    def visit_Assign(self, node: ast.Assign):\n        # Detect Flask app = Flask(__name__)\n        if isinstance(node.value, ast.Call):\n            if isinstance(node.value.func, ast.Name):\n                if node.value.func.id == 'Flask':\n                    for target in node.targets:\n                        if isinstance(target, ast.Name):\n                            self._app_names.add(target.id)\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.Async", "chunk_type": "class", "line_start": 122, "line_end": 219, "language": "python", "name": "FlaskRouteExtractor"}, "6efea09de937_class_FastAPIRouteExtractor": {"id": "6efea09de937_class_FastAPIRouteExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\api_docs.py", "content": "class FastAPIRouteExtractor(ast.NodeVisitor):\n    \"\"\"Extract routes from FastAPI applications.\"\"\"\n\n    METHODS = {'get', 'post', 'put', 'delete', 'patch', 'options', 'head'}\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def _check_decorators(self, node):\n        for decorator in node.decorator_list:\n            endpoint = self._parse_fastapi_decorator(decorator, node)\n            if endpoint:\n                self.endpoints.append(endpoint)\n\n    def _parse_fastapi_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.get(\"/path\"), @router.post(\"/path\")\n        if isinstan", "chunk_type": "class", "line_start": 222, "line_end": 296, "language": "python", "name": "FastAPIRouteExtractor"}, "ee4d0c2eb3b3_file": {"id": "ee4d0c2eb3b3_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "\"\"\"\nArchitecture Validator\n======================\nEnforce architectural patterns and layer separation.\n\nUsage:\n    python architecture.py [path] [--config arch.json]\n    python -m scripts.architecture src/\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set, Tuple\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass LayerRule:\n    \"\"\"A layer dependency rule.\"\"\"\n    layer: str\n    can_depend_on: List[str]\n    patterns: List[str]  # Path patterns for this layer\n\n\n@dataclass\nclass ArchViolation:\n    \"\"\"An architecture violation.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'error', 'warning'\n    category: str\n    message: str\n    from_layer: Optional[str] = None\n    to_layer: Optional[str] = None\n\n\n@dataclass\nclass ArchReport:\n    \"\"\"Architecture analysis report.\"\"\"\n    violations: List[ArchViolation] = field(default_factory=list)\n    layer_mapping: Dict[str, str] = field(default_factory=dict)\n    dependencies: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_layers:\n                if from_layer and to_layer:\n                    lines.appen", "chunk_type": "file", "line_start": 1, "line_end": 353, "language": "python", "name": "architecture.py"}, "ee4d0c2eb3b3_func_detect_layer": {"id": "ee4d0c2eb3b3_func_detect_layer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "def detect_layer(path: Path, rules: List[LayerRule]) -> Optional[str]:\n    \"\"\"Detect the layer a module belongs to based on path patterns.\"\"\"\n    name = path.stem.lower()\n    parts = [p.lower() for p in path.parts]\n\n    for rule in rules:\n        for pattern in rule.patterns:\n            # Convert glob to regex\n            regex = pattern.replace('*', '.*')\n            if re.search(regex, name) or any(re.search(regex, p) for p in parts):\n                return rule.layer\n\n    return None", "chunk_type": "function", "line_start": 140, "line_end": 152, "language": "python", "name": "detect_layer"}, "ee4d0c2eb3b3_func_analyze_file": {"id": "ee4d0c2eb3b3_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "def analyze_file(\n    path: Path,\n    rules: List[LayerRule]\n) -> Tuple[Optional[str], List[ArchViolation], Set[str]]:\n    \"\"\"Analyze a file for architecture violations.\"\"\"\n    violations = []\n    imports = set()\n\n    layer = detect_layer(path, rules)\n\n    tree = parse_file(path)\n    if tree is None:\n        return layer, violations, imports\n\n    # Import analysis\n    import_analyzer = ImportAnalyzer(path, layer, rules)\n    import_analyzer.visit(tree)\n    violations.extend(import_analyzer.violations)\n    imports = import_analyzer.imports\n\n    # Naming conventions\n    naming = NamingConventionChecker(path, layer)\n    naming.check(tree)\n    violations.extend(naming.violations)\n\n    return layer, violations, imports", "chunk_type": "function", "line_start": 246, "line_end": 271, "language": "python", "name": "analyze_file"}, "ee4d0c2eb3b3_func_analyze_architecture": {"id": "ee4d0c2eb3b3_func_analyze_architecture", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "def analyze_architecture(\n    root: Path,\n    rules: List[LayerRule] = None,\n    exclude_patterns: List[str] = None\n) -> ArchReport:\n    \"\"\"Analyze project architecture.\"\"\"\n    if rules is None:\n        rules = DEFAULT_RULES\n\n    report = ArchReport()\n\n    Console.info(f\"Analyzing architecture in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        layer, violations, imports = analyze_file(path, rules)\n\n        # Track layer mapping\n        report.layer_mapping[str(path)] = layer or 'unknown'\n\n        # Track violations\n        report.violations.extend(violations)\n\n        # Track dependencies\n        if layer:\n            for imp in imports:\n                for rule in rules:\n                    for pattern in rule.patterns:\n                        regex = pattern.replace('*', '.*')\n                        if re.search(regex, imp.lower()):\n                            report.depende", "chunk_type": "function", "line_start": 274, "line_end": 309, "language": "python", "name": "analyze_architecture"}, "ee4d0c2eb3b3_func_main": {"id": "ee4d0c2eb3b3_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Architecture Validator\")\n\n    # Parse args\n    strict = '--strict' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_architecture(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.errors:\n        Console.fail(f\"Found {len(report.errors)} architecture violations\")\n        return 1\n    elif report.violations:\n        if strict:\n            Console.fail(f\"Found {len(report.violations)} warnings (strict mode)\")\n            return 1\n        else:\n            Console.warn(f\"Found {len(report.violations)} warnings\")\n    else:\n        Console.ok(\"Architecture is clean\")\n\n    return 0", "chunk_type": "function", "line_start": 312, "line_end": 348, "language": "python", "name": "main"}, "ee4d0c2eb3b3_func_errors": {"id": "ee4d0c2eb3b3_func_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']", "chunk_type": "function", "line_start": 55, "line_end": 56, "language": "python", "name": "errors"}, "ee4d0c2eb3b3_func_to_markdown": {"id": "ee4d0c2eb3b3_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_layers:\n                if from_layer and to_layer:\n                    lines.append(f'    {from_layer} --> {to_layer}')\n\n        lines.extend([\"```\", \"\"])\n\n        # Summary\n        lines.extend([\n            \"## Summary\",\n            \"\",\n            f\"- **Modules analyzed:** {len(self.layer_mapping)}\",\n            f\"- **Violations:** {len(self.violations)}\",\n            f\"- **Errors:** {len(self.errors)}", "chunk_type": "function", "line_start": 58, "line_end": 107, "language": "python", "name": "to_markdown"}, "ee4d0c2eb3b3_func___init__": {"id": "ee4d0c2eb3b3_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "    def __init__(self, path: Path, layer: Optional[str]):\n        self.path = path\n        self.layer = layer\n        self.violations: List[ArchViolation] = []", "chunk_type": "function", "line_start": 219, "line_end": 222, "language": "python", "name": "__init__"}, "ee4d0c2eb3b3_func_visit_Import": {"id": "ee4d0c2eb3b3_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self.imports.add(alias.name)\n            self._check_import(alias.name, node.lineno)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 165, "line_end": 169, "language": "python", "name": "visit_Import"}, "ee4d0c2eb3b3_func_visit_ImportFrom": {"id": "ee4d0c2eb3b3_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self.imports.add(node.module)\n            self._check_import(node.module, node.lineno)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 171, "line_end": 175, "language": "python", "name": "visit_ImportFrom"}, "ee4d0c2eb3b3_func__check_import": {"id": "ee4d0c2eb3b3_func__check_import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "    def _check_import(self, module: str, lineno: int):\n        if not self.layer:\n            return\n\n        # Get allowed dependencies for current layer\n        allowed = set()\n        for rule in self.rules:\n            if rule.layer == self.layer:\n                allowed = set(rule.can_depend_on)\n                break\n\n        # Check if import violates layer rules\n        module_lower = module.lower()\n        for rule in self.rules:\n            for pattern in rule.patterns:\n                regex = pattern.replace('*', '.*')\n                if re.search(regex, module_lower):\n                    imported_layer = rule.layer\n\n                    if imported_layer != self.layer and imported_layer not in allowed:\n                        self.violations.append(ArchViolation(\n                            path=self.path,\n                            line=lineno,\n                            severity='error',\n                            category='Layer Violation',\n                            m", "chunk_type": "function", "line_start": 177, "line_end": 206, "language": "python", "name": "_check_import"}, "ee4d0c2eb3b3_func_check": {"id": "ee4d0c2eb3b3_func_check", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "    def check(self, tree: ast.Module):\n        if not self.layer or self.layer not in self.CONVENTIONS:\n            return\n\n        expected = self.CONVENTIONS[self.layer]\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.ClassDef):\n                if node.name.startswith('_') or node.name == 'Config':\n                    continue\n\n                # Check if class name follows convention\n                if not any(node.name.endswith(suffix) for suffix in expected):\n                    self.violations.append(ArchViolation(\n                        path=self.path,\n                        line=node.lineno,\n                        severity='warning',\n                        category='Naming Convention',\n                        message=f\"Class '{node.name}' in '{self.layer}' layer should end with: {', '.join(expected)}\"\n                    ))", "chunk_type": "function", "line_start": 224, "line_end": 243, "language": "python", "name": "check"}, "ee4d0c2eb3b3_class_LayerRule": {"id": "ee4d0c2eb3b3_class_LayerRule", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "class LayerRule:\n    \"\"\"A layer dependency rule.\"\"\"\n    layer: str\n    can_depend_on: List[str]\n    patterns: List[str]  # Path patterns for this layer", "chunk_type": "class", "line_start": 28, "line_end": 32, "language": "python", "name": "LayerRule"}, "ee4d0c2eb3b3_class_ArchViolation": {"id": "ee4d0c2eb3b3_class_ArchViolation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "class ArchViolation:\n    \"\"\"An architecture violation.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'error', 'warning'\n    category: str\n    message: str\n    from_layer: Optional[str] = None\n    to_layer: Optional[str] = None", "chunk_type": "class", "line_start": 36, "line_end": 44, "language": "python", "name": "ArchViolation"}, "ee4d0c2eb3b3_class_ArchReport": {"id": "ee4d0c2eb3b3_class_ArchReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "class ArchReport:\n    \"\"\"Architecture analysis report.\"\"\"\n    violations: List[ArchViolation] = field(default_factory=list)\n    layer_mapping: Dict[str, str] = field(default_factory=dict)\n    dependencies: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_lay", "chunk_type": "class", "line_start": 48, "line_end": 107, "language": "python", "name": "ArchReport"}, "ee4d0c2eb3b3_class_ImportAnalyzer": {"id": "ee4d0c2eb3b3_class_ImportAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "class ImportAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze imports for architecture violations.\"\"\"\n\n    def __init__(self, path: Path, layer: Optional[str], rules: List[LayerRule]):\n        self.path = path\n        self.layer = layer\n        self.rules = rules\n        self.violations: List[ArchViolation] = []\n        self.imports: Set[str] = set()\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self.imports.add(alias.name)\n            self._check_import(alias.name, node.lineno)\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self.imports.add(node.module)\n            self._check_import(node.module, node.lineno)\n        self.generic_visit(node)\n\n    def _check_import(self, module: str, lineno: int):\n        if not self.layer:\n            return\n\n        # Get allowed dependencies for current layer\n        allowed = set()\n        for rule in self.rules:\n            if rule.la", "chunk_type": "class", "line_start": 155, "line_end": 206, "language": "python", "name": "ImportAnalyzer"}, "ee4d0c2eb3b3_class_NamingConventionChecker": {"id": "ee4d0c2eb3b3_class_NamingConventionChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\architecture.py", "content": "class NamingConventionChecker:\n    \"\"\"Check naming conventions by layer.\"\"\"\n\n    CONVENTIONS = {\n        'controller': ['Controller', 'Handler', 'View', 'Router', 'Api', 'Manager'],\n        'service': ['Service', 'Manager', 'Logic', 'Settings', 'Response'],\n        'repository': ['Repository', 'Repo', 'DAO', 'Dal'],\n        'model': ['Model', 'Entity', 'Schema', 'DTO', 'Base', 'Create', 'Read', 'Update', 'Item', 'Info', 'Status', 'Payload', 'Login', 'Response', 'Request', 'Analytics', 'Performance', 'Risk', 'Grade', 'Token', 'WithStudent', 'Account', 'Institution', 'Classroom', 'Assignment', 'Announcement', 'Subscription', 'Transaction', 'GameSave', 'BugReport', 'Product', 'Permission', 'Enrollment', 'Submission', 'Condition', 'Link', 'Jurisdiction', 'Log', 'Message', 'Cache', 'Category', 'Image', 'Review', 'Question', 'Option', 'Answer', 'Module', 'Progress', 'Type'],\n    }\n\n    def __init__(self, path: Path, layer: Optional[str]):\n        self.path = path\n        self.layer = layer\n ", "chunk_type": "class", "line_start": 209, "line_end": 243, "language": "python", "name": "NamingConventionChecker"}, "62e4b0604081_file": {"id": "62e4b0604081_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "\"\"\"\nast-grep Wrapper\n================\nStructural code search and transformation using ast-grep.\n\nUsage:\n    from scripts.astgrep import search_pattern, apply_fix\n\"\"\"\n\nimport json\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass, field\n\nfrom .utils import Console, find_python_files\n\n\n# Check if ast-grep is available\ndef _find_astgrep() -> Optional[str]:\n    \"\"\"Find ast-grep binary.\"\"\"\n    for name in ['ast-grep', 'sg']:\n        try:\n            result = subprocess.run(\n                [name, '--version'],\n                capture_output=True,\n                text=True\n            )\n            if result.returncode == 0:\n                return name\n        except FileNotFoundError:\n            continue\n    return None\n\n\nASTGREP_BIN = _find_astgrep()\nASTGREP_AVAILABLE = ASTGREP_BIN is not None\n\n\n@dataclass\nclass PatternMatch:\n    \"\"\"A pattern match result.\"\"\"\n    path: Path\n    line: int\n    column: int\n    text: str\n    matched_text: str\n    pattern: str\n\n\n@dataclass\nclass PatternRule:\n    \"\"\"A pattern rule for search/fix.\"\"\"\n    id: str\n    pattern: str\n    message: str\n    fix: Optional[str] = None\n    severity: str = \"warning\"\n    language: str = \"python\"\n\n\n# Built-in patterns for common issues\nBUILTIN_PATTERNS = {\n    'python': [\n        PatternRule(\n            id='bare-except',\n            pattern='except:',\n            message='Bare except catches all exceptions',\n            fix='except Exception:',\n            severity='error'\n        ),\n        PatternRule(\n            id='print-statement',\n            pattern='print($$$ARGS)',\n            message='Consider using logging instead of print',\n            severity='warning'\n        ),\n        PatternRule(\n            id='mutable-default',\n            pattern='def $FN($$$ARGS, $ARG=[]):',\n            message='Mutable default argument',\n            severity='error'\n        ),\n        PatternRule(\n            id='hardcoded-passw", "chunk_type": "file", "line_start": 1, "line_end": 395, "language": "python", "name": "astgrep.py"}, "62e4b0604081_func__find_astgrep": {"id": "62e4b0604081_func__find_astgrep", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _find_astgrep() -> Optional[str]:\n    \"\"\"Find ast-grep binary.\"\"\"\n    for name in ['ast-grep', 'sg']:\n        try:\n            result = subprocess.run(\n                [name, '--version'],\n                capture_output=True,\n                text=True\n            )\n            if result.returncode == 0:\n                return name\n        except FileNotFoundError:\n            continue\n    return None", "chunk_type": "function", "line_start": 22, "line_end": 35, "language": "python", "name": "_find_astgrep"}, "62e4b0604081_func_search_pattern": {"id": "62e4b0604081_func_search_pattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def search_pattern(\n    pattern: str,\n    path: Path,\n    language: str = \"python\"\n) -> List[PatternMatch]:\n    \"\"\"Search for pattern in code.\"\"\"\n    results = []\n\n    if ASTGREP_AVAILABLE:\n        return _astgrep_search(pattern, path, language)\n\n    # Fallback to regex-based search\n    return _regex_search(pattern, path)", "chunk_type": "function", "line_start": 157, "line_end": 169, "language": "python", "name": "search_pattern"}, "62e4b0604081_func__astgrep_search": {"id": "62e4b0604081_func__astgrep_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _astgrep_search(\n    pattern: str,\n    path: Path,\n    language: str\n) -> List[PatternMatch]:\n    \"\"\"Search using ast-grep.\"\"\"\n    results = []\n\n    try:\n        cmd = [\n            ASTGREP_BIN,\n            '--pattern', pattern,\n            '--json',\n            str(path)\n        ]\n\n        if language:\n            cmd.extend(['--lang', language])\n\n        proc = subprocess.run(cmd, capture_output=True, text=True)\n\n        if proc.returncode == 0 and proc.stdout:\n            for line in proc.stdout.strip().split('\\n'):\n                if line:\n                    try:\n                        match = json.loads(line)\n                        results.append(PatternMatch(\n                            path=Path(match.get('file', '')),\n                            line=match.get('range', {}).get('start', {}).get('line', 0),\n                            column=match.get('range', {}).get('start', {}).get('column', 0),\n                            text=match.get('text', ''),\n                   ", "chunk_type": "function", "line_start": 172, "line_end": 212, "language": "python", "name": "_astgrep_search"}, "62e4b0604081_func__regex_search": {"id": "62e4b0604081_func__regex_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _regex_search(pattern: str, path: Path) -> List[PatternMatch]:\n    \"\"\"Fallback regex-based search.\"\"\"\n    results = []\n\n    # Convert ast-grep pattern to rough regex\n    regex = pattern\n    regex = re.escape(regex)\n    regex = regex.replace(r'\\$\\$\\$', '.*')  # $$$ matches anything\n    regex = regex.replace(r'\\$', r'\\w+')     # $ matches identifier\n\n    try:\n        files = [path] if path.is_file() else list(path.rglob('*.py'))\n\n        for file_path in files:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    for i, line in enumerate(f, 1):\n                        if re.search(regex, line):\n                            results.append(PatternMatch(\n                                path=file_path,\n                                line=i,\n                                column=0,\n                                text=line.strip(),\n                                matched_text=line.strip(),\n                                pattern=pattern\n ", "chunk_type": "function", "line_start": 215, "line_end": 247, "language": "python", "name": "_regex_search"}, "62e4b0604081_func_apply_fix": {"id": "62e4b0604081_func_apply_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def apply_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    language: str = \"python\",\n    dry_run: bool = True\n) -> int:\n    \"\"\"Apply fix pattern to files.\"\"\"\n    fixed = 0\n\n    if ASTGREP_AVAILABLE:\n        return _astgrep_fix(pattern, replacement, path, language, dry_run)\n\n    # Fallback to regex\n    return _regex_fix(pattern, replacement, path, dry_run)", "chunk_type": "function", "line_start": 250, "line_end": 264, "language": "python", "name": "apply_fix"}, "62e4b0604081_func__astgrep_fix": {"id": "62e4b0604081_func__astgrep_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _astgrep_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    language: str,\n    dry_run: bool\n) -> int:\n    \"\"\"Apply fix using ast-grep.\"\"\"\n    cmd = [\n        ASTGREP_BIN,\n        '--pattern', pattern,\n        '--rewrite', replacement,\n    ]\n\n    if not dry_run:\n        cmd.append('--update-all')\n\n    cmd.extend(['--lang', language, str(path)])\n\n    try:\n        proc = subprocess.run(cmd, capture_output=True, text=True)\n        # Count matches\n        return proc.stdout.count('\\n')\n    except Exception:\n        return 0", "chunk_type": "function", "line_start": 267, "line_end": 291, "language": "python", "name": "_astgrep_fix"}, "62e4b0604081_func__regex_fix": {"id": "62e4b0604081_func__regex_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _regex_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    dry_run: bool\n) -> int:\n    \"\"\"Fallback regex-based fix.\"\"\"\n    fixed = 0\n\n    # Convert patterns\n    regex = pattern.replace('$$$', '(.*)').replace('$', r'(\\w+)')\n    repl = replacement.replace('$$$', r'\\1').replace('$', r'\\1')\n\n    files = [path] if path.is_file() else list(path.rglob('*.py'))\n\n    for file_path in files:\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n\n            new_content, count = re.subn(regex, repl, content)\n\n            if count > 0:\n                fixed += count\n                if not dry_run:\n                    with open(file_path, 'w', encoding='utf-8') as f:\n                        f.write(new_content)\n        except Exception:\n            pass\n\n    return fixed", "chunk_type": "function", "line_start": 294, "line_end": 324, "language": "python", "name": "_regex_fix"}, "62e4b0604081_func_run_rules": {"id": "62e4b0604081_func_run_rules", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def run_rules(\n    rules: List[PatternRule],\n    path: Path\n) -> List[PatternMatch]:\n    \"\"\"Run multiple pattern rules.\"\"\"\n    all_matches = []\n\n    for rule in rules:\n        matches = search_pattern(rule.pattern, path, rule.language)\n        for match in matches:\n            match.pattern = f\"{rule.id}: {rule.message}\"\n        all_matches.extend(matches)\n\n    return all_matches", "chunk_type": "function", "line_start": 327, "line_end": 340, "language": "python", "name": "run_rules"}, "62e4b0604081_func_get_builtin_rules": {"id": "62e4b0604081_func_get_builtin_rules", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def get_builtin_rules(language: str = \"python\") -> List[PatternRule]:\n    \"\"\"Get built-in rules for language.\"\"\"\n    return BUILTIN_PATTERNS.get(language, [])", "chunk_type": "function", "line_start": 343, "line_end": 345, "language": "python", "name": "get_builtin_rules"}, "62e4b0604081_func_is_astgrep_available": {"id": "62e4b0604081_func_is_astgrep_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def is_astgrep_available() -> bool:\n    \"\"\"Check if ast-grep is available.\"\"\"\n    return ASTGREP_AVAILABLE", "chunk_type": "function", "line_start": 348, "line_end": 350, "language": "python", "name": "is_astgrep_available"}, "62e4b0604081_func_main": {"id": "62e4b0604081_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"ast-grep Wrapper\")\n\n    if ASTGREP_AVAILABLE:\n        Console.ok(f\"ast-grep available: {ASTGREP_BIN}\")\n    else:\n        Console.warn(\"ast-grep not found, using regex fallback\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if len(args) < 2:\n        Console.info(\"Usage: python astgrep.py <pattern> <path>\")\n        Console.info(\"\\nBuilt-in rules:\")\n        for lang, rules in BUILTIN_PATTERNS.items():\n            Console.info(f\"\\n  {lang}:\")\n            for rule in rules:\n                Console.info(f\"    - {rule.id}: {rule.message}\")\n        return 1\n\n    pattern = args[0]\n    path = Path(args[1])\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Pattern: {pattern}\")\n    Console.info(f\"Path: {path}\")\n\n    matches = search_pattern(pattern, path)\n\n    Console.info(f\"Found {len(matches)} matches\")\n\n    for match in matches[:20]:\n        print(f\"  {", "chunk_type": "function", "line_start": 353, "line_end": 390, "language": "python", "name": "main"}, "62e4b0604081_class_PatternMatch": {"id": "62e4b0604081_class_PatternMatch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "class PatternMatch:\n    \"\"\"A pattern match result.\"\"\"\n    path: Path\n    line: int\n    column: int\n    text: str\n    matched_text: str\n    pattern: str", "chunk_type": "class", "line_start": 43, "line_end": 50, "language": "python", "name": "PatternMatch"}, "62e4b0604081_class_PatternRule": {"id": "62e4b0604081_class_PatternRule", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\astgrep.py", "content": "class PatternRule:\n    \"\"\"A pattern rule for search/fix.\"\"\"\n    id: str\n    pattern: str\n    message: str\n    fix: Optional[str] = None\n    severity: str = \"warning\"\n    language: str = \"python\"", "chunk_type": "class", "line_start": 54, "line_end": 61, "language": "python", "name": "PatternRule"}, "c1f852009958_file": {"id": "c1f852009958_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "\"\"\"\nAuto-Context Loader\n===================\nAutomatically load relevant code context for AI agents.\n\nUsage:\n    python mcp.py context --auto      # Get auto-loaded context\n    python mcp.py context --recent    # Context from recent files\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport os\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ContextCache:\n    \"\"\"Cache of context state.\"\"\"\n    recent_files: List[str] = field(default_factory=list)\n    hot_files: Dict[str, int] = field(default_factory=dict)  # path -> access count\n    last_query: str = \"\"\n    last_task: str = \"\"\n    timestamp: str = \"\"\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)\n\n\n@dataclass\nclass ContextResult:\n    \"\"\"Result of context loading.\"\"\"\n    files: List[Tuple[str, str]]  # (path, content summary)\n    token_count: int\n    source: str  # 'recent', 'semantic', 'dependency'\n\n\ndef get_cache_path(root: Path = None) -> Path:\n    \"\"\"Get path to context cache.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    return root / '.mcp' / 'memory' / 'context_cache.json'\n\n\ndef load_cache(root: Path = None) -> ContextCache:\n    \"\"\"Load context cache from disk.\"\"\"\n    cache_path = get_cache_path(root)\n\n    if cache_path.exists():\n        try:\n            with open(cache_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                return ContextCache.from_dict(data)\n        except Exception:\n            pass\n\n    return ContextCache()\n\n\ndef save_cache(cache: ContextCache, root: Path = None):\n    \"\"\"Save context cache to disk.\"\"\"\n    cache_path = get_cache_path(root)\n    cache_path.parent.mkdir(parents=True, exist_ok=True)\n\n    cache.timestamp = datetime.utcnow().isoformat() + 'Z'\n\n    ", "chunk_type": "file", "line_start": 1, "line_end": 391, "language": "python", "name": "autocontext.py"}, "c1f852009958_func_get_cache_path": {"id": "c1f852009958_func_get_cache_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_cache_path(root: Path = None) -> Path:\n    \"\"\"Get path to context cache.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    return root / '.mcp' / 'memory' / 'context_cache.json'", "chunk_type": "function", "line_start": 48, "line_end": 51, "language": "python", "name": "get_cache_path"}, "c1f852009958_func_load_cache": {"id": "c1f852009958_func_load_cache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def load_cache(root: Path = None) -> ContextCache:\n    \"\"\"Load context cache from disk.\"\"\"\n    cache_path = get_cache_path(root)\n\n    if cache_path.exists():\n        try:\n            with open(cache_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                return ContextCache.from_dict(data)\n        except Exception:\n            pass\n\n    return ContextCache()", "chunk_type": "function", "line_start": 54, "line_end": 66, "language": "python", "name": "load_cache"}, "c1f852009958_func_save_cache": {"id": "c1f852009958_func_save_cache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def save_cache(cache: ContextCache, root: Path = None):\n    \"\"\"Save context cache to disk.\"\"\"\n    cache_path = get_cache_path(root)\n    cache_path.parent.mkdir(parents=True, exist_ok=True)\n\n    cache.timestamp = datetime.utcnow().isoformat() + 'Z'\n\n    with open(cache_path, 'w', encoding='utf-8') as f:\n        json.dump(cache.to_dict(), f, indent=2)", "chunk_type": "function", "line_start": 69, "line_end": 77, "language": "python", "name": "save_cache"}, "c1f852009958_func_track_file_access": {"id": "c1f852009958_func_track_file_access", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def track_file_access(path: Path, root: Path = None):\n    \"\"\"Track that a file was accessed.\"\"\"\n    cache = load_cache(root)\n\n    path_str = str(path)\n\n    # Update recent files (max 20)\n    if path_str in cache.recent_files:\n        cache.recent_files.remove(path_str)\n    cache.recent_files.insert(0, path_str)\n    cache.recent_files = cache.recent_files[:20]\n\n    # Update hot files\n    cache.hot_files[path_str] = cache.hot_files.get(path_str, 0) + 1\n\n    save_cache(cache, root)", "chunk_type": "function", "line_start": 80, "line_end": 95, "language": "python", "name": "track_file_access"}, "c1f852009958_func_get_recent_context": {"id": "c1f852009958_func_get_recent_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_recent_context(\n    limit: int = 5,\n    max_lines: int = 50,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from recently accessed files.\"\"\"\n    cache = load_cache(root)\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    for file_path in cache.recent_files[:limit]:\n        path = Path(file_path)\n        if not path.is_absolute():\n            path = root / path\n\n        if path.exists():\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    lines = f.readlines()[:max_lines]\n                    content = ''.join(lines)\n                    files.append((str(path), content))\n                    token_count += len(content.split())\n            except Exception:\n                pass\n\n    return ContextResult(files=files, token_count=token_count, source='recent')", "chunk_type": "function", "line_start": 98, "line_end": 125, "language": "python", "name": "get_recent_context"}, "c1f852009958_func_get_hot_context": {"id": "c1f852009958_func_get_hot_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_hot_context(\n    limit: int = 5,\n    max_lines: int = 50,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from most frequently accessed files.\"\"\"\n    cache = load_cache(root)\n    root = root or find_project_root() or Path.cwd()\n\n    # Sort by access count\n    sorted_files = sorted(cache.hot_files.items(), key=lambda x: x[1], reverse=True)\n\n    files = []\n    token_count = 0\n\n    for file_path, _ in sorted_files[:limit]:\n        path = Path(file_path)\n        if not path.is_absolute():\n            path = root / path\n\n        if path.exists():\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    lines = f.readlines()[:max_lines]\n                    content = ''.join(lines)\n                    files.append((str(path), content))\n                    token_count += len(content.split())\n            except Exception:\n                pass\n\n    return ContextResult(files=files, token_count=token_count, source='hot')", "chunk_type": "function", "line_start": 128, "line_end": 158, "language": "python", "name": "get_hot_context"}, "c1f852009958_func_get_semantic_context": {"id": "c1f852009958_func_get_semantic_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_semantic_context(\n    query: str,\n    limit: int = 5,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context via semantic search.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n\n        if store.load():\n            results = store.search(query, k=limit)\n\n            for result in results:\n                files.append((result.chunk.path, result.chunk.content))\n                token_count += len(result.chunk.content.split())\n    except Exception:\n        pass\n\n    # Update cache with query\n    cache = load_cache(root)\n    cache.last_query = query\n    save_cache(cache, root)\n\n    return ContextResult(files=files, token_count=token_count, source='semantic')", "chunk_type": "function", "line_start": 161, "line_end": 190, "language": "python", "name": "get_semantic_context"}, "c1f852009958_func_get_dependency_context": {"id": "c1f852009958_func_get_dependency_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_dependency_context(\n    file_path: Path,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from file dependencies (imports).\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    try:\n        from .treesitter_utils import parse_file\n        parsed = parse_file(file_path)\n\n        for imp in parsed.imports:\n            # Try to resolve import to file\n            parts = imp.replace('from ', '').replace('import ', '').split()[0].split('.')\n\n            for i in range(len(parts), 0, -1):\n                possible_path = root / '/'.join(parts[:i]) + '.py'\n                if possible_path.exists():\n                    try:\n                        with open(possible_path, 'r', encoding='utf-8') as f:\n                            content = f.read()[:2000]\n                            files.append((str(possible_path), content))\n                            token_count += len(content.split())\n                    except Exception:\n       ", "chunk_type": "function", "line_start": 193, "line_end": 225, "language": "python", "name": "get_dependency_context"}, "c1f852009958_func_get_project_map": {"id": "c1f852009958_func_get_project_map", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_project_map(root: Path, budget: int) -> str:\n    \"\"\"Layer 1: Get high-level project map.\"\"\"\n    summary_path = root / \"CODEBASE_SUMMARY.md\"\n    if summary_path.exists():\n        try:\n            content = summary_path.read_text(encoding='utf-8')\n            # Extract Directory Structure section\n            if \"## Directory Structure\" in content:\n                structure = content.split(\"## Directory Structure\")[1].split(\"##\")[0]\n                return f\"# Project Map\\n{structure[:budget]}\"\n            return content[:budget]\n        except Exception:\n            pass\n    return \"\"", "chunk_type": "function", "line_start": 230, "line_end": 243, "language": "python", "name": "get_project_map"}, "c1f852009958_func_get_auto_context": {"id": "c1f852009958_func_get_auto_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_auto_context(\n    task: str = \"\",\n    token_budget: int = 8000, # Increased default for deep context\n    root: Path = None\n) -> str:\n    \"\"\"Get hierarchically layered context for AI agent.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    # Budget Allocation\n    budget_map = int(token_budget * 0.05)\n    budget_mem = int(token_budget * 0.10)\n    budget_active = int(token_budget * 0.40)\n    budget_semantic = token_budget - (budget_map + budget_mem + budget_active)\n\n    layers = []\n\n    # Layer 1: Project Map\n    project_map = get_project_map(root, budget_map)\n    if project_map:\n        layers.append(project_map)\n\n    # Layer 2: Memory\n    memories = []\n    try:\n        from .memory import get_store\n        store = get_store()\n        recent_mems = store.recall(task) if task else store.list_all()\n        recent_mems.sort(key=lambda m: m.updated or m.created, reverse=True)\n\n        mem_tokens_used = 0\n        for mem in recent_mems[:5]:\n            encoded = f\"[{mem.key", "chunk_type": "function", "line_start": 245, "line_end": 337, "language": "python", "name": "get_auto_context"}, "c1f852009958_func_update_task": {"id": "c1f852009958_func_update_task", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def update_task(task: str, root: Path = None):\n    \"\"\"Update current task in cache.\"\"\"\n    cache = load_cache(root)\n    cache.last_task = task\n    save_cache(cache, root)", "chunk_type": "function", "line_start": 342, "line_end": 346, "language": "python", "name": "update_task"}, "c1f852009958_func_main": {"id": "c1f852009958_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Context Loader\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    root = find_project_root() or Path.cwd()\n\n    if '--recent' in sys.argv:\n        result = get_recent_context(root=root)\n        Console.info(f\"Recent files: {len(result.files)}\")\n        for path, _ in result.files:\n            print(f\"  - {path}\")\n        return 0\n\n    if '--hot' in sys.argv:\n        result = get_hot_context(root=root)\n        Console.info(f\"Hot files: {len(result.files)}\")\n        for path, _ in result.files:\n            print(f\"  - {path}\")\n        return 0\n\n    if '--auto' in sys.argv or not args:\n        task = ' '.join(args) if args else \"\"\n        context = get_auto_context(task=task, root=root)\n        print(context)\n        return 0\n\n    # Semantic search with query\n    query = ' '.join(args)\n    result = get_semantic_context(query, root=root)\n\n    Console.info(f\"Found {len(result.files)} relevant files for: {quer", "chunk_type": "function", "line_start": 349, "line_end": 386, "language": "python", "name": "main"}, "c1f852009958_func_to_dict": {"id": "c1f852009958_func_to_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "    def to_dict(self) -> dict:\n        return asdict(self)", "chunk_type": "function", "line_start": 32, "line_end": 33, "language": "python", "name": "to_dict"}, "c1f852009958_func_from_dict": {"id": "c1f852009958_func_from_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)", "chunk_type": "function", "line_start": 36, "line_end": 37, "language": "python", "name": "from_dict"}, "c1f852009958_class_ContextCache": {"id": "c1f852009958_class_ContextCache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "class ContextCache:\n    \"\"\"Cache of context state.\"\"\"\n    recent_files: List[str] = field(default_factory=list)\n    hot_files: Dict[str, int] = field(default_factory=dict)  # path -> access count\n    last_query: str = \"\"\n    last_task: str = \"\"\n    timestamp: str = \"\"\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)", "chunk_type": "class", "line_start": 24, "line_end": 37, "language": "python", "name": "ContextCache"}, "c1f852009958_class_ContextResult": {"id": "c1f852009958_class_ContextResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\autocontext.py", "content": "class ContextResult:\n    \"\"\"Result of context loading.\"\"\"\n    files: List[Tuple[str, str]]  # (path, content summary)\n    token_count: int\n    source: str  # 'recent', 'semantic', 'dependency'", "chunk_type": "class", "line_start": 41, "line_end": 45, "language": "python", "name": "ContextResult"}, "c483e1ec81c8_file": {"id": "c483e1ec81c8_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "\"\"\"\nAuto-Docstring Generator\n========================\nAutomatically add missing docstrings to Python functions and classes.\n\nUsage:\n    python auto_docs.py [path] [--write]\n    python -m scripts.auto_docs [path] [--write]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    get_type_annotation,\n    Console\n)\n\n\n@dataclass\nclass DocstringSuggestion:\n    \"\"\"A suggested docstring for a function or class.\"\"\"\n    path: Path\n    name: str\n    lineno: int\n    node_type: str  # 'function', 'class', 'method'\n    docstring: str\n    indent: str\n\n\ndef generate_function_docstring(\n    node: ast.FunctionDef | ast.AsyncFunctionDef,\n    indent: str = \"    \"\n) -> str:\n    \"\"\"\n    Generate a Google-style docstring for a function.\n\n    Args:\n        node: AST function node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - brief description\n    if node.name.startswith('_'):\n        lines[0] += f\"Private {'async ' if isinstance(node, ast.AsyncFunctionDef) else ''}function {node.name}.\"\n    else:\n        # Try to generate a meaningful description from the name\n        name_parts = node.name.split('_')\n        if name_parts[0] in ('get', 'fetch', 'retrieve'):\n            desc = f\"Get {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('set', 'update'):\n            desc = f\"Set {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('is', 'has', 'can', 'should'):\n            desc = f\"Check if {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'create':\n            desc = f\"Create {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'delete':\n            desc = f\"Delete {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'process':\n            desc = f\"Process {' '.join(name_parts[1:])}.\"\n        elif name_parts[", "chunk_type": "file", "line_start": 1, "line_end": 451, "language": "python", "name": "auto_docs.py"}, "c483e1ec81c8_func_generate_function_docstring": {"id": "c483e1ec81c8_func_generate_function_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_function_docstring(\n    node: ast.FunctionDef | ast.AsyncFunctionDef,\n    indent: str = \"    \"\n) -> str:\n    \"\"\"\n    Generate a Google-style docstring for a function.\n\n    Args:\n        node: AST function node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - brief description\n    if node.name.startswith('_'):\n        lines[0] += f\"Private {'async ' if isinstance(node, ast.AsyncFunctionDef) else ''}function {node.name}.\"\n    else:\n        # Try to generate a meaningful description from the name\n        name_parts = node.name.split('_')\n        if name_parts[0] in ('get', 'fetch', 'retrieve'):\n            desc = f\"Get {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('set', 'update'):\n            desc = f\"Set {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('is', 'has', 'can', 'should'):\n            desc = f\"Check if {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] ", "chunk_type": "function", "line_start": 37, "line_end": 141, "language": "python", "name": "generate_function_docstring"}, "c483e1ec81c8_func__generate_param_description": {"id": "c483e1ec81c8_func__generate_param_description", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def _generate_param_description(name: str, type_hint: str) -> str:\n    \"\"\"Generate a description for a parameter based on its name.\"\"\"\n    # Common patterns\n    if name in ('path', 'filepath', 'file_path'):\n        return \"Path to the file.\"\n    elif name in ('root', 'root_dir', 'directory', 'dir'):\n        return \"Root directory.\"\n    elif name in ('data', 'content'):\n        return \"Input data.\"\n    elif name in ('name', 'filename'):\n        return \"The name.\"\n    elif name in ('key', 'id', 'identifier'):\n        return \"Unique identifier.\"\n    elif name in ('value', 'val'):\n        return \"The value.\"\n    elif name in ('config', 'settings', 'options'):\n        return \"Configuration options.\"\n    elif name in ('callback', 'func', 'function'):\n        return \"Callback function.\"\n    elif name in ('timeout', 'delay'):\n        return \"Timeout in seconds.\"\n    elif name in ('count', 'limit', 'max', 'min'):\n        return f\"The {name} value.\"\n    elif name.startswith('is_') or name.starts", "chunk_type": "function", "line_start": 144, "line_end": 174, "language": "python", "name": "_generate_param_description"}, "c483e1ec81c8_func_generate_class_docstring": {"id": "c483e1ec81c8_func_generate_class_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_class_docstring(node: ast.ClassDef, indent: str = \"    \") -> str:\n    \"\"\"\n    Generate a Google-style docstring for a class.\n\n    Args:\n        node: AST class node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - class description\n    name_parts = []\n    for i, char in enumerate(node.name):\n        if char.isupper() and i > 0:\n            name_parts.append(' ')\n        name_parts.append(char.lower())\n\n    desc = ''.join(name_parts).capitalize()\n    lines[0] += f\"{desc} class.\"\n\n    # Check for __init__ to get attributes\n    init_method = None\n    for item in node.body:\n        if isinstance(item, ast.FunctionDef) and item.name == '__init__':\n            init_method = item\n            break\n\n    # Extract attributes from __init__\n    if init_method:\n        attrs = []\n        for stmt in ast.walk(init_method):\n            if isinstance(stmt, ast.Assign):\n                for target in stmt.ta", "chunk_type": "function", "line_start": 177, "line_end": 226, "language": "python", "name": "generate_class_docstring"}, "c483e1ec81c8_func_analyze_file_for_docstrings": {"id": "c483e1ec81c8_func_analyze_file_for_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def analyze_file_for_docstrings(path: Path) -> List[DocstringSuggestion]:\n    \"\"\"\n    Analyze a file for missing docstrings.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        List of docstring suggestions\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return []\n\n    analyzer = DocstringAnalyzer(path, source_lines)\n    analyzer.visit(tree)\n\n    return analyzer.suggestions", "chunk_type": "function", "line_start": 307, "line_end": 330, "language": "python", "name": "analyze_file_for_docstrings"}, "c483e1ec81c8_func_add_docstrings_to_file": {"id": "c483e1ec81c8_func_add_docstrings_to_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def add_docstrings_to_file(path: Path, suggestions: List[DocstringSuggestion]) -> str:\n    \"\"\"\n    Add docstrings to a file.\n\n    Args:\n        path: Path to Python file\n        suggestions: List of docstring suggestions for this file\n\n    Returns:\n        Modified source code\n    \"\"\"\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n\n    # Sort suggestions by line number in reverse order\n    # so we can insert from bottom to top without affecting line numbers\n    sorted_suggestions = sorted(suggestions, key=lambda s: s.lineno, reverse=True)\n\n    for suggestion in sorted_suggestions:\n        # Find the line with the function/class definition\n        def_line = suggestion.lineno - 1  # Convert to 0-indexed\n\n        # Find where to insert (after the definition line and any decorators)\n        insert_line = def_line + 1\n\n        # Skip past the colon and any existing pass/... statements\n        while insert_line < len(lines):\n            line = lines[insert_li", "chunk_type": "function", "line_start": 333, "line_end": 370, "language": "python", "name": "add_docstrings_to_file"}, "c483e1ec81c8_func_generate_docstrings": {"id": "c483e1ec81c8_func_generate_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_docstrings(\n    root: Path,\n    write: bool = False,\n    exclude_patterns: List[str] = None\n) -> Tuple[int, int]:\n    \"\"\"\n    Generate docstrings for all Python files in a directory.\n\n    Args:\n        root: Root directory\n        write: Whether to write changes to files\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        Tuple of (files_with_missing, total_missing)\n    \"\"\"\n    all_suggestions: List[DocstringSuggestion] = []\n    files_with_missing = 0\n\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        suggestions = analyze_file_for_docstrings(path)\n        if suggestions:\n            files_with_missing += 1\n            all_suggestions.extend(suggestions)\n\n            if write:\n                # Group suggestions by file\n                modified = add_docstrings_to_file(path, suggestions)\n                ", "chunk_type": "function", "line_start": 373, "line_end": 410, "language": "python", "name": "generate_docstrings"}, "c483e1ec81c8_func_main": {"id": "c483e1ec81c8_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Docstring Generator\")\n\n    # Parse args\n    write = '--write' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Write mode: {'ON' if write else 'OFF (use --write to apply changes)'}\")\n\n    files_with_missing, total_missing = generate_docstrings(path, write=write)\n\n    print()\n    if total_missing > 0:\n        Console.warn(f\"Found {total_missing} missing docstrings in {files_with_missing} files\")\n        if write:\n            Console.ok(\"Docstrings have been added\")\n        else:\n            Console.info(\"Run with --write to add docstrings\")\n    else:\n        Console.ok(\"All functions and classes have docstrings\")\n\n    return 0 if tot", "chunk_type": "function", "line_start": 413, "line_end": 446, "language": "python", "name": "main"}, "c483e1ec81c8_func___init__": {"id": "c483e1ec81c8_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.suggestions: List[DocstringSuggestion] = []\n        self._class_stack: List[str] = []", "chunk_type": "function", "line_start": 232, "line_end": 236, "language": "python", "name": "__init__"}, "c483e1ec81c8_func__get_indent": {"id": "c483e1ec81c8_func__get_indent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def _get_indent(self, lineno: int) -> str:\n        \"\"\"Get the indentation of a line.\"\"\"\n        if lineno <= 0 or lineno > len(self.source_lines):\n            return \"    \"\n        line = self.source_lines[lineno - 1]\n        return line[:len(line) - len(line.lstrip())]", "chunk_type": "function", "line_start": 238, "line_end": 243, "language": "python", "name": "_get_indent"}, "c483e1ec81c8_func_visit_FunctionDef": {"id": "c483e1ec81c8_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 245, "line_end": 247, "language": "python", "name": "visit_FunctionDef"}, "c483e1ec81c8_func_visit_AsyncFunctionDef": {"id": "c483e1ec81c8_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 249, "line_end": 251, "language": "python", "name": "visit_AsyncFunctionDef"}, "c483e1ec81c8_func__check_function": {"id": "c483e1ec81c8_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def _check_function(self, node: ast.FunctionDef | ast.AsyncFunctionDef):\n        \"\"\"Check if a function needs a docstring.\"\"\"\n        # Skip private and dunder methods\n        if node.name.startswith('__') and node.name.endswith('__'):\n            return\n\n        # Check if docstring exists\n        if ast.get_docstring(node):\n            return\n\n        # Get indentation for the docstring\n        body_indent = self._get_indent(node.lineno) + \"    \"\n\n        # Generate docstring\n        docstring = generate_function_docstring(node, body_indent)\n\n        node_type = 'method' if self._class_stack else 'function'\n\n        self.suggestions.append(DocstringSuggestion(\n            path=self.path,\n            name=node.name,\n            lineno=node.lineno,\n            node_type=node_type,\n            docstring=docstring,\n            indent=body_indent\n        ))", "chunk_type": "function", "line_start": 253, "line_end": 278, "language": "python", "name": "_check_function"}, "c483e1ec81c8_func_visit_ClassDef": {"id": "c483e1ec81c8_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        \"\"\"Check if a class needs a docstring.\"\"\"\n        # Skip private classes\n        if node.name.startswith('_'):\n            self.generic_visit(node)\n            return\n\n        # Check if docstring exists\n        if not ast.get_docstring(node):\n            body_indent = self._get_indent(node.lineno) + \"    \"\n            docstring = generate_class_docstring(node, body_indent)\n\n            self.suggestions.append(DocstringSuggestion(\n                path=self.path,\n                name=node.name,\n                lineno=node.lineno,\n                node_type='class',\n                docstring=docstring,\n                indent=body_indent\n            ))\n\n        # Visit methods\n        self._class_stack.append(node.name)\n        self.generic_visit(node)\n        self._class_stack.pop()", "chunk_type": "function", "line_start": 280, "line_end": 304, "language": "python", "name": "visit_ClassDef"}, "c483e1ec81c8_class_DocstringSuggestion": {"id": "c483e1ec81c8_class_DocstringSuggestion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "class DocstringSuggestion:\n    \"\"\"A suggested docstring for a function or class.\"\"\"\n    path: Path\n    name: str\n    lineno: int\n    node_type: str  # 'function', 'class', 'method'\n    docstring: str\n    indent: str", "chunk_type": "class", "line_start": 27, "line_end": 34, "language": "python", "name": "DocstringSuggestion"}, "c483e1ec81c8_class_DocstringAnalyzer": {"id": "c483e1ec81c8_class_DocstringAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_docs.py", "content": "class DocstringAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze a module for missing docstrings.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.suggestions: List[DocstringSuggestion] = []\n        self._class_stack: List[str] = []\n\n    def _get_indent(self, lineno: int) -> str:\n        \"\"\"Get the indentation of a line.\"\"\"\n        if lineno <= 0 or lineno > len(self.source_lines):\n            return \"    \"\n        line = self.source_lines[lineno - 1]\n        return line[:len(line) - len(line.lstrip())]\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node: ast.FunctionDef | ast.AsyncFunctionDef):\n        \"\"\"Check if a function needs a docstring.\"\"\"\n        # Ski", "chunk_type": "class", "line_start": 229, "line_end": 304, "language": "python", "name": "DocstringAnalyzer"}, "b34c0107c425_file": {"id": "b34c0107c425_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "\"\"\"\nAuto-Learning Integration\n=========================\nAutomatic recording of tool outcomes for continuous improvement.\n\nUsage:\n    Import and wrap tool functions for auto-learning.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any, Callable, Optional\nimport functools\nimport sys\nimport traceback\n\n# Import learning system\ntry:\n    from .learning import get_store, record_feedback, record_error as _record_error\nexcept ImportError:\n    # Fallback if not running as module\n    def record_feedback(*args, **kwargs): pass\n    def _record_error(*args, **kwargs): pass\n\n\ndef auto_learn(tool_name: str):\n    \"\"\"Decorator to auto-record tool outcomes.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper\n    return decorator\n\n\ndef record_error(\n    error_type: str,\n    pattern: str,\n    fix: str = \"\",\n    context: str = \"\"\n):\n    \"\"\"Record an error for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_error(error_type, pattern, fix, context)\n    except Exception:\n        pass  # Silent fail for learning\n\n\ndef record_correction(before: str, after: str, context: str = \"\"):\n    \"\"\"Record a user correction for learning.\"\"\"\n    try:\n        from .learning import get_sto", "chunk_type": "file", "line_start": 1, "line_end": 138, "language": "python", "name": "auto_learn.py"}, "b34c0107c425_func_auto_learn": {"id": "b34c0107c425_func_auto_learn", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def auto_learn(tool_name: str):\n    \"\"\"Decorator to auto-record tool outcomes.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper\n    return decorator", "chunk_type": "function", "line_start": 25, "line_end": 51, "language": "python", "name": "auto_learn"}, "b34c0107c425_func_record_error": {"id": "b34c0107c425_func_record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def record_error(\n    error_type: str,\n    pattern: str,\n    fix: str = \"\",\n    context: str = \"\"\n):\n    \"\"\"Record an error for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_error(error_type, pattern, fix, context)\n    except Exception:\n        pass  # Silent fail for learning", "chunk_type": "function", "line_start": 54, "line_end": 66, "language": "python", "name": "record_error"}, "b34c0107c425_func_record_correction": {"id": "b34c0107c425_func_record_correction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def record_correction(before: str, after: str, context: str = \"\"):\n    \"\"\"Record a user correction for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_feedback(\n            action='correction',\n            outcome='applied',\n            context=f\"Before: {before[:50]}... After: {after[:50]}...\",\n            details={'before': before, 'after': after}\n        )\n    except Exception:\n        pass", "chunk_type": "function", "line_start": 69, "line_end": 81, "language": "python", "name": "record_correction"}, "b34c0107c425_func_suggest_from_history": {"id": "b34c0107c425_func_suggest_from_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def suggest_from_history(error_type: str, pattern: str) -> Optional[str]:\n    \"\"\"Get fix suggestion from learning history.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        return store.suggest_fix(error_type, pattern)\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 84, "line_end": 91, "language": "python", "name": "suggest_from_history"}, "b34c0107c425_func_get_success_rate": {"id": "b34c0107c425_func_get_success_rate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def get_success_rate(tool_name: str) -> float:\n    \"\"\"Get success rate for a tool.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        return store.get_action_success_rate(tool_name)\n    except Exception:\n        return 0.5  # Unknown", "chunk_type": "function", "line_start": 94, "line_end": 101, "language": "python", "name": "get_success_rate"}, "b34c0107c425_func_main": {"id": "b34c0107c425_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    from .utils import Console\n    Console.header(\"Auto-Learning Status\")\n\n    try:\n        from .learning import get_store\n        store = get_store()\n\n        analysis = store.analyze_patterns()\n\n        print(f\"\\nTotal feedback: {analysis['total_feedback']}\")\n        print(f\"Error patterns: {analysis['total_errors']}\")\n\n        print(\"\\n## Tool Success Rates\")\n        for action, data in analysis.get('action_outcomes', {}).items():\n            rate = data['success_rate'] * 100\n            status = \"\u2713\" if rate > 80 else \"!\" if rate > 50 else \"\u2717\"\n            print(f\"  {status} {action}: {rate:.0f}% ({data['count']} uses)\")\n\n        print(\"\\n## Common Errors\")\n        for err in analysis.get('common_errors', [])[:5]:\n            print(f\"  - [{err['type']}] {err['pattern'][:40]}...\")\n            if err.get('fix'):\n                print(f\"    Fix: {err['fix'][:40]}...\")\n\n    except Exception as e:\n        print(f\"Error loading learning data: {e}\")\n\n", "chunk_type": "function", "line_start": 104, "line_end": 133, "language": "python", "name": "main"}, "b34c0107c425_func_decorator": {"id": "b34c0107c425_func_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper", "chunk_type": "function", "line_start": 27, "line_end": 50, "language": "python", "name": "decorator"}, "b34c0107c425_func_record_feedback": {"id": "b34c0107c425_func_record_feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def record_feedback(*args, **kwargs): pass", "chunk_type": "function", "line_start": 21, "line_end": 21, "language": "python", "name": "record_feedback"}, "b34c0107c425_func__record_error": {"id": "b34c0107c425_func__record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def _record_error(*args, **kwargs): pass", "chunk_type": "function", "line_start": 22, "line_end": 22, "language": "python", "name": "_record_error"}, "b34c0107c425_func_wrapper": {"id": "b34c0107c425_func_wrapper", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_learn.py", "content": "        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise", "chunk_type": "function", "line_start": 29, "line_end": 48, "language": "python", "name": "wrapper"}, "73b34fbb53fd_file": {"id": "73b34fbb53fd_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "\"\"\"\nAuto-Test Generator\n===================\nAutomatically generate pytest test stubs for Python functions and classes.\n\nUsage:\n    python auto_test.py [path] [--output-dir tests/]\n    python -m scripts.auto_test [path]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    FunctionInfo,\n    ClassInfo,\n    Console\n)\n\n\n@dataclass\nclass TestSuite:\n    \"\"\"Generated test suite for a module.\"\"\"\n    module_path: Path\n    module_name: str\n    test_imports: List[str] = field(default_factory=list)\n    test_functions: List[str] = field(default_factory=list)\n    test_classes: List[str] = field(default_factory=list)\n\n\ndef generate_test_function(func: FunctionInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test function for a given function.\n\n    Args:\n        func: Function information\n        module_name: Name of the module containing the function\n\n    Returns:\n        Test function source code\n    \"\"\"\n    lines = []\n\n    # Generate test function name\n    test_name = f\"test_{func.name}\"\n\n    # Add docstring\n    lines.append(f\"def {test_name}():\")\n    lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Generate basic test structure\n    if func.args:\n        # Generate sample arguments\n        lines.append(\"    # Arrange\")\n        for arg in func.args:\n            if arg in ('self', 'cls'):\n                continue\n\n            arg_type = func.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"    {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"    # Act\")\n\n        # Generate function call\n        call_args = [a for a in func.args if a not in ('self', 'cls')]\n        if call_args:\n            args_str = \", \".join(call_args)\n            lines.append(f\"    result = {module_name}.{func.name}({ar", "chunk_type": "file", "line_start": 1, "line_end": 439, "language": "python", "name": "auto_test.py"}, "73b34fbb53fd_func_generate_test_function": {"id": "73b34fbb53fd_func_generate_test_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_function(func: FunctionInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test function for a given function.\n\n    Args:\n        func: Function information\n        module_name: Name of the module containing the function\n\n    Returns:\n        Test function source code\n    \"\"\"\n    lines = []\n\n    # Generate test function name\n    test_name = f\"test_{func.name}\"\n\n    # Add docstring\n    lines.append(f\"def {test_name}():\")\n    lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Generate basic test structure\n    if func.args:\n        # Generate sample arguments\n        lines.append(\"    # Arrange\")\n        for arg in func.args:\n            if arg in ('self', 'cls'):\n                continue\n\n            arg_type = func.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"    {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"    # Act\")\n\n        # Generate function call\n     ", "chunk_type": "function", "line_start": 38, "line_end": 98, "language": "python", "name": "generate_test_function"}, "73b34fbb53fd_func_generate_edge_case_tests": {"id": "73b34fbb53fd_func_generate_edge_case_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_edge_case_tests(func: FunctionInfo, module_name: str) -> List[str]:\n    \"\"\"\n    Generate edge case tests for a function.\n\n    Args:\n        func: Function information\n        module_name: Module name\n\n    Returns:\n        List of edge case test functions\n    \"\"\"\n    tests = []\n\n    for arg in func.args:\n        if arg in ('self', 'cls'):\n            continue\n\n        arg_type = func.arg_types.get(arg, '')\n\n        # Test with None if Optional\n        if 'Optional' in arg_type or 'None' in arg_type:\n            test_lines = [\n                f\"def test_{func.name}_with_{arg}_none():\",\n                f'    \"\"\"Test {func.name} with None {arg}.\"\"\"',\n                f\"    # This should handle None gracefully\",\n                f\"    try:\",\n                f\"        result = {module_name}.{func.name}({arg}=None)\",\n                f\"        # Assert expected behavior with None\",\n                f\"    except (TypeError, ValueError) as e:\",\n                f\"        pass  # Expecte", "chunk_type": "function", "line_start": 101, "line_end": 148, "language": "python", "name": "generate_edge_case_tests"}, "73b34fbb53fd_func_generate_test_class": {"id": "73b34fbb53fd_func_generate_test_class", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_class(cls: ClassInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test class.\n\n    Args:\n        cls: Class information\n        module_name: Module name\n\n    Returns:\n        Test class source code\n    \"\"\"\n    lines = []\n\n    test_class_name = f\"Test{cls.name}\"\n\n    lines.append(f\"class {test_class_name}:\")\n    lines.append(f'    \"\"\"Tests for {cls.name} class.\"\"\"')\n    lines.append(\"\")\n\n    # Add fixture for class instance\n    lines.append(\"    @pytest.fixture\")\n    lines.append(\"    def instance(self):\")\n    lines.append(f'        \"\"\"Create a {cls.name} instance for testing.\"\"\"')\n    lines.append(f\"        return {module_name}.{cls.name}()  # TODO: Add constructor args\")\n    lines.append(\"\")\n\n    # Add test for instantiation\n    lines.append(\"    def test_instantiation(self):\")\n    lines.append(f'        \"\"\"Test {cls.name} can be instantiated.\"\"\"')\n    lines.append(f\"        obj = {module_name}.{cls.name}()  # TODO: Add constructor args\")\n    lines.append", "chunk_type": "function", "line_start": 151, "line_end": 193, "language": "python", "name": "generate_test_class"}, "73b34fbb53fd_func__generate_method_test": {"id": "73b34fbb53fd_func__generate_method_test", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _generate_method_test(method: FunctionInfo, class_name: str) -> List[str]:\n    \"\"\"Generate test for a class method.\"\"\"\n    lines = []\n\n    lines.append(f\"    def test_{method.name}(self, instance):\")\n    lines.append(f'        \"\"\"Test {class_name}.{method.name} method.\"\"\"')\n\n    # Generate method call\n    call_args = [a for a in method.args if a not in ('self', 'cls')]\n    if call_args:\n        lines.append(\"        # Arrange\")\n        for arg in call_args:\n            arg_type = method.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"        {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"        # Act\")\n        args_str = \", \".join(call_args)\n        lines.append(f\"        result = instance.{method.name}({args_str})\")\n    else:\n        lines.append(\"        # Act\")\n        lines.append(f\"        result = instance.{method.name}()\")\n\n    lines.append(\"\")\n    lines.append(\"        # Assert\")\n    li", "chunk_type": "function", "line_start": 196, "line_end": 225, "language": "python", "name": "_generate_method_test"}, "73b34fbb53fd_func__get_sample_value": {"id": "73b34fbb53fd_func__get_sample_value", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _get_sample_value(arg_name: str, arg_type: str) -> str:\n    \"\"\"Get a sample value for a parameter.\"\"\"\n    type_lower = arg_type.lower()\n\n    if 'str' in type_lower:\n        return f'\"test_{arg_name}\"'\n    elif 'int' in type_lower:\n        return \"42\"\n    elif 'float' in type_lower:\n        return \"3.14\"\n    elif 'bool' in type_lower:\n        return \"True\"\n    elif 'list' in type_lower:\n        return \"[]\"\n    elif 'dict' in type_lower:\n        return \"{}\"\n    elif 'path' in type_lower or 'path' in arg_name.lower():\n        return 'Path(\".\")'\n    elif 'none' in type_lower:\n        return \"None\"\n    else:\n        # Try to infer from name\n        if 'path' in arg_name.lower():\n            return 'Path(\".\")'\n        elif 'name' in arg_name.lower():\n            return '\"test_name\"'\n        elif 'id' in arg_name.lower():\n            return '\"test_id\"'\n        elif 'count' in arg_name.lower() or 'num' in arg_name.lower():\n            return \"10\"\n        elif 'flag' in arg_name.lower() or ", "chunk_type": "function", "line_start": 228, "line_end": 261, "language": "python", "name": "_get_sample_value"}, "73b34fbb53fd_func__generate_assertion": {"id": "73b34fbb53fd_func__generate_assertion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _generate_assertion(return_type: str) -> str:\n    \"\"\"Generate an assertion based on return type.\"\"\"\n    type_lower = return_type.lower()\n\n    if 'bool' in type_lower:\n        return \"assert isinstance(result, bool)\"\n    elif 'str' in type_lower:\n        return \"assert isinstance(result, str)\"\n    elif 'int' in type_lower:\n        return \"assert isinstance(result, int)\"\n    elif 'float' in type_lower:\n        return \"assert isinstance(result, (int, float))\"\n    elif 'list' in type_lower:\n        return \"assert isinstance(result, list)\"\n    elif 'dict' in type_lower:\n        return \"assert isinstance(result, dict)\"\n    elif 'none' in type_lower:\n        return \"assert result is None\"\n    elif 'optional' in type_lower:\n        return \"# Result may be None\"\n    else:\n        return \"assert result is not None  # TODO: Add specific assertion\"", "chunk_type": "function", "line_start": 264, "line_end": 285, "language": "python", "name": "_generate_assertion"}, "73b34fbb53fd_func_generate_test_file": {"id": "73b34fbb53fd_func_generate_test_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_file(module_path: Path, output_dir: Path = None) -> Optional[Path]:\n    \"\"\"\n    Generate a test file for a Python module.\n\n    Args:\n        module_path: Path to the module\n        output_dir: Output directory for test files\n\n    Returns:\n        Path to generated test file, or None if no tests generated\n    \"\"\"\n    module_info = analyze_module(module_path)\n    if module_info is None:\n        return None\n\n    # Skip if no public functions or classes\n    public_functions = [f for f in module_info.functions if not f.name.startswith('_')]\n    public_classes = [c for c in module_info.classes if not c.name.startswith('_')]\n\n    if not public_functions and not public_classes:\n        return None\n\n    # Generate module name\n    module_name = module_path.stem\n\n    # Build test file content\n    lines = [\n        '\"\"\"',\n        f'Tests for {module_name} module.',\n        '\"\"\"',\n        '',\n        'import pytest',\n        'from pathlib import Path',\n        '',\n        f'# Impo", "chunk_type": "function", "line_start": 288, "line_end": 363, "language": "python", "name": "generate_test_file"}, "73b34fbb53fd_func_generate_tests": {"id": "73b34fbb53fd_func_generate_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_tests(\n    root: Path,\n    output_dir: Path = None,\n    exclude_patterns: List[str] = None\n) -> int:\n    \"\"\"\n    Generate tests for all Python files in a directory.\n\n    Args:\n        root: Root directory\n        output_dir: Output directory for tests\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        Number of test files generated\n    \"\"\"\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    generated = 0\n\n    for path in files:\n        # Skip test files\n        if path.name.startswith('test_') or 'tests' in path.parts:\n            continue\n\n        test_path = generate_test_file(path, output_dir)\n        if test_path:\n            Console.ok(f\"Generated: {test_path}\")\n            generated += 1\n\n    return generated", "chunk_type": "function", "line_start": 366, "line_end": 399, "language": "python", "name": "generate_tests"}, "73b34fbb53fd_func_main": {"id": "73b34fbb53fd_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Test Generator\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_dir = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output-dir' and i + 1 < len(sys.argv):\n            output_dir = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    generated = generate_tests(path, output_dir)\n\n    print()\n    if generated > 0:\n        Console.ok(f\"Generated {generated} test files\")\n    else:\n        Console.info(\"No new test files generated (all modules already have tests or no public code found)\")\n\n    return 0", "chunk_type": "function", "line_start": 402, "line_end": 434, "language": "python", "name": "main"}, "73b34fbb53fd_class_TestSuite": {"id": "73b34fbb53fd_class_TestSuite", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\auto_test.py", "content": "class TestSuite:\n    \"\"\"Generated test suite for a module.\"\"\"\n    module_path: Path\n    module_name: str\n    test_imports: List[str] = field(default_factory=list)\n    test_functions: List[str] = field(default_factory=list)\n    test_classes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 29, "line_end": 35, "language": "python", "name": "TestSuite"}, "37496828d3aa_file": {"id": "37496828d3aa_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "\"\"\"\nChangelog Generator\n===================\nAuto-generate changelogs from git commits using conventional commit format.\n\nUsage:\n    python changelog.py [--since v1.0.0] [--output CHANGELOG.md]\n    python -m scripts.changelog\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport re\nimport sys\n\nfrom .utils import (\n    find_project_root,\n    get_git_log,\n    run_git_command,\n    GitCommit,\n    Console\n)\n\n\n@dataclass\nclass ChangelogEntry:\n    \"\"\"A single changelog entry.\"\"\"\n    commit_type: str\n    scope: Optional[str]\n    description: str\n    commit_hash: str\n    breaking: bool = False\n    issues: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ChangelogVersion:\n    \"\"\"A version section in the changelog.\"\"\"\n    version: str\n    date: str\n    entries: Dict[str, List[ChangelogEntry]] = field(default_factory=lambda: defaultdict(list))\n    breaking_changes: List[str] = field(default_factory=list)\n\n\n# Conventional commit types\nCOMMIT_TYPES = {\n    'feat': 'Features',\n    'fix': 'Bug Fixes',\n    'docs': 'Documentation',\n    'style': 'Styles',\n    'refactor': 'Code Refactoring',\n    'perf': 'Performance Improvements',\n    'test': 'Tests',\n    'build': 'Build System',\n    'ci': 'CI/CD',\n    'chore': 'Chores',\n    'revert': 'Reverts',\n}\n\n# Regex for parsing conventional commits\nCONVENTIONAL_COMMIT_PATTERN = re.compile(\n    r'^(?P<type>feat|fix|docs|style|refactor|perf|test|build|ci|chore|revert)'\n    r'(?:\\((?P<scope>[^)]+)\\))?'\n    r'(?P<breaking>!)?'\n    r':\\s*'\n    r'(?P<description>.+)$',\n    re.IGNORECASE\n)\n\n# Pattern for issue references\nISSUE_PATTERN = re.compile(r'#(\\d+)')\n\n\ndef parse_commit_message(message: str) -> Optional[ChangelogEntry]:\n    \"\"\"\n    Parse a conventional commit message.\n\n    Args:\n        message: Commit message\n\n    Returns:\n        ChangelogEntry or None if not conventional format\n    \"\"\"\n    match = CONVENTIONAL_COMMIT_PATTERN.mat", "chunk_type": "file", "line_start": 1, "line_end": 368, "language": "python", "name": "changelog.py"}, "37496828d3aa_func_parse_commit_message": {"id": "37496828d3aa_func_parse_commit_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "def parse_commit_message(message: str) -> Optional[ChangelogEntry]:\n    \"\"\"\n    Parse a conventional commit message.\n\n    Args:\n        message: Commit message\n\n    Returns:\n        ChangelogEntry or None if not conventional format\n    \"\"\"\n    match = CONVENTIONAL_COMMIT_PATTERN.match(message.strip())\n    if not match:\n        return None\n\n    groups = match.groupdict()\n\n    # Extract issue references\n    issues = ISSUE_PATTERN.findall(message)\n\n    return ChangelogEntry(\n        commit_type=groups['type'].lower(),\n        scope=groups['scope'],\n        description=groups['description'].strip(),\n        commit_hash=\"\",  # Will be set later\n        breaking=bool(groups['breaking']),\n        issues=issues\n    )", "chunk_type": "function", "line_start": 76, "line_end": 102, "language": "python", "name": "parse_commit_message"}, "37496828d3aa_func_get_git_tags": {"id": "37496828d3aa_func_get_git_tags", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "def get_git_tags() -> List[Tuple[str, str]]:\n    \"\"\"Get all git tags with their dates.\"\"\"\n    output = run_git_command(['tag', '-l', '--format=%(refname:short)|%(creatordate:short)'])\n    if not output:\n        return []\n\n    tags = []\n    for line in output.split('\\n'):\n        if '|' in line:\n            tag, date = line.split('|', 1)\n            tags.append((tag.strip(), date.strip()))\n\n    return tags", "chunk_type": "function", "line_start": 105, "line_end": 117, "language": "python", "name": "get_git_tags"}, "37496828d3aa_func_get_commits_since_tag": {"id": "37496828d3aa_func_get_commits_since_tag", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "def get_commits_since_tag(tag: str = None, cwd: Path = None) -> List[GitCommit]:\n    \"\"\"Get commits since a specific tag.\"\"\"\n    if tag:\n        args = ['log', f'{tag}..HEAD', '--format=%H|%h|%an|%ai|%s|%b', '--no-merges']\n    else:\n        args = ['log', '--format=%H|%h|%an|%ai|%s|%b', '--no-merges', '-100']\n\n    output = run_git_command(args, cwd=cwd)\n    if not output:\n        return []\n\n    commits = []\n    for entry in output.split('\\n'):\n        if not entry.strip():\n            continue\n\n        parts = entry.split('|')\n        if len(parts) >= 5:\n            commits.append(GitCommit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                date=parts[3],\n                message=parts[4],\n                body=parts[5] if len(parts) > 5 else \"\"\n            ))\n\n    return commits", "chunk_type": "function", "line_start": 120, "line_end": 147, "language": "python", "name": "get_commits_since_tag"}, "37496828d3aa_func_generate_changelog": {"id": "37496828d3aa_func_generate_changelog", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "def generate_changelog(\n    cwd: Path = None,\n    since_tag: str = None,\n    version: str = \"Unreleased\"\n) -> ChangelogVersion:\n    \"\"\"\n    Generate changelog from git commits.\n\n    Args:\n        cwd: Working directory\n        since_tag: Tag to start from\n        version: Version number for this release\n\n    Returns:\n        ChangelogVersion object\n    \"\"\"\n    commits = get_commits_since_tag(since_tag, cwd)\n\n    import datetime\n    changelog = ChangelogVersion(\n        version=version,\n        date=datetime.datetime.now().strftime('%Y-%m-%d')\n    )\n\n    for commit in commits:\n        entry = parse_commit_message(commit.message)\n        if entry:\n            entry.commit_hash = commit.short_hash\n\n            # Add to appropriate category\n            changelog.entries[entry.commit_type].append(entry)\n\n            # Track breaking changes\n            if entry.breaking or 'BREAKING CHANGE' in commit.body:\n                changelog.breaking_changes.append(\n                    f\"{entry.descr", "chunk_type": "function", "line_start": 150, "line_end": 197, "language": "python", "name": "generate_changelog"}, "37496828d3aa_func_format_changelog_markdown": {"id": "37496828d3aa_func_format_changelog_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "def format_changelog_markdown(\n    changelog: ChangelogVersion,\n    include_hash: bool = True,\n    repo_url: str = None\n) -> str:\n    \"\"\"\n    Format changelog as Markdown.\n\n    Args:\n        changelog: ChangelogVersion object\n        include_hash: Whether to include commit hashes\n        repo_url: Repository URL for linking\n\n    Returns:\n        Markdown formatted changelog\n    \"\"\"\n    lines = [\n        f\"## [{changelog.version}] - {changelog.date}\",\n        \"\",\n    ]\n\n    # Breaking changes first\n    if changelog.breaking_changes:\n        lines.extend([\n            \"### BREAKING CHANGES\",\n            \"\",\n        ])\n        for change in changelog.breaking_changes:\n            lines.append(f\"- {change}\")\n        lines.append(\"\")\n\n    # Categorized changes\n    category_order = ['feat', 'fix', 'perf', 'refactor', 'docs', 'test', 'build', 'ci', 'chore', 'other']\n\n    for category in category_order:\n        entries = changelog.entries.get(category, [])\n        if not entries:\n            c", "chunk_type": "function", "line_start": 200, "line_end": 273, "language": "python", "name": "format_changelog_markdown"}, "37496828d3aa_func_update_changelog_file": {"id": "37496828d3aa_func_update_changelog_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "def update_changelog_file(\n    changelog_path: Path,\n    new_content: str,\n    prepend: bool = True\n) -> None:\n    \"\"\"\n    Update a changelog file with new content.\n\n    Args:\n        changelog_path: Path to CHANGELOG.md\n        new_content: New content to add\n        prepend: Whether to prepend (True) or append\n    \"\"\"\n    header = \"# Changelog\\n\\nAll notable changes to this project will be documented in this file.\\n\\n\"\n\n    if changelog_path.exists():\n        with open(changelog_path, 'r', encoding='utf-8') as f:\n            existing = f.read()\n\n        # Remove header if present\n        if existing.startswith(\"# Changelog\"):\n            lines = existing.split('\\n')\n            # Find first version heading\n            for i, line in enumerate(lines):\n                if line.startswith('## '):\n                    existing = '\\n'.join(lines[i:])\n                    break\n\n        if prepend:\n            content = header + new_content + \"\\n\" + existing\n        else:\n            content ", "chunk_type": "function", "line_start": 276, "line_end": 312, "language": "python", "name": "update_changelog_file"}, "37496828d3aa_func_main": {"id": "37496828d3aa_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Changelog Generator\")\n\n    # Parse args\n    since_tag = None\n    output_file = None\n    version = \"Unreleased\"\n\n    args = sys.argv[1:]\n    i = 0\n    while i < len(args):\n        if args[i] == '--since' and i + 1 < len(args):\n            since_tag = args[i + 1]\n            i += 2\n        elif args[i] == '--output' and i + 1 < len(args):\n            output_file = Path(args[i + 1])\n            i += 2\n        elif args[i] == '--version' and i + 1 < len(args):\n            version = args[i + 1]\n            i += 2\n        else:\n            i += 1\n\n    # Find project root\n    cwd = find_project_root() or Path.cwd()\n\n    Console.info(f\"Analyzing: {cwd}\")\n    if since_tag:\n        Console.info(f\"Since tag: {since_tag}\")\n\n    # Generate changelog\n    changelog = generate_changelog(cwd, since_tag, version)\n\n    # Count entries\n    total_entries = sum(len(entries) for entries in changelog.entries.values())\n    Console.info(f\"Found {total_e", "chunk_type": "function", "line_start": 315, "line_end": 363, "language": "python", "name": "main"}, "37496828d3aa_class_ChangelogEntry": {"id": "37496828d3aa_class_ChangelogEntry", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "class ChangelogEntry:\n    \"\"\"A single changelog entry.\"\"\"\n    commit_type: str\n    scope: Optional[str]\n    description: str\n    commit_hash: str\n    breaking: bool = False\n    issues: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 28, "line_end": 35, "language": "python", "name": "ChangelogEntry"}, "37496828d3aa_class_ChangelogVersion": {"id": "37496828d3aa_class_ChangelogVersion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\changelog.py", "content": "class ChangelogVersion:\n    \"\"\"A version section in the changelog.\"\"\"\n    version: str\n    date: str\n    entries: Dict[str, List[ChangelogEntry]] = field(default_factory=lambda: defaultdict(list))\n    breaking_changes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 39, "line_end": 44, "language": "python", "name": "ChangelogVersion"}, "f4bf67bc1ffa_file": {"id": "f4bf67bc1ffa_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cicd.py", "content": "\"\"\"\nCI/CD Pipeline Generator\n========================\nGenerate CI/CD pipelines for various providers.\n\nUsage:\n    python mcp.py github-action\n    python mcp.py pipeline --gitlab\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ProjectType:\n    \"\"\"Detected project type.\"\"\"\n    language: str\n    framework: Optional[str]\n    package_manager: str\n    test_command: str\n    lint_command: str\n    has_docker: bool\n\n\n# GitHub Actions Templates\nGITHUB_PYTHON = '''name: Python CI\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: ['3.11']\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install pytest pytest-cov flake8 mypy\n\n    - name: Lint with flake8\n      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n\n    - name: Type check with mypy\n      run: mypy . --ignore-missing-imports || true\n\n    - name: Test with pytest\n      run: pytest --cov=. --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        files: ./coverage.xml\n'''\n\nGITHUB_NODE = '''name: Node.js CI\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: ['18.x', '20.x']\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ matrix.node-version }}\n ", "chunk_type": "file", "line_start": 1, "line_end": 369, "language": "python", "name": "cicd.py"}, "f4bf67bc1ffa_func_detect_project_type": {"id": "f4bf67bc1ffa_func_detect_project_type", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cicd.py", "content": "def detect_project_type(root: Path) -> ProjectType:\n    \"\"\"Detect project type from files.\"\"\"\n    # Check for Python\n    has_requirements = (root / 'requirements.txt').exists()\n    has_setup_py = (root / 'setup.py').exists()\n    has_pyproject = (root / 'pyproject.toml').exists()\n\n    # Check for Node\n    has_package_json = (root / 'package.json').exists()\n\n    # Check for Docker\n    has_docker = (root / 'Dockerfile').exists()\n\n    if has_requirements or has_setup_py or has_pyproject:\n        framework = None\n        if has_pyproject:\n            content = (root / 'pyproject.toml').read_text()\n            if 'fastapi' in content.lower():\n                framework = 'fastapi'\n            elif 'django' in content.lower():\n                framework = 'django'\n            elif 'flask' in content.lower():\n                framework = 'flask'\n\n        return ProjectType(\n            language='python',\n            framework=framework,\n            package_manager='pip',\n            test_command=", "chunk_type": "function", "line_start": 220, "line_end": 284, "language": "python", "name": "detect_project_type"}, "f4bf67bc1ffa_func_generate_github_action": {"id": "f4bf67bc1ffa_func_generate_github_action", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cicd.py", "content": "def generate_github_action(project_type: ProjectType) -> str:\n    \"\"\"Generate GitHub Actions workflow.\"\"\"\n    if project_type.has_docker:\n        return GITHUB_DOCKER\n\n    if project_type.language == 'python':\n        return GITHUB_PYTHON\n\n    if project_type.language == 'node':\n        return GITHUB_NODE\n\n    return GITHUB_PYTHON  # Default", "chunk_type": "function", "line_start": 287, "line_end": 298, "language": "python", "name": "generate_github_action"}, "f4bf67bc1ffa_func_generate_gitlab_ci": {"id": "f4bf67bc1ffa_func_generate_gitlab_ci", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cicd.py", "content": "def generate_gitlab_ci(project_type: ProjectType) -> str:\n    \"\"\"Generate GitLab CI config.\"\"\"\n    if project_type.language == 'python':\n        return GITLAB_PYTHON\n\n    if project_type.language == 'node':\n        return GITLAB_NODE\n\n    return GITLAB_PYTHON  # Default", "chunk_type": "function", "line_start": 301, "line_end": 309, "language": "python", "name": "generate_gitlab_ci"}, "f4bf67bc1ffa_func_write_github_action": {"id": "f4bf67bc1ffa_func_write_github_action", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cicd.py", "content": "def write_github_action(root: Path) -> Path:\n    \"\"\"Write GitHub Actions workflow to file.\"\"\"\n    project_type = detect_project_type(root)\n    content = generate_github_action(project_type)\n\n    workflow_dir = root / '.github' / 'workflows'\n    workflow_dir.mkdir(parents=True, exist_ok=True)\n\n    workflow_file = workflow_dir / 'ci.yml'\n    workflow_file.write_text(content)\n\n    return workflow_file", "chunk_type": "function", "line_start": 312, "line_end": 323, "language": "python", "name": "write_github_action"}, "f4bf67bc1ffa_func_write_gitlab_ci": {"id": "f4bf67bc1ffa_func_write_gitlab_ci", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cicd.py", "content": "def write_gitlab_ci(root: Path) -> Path:\n    \"\"\"Write GitLab CI config to file.\"\"\"\n    project_type = detect_project_type(root)\n    content = generate_gitlab_ci(project_type)\n\n    ci_file = root / '.gitlab-ci.yml'\n    ci_file.write_text(content)\n\n    return ci_file", "chunk_type": "function", "line_start": 326, "line_end": 334, "language": "python", "name": "write_gitlab_ci"}, "f4bf67bc1ffa_func_main": {"id": "f4bf67bc1ffa_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cicd.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"CI/CD Generator\")\n\n    root = find_project_root() or Path.cwd()\n    project_type = detect_project_type(root)\n\n    Console.info(f\"Detected: {project_type.language}\")\n    if project_type.framework:\n        Console.info(f\"Framework: {project_type.framework}\")\n    if project_type.has_docker:\n        Console.info(\"Docker: Yes\")\n\n    if '--gitlab' in sys.argv:\n        path = write_gitlab_ci(root)\n        Console.ok(f\"Generated: {path}\")\n        return 0\n\n    if '--print' in sys.argv:\n        content = generate_github_action(project_type)\n        print(content)\n        return 0\n\n    # Default: GitHub Actions\n    path = write_github_action(root)\n    Console.ok(f\"Generated: {path}\")\n\n    return 0", "chunk_type": "function", "line_start": 337, "line_end": 364, "language": "python", "name": "main"}, "f4bf67bc1ffa_class_ProjectType": {"id": "f4bf67bc1ffa_class_ProjectType", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cicd.py", "content": "class ProjectType:\n    \"\"\"Detected project type.\"\"\"\n    language: str\n    framework: Optional[str]\n    package_manager: str\n    test_command: str\n    lint_command: str\n    has_docker: bool", "chunk_type": "class", "line_start": 21, "line_end": 28, "language": "python", "name": "ProjectType"}, "d89f63d2b3c1_file": {"id": "d89f63d2b3c1_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "\"\"\"\nConfig Index\n=============\nIndex configuration files, env vars, and settings.\n\nUsage:\n    python mcp.py config-index\n    python mcp.py config-index --env\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport json\nimport os\nimport re\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ConfigItem:\n    \"\"\"A configuration item.\"\"\"\n    name: str\n    value: Optional[str]\n    source: str  # file path\n    type: str  # 'env', 'json', 'yaml', 'ini', 'toml'\n    line: int = 0\n\n\n# Patterns for finding env var usage in code\nENV_PATTERNS = [\n    r'os\\.environ\\[[\\'\"]([\\w_]+)[\\'\"]\\]',\n    r'os\\.environ\\.get\\([\\'\"]([\\w_]+)[\\'\"]',\n    r'os\\.getenv\\([\\'\"]([\\w_]+)[\\'\"]',\n    r'config\\[[\\'\"]([\\w_]+)[\\'\"]\\]',\n    r'settings\\.([\\w_]+)',\n    r'process\\.env\\.([\\w_]+)',\n    r'\\$\\{([\\w_]+)\\}',\n]\n\n\ndef find_config_files(root: Path) -> List[Path]:\n    \"\"\"Find configuration files.\"\"\"\n    patterns = [\n        '.env', '.env.*', 'config.json', 'config.yaml', 'config.yml',\n        'settings.json', 'settings.yaml', 'settings.yml', 'settings.py',\n        'pyproject.toml', 'setup.cfg', 'requirements.txt',\n        'package.json', 'tsconfig.json',\n        '*.ini', '*.toml', '*.conf'\n    ]\n\n    files = []\n\n    for pattern in patterns:\n        for path in root.glob(pattern):\n            if path.is_file() and '.git' not in str(path):\n                files.append(path)\n        for path in root.glob(f'**/{pattern}'):\n            if path.is_file() and '.git' not in str(path) and 'node_modules' not in str(path):\n                files.append(path)\n\n    return list(set(files))\n\n\ndef parse_env_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse .env file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    if '=' in line:\n        ", "chunk_type": "file", "line_start": 1, "line_end": 247, "language": "python", "name": "config_index.py"}, "d89f63d2b3c1_func_find_config_files": {"id": "d89f63d2b3c1_func_find_config_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "def find_config_files(root: Path) -> List[Path]:\n    \"\"\"Find configuration files.\"\"\"\n    patterns = [\n        '.env', '.env.*', 'config.json', 'config.yaml', 'config.yml',\n        'settings.json', 'settings.yaml', 'settings.yml', 'settings.py',\n        'pyproject.toml', 'setup.cfg', 'requirements.txt',\n        'package.json', 'tsconfig.json',\n        '*.ini', '*.toml', '*.conf'\n    ]\n\n    files = []\n\n    for pattern in patterns:\n        for path in root.glob(pattern):\n            if path.is_file() and '.git' not in str(path):\n                files.append(path)\n        for path in root.glob(f'**/{pattern}'):\n            if path.is_file() and '.git' not in str(path) and 'node_modules' not in str(path):\n                files.append(path)\n\n    return list(set(files))", "chunk_type": "function", "line_start": 44, "line_end": 64, "language": "python", "name": "find_config_files"}, "d89f63d2b3c1_func_parse_env_file": {"id": "d89f63d2b3c1_func_parse_env_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "def parse_env_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse .env file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    if '=' in line:\n                        name, _, value = line.partition('=')\n                        items.append(ConfigItem(\n                            name=name.strip(),\n                            value=value.strip().strip('\"\\''),\n                            source=str(file_path),\n                            type='env',\n                            line=i\n                        ))\n    except Exception:\n        pass\n\n    return items", "chunk_type": "function", "line_start": 67, "line_end": 88, "language": "python", "name": "parse_env_file"}, "d89f63d2b3c1_func_parse_json_file": {"id": "d89f63d2b3c1_func_parse_json_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "def parse_json_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse JSON config file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n\n        def extract(obj, prefix=''):\n            for key, value in obj.items() if isinstance(obj, dict) else []:\n                full_key = f\"{prefix}.{key}\" if prefix else key\n                if isinstance(value, dict):\n                    extract(value, full_key)\n                else:\n                    items.append(ConfigItem(\n                        name=full_key,\n                        value=str(value)[:50] if value is not None else None,\n                        source=str(file_path),\n                        type='json'\n                    ))\n\n        extract(data)\n    except Exception:\n        pass\n\n    return items", "chunk_type": "function", "line_start": 91, "line_end": 116, "language": "python", "name": "parse_json_file"}, "d89f63d2b3c1_func_find_env_usage_in_file": {"id": "d89f63d2b3c1_func_find_env_usage_in_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "def find_env_usage_in_file(file_path: Path) -> Set[str]:\n    \"\"\"Find env var usage in a code file.\"\"\"\n    env_vars = set()\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n\n        for pattern in ENV_PATTERNS:\n            matches = re.findall(pattern, content)\n            env_vars.update(matches)\n    except Exception:\n        pass\n\n    return env_vars", "chunk_type": "function", "line_start": 119, "line_end": 133, "language": "python", "name": "find_env_usage_in_file"}, "d89f63d2b3c1_func_index_configs": {"id": "d89f63d2b3c1_func_index_configs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "def index_configs(root: Path = None) -> Dict:\n    \"\"\"Build configuration index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Indexing configuration...\")\n\n    index = {\n        \"config_files\": [],\n        \"env_vars\": {},\n        \"env_usage\": {},\n        \"missing_vars\": []\n    }\n\n    # Find and parse config files\n    config_files = find_config_files(root)\n\n    for config_path in config_files:\n        index[\"config_files\"].append(str(config_path.relative_to(root)))\n\n        if config_path.name.startswith('.env'):\n            items = parse_env_file(config_path)\n            for item in items:\n                index[\"env_vars\"][item.name] = {\n                    \"source\": item.source,\n                    \"has_value\": item.value is not None and item.value != ''\n                }\n        elif config_path.suffix == '.json':\n            items = parse_json_file(config_path)\n\n    # Find env var usage in code\n    all_used = set()\n    extensions = ['.py', '.js', '.ts']\n\n", "chunk_type": "function", "line_start": 136, "line_end": 196, "language": "python", "name": "index_configs"}, "d89f63d2b3c1_func_get_env_vars_for_file": {"id": "d89f63d2b3c1_func_get_env_vars_for_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "def get_env_vars_for_file(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Get env vars used by a specific file.\"\"\"\n    return list(find_env_usage_in_file(file_path))", "chunk_type": "function", "line_start": 199, "line_end": 201, "language": "python", "name": "get_env_vars_for_file"}, "d89f63d2b3c1_func_main": {"id": "d89f63d2b3c1_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Config Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_configs(root)\n        return 0\n\n    if '--env' in sys.argv:\n        index = index_configs(root)\n        print(\"\\n## Defined Environment Variables\")\n        for name, info in index[\"env_vars\"].items():\n            status = \"\u2713\" if info[\"has_value\"] else \"\u2717\"\n            print(f\"  {status} {name}\")\n        return 0\n\n    if '--missing' in sys.argv:\n        index = index_configs(root)\n        if index[\"missing_vars\"]:\n            Console.warn(\"Used but not defined:\")\n            for var in index[\"missing_vars\"]:\n                print(f\"  - {var}\")\n        else:\n            Console.ok(\"All used env vars are defined!\")\n        return 0\n\n    if args:\n        file_path = Path(args[0])\n        vars_used = get_env_vars_for_file(file_path)\n        Console.info(f\"Env vars used", "chunk_type": "function", "line_start": 204, "line_end": 242, "language": "python", "name": "main"}, "d89f63d2b3c1_func_extract": {"id": "d89f63d2b3c1_func_extract", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "        def extract(obj, prefix=''):\n            for key, value in obj.items() if isinstance(obj, dict) else []:\n                full_key = f\"{prefix}.{key}\" if prefix else key\n                if isinstance(value, dict):\n                    extract(value, full_key)\n                else:\n                    items.append(ConfigItem(\n                        name=full_key,\n                        value=str(value)[:50] if value is not None else None,\n                        source=str(file_path),\n                        type='json'\n                    ))", "chunk_type": "function", "line_start": 99, "line_end": 110, "language": "python", "name": "extract"}, "d89f63d2b3c1_class_ConfigItem": {"id": "d89f63d2b3c1_class_ConfigItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\config_index.py", "content": "class ConfigItem:\n    \"\"\"A configuration item.\"\"\"\n    name: str\n    value: Optional[str]\n    source: str  # file path\n    type: str  # 'env', 'json', 'yaml', 'ini', 'toml'\n    line: int = 0", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "ConfigItem"}, "3ed10554d3aa_file": {"id": "3ed10554d3aa_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "\"\"\"\nSmart Context Loader\n====================\nExtract relevant context from codebases for AI agents with token budgets.\n\nUsage:\n    python context.py \"query\" [path] [--tokens 4000]\n    python -m scripts.context \"authentication\" src/\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport math\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    get_changed_files,\n    run_git_command,\n    Console\n)\n\n\n@dataclass\nclass ContextItem:\n    \"\"\"A piece of context from the codebase.\"\"\"\n    path: Path\n    content: str\n    relevance_score: float\n    item_type: str  # 'function', 'class', 'file', 'docstring'\n    line_start: int\n    line_end: int\n    tokens: int  # Estimated token count\n\n\n@dataclass\nclass ContextResult:\n    \"\"\"Result of context extraction.\"\"\"\n    query: str\n    items: List[ContextItem] = field(default_factory=list)\n    total_tokens: int = 0\n    files_scanned: int = 0\n\n    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)\n\n\ndef estimate_tokens(text: str) -> int:\n    \"\"\"Estimate token count (rough: 4 chars per token).\"\"\"\n    return len(text) // 4\n\n\ndef tokenize_query(query: str) -> List[str]:\n    \"\"\"Tokenize query into searchable terms", "chunk_type": "file", "line_start": 1, "line_end": 382, "language": "python", "name": "context.py"}, "3ed10554d3aa_func_estimate_tokens": {"id": "3ed10554d3aa_func_estimate_tokens", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "def estimate_tokens(text: str) -> int:\n    \"\"\"Estimate token count (rough: 4 chars per token).\"\"\"\n    return len(text) // 4", "chunk_type": "function", "line_start": 76, "line_end": 78, "language": "python", "name": "estimate_tokens"}, "3ed10554d3aa_func_tokenize_query": {"id": "3ed10554d3aa_func_tokenize_query", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "def tokenize_query(query: str) -> List[str]:\n    \"\"\"Tokenize query into searchable terms.\"\"\"\n    # Convert to lowercase and split on non-alphanumeric\n    terms = re.findall(r'[a-z0-9]+', query.lower())\n\n    # Expand common abbreviations\n    expansions = {\n        'auth': ['authentication', 'authorize', 'authorization'],\n        'db': ['database', 'connection'],\n        'api': ['endpoint', 'route', 'handler'],\n        'cfg': ['config', 'configuration', 'settings'],\n        'msg': ['message', 'notification'],\n        'err': ['error', 'exception'],\n        'req': ['request', 'require'],\n        'res': ['response', 'result'],\n    }\n\n    expanded = list(terms)\n    for term in terms:\n        if term in expansions:\n            expanded.extend(expansions[term])\n\n    return expanded", "chunk_type": "function", "line_start": 81, "line_end": 103, "language": "python", "name": "tokenize_query"}, "3ed10554d3aa_func_calculate_tf_idf": {"id": "3ed10554d3aa_func_calculate_tf_idf", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "def calculate_tf_idf(\n    terms: List[str],\n    document: str,\n    all_documents: List[str]\n) -> float:\n    \"\"\"Calculate TF-IDF relevance score.\"\"\"\n    doc_lower = document.lower()\n\n    # Term frequency in this document\n    tf_scores = []\n    for term in terms:\n        tf = doc_lower.count(term)\n        if tf > 0:\n            tf_scores.append(1 + math.log(tf))\n        else:\n            tf_scores.append(0)\n\n    if not tf_scores or sum(tf_scores) == 0:\n        return 0.0\n\n    # Inverse document frequency\n    idf_scores = []\n    for term in terms:\n        docs_with_term = sum(1 for doc in all_documents if term in doc.lower())\n        if docs_with_term > 0:\n            idf = math.log(len(all_documents) / docs_with_term)\n            idf_scores.append(idf)\n        else:\n            idf_scores.append(0)\n\n    # Combined TF-IDF\n    score = sum(tf * idf for tf, idf in zip(tf_scores, idf_scores))\n    return score", "chunk_type": "function", "line_start": 106, "line_end": 138, "language": "python", "name": "calculate_tf_idf"}, "3ed10554d3aa_func_get_recent_files": {"id": "3ed10554d3aa_func_get_recent_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "def get_recent_files(root: Path, limit: int = 10) -> List[Path]:\n    \"\"\"Get recently modified files from git.\"\"\"\n    output = run_git_command(\n        ['log', '--name-only', '--format=', '-n', '50'],\n        cwd=root\n    )\n\n    if not output:\n        return []\n\n    recent = []\n    seen = set()\n    for line in output.split('\\n'):\n        line = line.strip()\n        if line and line.endswith('.py') and line not in seen:\n            path = root / line\n            if path.exists():\n                recent.append(path)\n                seen.add(line)\n            if len(recent) >= limit:\n                break\n\n    return recent", "chunk_type": "function", "line_start": 141, "line_end": 163, "language": "python", "name": "get_recent_files"}, "3ed10554d3aa_func_extract_function_context": {"id": "3ed10554d3aa_func_extract_function_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "def extract_function_context(\n    path: Path,\n    tree: ast.Module,\n    source_lines: List[str]\n) -> List[Tuple[str, int, int, str]]:\n    \"\"\"Extract function definitions with context.\"\"\"\n    results = []\n\n    for node in ast.walk(tree):\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Get function signature and docstring\n            start = node.lineno - 1\n            end = node.end_lineno if node.end_lineno else start + 1\n\n            # Include signature + docstring + first few lines\n            content_lines = source_lines[start:min(end, start + 20)]\n            content = '\\n'.join(content_lines)\n\n            results.append((node.name, start + 1, end, content))\n\n    return results", "chunk_type": "function", "line_start": 166, "line_end": 186, "language": "python", "name": "extract_function_context"}, "3ed10554d3aa_func_extract_class_context": {"id": "3ed10554d3aa_func_extract_class_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "def extract_class_context(\n    path: Path,\n    tree: ast.Module,\n    source_lines: List[str]\n) -> List[Tuple[str, int, int, str]]:\n    \"\"\"Extract class definitions with context.\"\"\"\n    results = []\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.ClassDef):\n            start = node.lineno - 1\n            end = node.end_lineno if node.end_lineno else start + 1\n\n            # Include class definition + docstring + method signatures\n            content_lines = source_lines[start:min(end, start + 30)]\n            content = '\\n'.join(content_lines)\n\n            results.append((node.name, start + 1, end, content))\n\n    return results", "chunk_type": "function", "line_start": 189, "line_end": 208, "language": "python", "name": "extract_class_context"}, "3ed10554d3aa_func_load_context": {"id": "3ed10554d3aa_func_load_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "def load_context(\n    query: str,\n    root: Path,\n    token_budget: int = 4000,\n    exclude_patterns: List[str] = None\n) -> ContextResult:\n    \"\"\"\n    Load relevant context for a query.\n\n    Args:\n        query: Search query\n        root: Root directory\n        token_budget: Maximum tokens to return\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        ContextResult with relevant items\n    \"\"\"\n    result = ContextResult(query=query)\n\n    Console.info(f\"Searching for context: '{query}'\")\n\n    # Tokenize query\n    terms = tokenize_query(query)\n    Console.info(f\"Search terms: {', '.join(terms)}\")\n\n    # Get all Python files\n    files = list(find_python_files(root, exclude_patterns))\n    result.files_scanned = len(files)\n\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    # Get recent files for priority boost\n    recent_files = set(get_recent_files(root))\n\n    # Load all file contents for IDF calculation\n    all_contents = []\n    file_data = []\n\n    for path in files:\n", "chunk_type": "function", "line_start": 211, "line_end": 333, "language": "python", "name": "load_context"}, "3ed10554d3aa_func_main": {"id": "3ed10554d3aa_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Smart Context Loader\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    token_budget = 4000\n    for i, arg in enumerate(sys.argv):\n        if arg == '--tokens' and i + 1 < len(sys.argv):\n            try:\n                token_budget = int(sys.argv[i + 1])\n            except ValueError:\n                pass\n\n    if not args:\n        Console.fail(\"Usage: mcp context <query> [path] [--tokens N]\")\n        print(\"\\nExamples:\")\n        print('  mcp context \"authentication\"')\n        print('  mcp context \"database connection\" src/')\n        print('  mcp context \"api handler\" --tokens 8000')\n        return 1\n\n    query = args[0]\n\n    if len(args) > 1:\n        path = Path(args[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Root: {path}\")\n    Console.info(f\"Token budget: {toke", "chunk_type": "function", "line_start": 336, "line_end": 377, "language": "python", "name": "main"}, "3ed10554d3aa_func_to_markdown": {"id": "3ed10554d3aa_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 51, "line_end": 73, "language": "python", "name": "to_markdown"}, "3ed10554d3aa_class_ContextItem": {"id": "3ed10554d3aa_class_ContextItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "class ContextItem:\n    \"\"\"A piece of context from the codebase.\"\"\"\n    path: Path\n    content: str\n    relevance_score: float\n    item_type: str  # 'function', 'class', 'file', 'docstring'\n    line_start: int\n    line_end: int\n    tokens: int  # Estimated token count", "chunk_type": "class", "line_start": 32, "line_end": 40, "language": "python", "name": "ContextItem"}, "3ed10554d3aa_class_ContextResult": {"id": "3ed10554d3aa_class_ContextResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\context.py", "content": "class ContextResult:\n    \"\"\"Result of context extraction.\"\"\"\n    query: str\n    items: List[ContextItem] = field(default_factory=list)\n    total_tokens: int = 0\n    files_scanned: int = 0\n\n    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)", "chunk_type": "class", "line_start": 44, "line_end": 73, "language": "python", "name": "ContextResult"}, "8b5d9fa3433f_file": {"id": "8b5d9fa3433f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\coverage_index.py", "content": "\"\"\"\nCoverage Index\n==============\nTrack and index test coverage data.\n\nUsage:\n    python mcp.py coverage [file]\n    python mcp.py coverage --uncovered\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass CoverageData:\n    \"\"\"Coverage data for a file.\"\"\"\n    file: str\n    covered_lines: List[int] = field(default_factory=list)\n    uncovered_lines: List[int] = field(default_factory=list)\n    total_lines: int = 0\n    coverage_pct: float = 0.0\n\n\ndef load_coverage_file(coverage_path: Path) -> Optional[Dict]:\n    \"\"\"Load coverage data from .coverage or coverage.json.\"\"\"\n    # Try JSON format\n    json_path = coverage_path.parent / 'coverage.json'\n    if json_path.exists():\n        try:\n            with open(json_path, 'r') as f:\n                return json.load(f)\n        except Exception:\n            pass\n\n    # Try coverage.py format\n    if coverage_path.exists():\n        try:\n            import sqlite3\n            conn = sqlite3.connect(str(coverage_path))\n            cursor = conn.cursor()\n\n            # Query coverage data\n            cursor.execute(\"SELECT file_id, path FROM file\")\n            files = {row[0]: row[1] for row in cursor.fetchall()}\n\n            cursor.execute(\"SELECT file_id, lineno FROM line_bits\")\n            lines = {}\n            for file_id, lineno in cursor.fetchall():\n                if file_id not in lines:\n                    lines[file_id] = []\n                lines[file_id].append(lineno)\n\n            conn.close()\n\n            return {\n                \"files\": {files[fid]: {\"covered\": lns} for fid, lns in lines.items() if fid in files}\n            }\n        except Exception:\n            pass\n\n    return None\n\n\ndef get_file_coverage(file_path: Path, root: Path = None) -> Optional[CoverageData]:\n    \"\"\"Get coverage data for a specific file.\"\"\"\n    root = root or find_project_root() or Path.cwd()", "chunk_type": "file", "line_start": 1, "line_end": 275, "language": "python", "name": "coverage_index.py"}, "8b5d9fa3433f_func_load_coverage_file": {"id": "8b5d9fa3433f_func_load_coverage_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def load_coverage_file(coverage_path: Path) -> Optional[Dict]:\n    \"\"\"Load coverage data from .coverage or coverage.json.\"\"\"\n    # Try JSON format\n    json_path = coverage_path.parent / 'coverage.json'\n    if json_path.exists():\n        try:\n            with open(json_path, 'r') as f:\n                return json.load(f)\n        except Exception:\n            pass\n\n    # Try coverage.py format\n    if coverage_path.exists():\n        try:\n            import sqlite3\n            conn = sqlite3.connect(str(coverage_path))\n            cursor = conn.cursor()\n\n            # Query coverage data\n            cursor.execute(\"SELECT file_id, path FROM file\")\n            files = {row[0]: row[1] for row in cursor.fetchall()}\n\n            cursor.execute(\"SELECT file_id, lineno FROM line_bits\")\n            lines = {}\n            for file_id, lineno in cursor.fetchall():\n                if file_id not in lines:\n                    lines[file_id] = []\n                lines[file_id].append(lineno)\n\n        ", "chunk_type": "function", "line_start": 30, "line_end": 67, "language": "python", "name": "load_coverage_file"}, "8b5d9fa3433f_func_get_file_coverage": {"id": "8b5d9fa3433f_func_get_file_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def get_file_coverage(file_path: Path, root: Path = None) -> Optional[CoverageData]:\n    \"\"\"Get coverage data for a specific file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    coverage_path = root / '.coverage'\n\n    data = load_coverage_file(coverage_path)\n    if not data:\n        return None\n\n    file_key = str(file_path.relative_to(root)) if file_path.is_absolute() else str(file_path)\n\n    for key, file_data in data.get('files', {}).items():\n        if file_key in key or key.endswith(file_key):\n            covered = file_data.get('covered', file_data.get('executed_lines', []))\n            total = file_data.get('total', len(covered) + len(file_data.get('missing', [])))\n            missing = file_data.get('missing', file_data.get('uncovered', []))\n\n            pct = (len(covered) / total * 100) if total > 0 else 0\n\n            return CoverageData(\n                file=file_key,\n                covered_lines=covered,\n                uncovered_lines=missing,\n              ", "chunk_type": "function", "line_start": 70, "line_end": 97, "language": "python", "name": "get_file_coverage"}, "8b5d9fa3433f_func_get_tests_for_file": {"id": "8b5d9fa3433f_func_get_tests_for_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def get_tests_for_file(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Find tests that likely cover a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    tests = []\n    file_name = file_path.stem\n\n    # Look for test files\n    for test_file in root.rglob('test_*.py'):\n        if file_name in test_file.stem or file_name in test_file.read_text(errors='ignore'):\n            tests.append(str(test_file.relative_to(root)))\n\n    for test_file in root.rglob('*_test.py'):\n        if file_name in test_file.stem:\n            tests.append(str(test_file.relative_to(root)))\n\n    # Check tests/ directory\n    tests_dir = root / 'tests'\n    if tests_dir.exists():\n        for test_file in tests_dir.rglob('*.py'):\n            if file_name in test_file.stem:\n                tests.append(str(test_file.relative_to(root)))\n\n    return list(set(tests))", "chunk_type": "function", "line_start": 100, "line_end": 123, "language": "python", "name": "get_tests_for_file"}, "8b5d9fa3433f_func_suggest_tests_needed": {"id": "8b5d9fa3433f_func_suggest_tests_needed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def suggest_tests_needed(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Suggest what tests are needed for a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    suggestions = []\n    file_name = file_path.stem\n\n    existing_tests = get_tests_for_file(file_path, root)\n\n    if not existing_tests:\n        suggestions.append(f\"Create test file: tests/test_{file_name}.py\")\n\n    # Check coverage\n    coverage = get_file_coverage(file_path, root)\n    if coverage and coverage.uncovered_lines:\n        suggestions.append(f\"Add tests for uncovered lines: {coverage.uncovered_lines[:10]}\")\n\n    # Check for public functions without tests\n    try:\n        import ast\n        with open(file_path, 'r', encoding='utf-8') as f:\n            tree = ast.parse(f.read())\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef) and not node.name.startswith('_'):\n                test_name = f\"test_{node.name}\"\n                # Check if test exists\n             ", "chunk_type": "function", "line_start": 126, "line_end": 167, "language": "python", "name": "suggest_tests_needed"}, "8b5d9fa3433f_func_index_coverage": {"id": "8b5d9fa3433f_func_index_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def index_coverage(root: Path = None) -> Dict:\n    \"\"\"Build coverage index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    coverage_path = root / '.coverage'\n\n    Console.info(\"Indexing coverage data...\")\n\n    data = load_coverage_file(coverage_path)\n    if not data:\n        Console.warn(\"No coverage data found. Run pytest --cov first.\")\n        return {}\n\n    index = {\n        \"total_files\": 0,\n        \"covered_files\": 0,\n        \"average_coverage\": 0.0,\n        \"files\": {}\n    }\n\n    total_pct = 0.0\n\n    for file_key, file_data in data.get('files', {}).items():\n        covered = len(file_data.get('covered', file_data.get('executed_lines', [])))\n        missing = len(file_data.get('missing', file_data.get('uncovered', [])))\n        total = covered + missing\n\n        pct = (covered / total * 100) if total > 0 else 0\n\n        index[\"files\"][file_key] = {\n            \"covered\": covered,\n            \"missing\": missing,\n            \"total\": total,\n            \"percentage\": rou", "chunk_type": "function", "line_start": 170, "line_end": 222, "language": "python", "name": "index_coverage"}, "8b5d9fa3433f_func_main": {"id": "8b5d9fa3433f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Coverage Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_coverage(root)\n        return 0\n\n    if '--suggest' in sys.argv and args:\n        file_path = Path(args[0])\n        suggestions = suggest_tests_needed(file_path, root)\n        Console.info(f\"Test suggestions for {file_path.name}:\")\n        for s in suggestions:\n            print(f\"  - {s}\")\n        return 0\n\n    if args:\n        file_path = Path(args[0])\n        coverage = get_file_coverage(file_path, root)\n\n        if coverage:\n            print(f\"Coverage: {coverage.coverage_pct:.1f}%\")\n            print(f\"Covered lines: {len(coverage.covered_lines)}\")\n            if coverage.uncovered_lines:\n                print(f\"Uncovered: {coverage.uncovered_lines[:20]}\")\n        else:\n            Console.warn(\"No coverage data for this file\")\n\n        tests = get_tests_", "chunk_type": "function", "line_start": 225, "line_end": 270, "language": "python", "name": "main"}, "8b5d9fa3433f_class_CoverageData": {"id": "8b5d9fa3433f_class_CoverageData", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\coverage_index.py", "content": "class CoverageData:\n    \"\"\"Coverage data for a file.\"\"\"\n    file: str\n    covered_lines: List[int] = field(default_factory=list)\n    uncovered_lines: List[int] = field(default_factory=list)\n    total_lines: int = 0\n    coverage_pct: float = 0.0", "chunk_type": "class", "line_start": 21, "line_end": 27, "language": "python", "name": "CoverageData"}, "842c9e9df696_file": {"id": "842c9e9df696_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cybersec.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Cybersecurity Tool Wrapper\nIntegrates 70+ security tools from wizardpanda into the MCP CLI.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\nimport os\nimport subprocess\nimport sys\n\n# Tool Categories\nCATEGORIES = {\n    \"Network\": [\"nmap\", \"masscan\", \"arp-scan\", \"netdiscover\", \"fping\", \"hping3\"],\n    \"Web\": [\"gobuster\", \"dirb\", \"dirbuster\", \"nikto\", \"sqlmap\", \"wfuzz\", \"commix\"],\n    \"Exploitation\": [\"msfconsole\", \"msfvenom\", \"searchsploit\", \"beef-xss\", \"social-engineer-toolkit\"],\n    \"Password\": [\"hydra\", \"john\", \"hashcat\", \"medusa\", \"ncrack\"],\n    \"Wireless\": [\"aircrack-ng\", \"airmon-ng\", \"airodump-ng\", \"aireplay-ng\", \"reaver\", \"bully\", \"wifite\"],\n    \"Forensics\": [\"autopsy\", \"binwalk\", \"foremost\", \"scalpel\", \"chkrootkit\", \"rkhunter\"],\n    \"OSINT\": [\"theHarvester\", \"recon-ng\", \"whois\", \"dig\", \"nslookup\"],\n    \"Reverse\": [\"gdb\", \"radare2\", \"ghidra\", \"cutter\", \"objdump\"],\n    \"Post-Exploitation\": [\"impacket\", \"powersploit\", \"bloodhound\", \"mimikatz\"]\n}\n\n# Special Environment Paths\nCYBERSEC_ENV = Path.home() / \"cybersec-env\"\nCYBERSEC_BIN = CYBERSEC_ENV / \"bin\"\n\ndef get_impacket_tools() -> List[str]:\n    \"\"\"List tools available in the Impacket virtualenv.\"\"\"\n    if not CYBERSEC_BIN.exists():\n        return []\n    return [f.name for f in CYBERSEC_BIN.iterdir() if f.is_file() and f.name.endswith(\".py\")]\n\ndef show_help():\n    \"\"\"Show help for the cybersec command.\"\"\"\n    print(\"MCP Cybersecurity Tool Wrapper\")\n    print(\"Usage: mcp cybersec <category|tool|list> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  list              List all tool categories and available tools\")\n    print(\"  help <tool>       Show help for a specific tool\")\n    print(\"  <tool> [args]     Execute a specific tool (e.g., mcp cybersec nmap -sV target)\")\n    print(\"\\nCategories:\")\n    for cat in CATEGORIES:\n        print(f\"  {cat}\")\n\ndef list_tools():\n    \"\"\"List all tools organized by category.\"\"\"\n    print(\"Available Cybersecurity Tools:\")\n    for cat,", "chunk_type": "file", "line_start": 1, "line_end": 120, "language": "python", "name": "cybersec.py"}, "842c9e9df696_func_get_impacket_tools": {"id": "842c9e9df696_func_get_impacket_tools", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cybersec.py", "content": "def get_impacket_tools() -> List[str]:\n    \"\"\"List tools available in the Impacket virtualenv.\"\"\"\n    if not CYBERSEC_BIN.exists():\n        return []\n    return [f.name for f in CYBERSEC_BIN.iterdir() if f.is_file() and f.name.endswith(\".py\")]", "chunk_type": "function", "line_start": 30, "line_end": 34, "language": "python", "name": "get_impacket_tools"}, "842c9e9df696_func_show_help": {"id": "842c9e9df696_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cybersec.py", "content": "def show_help():\n    \"\"\"Show help for the cybersec command.\"\"\"\n    print(\"MCP Cybersecurity Tool Wrapper\")\n    print(\"Usage: mcp cybersec <category|tool|list> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  list              List all tool categories and available tools\")\n    print(\"  help <tool>       Show help for a specific tool\")\n    print(\"  <tool> [args]     Execute a specific tool (e.g., mcp cybersec nmap -sV target)\")\n    print(\"\\nCategories:\")\n    for cat in CATEGORIES:\n        print(f\"  {cat}\")", "chunk_type": "function", "line_start": 36, "line_end": 46, "language": "python", "name": "show_help"}, "842c9e9df696_func_list_tools": {"id": "842c9e9df696_func_list_tools", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cybersec.py", "content": "def list_tools():\n    \"\"\"List all tools organized by category.\"\"\"\n    print(\"Available Cybersecurity Tools:\")\n    for cat, tools in CATEGORIES.items():\n        print(f\"\\n[{cat}]\")\n        print(\", \".join(tools))\n\n    impacket_tools = get_impacket_tools()\n    if impacket_tools:\n        print(\"\\n[Impacket (Auto-activates VENV)]\")\n        # Split into manageable chunks for display\n        for i in range(0, len(impacket_tools), 5):\n            print(\", \".join(impacket_tools[i:i+5]))", "chunk_type": "function", "line_start": 48, "line_end": 60, "language": "python", "name": "list_tools"}, "842c9e9df696_func_run_tool": {"id": "842c9e9df696_func_run_tool", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cybersec.py", "content": "def run_tool(tool_name: str, args: List[str]):\n    \"\"\"Run a specific tool, handling env activation if needed.\"\"\"\n\n    # Check if it's an impacket tool\n    impacket_tools = get_impacket_tools()\n    if tool_name in impacket_tools or tool_name.replace(\".py\", \"\") in [t.replace(\".py\", \"\") for t in impacket_tools]:\n        if not tool_name.endswith(\".py\"):\n            tool_name += \".py\"\n\n        python_bin = CYBERSEC_BIN / \"python3\"\n        tool_path = CYBERSEC_BIN / tool_name\n\n        if not python_bin.exists() or not tool_path.exists():\n            print(f\"[FAIL] Impacket tool {tool_name} not found or venv invalid.\")\n            return 1\n\n        cmd = [str(python_bin), str(tool_path)] + args\n        print(f\"[EXEC] Running Impacket tool: {' '.join(cmd)}\")\n    else:\n        # Check if tool is in PATH\n        from shutil import which\n        if not which(tool_name):\n            print(f\"[FAIL] Tool '{tool_name}' not found in system PATH.\")\n            print(\"Tip: Use 'mcp cybersec list' to se", "chunk_type": "function", "line_start": 62, "line_end": 98, "language": "python", "name": "run_tool"}, "842c9e9df696_func_main": {"id": "842c9e9df696_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\cybersec.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"list\":\n        list_tools()\n    elif cmd == \"help\" and args:\n        run_tool(args[0], [\"--help\"])\n    elif cmd in CATEGORIES:\n        print(f\"Tools in category '{cmd}':\")\n        print(\", \".join(CATEGORIES[cmd]))\n    else:\n        return run_tool(cmd, args)", "chunk_type": "function", "line_start": 100, "line_end": 116, "language": "python", "name": "main"}, "0ba5471fa474_file": {"id": "0ba5471fa474_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "\"\"\"\nDead Code Detector\n==================\nFind unused functions, classes, imports, and variables in Python code.\n\nUsage:\n    python dead_code.py [path]\n    python -m scripts.dead_code [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Set, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass DeadCodeReport:\n    \"\"\"Report of detected dead code.\"\"\"\n    unused_imports: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_functions: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_classes: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_variables: List[Tuple[Path, int, str]] = field(default_factory=list)\n\n    @property\n    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))\n\n    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_imports]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Import\"], rows))\n            lines.append(\"\")\n\n        if self.unused_functions:\n            lines.append(\"## Unused Functions\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_functions]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Function\"], rows))\n            lines.append(\"\")\n\n        if self.unused_classe", "chunk_type": "file", "line_start": 1, "line_end": 287, "language": "python", "name": "dead_code.py"}, "0ba5471fa474_func_analyze_file": {"id": "0ba5471fa474_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "def analyze_file(path: Path) -> Tuple[Dict[str, Dict[str, int]], Set[str]]:\n    \"\"\"\n    Analyze a single file for definitions and usages.\n\n    Returns:\n        Tuple of (definitions dict, used names set)\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return {}, set()\n\n    # Collect definitions\n    def_collector = DefinitionCollector(path)\n    def_collector.visit(tree)\n\n    # Collect usages\n    usage_collector = UsageCollector()\n    usage_collector.visit(tree)\n\n    definitions = {\n        'imports': def_collector.imports,\n        'functions': def_collector.functions,\n        'classes': def_collector.classes,\n        'variables': def_collector.variables\n    }\n\n    return definitions, usage_collector.used_names", "chunk_type": "function", "line_start": 156, "line_end": 182, "language": "python", "name": "analyze_file"}, "0ba5471fa474_func_detect_dead_code": {"id": "0ba5471fa474_func_detect_dead_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "def detect_dead_code(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> DeadCodeReport:\n    \"\"\"\n    Detect dead code in a Python project.\n\n    Args:\n        root: Root directory to analyze\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        DeadCodeReport with findings\n    \"\"\"\n    report = DeadCodeReport()\n\n    # Collect all definitions and usages across the project\n    all_definitions: Dict[Path, Dict[str, Dict[str, int]]] = {}\n    all_usages: Set[str] = set()\n\n    # Known always-used names (builtins, common patterns)\n    always_used = {\n        'self', 'cls', 'args', 'kwargs',\n        'main', 'setup', 'teardown',\n        '__all__', '__version__', '__name__', '__main__'\n    }\n    all_usages.update(always_used)\n\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        definitions, usages = analyze_file(path)\n     ", "chunk_type": "function", "line_start": 185, "line_end": 254, "language": "python", "name": "detect_dead_code"}, "0ba5471fa474_func_main": {"id": "0ba5471fa474_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Dead Code Detector\")\n\n    # Get path from args or use project root\n    if len(sys.argv) > 1:\n        path = Path(sys.argv[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = detect_dead_code(path)\n\n    print(report.to_markdown())\n\n    if report.total_issues > 0:\n        Console.warn(f\"Found {report.total_issues} potential dead code issues\")\n    else:\n        Console.ok(\"No dead code detected\")\n\n    return report.total_issues", "chunk_type": "function", "line_start": 257, "line_end": 282, "language": "python", "name": "main"}, "0ba5471fa474_func_total_issues": {"id": "0ba5471fa474_func_total_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))", "chunk_type": "function", "line_start": 36, "line_end": 38, "language": "python", "name": "total_issues"}, "0ba5471fa474_func_to_markdown": {"id": "0ba5471fa474_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_imports]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Import\"], rows))\n            lines.append(\"\")\n\n        if self.unused_functions:\n            lines.append(\"## Unused Functions\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_functions]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Function\"], rows))\n            lines.append(\"\")\n\n        if self.unused_classes:\n            lines.append(\"## Unused Classes\\n\")\n            rows = [[str", "chunk_type": "function", "line_start": 40, "line_end": 74, "language": "python", "name": "to_markdown"}, "0ba5471fa474_func___init__": {"id": "0ba5471fa474_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def __init__(self):\n        self.used_names: Set[str] = set()", "chunk_type": "function", "line_start": 134, "line_end": 135, "language": "python", "name": "__init__"}, "0ba5471fa474_func_visit_Import": {"id": "0ba5471fa474_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            name = alias.asname or alias.name.split('.')[0]\n            self.imports[name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 88, "line_end": 92, "language": "python", "name": "visit_Import"}, "0ba5471fa474_func_visit_ImportFrom": {"id": "0ba5471fa474_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        for alias in node.names:\n            if alias.name != '*':\n                name = alias.asname or alias.name\n                self.imports[name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 94, "line_end": 99, "language": "python", "name": "visit_ImportFrom"}, "0ba5471fa474_func_visit_FunctionDef": {"id": "0ba5471fa474_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 101, "line_end": 104, "language": "python", "name": "visit_FunctionDef"}, "0ba5471fa474_func_visit_AsyncFunctionDef": {"id": "0ba5471fa474_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 106, "line_end": 109, "language": "python", "name": "visit_AsyncFunctionDef"}, "0ba5471fa474_func_visit_ClassDef": {"id": "0ba5471fa474_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        if not node.name.startswith('_'):\n            self.classes[node.name] = node.lineno\n\n        old_in_class = self._in_class\n        self._in_class = True\n        self.generic_visit(node)\n        self._in_class = old_in_class", "chunk_type": "function", "line_start": 111, "line_end": 118, "language": "python", "name": "visit_ClassDef"}, "0ba5471fa474_func_visit_Assign": {"id": "0ba5471fa474_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        if not self._in_class:\n            for target in node.targets:\n                if isinstance(target, ast.Name) and not target.id.startswith('_'):\n                    # Skip common constants/configs\n                    if target.id.isupper():\n                        continue\n                    self.variables[target.id] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 120, "line_end": 128, "language": "python", "name": "visit_Assign"}, "0ba5471fa474_func_visit_Name": {"id": "0ba5471fa474_func_visit_Name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Name(self, node: ast.Name):\n        self.used_names.add(node.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 137, "line_end": 139, "language": "python", "name": "visit_Name"}, "0ba5471fa474_func_visit_Attribute": {"id": "0ba5471fa474_func_visit_Attribute", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Attribute(self, node: ast.Attribute):\n        # Track the base name\n        if isinstance(node.value, ast.Name):\n            self.used_names.add(node.value.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 141, "line_end": 145, "language": "python", "name": "visit_Attribute"}, "0ba5471fa474_func_visit_Call": {"id": "0ba5471fa474_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Call(self, node: ast.Call):\n        if isinstance(node.func, ast.Name):\n            self.used_names.add(node.func.id)\n        elif isinstance(node.func, ast.Attribute):\n            if isinstance(node.func.value, ast.Name):\n                self.used_names.add(node.func.value.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 147, "line_end": 153, "language": "python", "name": "visit_Call"}, "0ba5471fa474_class_DeadCodeReport": {"id": "0ba5471fa474_class_DeadCodeReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "class DeadCodeReport:\n    \"\"\"Report of detected dead code.\"\"\"\n    unused_imports: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_functions: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_classes: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_variables: List[Tuple[Path, int, str]] = field(default_factory=list)\n\n    @property\n    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))\n\n    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p", "chunk_type": "class", "line_start": 28, "line_end": 74, "language": "python", "name": "DeadCodeReport"}, "0ba5471fa474_class_DefinitionCollector": {"id": "0ba5471fa474_class_DefinitionCollector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "class DefinitionCollector(ast.NodeVisitor):\n    \"\"\"Collect all definitions in a module.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.imports: Dict[str, int] = {}  # name -> lineno\n        self.functions: Dict[str, int] = {}\n        self.classes: Dict[str, int] = {}\n        self.variables: Dict[str, int] = {}\n        self._in_class = False\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            name = alias.asname or alias.name.split('.')[0]\n            self.imports[name] = node.lineno\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        for alias in node.names:\n            if alias.name != '*':\n                name = alias.asname or alias.name\n                self.imports[name] = node.lineno\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.", "chunk_type": "class", "line_start": 77, "line_end": 128, "language": "python", "name": "DefinitionCollector"}, "0ba5471fa474_class_UsageCollector": {"id": "0ba5471fa474_class_UsageCollector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\dead_code.py", "content": "class UsageCollector(ast.NodeVisitor):\n    \"\"\"Collect all name usages in a module.\"\"\"\n\n    def __init__(self):\n        self.used_names: Set[str] = set()\n\n    def visit_Name(self, node: ast.Name):\n        self.used_names.add(node.id)\n        self.generic_visit(node)\n\n    def visit_Attribute(self, node: ast.Attribute):\n        # Track the base name\n        if isinstance(node.value, ast.Name):\n            self.used_names.add(node.value.id)\n        self.generic_visit(node)\n\n    def visit_Call(self, node: ast.Call):\n        if isinstance(node.func, ast.Name):\n            self.used_names.add(node.func.id)\n        elif isinstance(node.func, ast.Attribute):\n            if isinstance(node.func.value, ast.Name):\n                self.used_names.add(node.func.value.id)\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 131, "line_end": 153, "language": "python", "name": "UsageCollector"}, "26f4a03aa6cd_file": {"id": "26f4a03aa6cd_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "\"\"\"\nDependency Analyzer\n===================\nAnalyze and visualize project dependencies, detect circular imports.\n\nUsage:\n    python deps.py [path] [--output deps.md]\n    python -m scripts.deps [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Set, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass DependencyInfo:\n    \"\"\"Dependency information for a module.\"\"\"\n    path: Path\n    module_name: str\n    imports: Set[str] = field(default_factory=set)\n    from_imports: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps\n\n\n@dataclass\nclass DependencyReport:\n    \"\"\"Report of dependency analysis.\"\"\"\n    modules: Dict[str, DependencyInfo] = field(default_factory=dict)\n    external_deps: Set[str] = field(default_factory=set)\n    internal_deps: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n    circular_deps: List[Tuple[str, str]] = field(default_factory=list)\n    missing_deps: List[Tuple[str, str]] = field(default_factory=list)\n\n\n# Standard library modules\nSTDLIB_MODULES = {\n    'abc', 'aifc', 'argparse', 'array', 'ast', 'asyncio', 'atexit',\n    'base64', 'bdb', 'binascii', 'bisect', 'builtins', 'bz2',\n    'calendar', 'cgi', 'cgitb', 'chunk', 'cmath', 'cmd', 'code',\n    'codecs', 'codeop', 'collections', 'colorsys', 'compileall',\n    'concurrent', 'configparser', 'contextlib', 'copy', 'copyreg',\n    'cProfile', 'crypt', 'csv', 'ctypes', 'curses',\n    'dataclasses', 'datetime', 'dbm', 'decimal', 'difflib', 'dis',\n    'distutils', 'doctest',\n    'email', 'encodings', 'enum', 'errno',\n    'faulthandler', 'fcntl', 'filecmp', '", "chunk_type": "file", "line_start": 1, "line_end": 367, "language": "python", "name": "deps.py"}, "26f4a03aa6cd_func_analyze_imports": {"id": "26f4a03aa6cd_func_analyze_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "def analyze_imports(path: Path) -> Optional[DependencyInfo]:\n    \"\"\"\n    Analyze imports in a Python file.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        DependencyInfo or None if parsing fails\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return None\n\n    info = DependencyInfo(\n        path=path,\n        module_name=path.stem\n    )\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                info.imports.add(alias.name.split('.')[0])\n        elif isinstance(node, ast.ImportFrom):\n            if node.module:\n                base_module = node.module.split('.')[0]\n                info.imports.add(base_module)\n                for alias in node.names:\n                    info.from_imports[node.module].add(alias.name)\n\n    return info", "chunk_type": "function", "line_start": 99, "line_end": 129, "language": "python", "name": "analyze_imports"}, "26f4a03aa6cd_func_path_to_module_name": {"id": "26f4a03aa6cd_func_path_to_module_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "def path_to_module_name(path: Path, root: Path) -> str:\n    \"\"\"Convert a file path to a module name.\"\"\"\n    try:\n        relative = path.relative_to(root)\n        parts = list(relative.with_suffix('').parts)\n        return '.'.join(parts)\n    except ValueError:\n        return path.stem", "chunk_type": "function", "line_start": 132, "line_end": 139, "language": "python", "name": "path_to_module_name"}, "26f4a03aa6cd_func_analyze_dependencies": {"id": "26f4a03aa6cd_func_analyze_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "def analyze_dependencies(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> DependencyReport:\n    \"\"\"\n    Analyze dependencies in a Python project.\n\n    Args:\n        root: Root directory\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        DependencyReport\n    \"\"\"\n    report = DependencyReport()\n\n    Console.info(f\"Scanning {root} for Python files...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    # Build module name mapping\n    module_names = set()\n    for path in files:\n        module_name = path_to_module_name(path, root)\n        module_names.add(module_name.split('.')[0])\n\n    # Analyze each file\n    for path in files:\n        info = analyze_imports(path)\n        if info:\n            module_name = path_to_module_name(path, root)\n            report.modules[module_name] = info\n\n            # Categorize dependencies\n            for dep in info.all_dependencies:\n                base_dep =", "chunk_type": "function", "line_start": 142, "line_end": 204, "language": "python", "name": "analyze_dependencies"}, "26f4a03aa6cd_func_generate_mermaid_diagram": {"id": "26f4a03aa6cd_func_generate_mermaid_diagram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "def generate_mermaid_diagram(report: DependencyReport, max_nodes: int = 20) -> str:\n    \"\"\"\n    Generate a Mermaid diagram of dependencies.\n\n    Args:\n        report: DependencyReport\n        max_nodes: Maximum number of nodes to show\n\n    Returns:\n        Mermaid diagram code\n    \"\"\"\n    lines = [\"```mermaid\", \"graph LR\"]\n\n    # Track nodes we've added\n    nodes_added = set()\n    edges_added = set()\n\n    # Add internal dependencies\n    for module, deps in list(report.internal_deps.items())[:max_nodes]:\n        base_module = module.split('.')[0]\n\n        if base_module not in nodes_added:\n            lines.append(f'    {base_module}[\"{base_module}\"]')\n            nodes_added.add(base_module)\n\n        for dep in list(deps)[:5]:  # Limit edges per node\n            base_dep = dep.split('.')[0]\n\n            if base_dep not in nodes_added and len(nodes_added) < max_nodes:\n                lines.append(f'    {base_dep}[\"{base_dep}\"]')\n                nodes_added.add(base_dep)\n\n            edg", "chunk_type": "function", "line_start": 207, "line_end": 250, "language": "python", "name": "generate_mermaid_diagram"}, "26f4a03aa6cd_func_format_report_markdown": {"id": "26f4a03aa6cd_func_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "def format_report_markdown(report: DependencyReport) -> str:\n    \"\"\"Format dependency report as Markdown.\"\"\"\n    lines = [\n        \"# Dependency Analysis\",\n        \"\",\n        \"## Summary\",\n        \"\",\n        f\"- **Internal Modules:** {len(report.modules)}\",\n        f\"- **External Dependencies:** {len(report.external_deps)}\",\n        f\"- **Circular Dependencies:** {len(report.circular_deps)}\",\n        \"\",\n    ]\n\n    # External dependencies\n    if report.external_deps:\n        lines.extend([\n            \"## External Dependencies\",\n            \"\",\n            \"These packages need to be installed:\",\n            \"\",\n        ])\n        for dep in sorted(report.external_deps):\n            lines.append(f\"- `{dep}`\")\n        lines.append(\"\")\n\n    # Circular dependencies (warning)\n    if report.circular_deps:\n        lines.extend([\n            \"## Circular Dependencies [WARNING]\",\n            \"\",\n            \"The following modules have circular imports:\",\n            \"\",\n        ])\n        for", "chunk_type": "function", "line_start": 253, "line_end": 316, "language": "python", "name": "format_report_markdown"}, "26f4a03aa6cd_func_main": {"id": "26f4a03aa6cd_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Dependency Analyzer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_dependencies(path)\n    markdown = format_report_markdown(report)\n\n    # Output\n    if output_file:\n        with open(output_file, 'w', encoding='utf-8') as f:\n            f.write(markdown)\n        Console.ok(f\"Report written to: {output_file}\")\n    else:\n        print(markdown)\n\n    # Summary\n    if report.circular_deps:\n        Console.warn(f\"Found {len(report.circular_deps)} circular dependenc", "chunk_type": "function", "line_start": 319, "line_end": 362, "language": "python", "name": "main"}, "26f4a03aa6cd_func_all_dependencies": {"id": "26f4a03aa6cd_func_all_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps", "chunk_type": "function", "line_start": 36, "line_end": 40, "language": "python", "name": "all_dependencies"}, "26f4a03aa6cd_class_DependencyInfo": {"id": "26f4a03aa6cd_class_DependencyInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "class DependencyInfo:\n    \"\"\"Dependency information for a module.\"\"\"\n    path: Path\n    module_name: str\n    imports: Set[str] = field(default_factory=set)\n    from_imports: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps", "chunk_type": "class", "line_start": 28, "line_end": 40, "language": "python", "name": "DependencyInfo"}, "26f4a03aa6cd_class_DependencyReport": {"id": "26f4a03aa6cd_class_DependencyReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\deps.py", "content": "class DependencyReport:\n    \"\"\"Report of dependency analysis.\"\"\"\n    modules: Dict[str, DependencyInfo] = field(default_factory=dict)\n    external_deps: Set[str] = field(default_factory=set)\n    internal_deps: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n    circular_deps: List[Tuple[str, str]] = field(default_factory=list)\n    missing_deps: List[Tuple[str, str]] = field(default_factory=list)", "chunk_type": "class", "line_start": 44, "line_end": 50, "language": "python", "name": "DependencyReport"}, "0c7c24949dc1_file": {"id": "0c7c24949dc1_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "\"\"\"\nDocumentation Coverage Checker\n==============================\nMeasure documentation coverage and identify undocumented code.\n\nUsage:\n    python doc_coverage.py [path] [--format google]\n    python -m scripts.doc_coverage src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass CoverageItem:\n    \"\"\"A single item that should have documentation.\"\"\"\n    path: Path\n    name: str\n    line: int\n    item_type: str  # 'function', 'class', 'method', 'module'\n    has_docstring: bool\n    docstring_valid: bool = True\n    issues: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass CoverageReport:\n    \"\"\"Documentation coverage report.\"\"\"\n    items: List[CoverageItem] = field(default_factory=list)\n\n    @property\n    def total(self) -> int:\n        return len(self.items)\n\n    @property\n    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)\n\n    @property\n    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)\n\n    @property\n    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0\n\n    @property\n    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]\n\n    @property\n    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Metric | Value |\",\n            f\"|--------|-------|\",\n            f\"| Total Items | {self.total} |\",\n            f\"| Documented | {self.documented} |\",\n            f\"| Covera", "chunk_type": "file", "line_start": 1, "line_end": 319, "language": "python", "name": "doc_coverage.py"}, "0c7c24949dc1_func_analyze_file": {"id": "0c7c24949dc1_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def analyze_file(path: Path, validator: DocstringValidator) -> List[CoverageItem]:\n    \"\"\"Analyze documentation coverage in a file.\"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    analyzer = CoverageAnalyzer(path, validator)\n    analyzer.visit(tree)\n\n    return analyzer.items", "chunk_type": "function", "line_start": 241, "line_end": 250, "language": "python", "name": "analyze_file"}, "0c7c24949dc1_func_check_coverage": {"id": "0c7c24949dc1_func_check_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def check_coverage(\n    root: Path,\n    doc_format: str = 'google',\n    exclude_patterns: List[str] = None\n) -> CoverageReport:\n    \"\"\"Check documentation coverage in a project.\"\"\"\n    report = CoverageReport()\n    validator = DocstringValidator(doc_format)\n\n    Console.info(f\"Checking documentation coverage in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        items = analyze_file(path, validator)\n        report.items.extend(items)\n\n    return report", "chunk_type": "function", "line_start": 253, "line_end": 271, "language": "python", "name": "check_coverage"}, "0c7c24949dc1_func_main": {"id": "0c7c24949dc1_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Documentation Coverage Checker\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    doc_format = 'google'\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--format' and i + 1 < len(sys.argv):\n            doc_format = sys.argv[i + 1]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Format: {doc_format}\")\n\n    report = check_coverage(path, doc_format)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.coverage_percent >= 80:\n        Console.ok(f\"Coverage: {report.coverage_percent:.1f}%\")\n    elif report.coverage_percent >= 50:\n        Console.warn(f\"Coverage: {report.coverage_percent:.1f}% (target: 80%)\")\n    else:\n        Console.fail(f\"Coverage: {report.coverage_percent:.1f}", "chunk_type": "function", "line_start": 274, "line_end": 310, "language": "python", "name": "main"}, "0c7c24949dc1_func_total": {"id": "0c7c24949dc1_func_total", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def total(self) -> int:\n        return len(self.items)", "chunk_type": "function", "line_start": 45, "line_end": 46, "language": "python", "name": "total"}, "0c7c24949dc1_func_documented": {"id": "0c7c24949dc1_func_documented", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)", "chunk_type": "function", "line_start": 49, "line_end": 50, "language": "python", "name": "documented"}, "0c7c24949dc1_func_valid": {"id": "0c7c24949dc1_func_valid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)", "chunk_type": "function", "line_start": 53, "line_end": 54, "language": "python", "name": "valid"}, "0c7c24949dc1_func_coverage_percent": {"id": "0c7c24949dc1_func_coverage_percent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0", "chunk_type": "function", "line_start": 57, "line_end": 58, "language": "python", "name": "coverage_percent"}, "0c7c24949dc1_func_undocumented": {"id": "0c7c24949dc1_func_undocumented", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]", "chunk_type": "function", "line_start": 61, "line_end": 62, "language": "python", "name": "undocumented"}, "0c7c24949dc1_func_invalid": {"id": "0c7c24949dc1_func_invalid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]", "chunk_type": "function", "line_start": 65, "line_end": 66, "language": "python", "name": "invalid"}, "0c7c24949dc1_func_to_markdown": {"id": "0c7c24949dc1_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Metric | Value |\",\n            f\"|--------|-------|\",\n            f\"| Total Items | {self.total} |\",\n            f\"| Documented | {self.documented} |\",\n            f\"| Coverage | {self.coverage_percent:.1f}% |\",\n            f\"| Valid Format | {self.valid} |\",\n            \"\",\n        ]\n\n        # Coverage bar\n        filled = int(self.coverage_percent / 5)\n        bar = \"[\" + \"#\" * filled + \"-\" * (20 - filled) + \"]\"\n        lines.append(f\"**Coverage:** {bar} {self.coverage_percent:.1f}%\")\n        lines.append(\"\")\n\n        # Undocumented items\n        if self.undocumented:\n            lines.append(\"## Undocumented Items\")\n            lines.append(\"\")\n\n            # Group by type\n            by_type: Dict[str, List[CoverageItem]] = {}\n            for item in self.undocumented:\n                if item.item_type not in b", "chunk_type": "function", "line_start": 68, "line_end": 120, "language": "python", "name": "to_markdown"}, "0c7c24949dc1_func___init__": {"id": "0c7c24949dc1_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def __init__(self, path: Path, validator: DocstringValidator):\n        self.path = path\n        self.validator = validator\n        self.items: List[CoverageItem] = []\n        self._in_class = False", "chunk_type": "function", "line_start": 163, "line_end": 167, "language": "python", "name": "__init__"}, "0c7c24949dc1_func_validate": {"id": "0c7c24949dc1_func_validate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def validate(self, docstring: str, node) -> Tuple[bool, List[str]]:\n        \"\"\"Validate docstring format.\"\"\"\n        issues = []\n\n        if not docstring or not docstring.strip():\n            return False, [\"Empty docstring\"]\n\n        lines = docstring.strip().split('\\n')\n\n        # Check first line\n        first_line = lines[0].strip()\n        if not first_line:\n            issues.append(\"First line is empty\")\n        elif not first_line.endswith('.') and not first_line.endswith('!'):\n            issues.append(\"First line should end with period\")\n\n        # Check for function-specific requirements\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Check Args section if function has parameters\n            params = [a.arg for a in node.args.args if a.arg not in ('self', 'cls')]\n            if params and 'Args:' not in docstring and 'Parameters:' not in docstring:\n                issues.append(f\"Missing Args section for: {', '.join(params)}\")\n\n      ", "chunk_type": "function", "line_start": 129, "line_end": 157, "language": "python", "name": "validate"}, "0c7c24949dc1_func_visit_Module": {"id": "0c7c24949dc1_func_visit_Module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_Module(self, node: ast.Module):\n        # Check module docstring\n        docstring = ast.get_docstring(node)\n        self.items.append(CoverageItem(\n            path=self.path,\n            name=self.path.stem,\n            line=1,\n            item_type='module',\n            has_docstring=docstring is not None\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 169, "line_end": 179, "language": "python", "name": "visit_Module"}, "0c7c24949dc1_func_visit_FunctionDef": {"id": "0c7c24949dc1_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 181, "line_end": 183, "language": "python", "name": "visit_FunctionDef"}, "0c7c24949dc1_func_visit_AsyncFunctionDef": {"id": "0c7c24949dc1_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 185, "line_end": 187, "language": "python", "name": "visit_AsyncFunctionDef"}, "0c7c24949dc1_func__check_function": {"id": "0c7c24949dc1_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def _check_function(self, node):\n        # Skip private/magic methods\n        if node.name.startswith('_') and not node.name.startswith('__init__'):\n            return\n\n        docstring = ast.get_docstring(node)\n        item_type = 'method' if self._in_class else 'function'\n\n        item = CoverageItem(\n            path=self.path,\n            name=node.name,\n            line=node.lineno,\n            item_type=item_type,\n            has_docstring=docstring is not None\n        )\n\n        if docstring:\n            valid, issues = self.validator.validate(docstring, node)\n            item.docstring_valid = valid\n            item.issues = issues\n\n        self.items.append(item)", "chunk_type": "function", "line_start": 189, "line_end": 210, "language": "python", "name": "_check_function"}, "0c7c24949dc1_func_visit_ClassDef": {"id": "0c7c24949dc1_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        # Skip private classes\n        if node.name.startswith('_'):\n            self.generic_visit(node)\n            return\n\n        docstring = ast.get_docstring(node)\n        item = CoverageItem(\n            path=self.path,\n            name=node.name,\n            line=node.lineno,\n            item_type='class',\n            has_docstring=docstring is not None\n        )\n\n        if docstring:\n            valid, issues = self.validator.validate(docstring, node)\n            item.docstring_valid = valid\n            item.issues = issues\n\n        self.items.append(item)\n\n        # Visit methods\n        old_in_class = self._in_class\n        self._in_class = True\n        self.generic_visit(node)\n        self._in_class = old_in_class", "chunk_type": "function", "line_start": 212, "line_end": 238, "language": "python", "name": "visit_ClassDef"}, "0c7c24949dc1_class_CoverageItem": {"id": "0c7c24949dc1_class_CoverageItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageItem:\n    \"\"\"A single item that should have documentation.\"\"\"\n    path: Path\n    name: str\n    line: int\n    item_type: str  # 'function', 'class', 'method', 'module'\n    has_docstring: bool\n    docstring_valid: bool = True\n    issues: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 28, "line_end": 36, "language": "python", "name": "CoverageItem"}, "0c7c24949dc1_class_CoverageReport": {"id": "0c7c24949dc1_class_CoverageReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageReport:\n    \"\"\"Documentation coverage report.\"\"\"\n    items: List[CoverageItem] = field(default_factory=list)\n\n    @property\n    def total(self) -> int:\n        return len(self.items)\n\n    @property\n    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)\n\n    @property\n    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)\n\n    @property\n    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0\n\n    @property\n    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]\n\n    @property\n    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n      ", "chunk_type": "class", "line_start": 40, "line_end": 120, "language": "python", "name": "CoverageReport"}, "0c7c24949dc1_class_DocstringValidator": {"id": "0c7c24949dc1_class_DocstringValidator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class DocstringValidator:\n    \"\"\"Validate docstring format.\"\"\"\n\n    def __init__(self, format: str = 'google'):\n        self.format = format\n\n    def validate(self, docstring: str, node) -> Tuple[bool, List[str]]:\n        \"\"\"Validate docstring format.\"\"\"\n        issues = []\n\n        if not docstring or not docstring.strip():\n            return False, [\"Empty docstring\"]\n\n        lines = docstring.strip().split('\\n')\n\n        # Check first line\n        first_line = lines[0].strip()\n        if not first_line:\n            issues.append(\"First line is empty\")\n        elif not first_line.endswith('.') and not first_line.endswith('!'):\n            issues.append(\"First line should end with period\")\n\n        # Check for function-specific requirements\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Check Args section if function has parameters\n            params = [a.arg for a in node.args.args if a.arg not in ('self', 'cls')]\n            if params and 'Args:", "chunk_type": "class", "line_start": 123, "line_end": 157, "language": "python", "name": "DocstringValidator"}, "0c7c24949dc1_class_CoverageAnalyzer": {"id": "0c7c24949dc1_class_CoverageAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze documentation coverage.\"\"\"\n\n    def __init__(self, path: Path, validator: DocstringValidator):\n        self.path = path\n        self.validator = validator\n        self.items: List[CoverageItem] = []\n        self._in_class = False\n\n    def visit_Module(self, node: ast.Module):\n        # Check module docstring\n        docstring = ast.get_docstring(node)\n        self.items.append(CoverageItem(\n            path=self.path,\n            name=self.path.stem,\n            line=1,\n            item_type='module',\n            has_docstring=docstring is not None\n        ))\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node):\n        # Skip private/magic methods\n        if", "chunk_type": "class", "line_start": 160, "line_end": 238, "language": "python", "name": "CoverageAnalyzer"}, "b59698c5a02a_file": {"id": "b59698c5a02a_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "\"\"\"\nDocumentation Index\n====================\nIndex READMEs, docstrings, and module summaries.\n\nUsage:\n    python mcp.py doc-index\n    python mcp.py doc-index --search \"api\"\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport ast\nimport json\nimport re\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass DocItem:\n    \"\"\"A documentation item.\"\"\"\n    type: str  # 'readme', 'module', 'class', 'function'\n    name: str\n    path: str\n    summary: str\n    full_text: str = \"\"\n\n\ndef extract_module_docstring(file_path: Path) -> Optional[str]:\n    \"\"\"Extract module docstring from a Python file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n        return ast.get_docstring(tree)\n    except Exception:\n        return None\n\n\ndef extract_docstrings(file_path: Path) -> List[DocItem]:\n    \"\"\"Extract all docstrings from a file.\"\"\"\n    docs = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n    except Exception:\n        return docs\n\n    # Module docstring\n    module_doc = ast.get_docstring(tree)\n    if module_doc:\n        docs.append(DocItem(\n            type='module',\n            name=file_path.stem,\n            path=str(file_path),\n            summary=module_doc.split('\\n')[0][:100],\n            full_text=module_doc[:500]\n        ))\n\n    # Function and class docstrings\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            doc = ast.get_docstring(node)\n            if doc:\n                docs.append(DocItem(\n                    type='function',\n                    name=node.name,\n                    path=str(file_path),\n                    summary=doc.split('\\n')[0][:100],\n                    full_text=doc[:500]\n                ))\n        elif isinstance(node, ast.ClassDef):\n", "chunk_type": "file", "line_start": 1, "line_end": 272, "language": "python", "name": "doc_index.py"}, "b59698c5a02a_func_extract_module_docstring": {"id": "b59698c5a02a_func_extract_module_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "def extract_module_docstring(file_path: Path) -> Optional[str]:\n    \"\"\"Extract module docstring from a Python file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n        return ast.get_docstring(tree)\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 32, "line_end": 40, "language": "python", "name": "extract_module_docstring"}, "b59698c5a02a_func_extract_docstrings": {"id": "b59698c5a02a_func_extract_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "def extract_docstrings(file_path: Path) -> List[DocItem]:\n    \"\"\"Extract all docstrings from a file.\"\"\"\n    docs = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n    except Exception:\n        return docs\n\n    # Module docstring\n    module_doc = ast.get_docstring(tree)\n    if module_doc:\n        docs.append(DocItem(\n            type='module',\n            name=file_path.stem,\n            path=str(file_path),\n            summary=module_doc.split('\\n')[0][:100],\n            full_text=module_doc[:500]\n        ))\n\n    # Function and class docstrings\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            doc = ast.get_docstring(node)\n            if doc:\n                docs.append(DocItem(\n                    type='function',\n                    name=node.name,\n                    path=str(file_path),\n                    summary=doc.split('\\n')[0][:100],\n                  ", "chunk_type": "function", "line_start": 43, "line_end": 88, "language": "python", "name": "extract_docstrings"}, "b59698c5a02a_func_find_readme_files": {"id": "b59698c5a02a_func_find_readme_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "def find_readme_files(root: Path) -> List[Path]:\n    \"\"\"Find README files in project.\"\"\"\n    readmes = []\n    patterns = ['README', 'README.md', 'README.rst', 'README.txt', 'DOCUMENTATION.md']\n\n    for pattern in patterns:\n        for readme in root.rglob(pattern):\n            if '.git' not in str(readme) and 'node_modules' not in str(readme):\n                readmes.append(readme)\n\n    return readmes", "chunk_type": "function", "line_start": 91, "line_end": 101, "language": "python", "name": "find_readme_files"}, "b59698c5a02a_func_index_readme": {"id": "b59698c5a02a_func_index_readme", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "def index_readme(readme_path: Path) -> DocItem:\n    \"\"\"Index a README file.\"\"\"\n    try:\n        content = readme_path.read_text(encoding='utf-8', errors='ignore')\n\n        # Get first paragraph as summary\n        lines = content.split('\\n')\n        summary_lines = []\n        for line in lines:\n            if line.strip() and not line.startswith('#'):\n                summary_lines.append(line)\n                if len(summary_lines) >= 3:\n                    break\n\n        summary = ' '.join(summary_lines)[:200]\n\n        return DocItem(\n            type='readme',\n            name=readme_path.name,\n            path=str(readme_path),\n            summary=summary,\n            full_text=content[:2000]\n        )\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 104, "line_end": 128, "language": "python", "name": "index_readme"}, "b59698c5a02a_func_index_documentation": {"id": "b59698c5a02a_func_index_documentation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "def index_documentation(root: Path = None) -> Dict:\n    \"\"\"Build documentation index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Indexing documentation...\")\n\n    index = {\n        \"total_items\": 0,\n        \"by_type\": {\"readme\": 0, \"module\": 0, \"class\": 0, \"function\": 0},\n        \"items\": []\n    }\n\n    # Index READMEs\n    for readme in find_readme_files(root):\n        item = index_readme(readme)\n        if item:\n            index[\"items\"].append({\n                \"type\": item.type,\n                \"name\": item.name,\n                \"path\": str(item.path),\n                \"summary\": item.summary\n            })\n            index[\"by_type\"][\"readme\"] += 1\n            index[\"total_items\"] += 1\n\n    # Index Python docstrings\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    for file_path in find_python_files(root, exclude):\n        docs = extract_docstrings(file_path)\n        for item in docs:\n            index[\"items\"].appen", "chunk_type": "function", "line_start": 131, "line_end": 179, "language": "python", "name": "index_documentation"}, "b59698c5a02a_func_search_docs": {"id": "b59698c5a02a_func_search_docs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "def search_docs(query: str, root: Path = None) -> List[DocItem]:\n    \"\"\"Search documentation index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    index_path = root / '.mcp' / 'doc_index.json'\n\n    if not index_path.exists():\n        index_documentation(root)\n\n    with open(index_path, 'r') as f:\n        index = json.load(f)\n\n    results = []\n    query_lower = query.lower()\n\n    for item in index.get('items', []):\n        if query_lower in item['name'].lower() or query_lower in item['summary'].lower():\n            results.append(DocItem(\n                type=item['type'],\n                name=item['name'],\n                path=item['path'],\n                summary=item['summary']\n            ))\n\n    return results", "chunk_type": "function", "line_start": 182, "line_end": 205, "language": "python", "name": "search_docs"}, "b59698c5a02a_func_get_module_summary": {"id": "b59698c5a02a_func_get_module_summary", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "def get_module_summary(module_path: Path) -> str:\n    \"\"\"Get summary of a module.\"\"\"\n    docs = extract_docstrings(module_path)\n\n    lines = [f\"# Module: {module_path.stem}\", \"\"]\n\n    # Module docstring\n    module_docs = [d for d in docs if d.type == 'module']\n    if module_docs:\n        lines.append(module_docs[0].full_text)\n        lines.append(\"\")\n\n    # Classes\n    class_docs = [d for d in docs if d.type == 'class']\n    if class_docs:\n        lines.append(\"## Classes\")\n        for d in class_docs:\n            lines.append(f\"- **{d.name}**: {d.summary}\")\n        lines.append(\"\")\n\n    # Functions\n    func_docs = [d for d in docs if d.type == 'function']\n    if func_docs:\n        lines.append(\"## Functions\")\n        for d in func_docs[:10]:\n            lines.append(f\"- **{d.name}**: {d.summary}\")\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 208, "line_end": 235, "language": "python", "name": "get_module_summary"}, "b59698c5a02a_func_main": {"id": "b59698c5a02a_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Documentation Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_documentation(root)\n        return 0\n\n    if '--search' in sys.argv and args:\n        query = args[0]\n        results = search_docs(query, root)\n        Console.info(f\"Found {len(results)} results for '{query}':\")\n        for r in results[:15]:\n            print(f\"  [{r.type}] {r.name}: {r.summary[:50]}...\")\n        return 0\n\n    if args:\n        # Show module summary\n        file_path = Path(args[0])\n        if file_path.exists():\n            summary = get_module_summary(file_path)\n            print(summary)\n    else:\n        # Just index\n        index_documentation(root)\n\n    return 0", "chunk_type": "function", "line_start": 238, "line_end": 267, "language": "python", "name": "main"}, "b59698c5a02a_class_DocItem": {"id": "b59698c5a02a_class_DocItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\doc_index.py", "content": "class DocItem:\n    \"\"\"A documentation item.\"\"\"\n    type: str  # 'readme', 'module', 'class', 'function'\n    name: str\n    path: str\n    summary: str\n    full_text: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "DocItem"}, "942e3b87b168_file": {"id": "942e3b87b168_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "\"\"\"\nEmbeddings Generation\n=====================\nGenerate vector embeddings for code semantic search.\nUses sentence-transformers or falls back to TF-IDF.\n\nUsage:\n    from scripts.embeddings import embed_text, embed_code\n\"\"\"\n\nimport sys\nimport re\nimport math\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass\n\nfrom .utils import Console\n\n\n# Try to import sentence-transformers\ntry:\n    from sentence_transformers import SentenceTransformer\n    TRANSFORMERS_AVAILABLE = True\nexcept ImportError:\n    TRANSFORMERS_AVAILABLE = False\n\n# Try to import numpy\ntry:\n    import numpy as np\n    NUMPY_AVAILABLE = True\nexcept ImportError:\n    NUMPY_AVAILABLE = False\n\n\n# Model cache\n_model = None\n_model_name = \"all-MiniLM-L6-v2\"  # 22MB, good quality/speed balance\n\n\ndef get_model():\n    \"\"\"Get or load embedding model.\"\"\"\n    global _model\n\n    if _model is not None:\n        return _model\n\n    if not TRANSFORMERS_AVAILABLE:\n        return None\n\n    try:\n        # Try to load from local cache first\n        _model = SentenceTransformer(_model_name)\n        return _model\n    except Exception as e:\n        Console.warn(f\"Could not load embedding model: {e}\")\n        return None\n\n\ndef embed_text(text: str) -> Optional[List[float]]:\n    \"\"\"Generate embedding for text.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True)\n        return embedding.tolist()\n\n    # Fallback to simple TF-IDF-like embedding\n    return _fallback_embed(text)\n\n\ndef embed_texts(texts: List[str]) -> List[List[float]]:\n    \"\"\"Generate embeddings for multiple texts.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embeddings = model.encode(texts, convert_to_numpy=True)\n        return embeddings.tolist()\n\n    # Fallback\n    return [_fallback_embed(t) for t in texts]\n\n\ndef embed_code(code: str, language: str = \"python\") -> Optional[List[float]]:\n    \"\"\"Generate embedding for code with language-awar", "chunk_type": "file", "line_start": 1, "line_end": 217, "language": "python", "name": "embeddings.py"}, "942e3b87b168_func_get_model": {"id": "942e3b87b168_func_get_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def get_model():\n    \"\"\"Get or load embedding model.\"\"\"\n    global _model\n\n    if _model is not None:\n        return _model\n\n    if not TRANSFORMERS_AVAILABLE:\n        return None\n\n    try:\n        # Try to load from local cache first\n        _model = SentenceTransformer(_model_name)\n        return _model\n    except Exception as e:\n        Console.warn(f\"Could not load embedding model: {e}\")\n        return None", "chunk_type": "function", "line_start": 41, "line_end": 57, "language": "python", "name": "get_model"}, "942e3b87b168_func_embed_text": {"id": "942e3b87b168_func_embed_text", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_text(text: str) -> Optional[List[float]]:\n    \"\"\"Generate embedding for text.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True)\n        return embedding.tolist()\n\n    # Fallback to simple TF-IDF-like embedding\n    return _fallback_embed(text)", "chunk_type": "function", "line_start": 60, "line_end": 69, "language": "python", "name": "embed_text"}, "942e3b87b168_func_embed_texts": {"id": "942e3b87b168_func_embed_texts", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_texts(texts: List[str]) -> List[List[float]]:\n    \"\"\"Generate embeddings for multiple texts.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embeddings = model.encode(texts, convert_to_numpy=True)\n        return embeddings.tolist()\n\n    # Fallback\n    return [_fallback_embed(t) for t in texts]", "chunk_type": "function", "line_start": 72, "line_end": 81, "language": "python", "name": "embed_texts"}, "942e3b87b168_func_embed_code": {"id": "942e3b87b168_func_embed_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_code(code: str, language: str = \"python\") -> Optional[List[float]]:\n    \"\"\"Generate embedding for code with language-aware preprocessing.\"\"\"\n    # Preprocess code for better embeddings\n    processed = _preprocess_code(code, language)\n    return embed_text(processed)", "chunk_type": "function", "line_start": 84, "line_end": 88, "language": "python", "name": "embed_code"}, "942e3b87b168_func__preprocess_code": {"id": "942e3b87b168_func__preprocess_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def _preprocess_code(code: str, language: str) -> str:\n    \"\"\"Preprocess code for embedding.\"\"\"\n    # Remove comments based on language\n    if language in ('python', 'ruby'):\n        code = re.sub(r'#.*$', '', code, flags=re.MULTILINE)\n    elif language in ('javascript', 'typescript', 'java', 'c', 'cpp', 'go', 'rust'):\n        code = re.sub(r'//.*$', '', code, flags=re.MULTILINE)\n        code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n\n    # Normalize whitespace\n    code = ' '.join(code.split())\n\n    # Split camelCase and snake_case for better semantic matching\n    code = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', code)\n    code = code.replace('_', ' ')\n\n    return code.lower()", "chunk_type": "function", "line_start": 91, "line_end": 107, "language": "python", "name": "_preprocess_code"}, "942e3b87b168_func__fallback_embed": {"id": "942e3b87b168_func__fallback_embed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def _fallback_embed(text: str, dim: int = 384) -> List[float]:\n    \"\"\"Simple fallback embedding using hashing + TF-IDF-like approach.\"\"\"\n    # Tokenize\n    tokens = re.findall(r'[a-z0-9]+', text.lower())\n\n    if not tokens:\n        return [0.0] * dim\n\n    # Create embedding via feature hashing\n    embedding = [0.0] * dim\n\n    for token in tokens:\n        # Hash token to get index\n        h = hash(token)\n        idx = abs(h) % dim\n\n        # Add weighted value\n        tf = tokens.count(token) / len(tokens)\n        embedding[idx] += tf\n\n    # Normalize\n    norm = math.sqrt(sum(x * x for x in embedding))\n    if norm > 0:\n        embedding = [x / norm for x in embedding]\n\n    return embedding", "chunk_type": "function", "line_start": 110, "line_end": 135, "language": "python", "name": "_fallback_embed"}, "942e3b87b168_func_cosine_similarity": {"id": "942e3b87b168_func_cosine_similarity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def cosine_similarity(a: List[float], b: List[float]) -> float:\n    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n    if len(a) != len(b):\n        return 0.0\n\n    dot = sum(x * y for x, y in zip(a, b))\n    norm_a = math.sqrt(sum(x * x for x in a))\n    norm_b = math.sqrt(sum(x * x for x in b))\n\n    if norm_a == 0 or norm_b == 0:\n        return 0.0\n\n    return dot / (norm_a * norm_b)", "chunk_type": "function", "line_start": 138, "line_end": 150, "language": "python", "name": "cosine_similarity"}, "942e3b87b168_func_embedding_dimension": {"id": "942e3b87b168_func_embedding_dimension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embedding_dimension() -> int:\n    \"\"\"Get embedding dimension.\"\"\"\n    model = get_model()\n    if model is not None:\n        return model.get_sentence_embedding_dimension()\n    return 384  # Fallback dimension", "chunk_type": "function", "line_start": 153, "line_end": 158, "language": "python", "name": "embedding_dimension"}, "942e3b87b168_func_is_transformers_available": {"id": "942e3b87b168_func_is_transformers_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def is_transformers_available() -> bool:\n    \"\"\"Check if sentence-transformers is available.\"\"\"\n    return TRANSFORMERS_AVAILABLE", "chunk_type": "function", "line_start": 161, "line_end": 163, "language": "python", "name": "is_transformers_available"}, "942e3b87b168_func_embed_with_info": {"id": "942e3b87b168_func_embed_with_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_with_info(text: str) -> EmbeddingResult:\n    \"\"\"Generate embedding with metadata.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True).tolist()\n        return EmbeddingResult(text=text, embedding=embedding, method='transformer')\n\n    embedding = _fallback_embed(text)\n    return EmbeddingResult(text=text, embedding=embedding, method='fallback')", "chunk_type": "function", "line_start": 174, "line_end": 183, "language": "python", "name": "embed_with_info"}, "942e3b87b168_func_main": {"id": "942e3b87b168_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Embedding Generation\")\n\n    if TRANSFORMERS_AVAILABLE:\n        Console.ok(\"sentence-transformers available\")\n        model = get_model()\n        if model:\n            Console.ok(f\"Model: {_model_name}\")\n            Console.ok(f\"Dimension: {embedding_dimension()}\")\n    else:\n        Console.warn(\"sentence-transformers not available, using fallback\")\n        Console.info(f\"Fallback dimension: 384\")\n\n    # Test embedding\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        text = ' '.join(args)\n        Console.info(f\"Embedding: {text[:50]}...\")\n\n        result = embed_with_info(text)\n        Console.ok(f\"Method: {result.method}\")\n        Console.ok(f\"Dimension: {len(result.embedding)}\")\n        Console.ok(f\"Sample values: {result.embedding[:5]}\")\n\n    return 0", "chunk_type": "function", "line_start": 186, "line_end": 212, "language": "python", "name": "main"}, "942e3b87b168_class_EmbeddingResult": {"id": "942e3b87b168_class_EmbeddingResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\embeddings.py", "content": "class EmbeddingResult:\n    \"\"\"Result of embedding generation.\"\"\"\n    text: str\n    embedding: List[float]\n    method: str  # 'transformer' or 'fallback'", "chunk_type": "class", "line_start": 167, "line_end": 171, "language": "python", "name": "EmbeddingResult"}, "0e4701a6a4ba_file": {"id": "0e4701a6a4ba_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "\"\"\"\nError Pattern Analyzer\n======================\nAnalyze exception handling and error patterns in code.\n\nUsage:\n    python errors.py [path]\n    python -m scripts.errors src/\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass ErrorPattern:\n    \"\"\"An error handling pattern.\"\"\"\n    path: Path\n    line: int\n    pattern_type: str  # 'bare_except', 'swallowed', 'broad', 'reraise', 'logged'\n    exception_type: Optional[str] = None\n    severity: str = 'medium'\n    description: str = \"\"\n\n\n@dataclass\nclass ErrorReport:\n    \"\"\"Complete error analysis report.\"\"\"\n    patterns: List[ErrorPattern] = field(default_factory=list)\n    exception_usage: Counter = field(default_factory=Counter)\n    total_try_blocks: int = 0\n\n    @property\n    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{exc}` | {count} |\")\n            lines.append(\"\")\n\n        # Issues by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [p for p in self.patterns if p.severity == severity]\n            if not items:\n         ", "chunk_type": "file", "line_start": 1, "line_end": 341, "language": "python", "name": "errors.py"}, "0e4701a6a4ba_func_analyze_file": {"id": "0e4701a6a4ba_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "def analyze_file(path: Path) -> Tuple[List[ErrorPattern], Counter, int]:\n    \"\"\"Analyze a file for error patterns.\"\"\"\n    patterns = []\n    exception_usage: Counter = Counter()\n    try_count = 0\n\n    tree = parse_file(path)\n    if tree is None:\n        return patterns, exception_usage, try_count\n\n    # Exception handling analysis\n    exc_analyzer = ExceptionAnalyzer(path)\n    exc_analyzer.visit(tree)\n    patterns.extend(exc_analyzer.patterns)\n    exception_usage.update(exc_analyzer.exception_usage)\n    try_count = exc_analyzer.try_count\n\n    # Raise analysis\n    raise_analyzer = RaiseAnalyzer(path)\n    raise_analyzer.visit(tree)\n    patterns.extend(raise_analyzer.patterns)\n    exception_usage.update(raise_analyzer.exception_usage)\n\n    return patterns, exception_usage, try_count", "chunk_type": "function", "line_start": 254, "line_end": 277, "language": "python", "name": "analyze_file"}, "0e4701a6a4ba_func_analyze_project": {"id": "0e4701a6a4ba_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> ErrorReport:\n    \"\"\"Analyze project for error patterns.\"\"\"\n    report = ErrorReport()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        patterns, exc_usage, try_count = analyze_file(path)\n        report.patterns.extend(patterns)\n        report.exception_usage.update(exc_usage)\n        report.total_try_blocks += try_count\n\n    return report", "chunk_type": "function", "line_start": 280, "line_end": 298, "language": "python", "name": "analyze_project"}, "0e4701a6a4ba_func_main": {"id": "0e4701a6a4ba_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Error Pattern Analyzer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    issues = report.issues\n    if issues:\n        Console.warn(f\"Found {len(issues)} error handling issues\")\n    else:\n        Console.ok(\"No error handling issues found\")\n\n    Console.info(f\"Analyzed {report.total_try_blocks} try blocks\")\n\n    return 0", "chunk_type": "function", "line_start": 305, "line_end": 336, "language": "python", "name": "main"}, "0e4701a6a4ba_func_issues": {"id": "0e4701a6a4ba_func_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]", "chunk_type": "function", "line_start": 46, "line_end": 47, "language": "python", "name": "issues"}, "0e4701a6a4ba_func_to_markdown": {"id": "0e4701a6a4ba_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{exc}` | {count} |\")\n            lines.append(\"\")\n\n        # Issues by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [p for p in self.patterns if p.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Severity\")\n            lines.append(\"\")\n\n          ", "chunk_type": "function", "line_start": 49, "line_end": 86, "language": "python", "name": "to_markdown"}, "0e4701a6a4ba_func___init__": {"id": "0e4701a6a4ba_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()", "chunk_type": "function", "line_start": 229, "line_end": 232, "language": "python", "name": "__init__"}, "0e4701a6a4ba_func_visit_Try": {"id": "0e4701a6a4ba_func_visit_Try", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def visit_Try(self, node: ast.Try):\n        self.try_count += 1\n\n        for handler in node.handlers:\n            self._analyze_handler(handler)\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 113, "line_end": 119, "language": "python", "name": "visit_Try"}, "0e4701a6a4ba_func__analyze_handler": {"id": "0e4701a6a4ba_func__analyze_handler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def _analyze_handler(self, handler: ast.ExceptHandler):\n        # Get exception type\n        if handler.type is None:\n            # Bare except\n            self.patterns.append(ErrorPattern(\n                path=self.path,\n                line=handler.lineno,\n                pattern_type='bare_except',\n                severity='high',\n                description=\"Bare 'except:' catches all exceptions including KeyboardInterrupt\"\n            ))\n            self.exception_usage['Exception'] += 1\n        elif isinstance(handler.type, ast.Name):\n            exc_name = handler.type.id\n            self.exception_usage[exc_name] += 1\n\n            # Check for broad exception\n            if exc_name == 'Exception':\n                self.patterns.append(ErrorPattern(\n                    path=self.path,\n                    line=handler.lineno,\n                    pattern_type='broad_exception',\n                    exception_type=exc_name,\n                    severity='medium',\n                ", "chunk_type": "function", "line_start": 121, "line_end": 179, "language": "python", "name": "_analyze_handler"}, "0e4701a6a4ba_func__is_swallowed": {"id": "0e4701a6a4ba_func__is_swallowed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def _is_swallowed(self, handler: ast.ExceptHandler) -> bool:\n        \"\"\"Check if exception is swallowed (ignored).\"\"\"\n        if not handler.body:\n            return True\n\n        if len(handler.body) == 1:\n            stmt = handler.body[0]\n            # Just 'pass'\n            if isinstance(stmt, ast.Pass):\n                return True\n            # Just '...'\n            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant):\n                if stmt.value.value is ...:\n                    return True\n\n        # Check if there's any logging or re-raise\n        for node in ast.walk(handler):\n            if isinstance(node, ast.Raise):\n                return False\n            if isinstance(node, ast.Call):\n                func = self._get_func_name(node.func)\n                if any(x in func for x in ['log', 'error', 'warn', 'print', 'logger']):\n                    return False\n\n        return False", "chunk_type": "function", "line_start": 181, "line_end": 205, "language": "python", "name": "_is_swallowed"}, "0e4701a6a4ba_func__has_logging": {"id": "0e4701a6a4ba_func__has_logging", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def _has_logging(self, handler: ast.ExceptHandler) -> bool:\n        \"\"\"Check if handler has logging.\"\"\"\n        for node in ast.walk(handler):\n            if isinstance(node, ast.Call):\n                func = self._get_func_name(node.func)\n                if any(x in func for x in ['logging', 'logger', 'log']):\n                    return True\n        return False", "chunk_type": "function", "line_start": 207, "line_end": 214, "language": "python", "name": "_has_logging"}, "0e4701a6a4ba_func__get_func_name": {"id": "0e4701a6a4ba_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id.lower()\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\".lower()\n            return node.attr.lower()\n        return \"\"", "chunk_type": "function", "line_start": 216, "line_end": 223, "language": "python", "name": "_get_func_name"}, "0e4701a6a4ba_func_visit_Raise": {"id": "0e4701a6a4ba_func_visit_Raise", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "    def visit_Raise(self, node: ast.Raise):\n        if node.exc:\n            if isinstance(node.exc, ast.Call):\n                if isinstance(node.exc.func, ast.Name):\n                    self.exception_usage[node.exc.func.id] += 1\n\n                    # Check for generic Exception raise\n                    if node.exc.func.id == 'Exception':\n                        self.patterns.append(ErrorPattern(\n                            path=self.path,\n                            line=node.lineno,\n                            pattern_type='generic_raise',\n                            exception_type='Exception',\n                            severity='low',\n                            description=\"Raising generic 'Exception', consider using specific exception types\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 234, "line_end": 251, "language": "python", "name": "visit_Raise"}, "0e4701a6a4ba_class_ErrorPattern": {"id": "0e4701a6a4ba_class_ErrorPattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "class ErrorPattern:\n    \"\"\"An error handling pattern.\"\"\"\n    path: Path\n    line: int\n    pattern_type: str  # 'bare_except', 'swallowed', 'broad', 'reraise', 'logged'\n    exception_type: Optional[str] = None\n    severity: str = 'medium'\n    description: str = \"\"", "chunk_type": "class", "line_start": 28, "line_end": 35, "language": "python", "name": "ErrorPattern"}, "0e4701a6a4ba_class_ErrorReport": {"id": "0e4701a6a4ba_class_ErrorReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "class ErrorReport:\n    \"\"\"Complete error analysis report.\"\"\"\n    patterns: List[ErrorPattern] = field(default_factory=list)\n    exception_usage: Counter = field(default_factory=Counter)\n    total_try_blocks: int = 0\n\n    @property\n    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{e", "chunk_type": "class", "line_start": 39, "line_end": 86, "language": "python", "name": "ErrorReport"}, "0e4701a6a4ba_class_ExceptionAnalyzer": {"id": "0e4701a6a4ba_class_ExceptionAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "class ExceptionAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze exception handling patterns.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()\n        self.try_count = 0\n\n    def visit_Try(self, node: ast.Try):\n        self.try_count += 1\n\n        for handler in node.handlers:\n            self._analyze_handler(handler)\n\n        self.generic_visit(node)\n\n    def _analyze_handler(self, handler: ast.ExceptHandler):\n        # Get exception type\n        if handler.type is None:\n            # Bare except\n            self.patterns.append(ErrorPattern(\n                path=self.path,\n                line=handler.lineno,\n                pattern_type='bare_except',\n                severity='high',\n                description=\"Bare 'except:' catches all exceptions including KeyboardInterrupt\"\n            ))\n            self.exception_usage['Exception'] += 1\n        elif isinstance(handler.type", "chunk_type": "class", "line_start": 104, "line_end": 223, "language": "python", "name": "ExceptionAnalyzer"}, "0e4701a6a4ba_class_RaiseAnalyzer": {"id": "0e4701a6a4ba_class_RaiseAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\errors.py", "content": "class RaiseAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze raise statements.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()\n\n    def visit_Raise(self, node: ast.Raise):\n        if node.exc:\n            if isinstance(node.exc, ast.Call):\n                if isinstance(node.exc.func, ast.Name):\n                    self.exception_usage[node.exc.func.id] += 1\n\n                    # Check for generic Exception raise\n                    if node.exc.func.id == 'Exception':\n                        self.patterns.append(ErrorPattern(\n                            path=self.path,\n                            line=node.lineno,\n                            pattern_type='generic_raise',\n                            exception_type='Exception',\n                            severity='low',\n                            description=\"Raising generic 'Exception', consider using specific exception types\"\n   ", "chunk_type": "class", "line_start": 226, "line_end": 251, "language": "python", "name": "RaiseAnalyzer"}, "4c890072d29f_file": {"id": "4c890072d29f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "\"\"\"\nSmart File Finder\n=================\nFind files by natural language queries and patterns.\n\nUsage:\n    python finder.py \"authentication\" [path]\n    python -m scripts.finder \"database handler\"\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    run_git_command,\n    Console\n)\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result.\"\"\"\n    path: Path\n    score: float\n    match_type: str  # 'filename', 'content', 'import', 'function', 'class'\n    context: str\n    line: Optional[int] = None\n\n\n@dataclass\nclass SearchResults:\n    \"\"\"Collection of search results.\"\"\"\n    query: str\n    results: List[SearchResult] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n            for r in sorted(items, key=lambda x: x.score, reverse=True)[:10]:\n                if r.line:\n                    lines.append(f\"- `{r.path}:{r.line}` (score: {r.score:.2f})\")\n                else:\n                    lines.append(f\"- `{r.path}` (score: {r.score:.2f})\")\n                lines.appen", "chunk_type": "file", "line_start": 1, "line_end": 300, "language": "python", "name": "finder.py"}, "4c890072d29f_func_expand_query": {"id": "4c890072d29f_func_expand_query", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "def expand_query(query: str) -> List[str]:\n    \"\"\"Expand query into search terms.\"\"\"\n    terms = re.findall(r'[a-z0-9]+', query.lower())\n    expanded = list(terms)\n\n    for term in terms:\n        if term in QUERY_EXPANSIONS:\n            expanded.extend(QUERY_EXPANSIONS[term])\n\n    return list(set(expanded))", "chunk_type": "function", "line_start": 97, "line_end": 106, "language": "python", "name": "expand_query"}, "4c890072d29f_func_score_filename_match": {"id": "4c890072d29f_func_score_filename_match", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "def score_filename_match(filename: str, terms: List[str]) -> float:\n    \"\"\"Score a filename against search terms.\"\"\"\n    name_lower = filename.lower()\n    score = 0.0\n\n    for term in terms:\n        if term in name_lower:\n            # Exact match gets higher score\n            score += 2.0\n            # Even higher if at word boundary\n            if f\"_{term}\" in name_lower or name_lower.startswith(term):\n                score += 1.0\n\n    return score", "chunk_type": "function", "line_start": 109, "line_end": 122, "language": "python", "name": "score_filename_match"}, "4c890072d29f_func_search_file_content": {"id": "4c890072d29f_func_search_file_content", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "def search_file_content(\n    path: Path,\n    terms: List[str]\n) -> List[Tuple[int, str, float]]:\n    \"\"\"Search file content for terms.\"\"\"\n    matches = []\n\n    try:\n        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return matches\n\n    for i, line in enumerate(lines, 1):\n        line_lower = line.lower()\n        score = sum(1.0 for term in terms if term in line_lower)\n        if score > 0:\n            matches.append((i, line.strip()[:100], score))\n\n    return matches", "chunk_type": "function", "line_start": 125, "line_end": 144, "language": "python", "name": "search_file_content"}, "4c890072d29f_func_search_module_structure": {"id": "4c890072d29f_func_search_module_structure", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "def search_module_structure(\n    path: Path,\n    terms: List[str]\n) -> List[SearchResult]:\n    \"\"\"Search module functions and classes.\"\"\"\n    results = []\n\n    module = analyze_module(path)\n    if module is None:\n        return results\n\n    # Search functions\n    for func in module.functions:\n        name_lower = func.name.lower()\n        score = sum(2.0 for term in terms if term in name_lower)\n\n        # Check docstring\n        if func.docstring:\n            doc_lower = func.docstring.lower()\n            score += sum(0.5 for term in terms if term in doc_lower)\n\n        if score > 0:\n            results.append(SearchResult(\n                path=path,\n                score=score,\n                match_type='function',\n                context=f\"def {func.name}(): {func.docstring or ''}\",\n                line=func.lineno\n            ))\n\n    # Search classes\n    for cls in module.classes:\n        name_lower = cls.name.lower()\n        score = sum(2.0 for term in terms if term in name_lower)", "chunk_type": "function", "line_start": 147, "line_end": 206, "language": "python", "name": "search_module_structure"}, "4c890072d29f_func_find_files": {"id": "4c890072d29f_func_find_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "def find_files(\n    query: str,\n    root: Path,\n    limit: int = 20,\n    exclude_patterns: List[str] = None\n) -> SearchResults:\n    \"\"\"Find files matching a query.\"\"\"\n    results = SearchResults(query=query)\n    terms = expand_query(query)\n\n    Console.info(f\"Searching for: '{query}'\")\n    Console.info(f\"Terms: {', '.join(terms)}\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    all_results = []\n\n    for path in files:\n        # Filename match\n        filename_score = score_filename_match(path.name, terms)\n        if filename_score > 0:\n            all_results.append(SearchResult(\n                path=path,\n                score=filename_score,\n                match_type='filename',\n                context=path.name\n            ))\n\n        # Module structure search\n        structure_results = search_module_structure(path, terms)\n        all_results.extend(structure_results)\n\n        # Content search (only if not foun", "chunk_type": "function", "line_start": 209, "line_end": 258, "language": "python", "name": "find_files"}, "4c890072d29f_func_main": {"id": "4c890072d29f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Smart File Finder\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.fail(\"Usage: mcp find <query> [path]\")\n        print(\"\\nExamples:\")\n        print('  mcp find \"authentication\"')\n        print('  mcp find \"database handler\"')\n        print('  mcp find \"api endpoint\" src/')\n        return 1\n\n    query = args[0]\n\n    if len(args) > 1:\n        path = Path(args[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Searching in: {path}\")\n\n    results = find_files(query, path)\n\n    print(results.to_markdown())\n\n    Console.ok(f\"Found {len(results.results)} results\")\n\n    return 0", "chunk_type": "function", "line_start": 261, "line_end": 295, "language": "python", "name": "main"}, "4c890072d29f_func_to_markdown": {"id": "4c890072d29f_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n            for r in sorted(items, key=lambda x: x.score, reverse=True)[:10]:\n                if r.line:\n                    lines.append(f\"- `{r.pat", "chunk_type": "function", "line_start": 43, "line_end": 79, "language": "python", "name": "to_markdown"}, "4c890072d29f_class_SearchResult": {"id": "4c890072d29f_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "class SearchResult:\n    \"\"\"A search result.\"\"\"\n    path: Path\n    score: float\n    match_type: str  # 'filename', 'content', 'import', 'function', 'class'\n    context: str\n    line: Optional[int] = None", "chunk_type": "class", "line_start": 28, "line_end": 34, "language": "python", "name": "SearchResult"}, "4c890072d29f_class_SearchResults": {"id": "4c890072d29f_class_SearchResults", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\finder.py", "content": "class SearchResults:\n    \"\"\"Collection of search results.\"\"\"\n    query: str\n    results: List[SearchResult] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n          ", "chunk_type": "class", "line_start": 38, "line_end": 79, "language": "python", "name": "SearchResults"}, "53b586a3f0cd_file": {"id": "53b586a3f0cd_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "\"\"\"\nAuto-Fix Tool\n=============\nAutomatically fix common code issues.\n\nUsage:\n    python fix.py [path] [--lint] [--format] [--imports]\n    python -m scripts.fix src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass FixResult:\n    \"\"\"Result of a fix operation.\"\"\"\n    path: Path\n    fix_type: str\n    original: str\n    fixed: str\n    line: int\n    description: str\n\n\n@dataclass\nclass FixReport:\n    \"\"\"Complete fix report.\"\"\"\n    fixes_applied: List[FixResult] = field(default_factory=list)\n    files_modified: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        return \"\\n\".join(lines)\n\n\ndef sort_imports(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Sort and organize imports.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n\n    # Find import block\n    import_lines = []\n    import_start = None\n    import_end = None\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n        if stripped.startswith('import ') or stripped.startswith('fro", "chunk_type": "file", "line_start": 1, "line_end": 476, "language": "python", "name": "fix.py"}, "53b586a3f0cd_func_sort_imports": {"id": "53b586a3f0cd_func_sort_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "def sort_imports(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Sort and organize imports.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n\n    # Find import block\n    import_lines = []\n    import_start = None\n    import_end = None\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n        if stripped.startswith('import ') or stripped.startswith('from '):\n            if import_start is None:\n                import_start = i\n            import_end = i\n            import_lines.append((i, line))\n        elif import_start is not None and stripped and not stripped.startswith('#'):\n            break\n\n    if not import_lines:\n        return content, fixes\n\n    # Group imports\n    stdlib = []\n    third_party = []\n    local = []\n\n    STDLIB = {\n        'os', 'sys', 're', 'json', 'pathlib', 'typing', 'collections',\n        'itertools', 'functools', 'datetime', 'time', 'logging', 'ast',\n        'subprocess', 'threading', 'multiprocessing', 'queue', 'socket',\n        'ht", "chunk_type": "function", "line_start": 73, "line_end": 165, "language": "python", "name": "sort_imports"}, "53b586a3f0cd_func_fix_trailing_whitespace": {"id": "53b586a3f0cd_func_fix_trailing_whitespace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_trailing_whitespace(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Remove trailing whitespace.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n    fixed_lines = []\n\n    for i, line in enumerate(lines):\n        if line != line.rstrip():\n            fixes.append(FixResult(\n                path=Path(''),\n                fix_type='whitespace',\n                original=line,\n                fixed=line.rstrip(),\n                line=i + 1,\n                description='Removed trailing whitespace'\n            ))\n            fixed_lines.append(line.rstrip())\n        else:\n            fixed_lines.append(line)\n\n    return '\\n'.join(fixed_lines), fixes", "chunk_type": "function", "line_start": 168, "line_end": 188, "language": "python", "name": "fix_trailing_whitespace"}, "53b586a3f0cd_func_fix_blank_lines": {"id": "53b586a3f0cd_func_fix_blank_lines", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_blank_lines(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Fix excessive blank lines.\"\"\"\n    fixes = []\n\n    # Replace 3+ blank lines with 2\n    pattern = r'\\n{4,}'\n    if re.search(pattern, content):\n        content = re.sub(pattern, '\\n\\n\\n', content)\n        fixes.append(FixResult(\n            path=Path(''),\n            fix_type='formatting',\n            original='',\n            fixed='',\n            line=0,\n            description='Reduced excessive blank lines'\n        ))\n\n    # Ensure file ends with single newline\n    if content and not content.endswith('\\n'):\n        content += '\\n'\n        fixes.append(FixResult(\n            path=Path(''),\n            fix_type='formatting',\n            original='',\n            fixed='',\n            line=0,\n            description='Added final newline'\n        ))\n\n    return content, fixes", "chunk_type": "function", "line_start": 191, "line_end": 220, "language": "python", "name": "fix_blank_lines"}, "53b586a3f0cd_func_remove_unused_imports": {"id": "53b586a3f0cd_func_remove_unused_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "def remove_unused_imports(path: Path, content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Remove unused imports.\"\"\"\n    fixes = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return content, fixes\n\n    # Find all imports\n    imported_names = {}  # name -> line\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                name = alias.asname or alias.name.split('.')[0]\n                imported_names[name] = node.lineno\n        elif isinstance(node, ast.ImportFrom):\n            for alias in node.names:\n                if alias.name != '*':\n                    name = alias.asname or alias.name\n                    imported_names[name] = node.lineno\n\n    # Find all name usages\n    used_names: Set[str] = set()\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Name):\n            used_names.add(node.id)\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n     ", "chunk_type": "function", "line_start": 223, "line_end": 286, "language": "python", "name": "remove_unused_imports"}, "53b586a3f0cd_func_fix_file": {"id": "53b586a3f0cd_func_fix_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_file(\n    path: Path,\n    fix_imports: bool = True,\n    fix_whitespace: bool = True,\n    fix_formatting: bool = True,\n    fix_unused: bool = True,\n    dry_run: bool = False\n) -> List[FixResult]:\n    \"\"\"Fix issues in a single file.\"\"\"\n    all_fixes = []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            content = f.read()\n    except Exception:\n        return all_fixes\n\n    original = content\n\n    # Apply fixes\n    if fix_imports:\n        content, fixes = sort_imports(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_whitespace:\n        content, fixes = fix_trailing_whitespace(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_formatting:\n        content, fixes = fix_blank_lines(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_unused:\n        content, fixes = remove_unused_imports(path, c", "chunk_type": "function", "line_start": 289, "line_end": 338, "language": "python", "name": "fix_file"}, "53b586a3f0cd_func_fix_project": {"id": "53b586a3f0cd_func_fix_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_project(\n    root: Path,\n    fix_imports: bool = True,\n    fix_whitespace: bool = True,\n    fix_formatting: bool = True,\n    fix_unused: bool = True,\n    dry_run: bool = False,\n    exclude_patterns: List[str] = None\n) -> FixReport:\n    \"\"\"Fix issues in a project.\"\"\"\n    report = FixReport()\n\n    Console.info(f\"Fixing issues in {root}...\")\n    if dry_run:\n        Console.warn(\"DRY RUN - no files will be modified\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        fixes = fix_file(\n            path,\n            fix_imports=fix_imports,\n            fix_whitespace=fix_whitespace,\n            fix_formatting=fix_formatting,\n            fix_unused=fix_unused,\n            dry_run=dry_run\n        )\n\n        if fixes:\n            report.files_modified += 1\n            report.fixes_applied.extend(fixes)\n\n    return report", "chunk_type": "function", "line_start": 341, "line_end": 374, "language": "python", "name": "fix_project"}, "53b586a3f0cd_func_fix_staged_files": {"id": "53b586a3f0cd_func_fix_staged_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_staged_files(dry_run: bool = False) -> FixReport:\n    \"\"\"Fix only git staged files.\"\"\"\n    import subprocess\n\n    report = FixReport()\n\n    try:\n        result = subprocess.run(\n            ['git', 'diff', '--cached', '--name-only', '--diff-filter=ACM'],\n            capture_output=True, text=True\n        )\n        staged = [f.strip() for f in result.stdout.strip().split('\\n') if f.strip().endswith('.py')]\n    except Exception:\n        return report\n\n    if not staged:\n        return report\n\n    Console.info(f\"Fixing {len(staged)} staged files...\")\n\n    for file_path in staged:\n        path = Path(file_path)\n        if path.exists():\n            fixes = fix_file(path, dry_run=dry_run)\n            if fixes:\n                report.files_modified += 1\n                report.fixes_applied.extend(fixes)\n\n    return report", "chunk_type": "function", "line_start": 377, "line_end": 405, "language": "python", "name": "fix_staged_files"}, "53b586a3f0cd_func_main": {"id": "53b586a3f0cd_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Fix Tool\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    dry_run = '--dry-run' in sys.argv\n    safe_only = '--safe' in sys.argv\n    apply_mode = '--apply' in sys.argv\n    staged_only = '--staged' in sys.argv\n\n    # Safe mode: only whitespace, imports, formatting (no complex changes)\n    if safe_only:\n        fix_imports = True\n        fix_format = True\n        fix_lint = False  # Don't remove unused imports in safe mode\n    else:\n        fix_imports = '--imports' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n        fix_format = '--format' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n        fix_lint = '--lint' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n\n    # Apply mode: actually apply fixes (not dry run)\n", "chunk_type": "function", "line_start": 408, "line_end": 470, "language": "python", "name": "main"}, "53b586a3f0cd_func_to_markdown": {"id": "53b586a3f0cd_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 43, "line_end": 70, "language": "python", "name": "to_markdown"}, "53b586a3f0cd_class_FixResult": {"id": "53b586a3f0cd_class_FixResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "class FixResult:\n    \"\"\"Result of a fix operation.\"\"\"\n    path: Path\n    fix_type: str\n    original: str\n    fixed: str\n    line: int\n    description: str", "chunk_type": "class", "line_start": 27, "line_end": 34, "language": "python", "name": "FixResult"}, "53b586a3f0cd_class_FixReport": {"id": "53b586a3f0cd_class_FixReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\fix.py", "content": "class FixReport:\n    \"\"\"Complete fix report.\"\"\"\n    fixes_applied: List[FixResult] = field(default_factory=list)\n    files_modified: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        retur", "chunk_type": "class", "line_start": 38, "line_end": 70, "language": "python", "name": "FixReport"}, "2808cf1cd138_file": {"id": "2808cf1cd138_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "\"\"\"\nGit History Index\n=================\nIndex git commits, blame, and file evolution for AI agents.\n\nUsage:\n    python mcp.py git-history [file]\n    python mcp.py blame [file]\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport re\nimport subprocess\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Commit:\n    \"\"\"A git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    email: str\n    date: str\n    message: str\n    files_changed: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass BlameInfo:\n    \"\"\"Blame info for a line.\"\"\"\n    line_num: int\n    commit_hash: str\n    author: str\n    date: str\n    content: str\n\n\n@dataclass\nclass FileHistory:\n    \"\"\"History of a file.\"\"\"\n    path: str\n    commits: List[Commit] = field(default_factory=list)\n    authors: List[str] = field(default_factory=list)\n    first_commit: Optional[str] = None\n    last_commit: Optional[str] = None\n\n\ndef run_git(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"Run git command and return output.\"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd()\n        )\n        if result.returncode == 0:\n            return result.stdout.strip()\n        return None\n    except Exception:\n        return None\n\n\ndef get_commits(\n    path: Path = None,\n    since: str = None,\n    limit: int = 100,\n    file_path: Path = None\n) -> List[Commit]:\n    \"\"\"Get list of commits.\"\"\"\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        '--name-only'\n    ]\n\n    if since:\n        args.append(f'--since={since}')\n\n    if file_path:\n        args.extend(['--', str(file_path)])\n\n    output = run_git(args, path)\n    if not output:\n        return []\n\n    commits = []\n    current_commit = None\n\n    for line in ou", "chunk_type": "file", "line_start": 1, "line_end": 328, "language": "python", "name": "git_index.py"}, "2808cf1cd138_func_run_git": {"id": "2808cf1cd138_func_run_git", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "def run_git(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"Run git command and return output.\"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd()\n        )\n        if result.returncode == 0:\n            return result.stdout.strip()\n        return None\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 55, "line_end": 68, "language": "python", "name": "run_git"}, "2808cf1cd138_func_get_commits": {"id": "2808cf1cd138_func_get_commits", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_commits(\n    path: Path = None,\n    since: str = None,\n    limit: int = 100,\n    file_path: Path = None\n) -> List[Commit]:\n    \"\"\"Get list of commits.\"\"\"\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        '--name-only'\n    ]\n\n    if since:\n        args.append(f'--since={since}')\n\n    if file_path:\n        args.extend(['--', str(file_path)])\n\n    output = run_git(args, path)\n    if not output:\n        return []\n\n    commits = []\n    current_commit = None\n\n    for line in output.split('\\n'):\n        if '|' in line and line.count('|') >= 5:\n            # Commit line\n            parts = line.split('|', 5)\n            if current_commit:\n                commits.append(current_commit)\n\n            current_commit = Commit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                email=parts[3],\n                date=parts[4],\n                message=parts[5] if len(parts) > 5 else ", "chunk_type": "function", "line_start": 71, "line_end": 120, "language": "python", "name": "get_commits"}, "2808cf1cd138_func_get_blame": {"id": "2808cf1cd138_func_get_blame", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_blame(file_path: Path, root: Path = None) -> List[BlameInfo]:\n    \"\"\"Get blame info for file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    args = ['blame', '--line-porcelain', str(file_path)]\n    output = run_git(args, root)\n\n    if not output:\n        return []\n\n    blame_info = []\n    current = {}\n    line_num = 0\n\n    for line in output.split('\\n'):\n        if line.startswith('author '):\n            current['author'] = line[7:]\n        elif line.startswith('author-time '):\n            ts = int(line[12:])\n            current['date'] = datetime.fromtimestamp(ts).isoformat()\n        elif line.startswith('\\t'):\n            line_num += 1\n            if 'commit_hash' in current:\n                blame_info.append(BlameInfo(\n                    line_num=line_num,\n                    commit_hash=current.get('commit_hash', ''),\n                    author=current.get('author', 'Unknown'),\n                    date=current.get('date', ''),\n                    content=line", "chunk_type": "function", "line_start": 123, "line_end": 157, "language": "python", "name": "get_blame"}, "2808cf1cd138_func_get_file_history": {"id": "2808cf1cd138_func_get_file_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_file_history(file_path: Path, root: Path = None) -> FileHistory:\n    \"\"\"Get complete history of a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    commits = get_commits(root, file_path=file_path)\n\n    authors = list(set(c.author for c in commits))\n\n    return FileHistory(\n        path=str(file_path),\n        commits=commits,\n        authors=authors,\n        first_commit=commits[-1].short_hash if commits else None,\n        last_commit=commits[0].short_hash if commits else None\n    )", "chunk_type": "function", "line_start": 160, "line_end": 174, "language": "python", "name": "get_file_history"}, "2808cf1cd138_func_get_change_intent": {"id": "2808cf1cd138_func_get_change_intent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_change_intent(file_path: Path, root: Path = None) -> str:\n    \"\"\"Get the intent behind recent changes to a file.\"\"\"\n    history = get_file_history(file_path, root)\n\n    if not history.commits:\n        return \"No git history available\"\n\n    # Summarize recent commits\n    recent = history.commits[:5]\n\n    lines = [f\"Recent changes to {file_path.name}:\", \"\"]\n    for commit in recent:\n        lines.append(f\"- {commit.message} ({commit.author}, {commit.date[:10]})\")\n\n    lines.append(\"\")\n    lines.append(f\"Authors: {', '.join(history.authors[:5])}\")\n    lines.append(f\"Total commits: {len(history.commits)}\")\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 177, "line_end": 195, "language": "python", "name": "get_change_intent"}, "2808cf1cd138_func_search_commits": {"id": "2808cf1cd138_func_search_commits", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "def search_commits(query: str, root: Path = None, limit: int = 20) -> List[Commit]:\n    \"\"\"Search commit messages.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        f'--grep={query}',\n        '-i'  # Case insensitive\n    ]\n\n    output = run_git(args, root)\n    if not output:\n        return []\n\n    commits = []\n    for line in output.split('\\n'):\n        if '|' in line:\n            parts = line.split('|', 5)\n            commits.append(Commit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                email=parts[3],\n                date=parts[4],\n                message=parts[5] if len(parts) > 5 else \"\"\n            ))\n\n    return commits", "chunk_type": "function", "line_start": 198, "line_end": 227, "language": "python", "name": "search_commits"}, "2808cf1cd138_func_index_git_history": {"id": "2808cf1cd138_func_index_git_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "def index_git_history(root: Path = None, since: str = \"3 months\") -> Dict:\n    \"\"\"Build git history index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(f\"Indexing git history (since {since})...\")\n\n    commits = get_commits(root, since=since, limit=500)\n\n    # Build index\n    index = {\n        \"commit_count\": len(commits),\n        \"authors\": {},\n        \"files\": {},\n        \"commits\": []\n    }\n\n    for commit in commits:\n        # Track authors\n        if commit.author not in index[\"authors\"]:\n            index[\"authors\"][commit.author] = 0\n        index[\"authors\"][commit.author] += 1\n\n        # Track files\n        for file in commit.files_changed:\n            if file not in index[\"files\"]:\n                index[\"files\"][file] = []\n            index[\"files\"][file].append(commit.short_hash)\n\n        # Store commit (without files to save space)\n        index[\"commits\"].append({\n            \"hash\": commit.short_hash,\n            \"author\": commit.author,\n       ", "chunk_type": "function", "line_start": 230, "line_end": 275, "language": "python", "name": "index_git_history"}, "2808cf1cd138_func_main": {"id": "2808cf1cd138_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Git History Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        since = \"3 months\"\n        for i, arg in enumerate(sys.argv):\n            if arg == '--since' and i + 1 < len(sys.argv):\n                since = sys.argv[i + 1]\n        index_git_history(root, since)\n        return 0\n\n    if '--search' in sys.argv and args:\n        query = args[0]\n        Console.info(f\"Searching commits: {query}\")\n        commits = search_commits(query, root)\n\n        for commit in commits:\n            print(f\"{commit.short_hash} {commit.message[:60]} ({commit.author})\")\n        return 0\n\n    if '--blame' in sys.argv and args:\n        file_path = Path(args[0])\n        Console.info(f\"Blame: {file_path}\")\n\n        blame = get_blame(file_path, root)\n        for info in blame[:30]:\n            print(f\"{info.line_num:4d} {info.commit_hash[:7]} {info.a", "chunk_type": "function", "line_start": 278, "line_end": 323, "language": "python", "name": "main"}, "2808cf1cd138_class_Commit": {"id": "2808cf1cd138_class_Commit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "class Commit:\n    \"\"\"A git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    email: str\n    date: str\n    message: str\n    files_changed: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 24, "line_end": 32, "language": "python", "name": "Commit"}, "2808cf1cd138_class_BlameInfo": {"id": "2808cf1cd138_class_BlameInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "class BlameInfo:\n    \"\"\"Blame info for a line.\"\"\"\n    line_num: int\n    commit_hash: str\n    author: str\n    date: str\n    content: str", "chunk_type": "class", "line_start": 36, "line_end": 42, "language": "python", "name": "BlameInfo"}, "2808cf1cd138_class_FileHistory": {"id": "2808cf1cd138_class_FileHistory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\git_index.py", "content": "class FileHistory:\n    \"\"\"History of a file.\"\"\"\n    path: str\n    commits: List[Commit] = field(default_factory=list)\n    authors: List[str] = field(default_factory=list)\n    first_commit: Optional[str] = None\n    last_commit: Optional[str] = None", "chunk_type": "class", "line_start": 46, "line_end": 52, "language": "python", "name": "FileHistory"}, "b9ac42e4e4ce_file": {"id": "b9ac42e4e4ce_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "\"\"\"\nImpact Analysis\n================\nAnalyze what breaks when code changes.\n\nUsage:\n    python mcp.py impact [file]\n    python mcp.py impact --test [file]  # Show affected tests\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set, Tuple\nimport ast\nimport json\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass ImpactReport:\n    \"\"\"Report of change impact.\"\"\"\n    file: str\n    direct_dependents: List[str] = field(default_factory=list)  # Files that import this\n    indirect_dependents: List[str] = field(default_factory=list)  # Transitive deps\n    affected_tests: List[str] = field(default_factory=list)\n    total_impact: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n            lines.append(\"## Affected Tests\")\n            for test in self.affected_tests[:10]:\n                lines.append(f\"- {test}\")\n\n        return '\\n'.join(lines)\n\n\nclass DependencyGraph:\n    \"\"\"Graph of file dependencies.\"\"\"\n\n    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path\n\n    def add_file(self, file_path: Path, ro", "chunk_type": "file", "line_start": 1, "line_end": 235, "language": "python", "name": "impact.py"}, "b9ac42e4e4ce_func_build_dependency_graph": {"id": "b9ac42e4e4ce_func_build_dependency_graph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "def build_dependency_graph(root: Path = None) -> DependencyGraph:\n    \"\"\"Build and return dependency graph.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Building dependency graph...\")\n\n    graph = DependencyGraph()\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    graph.build(root, exclude)\n\n    Console.ok(f\"Indexed {len(graph.imports)} files\")\n\n    return graph", "chunk_type": "function", "line_start": 131, "line_end": 143, "language": "python", "name": "build_dependency_graph"}, "b9ac42e4e4ce_func_analyze_impact": {"id": "b9ac42e4e4ce_func_analyze_impact", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "def analyze_impact(file_path: Path, root: Path = None) -> ImpactReport:\n    \"\"\"Analyze impact of changing a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    graph = build_dependency_graph(root)\n\n    try:\n        file_key = str(file_path.relative_to(root))\n    except ValueError:\n        file_key = str(file_path)\n\n    direct = list(graph.get_dependents(file_key))\n\n    all_deps = graph.get_transitive_dependents(file_key)\n    indirect = [d for d in all_deps if d not in direct]\n\n    # Find affected tests\n    tests = [d for d in all_deps if 'test' in d.lower() or d.startswith('tests/')]\n\n    return ImpactReport(\n        file=file_key,\n        direct_dependents=direct,\n        indirect_dependents=indirect,\n        affected_tests=tests,\n        total_impact=len(all_deps)\n    )", "chunk_type": "function", "line_start": 146, "line_end": 171, "language": "python", "name": "analyze_impact"}, "b9ac42e4e4ce_func_save_impact_graph": {"id": "b9ac42e4e4ce_func_save_impact_graph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "def save_impact_graph(root: Path = None):\n    \"\"\"Save dependency graph to disk.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    graph = build_dependency_graph(root)\n\n    # Convert to serializable format\n    data = {\n        \"imports\": {k: list(v) for k, v in graph.imports.items()},\n        \"imported_by\": {k: list(v) for k, v in graph.imported_by.items()},\n        \"file_count\": len(graph.imports)\n    }\n\n    index_path = root / '.mcp' / 'impact_graph.json'\n    index_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(index_path, 'w', encoding='utf-8') as f:\n        json.dump(data, f, indent=2)\n\n    Console.ok(f\"Saved impact graph to {index_path}\")", "chunk_type": "function", "line_start": 174, "line_end": 193, "language": "python", "name": "save_impact_graph"}, "b9ac42e4e4ce_func_main": {"id": "b9ac42e4e4ce_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Impact Analysis\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        save_impact_graph(root)\n        return 0\n\n    if not args:\n        Console.info(\"Usage: python impact.py <file>\")\n        Console.info(\"Options:\")\n        Console.info(\"  --index    Save dependency graph\")\n        Console.info(\"  --test     Show only affected tests\")\n        return 1\n\n    file_path = Path(args[0])\n\n    if not file_path.exists():\n        Console.fail(f\"File not found: {file_path}\")\n        return 1\n\n    report = analyze_impact(file_path, root)\n\n    if '--test' in sys.argv:\n        Console.info(f\"Affected tests for {file_path.name}:\")\n        for test in report.affected_tests:\n            print(f\"  - {test}\")\n        print(f\"\\nTotal: {len(report.affected_tests)} tests\")\n    else:\n        print(report.to_markdown())\n\n    return 0", "chunk_type": "function", "line_start": 196, "line_end": 230, "language": "python", "name": "main"}, "b9ac42e4e4ce_func_to_markdown": {"id": "b9ac42e4e4ce_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n            lines.append(\"## Affected Tests\")\n            for test in self.affected_tests[:10]:\n                lines.append(f\"- {test}\")\n\n        return '\\n'.join(lines)", "chunk_type": "function", "line_start": 31, "line_end": 56, "language": "python", "name": "to_markdown"}, "b9ac42e4e4ce_func___init__": {"id": "b9ac42e4e4ce_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path", "chunk_type": "function", "line_start": 62, "line_end": 65, "language": "python", "name": "__init__"}, "b9ac42e4e4ce_func_add_file": {"id": "b9ac42e4e4ce_func_add_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "    def add_file(self, file_path: Path, root: Path):\n        \"\"\"Add a file's imports to the graph.\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                source = f.read()\n            tree = ast.parse(source)\n        except Exception:\n            return\n\n        file_key = str(file_path.relative_to(root))\n\n        # Register this module\n        module_name = str(file_path.relative_to(root).with_suffix('')).replace('\\\\', '.').replace('/', '.')\n        self.module_to_file[module_name] = file_key\n\n        # Extract imports\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    self.imports[file_key].add(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                if node.module:\n                    self.imports[file_key].add(node.module)", "chunk_type": "function", "line_start": 67, "line_end": 89, "language": "python", "name": "add_file"}, "b9ac42e4e4ce_func_build": {"id": "b9ac42e4e4ce_func_build", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "    def build(self, root: Path, exclude_patterns: List[str] = None):\n        \"\"\"Build full dependency graph.\"\"\"\n        for file_path in find_python_files(root, exclude_patterns):\n            self.add_file(file_path, root)\n\n        # Build reverse mapping\n        for file_key, imports in self.imports.items():\n            for imp in imports:\n                # Try to resolve import to file\n                if imp in self.module_to_file:\n                    self.imported_by[self.module_to_file[imp]].add(file_key)", "chunk_type": "function", "line_start": 91, "line_end": 101, "language": "python", "name": "build"}, "b9ac42e4e4ce_func_get_dependents": {"id": "b9ac42e4e4ce_func_get_dependents", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_dependents(self, file_path: str) -> Set[str]:\n        \"\"\"Get files that depend on this file.\"\"\"\n        return self.imported_by.get(file_path, set())", "chunk_type": "function", "line_start": 103, "line_end": 105, "language": "python", "name": "get_dependents"}, "b9ac42e4e4ce_func_get_dependencies": {"id": "b9ac42e4e4ce_func_get_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_dependencies(self, file_path: str) -> Set[str]:\n        \"\"\"Get files this file depends on.\"\"\"\n        return self.imports.get(file_path, set())", "chunk_type": "function", "line_start": 107, "line_end": 109, "language": "python", "name": "get_dependencies"}, "b9ac42e4e4ce_func_get_transitive_dependents": {"id": "b9ac42e4e4ce_func_get_transitive_dependents", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_transitive_dependents(self, file_path: str, visited: Set[str] = None) -> Set[str]:\n        \"\"\"Get all transitive dependents.\"\"\"\n        if visited is None:\n            visited = set()\n\n        if file_path in visited:\n            return set()\n\n        visited.add(file_path)\n\n        all_deps = set()\n        direct = self.get_dependents(file_path)\n        all_deps.update(direct)\n\n        for dep in direct:\n            all_deps.update(self.get_transitive_dependents(dep, visited))\n\n        return all_deps", "chunk_type": "function", "line_start": 111, "line_end": 128, "language": "python", "name": "get_transitive_dependents"}, "b9ac42e4e4ce_class_ImpactReport": {"id": "b9ac42e4e4ce_class_ImpactReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "class ImpactReport:\n    \"\"\"Report of change impact.\"\"\"\n    file: str\n    direct_dependents: List[str] = field(default_factory=list)  # Files that import this\n    indirect_dependents: List[str] = field(default_factory=list)  # Transitive deps\n    affected_tests: List[str] = field(default_factory=list)\n    total_impact: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n        ", "chunk_type": "class", "line_start": 23, "line_end": 56, "language": "python", "name": "ImpactReport"}, "b9ac42e4e4ce_class_DependencyGraph": {"id": "b9ac42e4e4ce_class_DependencyGraph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\impact.py", "content": "class DependencyGraph:\n    \"\"\"Graph of file dependencies.\"\"\"\n\n    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path\n\n    def add_file(self, file_path: Path, root: Path):\n        \"\"\"Add a file's imports to the graph.\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                source = f.read()\n            tree = ast.parse(source)\n        except Exception:\n            return\n\n        file_key = str(file_path.relative_to(root))\n\n        # Register this module\n        module_name = str(file_path.relative_to(root).with_suffix('')).replace('\\\\', '.').replace('/', '.')\n        self.module_to_file[module_name] = file_key\n\n        # Extract imports\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n           ", "chunk_type": "class", "line_start": 59, "line_end": 128, "language": "python", "name": "DependencyGraph"}, "e799c454181b_file": {"id": "e799c454181b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\index_all.py", "content": "\"\"\"\nUnified Index Manager\n=====================\nRun all indexes at once for complete codebase intelligence.\n\nUsage:\n    python mcp.py index-all      # Full reindex\n    python mcp.py index-all --what  # Show what's indexed\n\"\"\"\n\nfrom datetime import datetime\nfrom pathlib import Path\nimport json\nimport sys\nimport time\n\nfrom .utils import Console, find_project_root\n\n\ndef run_all_indexes(root: Path = None, verbose: bool = True) -> dict:\n    \"\"\"Run all indexes and return summary.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    if verbose:\n        Console.header(\"Full Index Build\")\n        Console.info(f\"Indexing {root}...\")\n\n    start_time = time.time()\n    results = {}\n\n    # 1. Semantic code index\n    if verbose:\n        Console.info(\"1/7 Semantic code index...\")\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n        count = store.index_codebase(root)\n        results['semantic'] = {'status': 'ok', 'items': count}\n    except Exception as e:\n        results['semantic'] = {'status': 'error', 'error': str(e)}\n\n    # 2. Git history index\n    if verbose:\n        Console.info(\"2/7 Git history index...\")\n    try:\n        from .git_index import index_git_history\n        index = index_git_history(root, since=\"3 months\")\n        results['git'] = {'status': 'ok', 'commits': index.get('commit_count', 0)}\n    except Exception as e:\n        results['git'] = {'status': 'error', 'error': str(e)}\n\n    # 3. TODO/FIXME index\n    if verbose:\n        Console.info(\"3/7 TODO/FIXME index...\")\n    try:\n        from .todo_index import index_todos\n        index = index_todos(root)\n        results['todos'] = {'status': 'ok', 'items': index.get('total', 0)}\n    except Exception as e:\n        results['todos'] = {'status': 'error', 'error': str(e)}\n\n    # 4. Impact graph\n    if verbose:\n        Console.info(\"4/7 Dependency impact graph...\")\n    try:\n        from .impact import save_impact_graph\n        save_impact_graph(r", "chunk_type": "file", "line_start": 1, "line_end": 195, "language": "python", "name": "index_all.py"}, "e799c454181b_func_run_all_indexes": {"id": "e799c454181b_func_run_all_indexes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\index_all.py", "content": "def run_all_indexes(root: Path = None, verbose: bool = True) -> dict:\n    \"\"\"Run all indexes and return summary.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    if verbose:\n        Console.header(\"Full Index Build\")\n        Console.info(f\"Indexing {root}...\")\n\n    start_time = time.time()\n    results = {}\n\n    # 1. Semantic code index\n    if verbose:\n        Console.info(\"1/7 Semantic code index...\")\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n        count = store.index_codebase(root)\n        results['semantic'] = {'status': 'ok', 'items': count}\n    except Exception as e:\n        results['semantic'] = {'status': 'error', 'error': str(e)}\n\n    # 2. Git history index\n    if verbose:\n        Console.info(\"2/7 Git history index...\")\n    try:\n        from .git_index import index_git_history\n        index = index_git_history(root, since=\"3 months\")\n        results['git'] = {'status': 'ok', 'commits': index.", "chunk_type": "function", "line_start": 20, "line_end": 123, "language": "python", "name": "run_all_indexes"}, "e799c454181b_func_show_index_status": {"id": "e799c454181b_func_show_index_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\index_all.py", "content": "def show_index_status(root: Path = None):\n    \"\"\"Show what's currently indexed.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    mcp_dir = root / '.mcp'\n\n    print(\"\\n## Index Status\")\n    print(\"\")\n\n    indexes = [\n        ('vector_index', 'Semantic Code', 'chunks.json'),\n        ('git_index.json', 'Git History', None),\n        ('todo_index.json', 'TODOs/FIXMEs', None),\n        ('impact_graph.json', 'Impact Graph', None),\n        ('doc_index.json', 'Documentation', None),\n        ('config_index.json', 'Config', None),\n        ('coverage_index.json', 'Coverage', None),\n    ]\n\n    for idx_name, display_name, sub_file in indexes:\n        idx_path = mcp_dir / idx_name\n\n        if sub_file:\n            idx_path = idx_path / sub_file\n\n        if idx_path.exists():\n            size = idx_path.stat().st_size\n            size_str = f\"{size / 1024:.1f}KB\" if size > 1024 else f\"{size}B\"\n            print(f\"  \u2713 {display_name:20} ({size_str})\")\n        else:\n            print(f\"  \u2717 {dis", "chunk_type": "function", "line_start": 126, "line_end": 155, "language": "python", "name": "show_index_status"}, "e799c454181b_func_main": {"id": "e799c454181b_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\index_all.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    root = find_project_root() or Path.cwd()\n\n    if '--what' in sys.argv or '--status' in sys.argv:\n        Console.header(\"Index Status\")\n        show_index_status(root)\n        return 0\n\n    if '--quick' in sys.argv:\n        # Quick mode: only semantic + todos\n        Console.header(\"Quick Index\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(root / '.mcp' / 'vector_index')\n            store.index_codebase(root)\n        except Exception:\n            pass\n\n        try:\n            from .todo_index import index_todos\n            index_todos(root)\n        except Exception:\n            pass\n\n        Console.ok(\"Quick index complete\")\n        return 0\n\n    # Full index\n    run_all_indexes(root, verbose=True)\n\n    return 0", "chunk_type": "function", "line_start": 158, "line_end": 190, "language": "python", "name": "main"}, "09095d15e69f_file": {"id": "09095d15e69f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "\"\"\"\nLearning System\n================\nLearn from feedback, preferences, and past mistakes.\n\nUsage:\n    python mcp.py learn --show-patterns\n    python mcp.py learn --from-feedback\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Feedback:\n    \"\"\"A feedback entry.\"\"\"\n    action: str\n    outcome: str  # 'success', 'failure', 'partial'\n    context: str\n    timestamp: str\n    details: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass ErrorPattern:\n    \"\"\"A learned error pattern.\"\"\"\n    error_type: str\n    pattern: str\n    fix: str\n    occurrences: int = 1\n    last_seen: str = \"\"\n    contexts: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Preference:\n    \"\"\"A user preference.\"\"\"\n    key: str\n    value: Any\n    learned_from: str = \"default\"\n    confidence: float = 0.5\n\n\nclass LearningStore:\n    \"\"\"Store for learning data.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()\n\n    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.js", "chunk_type": "file", "line_start": 1, "line_end": 311, "language": "python", "name": "learning.py"}, "09095d15e69f_func_get_store": {"id": "09095d15e69f_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "def get_store() -> LearningStore:\n    global _store\n    if _store is None:\n        _store = LearningStore()\n    return _store", "chunk_type": "function", "line_start": 248, "line_end": 252, "language": "python", "name": "get_store"}, "09095d15e69f_func_record_feedback": {"id": "09095d15e69f_func_record_feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def record_feedback(\n        self,\n        action: str,\n        outcome: str,\n        context: str = \"\",\n        details: Dict = None\n    ):\n        \"\"\"Record feedback on an action.\"\"\"\n        fb = Feedback(\n            action=action,\n            outcome=outcome,\n            context=context,\n            timestamp=datetime.utcnow().isoformat() + 'Z',\n            details=details or {}\n        )\n        self.feedback.append(fb)\n        self.save()", "chunk_type": "function", "line_start": 119, "line_end": 135, "language": "python", "name": "record_feedback"}, "09095d15e69f_func_record_error": {"id": "09095d15e69f_func_record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def record_error(self, error_type: str, pattern: str, fix: str, context: str = \"\"):\n        \"\"\"Record an error and its fix.\"\"\"\n        key = f\"{error_type}:{pattern[:50]}\"\n\n        if key in self.errors:\n            err = self.errors[key]\n            err.occurrences += 1\n            err.last_seen = datetime.utcnow().isoformat() + 'Z'\n            if context and context not in err.contexts:\n                err.contexts.append(context)\n                err.contexts = err.contexts[-5:]  # Keep last 5\n        else:\n            self.errors[key] = ErrorPattern(\n                error_type=error_type,\n                pattern=pattern,\n                fix=fix,\n                last_seen=datetime.utcnow().isoformat() + 'Z',\n                contexts=[context] if context else []\n            )\n\n        self.save()", "chunk_type": "function", "line_start": 137, "line_end": 157, "language": "python", "name": "record_error"}, "09095d15e69f_func_suggest_fix": {"id": "09095d15e69f_func_suggest_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def suggest_fix(self, error_type: str, pattern: str) -> Optional[str]:\n        \"\"\"Suggest a fix for an error based on patterns.\"\"\"\n        key = f\"{error_type}:{pattern[:50]}\"\n\n        if key in self.errors:\n            return self.errors[key].fix\n\n        # Fuzzy match\n        for k, err in self.errors.items():\n            if error_type in k and pattern[:20] in err.pattern:\n                return err.fix\n\n        return None", "chunk_type": "function", "line_start": 174, "line_end": 186, "language": "python", "name": "suggest_fix"}, "09095d15e69f_func_main": {"id": "09095d15e69f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Learning System\")\n\n    store = get_store()\n\n    Console.info(f\"Storage: {store.storage_path}\")\n    Console.info(f\"Feedback entries: {len(store.feedback)}\")\n    Console.info(f\"Error patterns: {len(store.errors)}\")\n    Console.info(f\"Preferences: {len(store.preferences)}\")\n\n    if '--show-patterns' in sys.argv or '--patterns' in sys.argv:\n        analysis = store.analyze_patterns()\n\n        print(\"\\n## Action Outcomes\")\n        for action, data in analysis[\"action_outcomes\"].items():\n            print(f\"  {action}: {data['success_rate']*100:.0f}% success ({data['count']} times)\")\n\n        print(\"\\n## Common Errors\")\n        for err in analysis[\"common_errors\"]:\n            print(f\"  [{err['type']}] {err['pattern']}\")\n            print(f\"    Fix: {err['fix']}\")\n            print(f\"    Occurred: {err['occurrences']} times\")\n\n        return 0\n\n    if '--preferences' in sys.argv:\n        print(\"\\n## Preferences\")\n        for key, pre", "chunk_type": "function", "line_start": 270, "line_end": 306, "language": "python", "name": "main"}, "09095d15e69f_func___init__": {"id": "09095d15e69f_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()", "chunk_type": "function", "line_start": 55, "line_end": 68, "language": "python", "name": "__init__"}, "09095d15e69f_func_load": {"id": "09095d15e69f_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.json'\n        if err_path.exists():\n            try:\n                with open(err_path, 'r') as f:\n                    data = json.load(f)\n                    self.errors = {k: ErrorPattern(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n        # Load preferences\n        pref_path = self.storage_path / 'preferences.json'\n        if pref_path.exists():\n            try:\n                with open(pref_path, 'r') as f:\n                    data = json.load(f)\n                    self.preferences = {k: Pr", "chunk_type": "function", "line_start": 70, "line_end": 100, "language": "python", "name": "load"}, "09095d15e69f_func_save": {"id": "09095d15e69f_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def save(self):\n        \"\"\"Save all learning data.\"\"\"\n        # Save feedback\n        fb_path = self.storage_path / 'feedback.json'\n        with open(fb_path, 'w') as f:\n            json.dump([asdict(fb) for fb in self.feedback[-1000:]], f, indent=2)\n\n        # Save errors\n        err_path = self.storage_path / 'errors.json'\n        with open(err_path, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.errors.items()}, f, indent=2)\n\n        # Save preferences\n        pref_path = self.storage_path / 'preferences.json'\n        with open(pref_path, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.preferences.items()}, f, indent=2)", "chunk_type": "function", "line_start": 102, "line_end": 117, "language": "python", "name": "save"}, "09095d15e69f_func_get_preference": {"id": "09095d15e69f_func_get_preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_preference(self, key: str, default: Any = None) -> Any:\n        \"\"\"Get a preference value.\"\"\"\n        pref = self.preferences.get(key)\n        return pref.value if pref else default", "chunk_type": "function", "line_start": 159, "line_end": 162, "language": "python", "name": "get_preference"}, "09095d15e69f_func_set_preference": {"id": "09095d15e69f_func_set_preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def set_preference(self, key: str, value: Any, source: str = \"user\"):\n        \"\"\"Set a preference.\"\"\"\n        self.preferences[key] = Preference(\n            key=key,\n            value=value,\n            learned_from=source,\n            confidence=1.0 if source == \"user\" else 0.7\n        )\n        self.save()", "chunk_type": "function", "line_start": 164, "line_end": 172, "language": "python", "name": "set_preference"}, "09095d15e69f_func_get_action_success_rate": {"id": "09095d15e69f_func_get_action_success_rate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_action_success_rate(self, action: str) -> float:\n        \"\"\"Get success rate for an action type.\"\"\"\n        relevant = [fb for fb in self.feedback if fb.action == action]\n        if not relevant:\n            return 0.5  # Unknown\n\n        successes = sum(1 for fb in relevant if fb.outcome == 'success')\n        return successes / len(relevant)", "chunk_type": "function", "line_start": 188, "line_end": 195, "language": "python", "name": "get_action_success_rate"}, "09095d15e69f_func_get_common_errors": {"id": "09095d15e69f_func_get_common_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_common_errors(self, limit: int = 10) -> List[ErrorPattern]:\n        \"\"\"Get most common errors.\"\"\"\n        sorted_errors = sorted(\n            self.errors.values(),\n            key=lambda e: e.occurrences,\n            reverse=True\n        )\n        return sorted_errors[:limit]", "chunk_type": "function", "line_start": 197, "line_end": 204, "language": "python", "name": "get_common_errors"}, "09095d15e69f_func_analyze_patterns": {"id": "09095d15e69f_func_analyze_patterns", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "    def analyze_patterns(self) -> Dict:\n        \"\"\"Analyze learning patterns.\"\"\"\n        analysis = {\n            \"total_feedback\": len(self.feedback),\n            \"total_errors\": len(self.errors),\n            \"total_preferences\": len(self.preferences),\n            \"action_outcomes\": {},\n            \"common_errors\": []\n        }\n\n        # Analyze action outcomes\n        action_counts = Counter()\n        action_success = Counter()\n\n        for fb in self.feedback:\n            action_counts[fb.action] += 1\n            if fb.outcome == 'success':\n                action_success[fb.action] += 1\n\n        for action, count in action_counts.most_common(10):\n            rate = action_success[action] / count if count > 0 else 0\n            analysis[\"action_outcomes\"][action] = {\n                \"count\": count,\n                \"success_rate\": round(rate, 2)\n            }\n\n        # Common errors\n        for err in self.get_common_errors(5):\n            analysis[\"common_errors\"].append({\n        ", "chunk_type": "function", "line_start": 206, "line_end": 241, "language": "python", "name": "analyze_patterns"}, "09095d15e69f_class_Feedback": {"id": "09095d15e69f_class_Feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "class Feedback:\n    \"\"\"A feedback entry.\"\"\"\n    action: str\n    outcome: str  # 'success', 'failure', 'partial'\n    context: str\n    timestamp: str\n    details: Dict[str, Any] = field(default_factory=dict)", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "Feedback"}, "09095d15e69f_class_ErrorPattern": {"id": "09095d15e69f_class_ErrorPattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "class ErrorPattern:\n    \"\"\"A learned error pattern.\"\"\"\n    error_type: str\n    pattern: str\n    fix: str\n    occurrences: int = 1\n    last_seen: str = \"\"\n    contexts: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 33, "line_end": 40, "language": "python", "name": "ErrorPattern"}, "09095d15e69f_class_Preference": {"id": "09095d15e69f_class_Preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "class Preference:\n    \"\"\"A user preference.\"\"\"\n    key: str\n    value: Any\n    learned_from: str = \"default\"\n    confidence: float = 0.5", "chunk_type": "class", "line_start": 44, "line_end": 49, "language": "python", "name": "Preference"}, "09095d15e69f_class_LearningStore": {"id": "09095d15e69f_class_LearningStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\learning.py", "content": "class LearningStore:\n    \"\"\"Store for learning data.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()\n\n    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.json'\n        if err_path.ex", "chunk_type": "class", "line_start": 52, "line_end": 241, "language": "python", "name": "LearningStore"}, "e53ff654b277_file": {"id": "e53ff654b277_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "\"\"\"\nPersistent Memory System\n========================\nCross-session knowledge base for AI agents.\n\nUsage:\n    python mcp.py remember \"key\" \"value\"\n    python mcp.py recall \"query\"\n    python mcp.py forget \"key\"\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport hashlib\nimport json\nimport sys\n\nfrom .embeddings import embed_text, cosine_similarity\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Memory:\n    \"\"\"A memory item.\"\"\"\n    key: str\n    value: str\n    tags: List[str] = field(default_factory=list)\n    created: str = \"\"\n    updated: str = \"\"\n    access_count: int = 0\n    embedding: List[float] = field(default_factory=list)\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)\n\n\nclass MemoryStore:\n    \"\"\"Persistent memory storage.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()\n\n    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'\n\n    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}\n\n    def save(self):\n        \"\"\"Save memories to disk.\"\"\"\n        file_path = self._get_file_path()\n        with open(fil", "chunk_type": "file", "line_start": 1, "line_end": 277, "language": "python", "name": "memory.py"}, "e53ff654b277_func_get_store": {"id": "e53ff654b277_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "def get_store() -> MemoryStore:\n    \"\"\"Get or create memory store.\"\"\"\n    global _store\n    if _store is None:\n        _store = MemoryStore()\n    return _store", "chunk_type": "function", "line_start": 193, "line_end": 198, "language": "python", "name": "get_store"}, "e53ff654b277_func_remember": {"id": "e53ff654b277_func_remember", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def remember(self, key: str, value: str, tags: List[str] = None) -> Memory:\n        \"\"\"Store a memory.\"\"\"\n        now = datetime.utcnow().isoformat() + 'Z'\n\n        # Generate embedding for semantic search\n        combined = f\"{key} {value}\"\n        embedding = embed_text(combined) or []\n\n        if key in self.memories:\n            # Update existing\n            memory = self.memories[key]\n            memory.value = value\n            memory.updated = now\n            memory.tags = tags or memory.tags\n            memory.embedding = embedding\n        else:\n            # Create new\n            memory = Memory(\n                key=key,\n                value=value,\n                tags=tags or [],\n                created=now,\n                updated=now,\n                embedding=embedding\n            )\n\n        self.memories[key] = memory\n        self.save()\n        return memory", "chunk_type": "function", "line_start": 79, "line_end": 107, "language": "python", "name": "remember"}, "e53ff654b277_func_recall": {"id": "e53ff654b277_func_recall", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def recall(self, query: str, limit: int = 10) -> List[Memory]:\n        \"\"\"Search memories semantically.\"\"\"\n        if not self.memories:\n            return []\n\n        # Generate query embedding\n        query_emb = embed_text(query)\n\n        results = []\n        for key, memory in self.memories.items():\n            # Update access count\n            memory.access_count += 1\n\n            # Calculate relevance score\n            score = 0.0\n\n            # Exact key match\n            if query.lower() in key.lower():\n                score += 1.0\n\n            # Value match\n            if query.lower() in memory.value.lower():\n                score += 0.5\n\n            # Tag match\n            for tag in memory.tags:\n                if query.lower() in tag.lower():\n                    score += 0.3\n\n            # Semantic similarity\n            if query_emb and memory.embedding:\n                semantic_score = cosine_similarity(query_emb, memory.embedding)\n                score += semantic_s", "chunk_type": "function", "line_start": 109, "line_end": 150, "language": "python", "name": "recall"}, "e53ff654b277_func_forget": {"id": "e53ff654b277_func_forget", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def forget(self, key: str) -> bool:\n        \"\"\"Remove a memory.\"\"\"\n        if key in self.memories:\n            del self.memories[key]\n            self.save()\n            return True\n        return False", "chunk_type": "function", "line_start": 152, "line_end": 158, "language": "python", "name": "forget"}, "e53ff654b277_func_main": {"id": "e53ff654b277_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Persistent Memory\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    store = get_store()\n\n    Console.info(f\"Memory storage: {store.storage_path}\")\n    Console.info(f\"Total memories: {len(store.memories)}\")\n\n    if len(args) >= 2:\n        key = args[0]\n        value = args[1]\n        tags = args[2:] if len(args) > 2 else []\n\n        memory = store.remember(key, value, tags)\n        Console.ok(f\"Remembered: {key}\")\n        print(f\"  Value: {value}\")\n        if tags:\n            print(f\"  Tags: {', '.join(tags)}\")\n        return 0\n\n    if len(args) == 1:\n        query = args[0]\n\n        if '--forget' in sys.argv or '--delete' in sys.argv:\n            if store.forget(query):\n                Console.ok(f\"Forgot: {query}\")\n            else:\n                Console.warn(f\"Not found: {query}\")\n            return 0\n\n        # Search\n        Console.info(f\"Recalling: {query}\")\n        results = store.recall(query)\n\n   ", "chunk_type": "function", "line_start": 216, "line_end": 272, "language": "python", "name": "main"}, "e53ff654b277_func_to_dict": {"id": "e53ff654b277_func_to_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def to_dict(self) -> dict:\n        return asdict(self)", "chunk_type": "function", "line_start": 35, "line_end": 36, "language": "python", "name": "to_dict"}, "e53ff654b277_func_from_dict": {"id": "e53ff654b277_func_from_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)", "chunk_type": "function", "line_start": 39, "line_end": 40, "language": "python", "name": "from_dict"}, "e53ff654b277_func___init__": {"id": "e53ff654b277_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()", "chunk_type": "function", "line_start": 46, "line_end": 56, "language": "python", "name": "__init__"}, "e53ff654b277_func__get_file_path": {"id": "e53ff654b277_func__get_file_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'", "chunk_type": "function", "line_start": 58, "line_end": 59, "language": "python", "name": "_get_file_path"}, "e53ff654b277_func_load": {"id": "e53ff654b277_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}", "chunk_type": "function", "line_start": 61, "line_end": 70, "language": "python", "name": "load"}, "e53ff654b277_func_save": {"id": "e53ff654b277_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def save(self):\n        \"\"\"Save memories to disk.\"\"\"\n        file_path = self._get_file_path()\n        with open(file_path, 'w', encoding='utf-8') as f:\n            data = {k: v.to_dict() for k, v in self.memories.items()}\n            json.dump(data, f, indent=2)", "chunk_type": "function", "line_start": 72, "line_end": 77, "language": "python", "name": "save"}, "e53ff654b277_func_list_all": {"id": "e53ff654b277_func_list_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def list_all(self, tag: str = None) -> List[Memory]:\n        \"\"\"List all memories, optionally filtered by tag.\"\"\"\n        if tag:\n            return [m for m in self.memories.values() if tag in m.tags]\n        return list(self.memories.values())", "chunk_type": "function", "line_start": 160, "line_end": 164, "language": "python", "name": "list_all"}, "e53ff654b277_func_get_by_key": {"id": "e53ff654b277_func_get_by_key", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def get_by_key(self, key: str) -> Optional[Memory]:\n        \"\"\"Get memory by exact key.\"\"\"\n        return self.memories.get(key)", "chunk_type": "function", "line_start": 166, "line_end": 168, "language": "python", "name": "get_by_key"}, "e53ff654b277_func_export_all": {"id": "e53ff654b277_func_export_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def export_all(self) -> str:\n        \"\"\"Export all memories as JSON.\"\"\"\n        return json.dumps({k: v.to_dict() for k, v in self.memories.items()}, indent=2)", "chunk_type": "function", "line_start": 170, "line_end": 172, "language": "python", "name": "export_all"}, "e53ff654b277_func_import_memories": {"id": "e53ff654b277_func_import_memories", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "    def import_memories(self, json_str: str) -> int:\n        \"\"\"Import memories from JSON.\"\"\"\n        try:\n            data = json.loads(json_str)\n            count = 0\n            for key, mem_data in data.items():\n                if key not in self.memories:\n                    self.memories[key] = Memory.from_dict(mem_data)\n                    count += 1\n            self.save()\n            return count\n        except Exception:\n            return 0", "chunk_type": "function", "line_start": 174, "line_end": 186, "language": "python", "name": "import_memories"}, "e53ff654b277_class_Memory": {"id": "e53ff654b277_class_Memory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "class Memory:\n    \"\"\"A memory item.\"\"\"\n    key: str\n    value: str\n    tags: List[str] = field(default_factory=list)\n    created: str = \"\"\n    updated: str = \"\"\n    access_count: int = 0\n    embedding: List[float] = field(default_factory=list)\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)", "chunk_type": "class", "line_start": 25, "line_end": 40, "language": "python", "name": "Memory"}, "e53ff654b277_class_MemoryStore": {"id": "e53ff654b277_class_MemoryStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\memory.py", "content": "class MemoryStore:\n    \"\"\"Persistent memory storage.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()\n\n    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'\n\n    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}\n\n    def save(self):\n        \"\"\"", "chunk_type": "class", "line_start": 43, "line_end": 186, "language": "python", "name": "MemoryStore"}, "2fd12bdb9075_file": {"id": "2fd12bdb9075_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "\"\"\"\nMigration Helper\n================\nAssist with Python version and framework migrations.\n\nUsage:\n    python migrate.py [path] [--target 3.11]\n    python -m scripts.migrate src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass MigrationIssue:\n    \"\"\"A migration issue or suggestion.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'required', 'recommended', 'optional'\n    category: str\n    title: str\n    description: str\n    old_syntax: Optional[str] = None\n    new_syntax: Optional[str] = None\n\n\n@dataclass\nclass MigrationReport:\n    \"\"\"Complete migration report.\"\"\"\n    target_version: str\n    issues: List[MigrationIssue] = field(default_factory=list)\n\n    @property\n    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']\n\n    @property\n    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        for severity in ['required', 'recommended', 'optional']:\n            items = [i for i in self.issues if i.severity == severity]\n            if not items:\n                continue\n\n            lines.extend([f\"## {severity.title()}\", \"\"])\n\n ", "chunk_type": "file", "line_start": 1, "line_end": 360, "language": "python", "name": "migrate.py"}, "2fd12bdb9075_func_analyze_file": {"id": "2fd12bdb9075_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "def analyze_file(\n    path: Path,\n    target: str\n) -> List[MigrationIssue]:\n    \"\"\"Analyze a file for migration issues.\"\"\"\n    issues = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return issues\n\n    # Run analyzers\n    deprecation = DeprecationAnalyzer(path, target)\n    deprecation.visit(tree)\n    issues.extend(deprecation.issues)\n\n    modernizer = SyntaxModernizer(path, source_lines, target)\n    modernizer.visit(tree)\n    issues.extend(modernizer.issues)\n\n    string_format = StringFormatAnalyzer(path, source_lines)\n    string_format.visit(tree)\n    issues.extend(string_format.issues)\n\n    return issues", "chunk_type": "function", "line_start": 266, "line_end": 296, "language": "python", "name": "analyze_file"}, "2fd12bdb9075_func_check_migration": {"id": "2fd12bdb9075_func_check_migration", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "def check_migration(\n    root: Path,\n    target: str = \"3.11\",\n    exclude_patterns: List[str] = None\n) -> MigrationReport:\n    \"\"\"Check project for migration issues.\"\"\"\n    report = MigrationReport(target_version=target)\n\n    Console.info(f\"Checking migration to Python {target}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        issues = analyze_file(path, target)\n        report.issues.extend(issues)\n\n    return report", "chunk_type": "function", "line_start": 299, "line_end": 316, "language": "python", "name": "check_migration"}, "2fd12bdb9075_func_main": {"id": "2fd12bdb9075_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Migration Helper\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    target = \"3.11\"\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--target' and i + 1 < len(sys.argv):\n            target = sys.argv[i + 1]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Target version: Python {target}\")\n\n    report = check_migration(path, target)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.required:\n        Console.warn(f\"Found {len(report.required)} required changes\")\n    elif report.recommended:\n        Console.info(f\"Found {len(report.recommended)} recommended changes\")\n    else:\n        Console.ok(\"Code is ready for migration\")\n\n    return 0", "chunk_type": "function", "line_start": 319, "line_end": 355, "language": "python", "name": "main"}, "2fd12bdb9075_func_required": {"id": "2fd12bdb9075_func_required", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']", "chunk_type": "function", "line_start": 47, "line_end": 48, "language": "python", "name": "required"}, "2fd12bdb9075_func_recommended": {"id": "2fd12bdb9075_func_recommended", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']", "chunk_type": "function", "line_start": 51, "line_end": 52, "language": "python", "name": "recommended"}, "2fd12bdb9075_func_to_markdown": {"id": "2fd12bdb9075_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        for severity in ['required', 'recommended', 'optional']:\n            items = [i for i in self.issues if i.severity == severity]\n            if not items:\n                continue\n\n            lines.extend([f\"## {severity.title()}\", \"\"])\n\n            for issue in items:\n                lines.append(f\"### {issue.title}\")\n                lines.append(f\"**File:** `{issue.path}:{issue.line}`\")\n                lines.app", "chunk_type": "function", "line_start": 54, "line_end": 96, "language": "python", "name": "to_markdown"}, "2fd12bdb9075_func___init__": {"id": "2fd12bdb9075_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.issues: List[MigrationIssue] = []", "chunk_type": "function", "line_start": 243, "line_end": 246, "language": "python", "name": "__init__"}, "2fd12bdb9075_func_visit_ImportFrom": {"id": "2fd12bdb9075_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module == 'typing':\n            for alias in node.names:\n                self._typing_imports.add(alias.name)\n\n                # Check deprecated typing imports\n                if alias.name in DEPRECATED_PATTERNS:\n                    new, version, desc = DEPRECATED_PATTERNS[f'typing.{alias.name}']\n                    if self._version_ge(version):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Deprecated: typing.{alias.name}\",\n                            description=desc,\n                            old_syntax=f\"from typing import {alias.name}\",\n                            new_syntax=f\"# Use {new} directly\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 135, "line_end": 155, "language": "python", "name": "visit_ImportFrom"}, "2fd12bdb9075_func_visit_Subscript": {"id": "2fd12bdb9075_func_visit_Subscript", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Subscript(self, node: ast.Subscript):\n        # Check for Optional[X] -> X | None\n        if isinstance(node.value, ast.Attribute):\n            if isinstance(node.value.value, ast.Name):\n                if node.value.value.id == 'typing':\n                    attr = node.value.attr\n                    if attr in ('Optional', 'Union') and self._version_ge('3.10+'):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Modernize: typing.{attr}\",\n                            description=f\"Python 3.10+ supports | syntax for unions\",\n                            old_syntax=f\"typing.{attr}[...]\",\n                            new_syntax=\"X | Y | None\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 157, "line_end": 175, "language": "python", "name": "visit_Subscript"}, "2fd12bdb9075_func_visit_Call": {"id": "2fd12bdb9075_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Call(self, node: ast.Call):\n        # Check for deprecated function calls\n        func_name = self._get_func_name(node.func)\n\n        # Check for old string formatting\n        if func_name == 'format' or '%' in str(node):\n            pass  # Would need more context\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 177, "line_end": 185, "language": "python", "name": "visit_Call"}, "2fd12bdb9075_func__get_func_name": {"id": "2fd12bdb9075_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 187, "line_end": 192, "language": "python", "name": "_get_func_name"}, "2fd12bdb9075_func__version_ge": {"id": "2fd12bdb9075_func__version_ge", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def _version_ge(self, version: str) -> bool:\n        \"\"\"Check if target version is >= specified version.\"\"\"\n        target_parts = self.target.split('.')\n        version_parts = version.replace('+', '').split('.')\n\n        try:\n            for t, v in zip(target_parts, version_parts):\n                if int(t) > int(v):\n                    return True\n                elif int(t) < int(v):\n                    return False\n            return True\n        except ValueError:\n            return False", "chunk_type": "function", "line_start": 194, "line_end": 207, "language": "python", "name": "_version_ge"}, "2fd12bdb9075_func_visit_FunctionDef": {"id": "2fd12bdb9075_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        # Check for missing type hints\n        if not node.returns and not node.name.startswith('_'):\n            self.issues.append(MigrationIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='optional',\n                category='type_hints',\n                title=f\"Add return type to {node.name}\",\n                description=\"Adding type hints improves code quality and IDE support\"\n            ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 219, "line_end": 231, "language": "python", "name": "visit_FunctionDef"}, "2fd12bdb9075_func_visit_Assign": {"id": "2fd12bdb9075_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        # Check for walrus operator opportunities in Python 3.8+\n        pass\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 233, "line_end": 237, "language": "python", "name": "visit_Assign"}, "2fd12bdb9075_func_visit_BinOp": {"id": "2fd12bdb9075_func_visit_BinOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_BinOp(self, node: ast.BinOp):\n        # Check for % string formatting\n        if isinstance(node.op, ast.Mod):\n            if isinstance(node.left, ast.Constant) and isinstance(node.left.value, str):\n                self.issues.append(MigrationIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='optional',\n                    category='string_format',\n                    title=\"Modernize string formatting\",\n                    description=\"Consider using f-strings for better readability\",\n                    old_syntax='\"%s\" % value',\n                    new_syntax='f\"{value}\"'\n                ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 248, "line_end": 263, "language": "python", "name": "visit_BinOp"}, "2fd12bdb9075_class_MigrationIssue": {"id": "2fd12bdb9075_class_MigrationIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "class MigrationIssue:\n    \"\"\"A migration issue or suggestion.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'required', 'recommended', 'optional'\n    category: str\n    title: str\n    description: str\n    old_syntax: Optional[str] = None\n    new_syntax: Optional[str] = None", "chunk_type": "class", "line_start": 28, "line_end": 37, "language": "python", "name": "MigrationIssue"}, "2fd12bdb9075_class_MigrationReport": {"id": "2fd12bdb9075_class_MigrationReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "class MigrationReport:\n    \"\"\"Complete migration report.\"\"\"\n    target_version: str\n    issues: List[MigrationIssue] = field(default_factory=list)\n\n    @property\n    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']\n\n    @property\n    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        f", "chunk_type": "class", "line_start": 41, "line_end": 96, "language": "python", "name": "MigrationReport"}, "2fd12bdb9075_class_DeprecationAnalyzer": {"id": "2fd12bdb9075_class_DeprecationAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "class DeprecationAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for deprecated patterns.\"\"\"\n\n    def __init__(self, path: Path, target: str):\n        self.path = path\n        self.target = target\n        self.issues: List[MigrationIssue] = []\n        self._typing_imports: Set[str] = set()\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module == 'typing':\n            for alias in node.names:\n                self._typing_imports.add(alias.name)\n\n                # Check deprecated typing imports\n                if alias.name in DEPRECATED_PATTERNS:\n                    new, version, desc = DEPRECATED_PATTERNS[f'typing.{alias.name}']\n                    if self._version_ge(version):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Depre", "chunk_type": "class", "line_start": 126, "line_end": 207, "language": "python", "name": "DeprecationAnalyzer"}, "2fd12bdb9075_class_SyntaxModernizer": {"id": "2fd12bdb9075_class_SyntaxModernizer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "class SyntaxModernizer(ast.NodeVisitor):\n    \"\"\"Suggest syntax modernization.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str], target: str):\n        self.path = path\n        self.source_lines = source_lines\n        self.target = target\n        self.issues: List[MigrationIssue] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        # Check for missing type hints\n        if not node.returns and not node.name.startswith('_'):\n            self.issues.append(MigrationIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='optional',\n                category='type_hints',\n                title=f\"Add return type to {node.name}\",\n                description=\"Adding type hints improves code quality and IDE support\"\n            ))\n\n        self.generic_visit(node)\n\n    def visit_Assign(self, node: ast.Assign):\n        # Check for walrus operator opportunities in Python 3.8+\n        pass\n\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 210, "line_end": 237, "language": "python", "name": "SyntaxModernizer"}, "2fd12bdb9075_class_StringFormatAnalyzer": {"id": "2fd12bdb9075_class_StringFormatAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\migrate.py", "content": "class StringFormatAnalyzer(ast.NodeVisitor):\n    \"\"\"Check string formatting patterns.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.issues: List[MigrationIssue] = []\n\n    def visit_BinOp(self, node: ast.BinOp):\n        # Check for % string formatting\n        if isinstance(node.op, ast.Mod):\n            if isinstance(node.left, ast.Constant) and isinstance(node.left.value, str):\n                self.issues.append(MigrationIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='optional',\n                    category='string_format',\n                    title=\"Modernize string formatting\",\n                    description=\"Consider using f-strings for better readability\",\n                    old_syntax='\"%s\" % value',\n                    new_syntax='f\"{value}\"'\n                ))\n\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 240, "line_end": 263, "language": "python", "name": "StringFormatAnalyzer"}, "772f9b4a0d22_file": {"id": "772f9b4a0d22_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\model_manager.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Model Priority Manager\nManages model selection based on user preference and availability.\nPriority 1: Gemini 3 Flash\nPriority 2: Claude Opus (Latest/4.5 Thinking)\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\n# Configuration Path\nCONFIG_PATH = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules/model_preferences.json\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules/model_preferences.json\")\n\nDEFAULT_PRIORITY = [\n    \"Gemini 3 Flash\",\n    \"Claude Opus (4.5 Thinking)\",\n    \"GPT-4o\"\n]\n\ndef get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n\ndef save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)\n\ndef get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])\n\ndef switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]\n\ndef main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n", "chunk_type": "file", "line_start": 1, "line_end": 73, "language": "python", "name": "model_manager.py"}, "772f9b4a0d22_func_get_preferences": {"id": "772f9b4a0d22_func_get_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\model_manager.py", "content": "def get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}", "chunk_type": "function", "line_start": 23, "line_end": 27, "language": "python", "name": "get_preferences"}, "772f9b4a0d22_func_save_preferences": {"id": "772f9b4a0d22_func_save_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\model_manager.py", "content": "def save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)", "chunk_type": "function", "line_start": 29, "line_end": 31, "language": "python", "name": "save_preferences"}, "772f9b4a0d22_func_get_current_model": {"id": "772f9b4a0d22_func_get_current_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\model_manager.py", "content": "def get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])", "chunk_type": "function", "line_start": 33, "line_end": 35, "language": "python", "name": "get_current_model"}, "772f9b4a0d22_func_switch_model": {"id": "772f9b4a0d22_func_switch_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\model_manager.py", "content": "def switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]", "chunk_type": "function", "line_start": 37, "line_end": 52, "language": "python", "name": "switch_model"}, "772f9b4a0d22_func_main": {"id": "772f9b4a0d22_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\model_manager.py", "content": "def main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n        save_preferences(prefs)\n        print(\"[MODEL] Preferences reset to defaults.\")\n    return 0", "chunk_type": "function", "line_start": 54, "line_end": 69, "language": "python", "name": "main"}, "86ef78906eca_file": {"id": "86ef78906eca_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "\"\"\"\nMulti-Repo Search\n=================\nSearch across all registered projects.\n\nUsage:\n    python mcp.py search-all \"query\"\n    python mcp.py repos --add /path/to/repo\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass RepoInfo:\n    \"\"\"Information about a registered repository.\"\"\"\n    path: str\n    name: str\n    added: str\n    last_indexed: Optional[str] = None\n    file_count: int = 0\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result from multi-repo search.\"\"\"\n    repo: str\n    file: str\n    line: int\n    content: str\n    score: float\n\n\nclass MultiRepoStore:\n    \"\"\"Manage multiple repository indexes.\"\"\"\n\n    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()\n\n    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'\n\n    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)\n\n    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a repository to track.\"\"\"\n        path = path.resolve()\n        if not path.exists():\n            return False\n\n        key = str(path)\n\n        # Count files\n        file_count = sum(1 for _ in path.rglob('*.py'))\n\n        self.repos[key] = RepoInfo(\n            pat", "chunk_type": "file", "line_start": 1, "line_end": 250, "language": "python", "name": "multi_repo.py"}, "86ef78906eca_func_get_store": {"id": "86ef78906eca_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "def get_store() -> MultiRepoStore:\n    global _store\n    if _store is None:\n        _store = MultiRepoStore()\n    return _store", "chunk_type": "function", "line_start": 188, "line_end": 192, "language": "python", "name": "get_store"}, "86ef78906eca_func_main": {"id": "86ef78906eca_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Multi-Repo Search\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    store = get_store()\n\n    Console.info(f\"Registered repos: {len(store.repos)}\")\n\n    if '--add' in sys.argv and args:\n        path = Path(args[0]).resolve()\n        if store.add_repo(path):\n            Console.ok(f\"Added: {path}\")\n        else:\n            Console.fail(f\"Not found: {path}\")\n        return 0\n\n    if '--remove' in sys.argv and args:\n        if store.remove_repo(args[0]):\n            Console.ok(f\"Removed: {args[0]}\")\n        else:\n            Console.fail(f\"Not found: {args[0]}\")\n        return 0\n\n    if '--list' in sys.argv or not args:\n        repos = store.list_repos()\n        if repos:\n            print(\"\\n## Registered Repositories\")\n            for repo in repos:\n                print(f\"  [{repo.name}] {repo.path}\")\n                print(f\"    Files: {repo.file_count}, Added: {repo.added[:10]}\")\n        else:\n            Co", "chunk_type": "function", "line_start": 195, "line_end": 245, "language": "python", "name": "main"}, "86ef78906eca_func___init__": {"id": "86ef78906eca_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()", "chunk_type": "function", "line_start": 44, "line_end": 50, "language": "python", "name": "__init__"}, "86ef78906eca_func__config_path": {"id": "86ef78906eca_func__config_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'", "chunk_type": "function", "line_start": 52, "line_end": 53, "language": "python", "name": "_config_path"}, "86ef78906eca_func_load": {"id": "86ef78906eca_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass", "chunk_type": "function", "line_start": 55, "line_end": 64, "language": "python", "name": "load"}, "86ef78906eca_func_save": {"id": "86ef78906eca_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)", "chunk_type": "function", "line_start": 66, "line_end": 70, "language": "python", "name": "save"}, "86ef78906eca_func_add_repo": {"id": "86ef78906eca_func_add_repo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a repository to track.\"\"\"\n        path = path.resolve()\n        if not path.exists():\n            return False\n\n        key = str(path)\n\n        # Count files\n        file_count = sum(1 for _ in path.rglob('*.py'))\n\n        self.repos[key] = RepoInfo(\n            path=key,\n            name=path.name,\n            added=datetime.utcnow().isoformat() + 'Z',\n            file_count=file_count\n        )\n\n        self.save()\n        return True", "chunk_type": "function", "line_start": 72, "line_end": 91, "language": "python", "name": "add_repo"}, "86ef78906eca_func_remove_repo": {"id": "86ef78906eca_func_remove_repo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def remove_repo(self, path: str) -> bool:\n        \"\"\"Remove a repository.\"\"\"\n        if path in self.repos:\n            del self.repos[path]\n            self.save()\n            return True\n        return False", "chunk_type": "function", "line_start": 93, "line_end": 99, "language": "python", "name": "remove_repo"}, "86ef78906eca_func_list_repos": {"id": "86ef78906eca_func_list_repos", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def list_repos(self) -> List[RepoInfo]:\n        \"\"\"List all registered repos.\"\"\"\n        return list(self.repos.values())", "chunk_type": "function", "line_start": 101, "line_end": 103, "language": "python", "name": "list_repos"}, "86ef78906eca_func_search_all": {"id": "86ef78906eca_func_search_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def search_all(self, query: str, limit: int = 20) -> List[SearchResult]:\n        \"\"\"Search across all repos.\"\"\"\n        results = []\n        query_lower = query.lower()\n\n        for repo_path, repo_info in self.repos.items():\n            path = Path(repo_path)\n            if not path.exists():\n                continue\n\n            # Search files\n            for file_path in path.rglob('*.py'):\n                if '.git' in str(file_path) or 'node_modules' in str(file_path):\n                    continue\n\n                try:\n                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                        for i, line in enumerate(f, 1):\n                            if query_lower in line.lower():\n                                results.append(SearchResult(\n                                    repo=repo_info.name,\n                                    file=str(file_path.relative_to(path)),\n                                    line=i,\n                           ", "chunk_type": "function", "line_start": 105, "line_end": 139, "language": "python", "name": "search_all"}, "86ef78906eca_func_find_similar_code": {"id": "86ef78906eca_func_find_similar_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def find_similar_code(self, code_snippet: str, limit: int = 10) -> List[SearchResult]:\n        \"\"\"Find similar code across repos.\"\"\"\n        results = []\n\n        # Tokenize snippet\n        tokens = set(code_snippet.lower().split())\n        tokens = {t for t in tokens if len(t) > 2}\n\n        if not tokens:\n            return results\n\n        for repo_path, repo_info in self.repos.items():\n            path = Path(repo_path)\n            if not path.exists():\n                continue\n\n            for file_path in path.rglob('*.py'):\n                if '.git' in str(file_path):\n                    continue\n\n                try:\n                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n\n                    # Calculate similarity\n                    file_tokens = set(content.lower().split())\n                    overlap = len(tokens & file_tokens) / len(tokens) if tokens else 0\n\n                    if overlap > 0.3:  ", "chunk_type": "function", "line_start": 141, "line_end": 181, "language": "python", "name": "find_similar_code"}, "86ef78906eca_class_RepoInfo": {"id": "86ef78906eca_class_RepoInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class RepoInfo:\n    \"\"\"Information about a registered repository.\"\"\"\n    path: str\n    name: str\n    added: str\n    last_indexed: Optional[str] = None\n    file_count: int = 0", "chunk_type": "class", "line_start": 22, "line_end": 28, "language": "python", "name": "RepoInfo"}, "86ef78906eca_class_SearchResult": {"id": "86ef78906eca_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class SearchResult:\n    \"\"\"A search result from multi-repo search.\"\"\"\n    repo: str\n    file: str\n    line: int\n    content: str\n    score: float", "chunk_type": "class", "line_start": 32, "line_end": 38, "language": "python", "name": "SearchResult"}, "86ef78906eca_class_MultiRepoStore": {"id": "86ef78906eca_class_MultiRepoStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class MultiRepoStore:\n    \"\"\"Manage multiple repository indexes.\"\"\"\n\n    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()\n\n    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'\n\n    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)\n\n    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a r", "chunk_type": "class", "line_start": 41, "line_end": 181, "language": "python", "name": "MultiRepoStore"}, "f26e0e0d2f39_file": {"id": "f26e0e0d2f39_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP NSync Module\nProvides real-time cross-device synchronization and remote execution.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import List, Optional\nimport os\nimport subprocess\nimport sys\nimport time\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler\nexcept ImportError:\n    Observer = None\n    FileSystemEventHandler = object\n\n# NSync Configuration\nfrom .utils import find_project_root\n\n# NSync Configuration\n# Enforce containment within the current project\n_project_root = find_project_root() or Path.cwd()\nWINDOWS_NSYNC = _project_root / \".nsync\"\nLINUX_NSYNC = _project_root / \".nsync\"\n\ndef get_remote_peer():\n    import socket\n    host = socket.gethostname()\n    if host.lower() == \"wizardpanda\":\n        return \"quasar\"\n    return \"wizardpanda\"\n\nREMOTE_USER = \"p4nd4pr0t0c01\"\n\nclass NSyncHandler(FileSystemEventHandler):\n    \"\"\"Handles file system events and triggers git sync.\"\"\"\n    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds\n\n    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now\n\n    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle conflicts cleanly\n            subprocess.run([\"git\", \"pull\", \"--rebase\", get_remote_peer(), \"master\"], capture_output=True)\n\n            # Pu", "chunk_type": "file", "line_start": 1, "line_end": 372, "language": "python", "name": "nsync.py"}, "f26e0e0d2f39_func_get_remote_peer": {"id": "f26e0e0d2f39_func_get_remote_peer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def get_remote_peer():\n    import socket\n    host = socket.gethostname()\n    if host.lower() == \"wizardpanda\":\n        return \"quasar\"\n    return \"wizardpanda\"", "chunk_type": "function", "line_start": 30, "line_end": 35, "language": "python", "name": "get_remote_peer"}, "f26e0e0d2f39_func_get_nsync_path": {"id": "f26e0e0d2f39_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def get_nsync_path() -> Path:\n    \"\"\"Determine the local NSync path based on OS.\"\"\"\n    if os.name == 'nt':\n        return WINDOWS_NSYNC\n    return LINUX_NSYNC", "chunk_type": "function", "line_start": 106, "line_end": 110, "language": "python", "name": "get_nsync_path"}, "f26e0e0d2f39_func_show_help": {"id": "f26e0e0d2f39_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def show_help():\n    print(\"MCP NSync: Real-time synchronization and remote execution\")\n    print(\"Usage: mcp nsync <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  watch               Start the real-time sync service\")\n    print(\"  status              Check sync status and peer connectivity\")\n    print(\"  run <file>          Sync and execute a file on wizardpanda\")\n    print(\"  sync                Perform a manual sync cycle\")\n    print(\"  setup               Install Git hooks for sync automation\")\n    print(\"  init-project <name> Initialize a new project folder with MCP links\")", "chunk_type": "function", "line_start": 112, "line_end": 121, "language": "python", "name": "show_help"}, "f26e0e0d2f39_func_init_project": {"id": "f26e0e0d2f39_func_init_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def init_project(name: str):\n    \"\"\"Initialize a sub-project within NSync with MCP links.\"\"\"\n    nsync_path = get_nsync_path()\n    project_path = nsync_path / name\n\n    if project_path.exists():\n        print(f\"[FAIL] Project {name} already exists at {project_path}\")\n        return 1\n\n    project_path.mkdir(parents=True)\n    print(f\"[OK] Created project directory: {project_path}\")\n\n    # Create link to mcp-global-rules\n    mcp_source = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules\")\n    mcp_target = project_path / \"mcp-global-rules\"\n\n    try:\n        if os.name == 'nt':\n            # Use Junction for Windows directory link\n            subprocess.run([\"cmd\", \"/c\", \"mklink\", \"/J\", str(mcp_target), str(mcp_source)], check=True)\n        else:\n            os.symlink(mcp_source, mcp_target)\n        print(f\"[OK] Linked mcp-global-rules to {mcp_target}\")\n    except Exception as e:\n        print(f\"[WA", "chunk_type": "function", "line_start": 123, "line_end": 189, "language": "python", "name": "init_project"}, "f26e0e0d2f39_func_start_watch": {"id": "f26e0e0d2f39_func_start_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def start_watch():\n    if not Observer:\n        print(\"[FAIL] 'watchdog' package not found. Install with: pip install watchdog\")\n        return 1\n\n    path = get_nsync_path()\n    if not path.exists():\n        print(f\"[FAIL] NSync directory not found at {path}\")\n        return 1\n\n    # [NEW] PID-based singleton protection\n    import tempfile\n    pid_file = Path(tempfile.gettempdir()) / \"nsync_watch.pid\"\n    if pid_file.exists():\n        try:\n            with open(pid_file, \"r\") as f:\n                old_pid = int(f.read().strip())\n                if os.name == 'nt':\n                    # Windows PID check\n                    subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {old_pid}\"], check=True, capture_output=True)\n                else:\n                    # Linux PID check\n                    os.kill(old_pid, 0)\n                print(f\"[NSYNC] Watch service already running (PID {old_pid}). Exiting.\")\n                return 0\n        except:\n            pid_file.unlink()\n\n    with open(pi", "chunk_type": "function", "line_start": 191, "line_end": 262, "language": "python", "name": "start_watch"}, "f26e0e0d2f39_func_remote_run": {"id": "f26e0e0d2f39_func_remote_run", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def remote_run(filename: str):\n    \"\"\"Sync and run a script on wizardpanda.\"\"\"\n    local_path = get_nsync_path() / filename\n    if not local_path.exists():\n        print(f\"[FAIL] File {filename} not found in NSync directory.\")\n        return 1\n\n    print(f\"[NSYNC] Syncing {filename} to {get_remote_peer()}...\")\n    # Manual sync before execution\n    handler = NSyncHandler(get_nsync_path())\n    handler.sync()\n\n    remote_cmd = f\"cd ~/Projects/NSync && python3 {filename}\"\n    ssh_cmd = [\"ssh\", f\"{REMOTE_USER}@{get_remote_peer()}\", remote_cmd]\n\n    print(f\"[EXEC] Executing on {get_remote_peer()}...\\n\" + \"-\"*40)\n    subprocess.run(ssh_cmd)\n    print(\"-\"*40 + \"\\n[NSYNC] Remote execution complete.\")\n    return 0", "chunk_type": "function", "line_start": 264, "line_end": 282, "language": "python", "name": "remote_run"}, "f26e0e0d2f39_func_check_status": {"id": "f26e0e0d2f39_func_check_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def check_status():\n    \"\"\"Verify connectivity and repo states.\"\"\"\n    path = get_nsync_path()\n    print(f\"Local Path: {path}\")\n    if path.exists():\n        print(\"[OK] Local directory exists.\")\n        os.chdir(path)\n        res = subprocess.run([\"git\", \"status\"], capture_output=True, text=True)\n        if res.returncode == 0:\n            print(\"[OK] Git repository initialized.\")\n        else:\n            print(\"[WARN] Git not initialized in NSync directory.\")\n    else:\n        print(\"[FAIL] Local directory missing.\")\n\n    print(f\"Peer: {get_remote_peer()}\")\n    res = subprocess.run([\"ssh\", f\"{REMOTE_USER}@{get_remote_peer()}\", \"date\"], capture_output=True)\n    if res.returncode == 0:\n        print(\"[OK] Peer reachable via SSH.\")\n    else:\n        print(\"[FAIL] Peer unreachable or SSH failed.\")", "chunk_type": "function", "line_start": 284, "line_end": 304, "language": "python", "name": "check_status"}, "f26e0e0d2f39_func_setup_hooks": {"id": "f26e0e0d2f39_func_setup_hooks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def setup_hooks():\n    \"\"\"Install Git hooks for sync automation.\"\"\"\n    path = get_nsync_path()\n    hooks_dir = path / \".git\" / \"hooks\"\n    if not hooks_dir.exists():\n        print(f\"[FAIL] Git hooks directory missing at {hooks_dir}\")\n        return 1\n\n    # Post-commit hook: Trigger sync immediately\n    post_commit_path = hooks_dir / (\"post-commit\" if os.name != 'nt' else \"post-commit\")\n    # Note: On Windows Git Bash uses the same name\n\n    sync_cmd = \"mcp nsync sync\"\n    if os.name == 'nt':\n        # Create a shell script for Git to run\n        with open(post_commit_path, \"w\") as f:\n            f.write(f\"#!/bin/sh\\n{sync_cmd}\\n\")\n    else:\n        with open(post_commit_path, \"w\") as f:\n            f.write(f\"#!/bin/bash\\npython3 /home/p4nd4pr0t0c01/Projects/mcp-global-rules/mcp.py nsync sync\\n\")\n\n    os.chmod(post_commit_path, 0o755)\n    print(f\"[OK] Installed post-commit hook at {post_commit_path}\")\n\n    # Post-merge hook: Re-index context\n    post_merge_path = hooks_dir / \"post-mer", "chunk_type": "function", "line_start": 306, "line_end": 342, "language": "python", "name": "setup_hooks"}, "f26e0e0d2f39_func_main": {"id": "f26e0e0d2f39_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"watch\":\n        return start_watch()\n    elif cmd == \"run\" and args:\n        return remote_run(args[0])\n    elif cmd == \"status\":\n        return check_status()\n    elif cmd == \"sync\":\n        handler = NSyncHandler(get_nsync_path())\n        handler.sync()\n        return 0\n    elif cmd == \"setup\":\n        return setup_hooks()\n    elif cmd == \"init-project\" and args:\n        return init_project(args[0])\n    else:\n        show_help()\n    return 0", "chunk_type": "function", "line_start": 344, "line_end": 368, "language": "python", "name": "main"}, "f26e0e0d2f39_func___init__": {"id": "f26e0e0d2f39_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds", "chunk_type": "function", "line_start": 41, "line_end": 44, "language": "python", "name": "__init__"}, "f26e0e0d2f39_func_on_any_event": {"id": "f26e0e0d2f39_func_on_any_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now", "chunk_type": "function", "line_start": 46, "line_end": 53, "language": "python", "name": "on_any_event"}, "f26e0e0d2f39_func_sync": {"id": "f26e0e0d2f39_func_sync", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle conflicts cleanly\n            subprocess.run([\"git\", \"pull\", \"--rebase\", get_remote_peer(), \"master\"], capture_output=True)\n\n            # Push to peer\n            subprocess.run([\"git\", \"push\", get_remote_peer(), \"master\"], capture_output=True)\n            print(f\"[NSYNC] Sync complete.\")\n        except Exception as e:\n            print(f\"[FAIL] Sync failed: {e}\")", "chunk_type": "function", "line_start": 55, "line_end": 75, "language": "python", "name": "sync"}, "f26e0e0d2f39_func_ensure_rules_links": {"id": "f26e0e0d2f39_func_ensure_rules_links", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "    def ensure_rules_links(self):\n        \"\"\"Iterate through all projects and ensure mcp-global-rules is linked.\"\"\"\n        mcp_source = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules\")\n\n        for item in self.repo_path.iterdir():\n            if item.is_dir() and not item.name.startswith(\".\"):\n                target = item / \"mcp-global-rules\"\n\n                # If it's a real directory (not a link), remove it to make way for the link\n                if target.exists() and not target.is_symlink():\n                    if os.name != 'nt': # Extra check for Linux directory sync issue\n                         # Only remove if it's not a junction/symlink\n                         import shutil\n                         try:\n                             if target.is_dir() and not target.is_symlink():\n                                 shutil.rmtree(target)\n                         except:\n            ", "chunk_type": "function", "line_start": 77, "line_end": 104, "language": "python", "name": "ensure_rules_links"}, "f26e0e0d2f39_func_poll_remote": {"id": "f26e0e0d2f39_func_poll_remote", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "    def poll_remote():\n        while True:\n            time.sleep(30) # Poll every 30 seconds\n            print(\"[NSYNC] Periodic check for remote changes...\")\n            handler.sync()", "chunk_type": "function", "line_start": 230, "line_end": 234, "language": "python", "name": "poll_remote"}, "f26e0e0d2f39_class_NSyncHandler": {"id": "f26e0e0d2f39_class_NSyncHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\nsync.py", "content": "class NSyncHandler(FileSystemEventHandler):\n    \"\"\"Handles file system events and triggers git sync.\"\"\"\n    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds\n\n    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now\n\n    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle confli", "chunk_type": "class", "line_start": 39, "line_end": 104, "language": "python", "name": "NSyncHandler"}, "6b64abd00cbf_file": {"id": "6b64abd00cbf_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "\"\"\"\nBug Prediction\n==============\nPredict bugs before they happen based on code patterns.\n\nUsage:\n    python mcp.py predict-bugs [file]\n    python mcp.py risk-score\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport json\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass BugPrediction:\n    \"\"\"A predicted bug.\"\"\"\n    file: str\n    line: int\n    risk_level: str  # 'high', 'medium', 'low'\n    category: str\n    description: str\n    confidence: float\n    suggestion: str = \"\"\n\n\n@dataclass\nclass RiskReport:\n    \"\"\"Risk assessment report.\"\"\"\n    total_risk_score: float\n    risk_level: str\n    predictions: List[BugPrediction] = field(default_factory=list)\n    hotspots: List[str] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n            lines.append(\"## Hotspots\")\n            for hs in self.hotspots[:5]:\n                lines.append(f\"- {hs}\")\n\n        return '\\n'.join(lines)\n\n\n# Risk patterns\nRISK_PATTERNS = {\n    'complexity': {\n        'threshold': 10,\n        'weight': 2.0,\n        'description': 'High cyclomatic complexity'\n    },\n    'nesting': {\n        'threshold': 4,\n ", "chunk_type": "file", "line_start": 1, "line_end": 367, "language": "python", "name": "predict.py"}, "6b64abd00cbf_func_predict_bugs": {"id": "6b64abd00cbf_func_predict_bugs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "def predict_bugs(file_path: Path) -> List[BugPrediction]:\n    \"\"\"Predict bugs in a file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n            lines = source.split('\\n')\n\n        tree = ast.parse(source)\n    except Exception:\n        return []\n\n    predictor = BugPredictor(lines)\n    predictor.current_file = str(file_path)\n    predictor.visit(tree)\n\n    return predictor.predictions", "chunk_type": "function", "line_start": 253, "line_end": 268, "language": "python", "name": "predict_bugs"}, "6b64abd00cbf_func_predict_bugs_project": {"id": "6b64abd00cbf_func_predict_bugs_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "def predict_bugs_project(root: Path) -> List[BugPrediction]:\n    \"\"\"Predict bugs across project.\"\"\"\n    all_predictions = []\n\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n\n    for file_path in find_python_files(root, exclude):\n        predictions = predict_bugs(file_path)\n        all_predictions.extend(predictions)\n\n    # Sort by risk level\n    level_order = {'high': 0, 'medium': 1, 'low': 2}\n    all_predictions.sort(key=lambda p: level_order.get(p.risk_level, 3))\n\n    return all_predictions", "chunk_type": "function", "line_start": 271, "line_end": 285, "language": "python", "name": "predict_bugs_project"}, "6b64abd00cbf_func_calculate_risk_score": {"id": "6b64abd00cbf_func_calculate_risk_score", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "def calculate_risk_score(predictions: List[BugPrediction]) -> float:\n    \"\"\"Calculate overall risk score (0-100).\"\"\"\n    if not predictions:\n        return 0.0\n\n    score = 0.0\n    for pred in predictions:\n        weight = RISK_PATTERNS.get(pred.category, {}).get('weight', 1.0)\n        level_mult = {'high': 3, 'medium': 2, 'low': 1}.get(pred.risk_level, 1)\n        score += weight * level_mult * pred.confidence\n\n    # Normalize to 0-100\n    return min(100, score)", "chunk_type": "function", "line_start": 288, "line_end": 300, "language": "python", "name": "calculate_risk_score"}, "6b64abd00cbf_func_get_risk_report": {"id": "6b64abd00cbf_func_get_risk_report", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "def get_risk_report(root: Path = None) -> RiskReport:\n    \"\"\"Generate risk report for project.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    predictions = predict_bugs_project(root)\n    score = calculate_risk_score(predictions)\n\n    # Determine level\n    if score >= 50:\n        level = 'high'\n    elif score >= 20:\n        level = 'medium'\n    else:\n        level = 'low'\n\n    # Find hotspots (files with most issues)\n    file_counts = Counter(p.file for p in predictions)\n    hotspots = [f\"{path} ({count} issues)\" for path, count in file_counts.most_common(5)]\n\n    return RiskReport(\n        total_risk_score=score,\n        risk_level=level,\n        predictions=predictions,\n        hotspots=hotspots\n    )", "chunk_type": "function", "line_start": 303, "line_end": 327, "language": "python", "name": "get_risk_report"}, "6b64abd00cbf_func_main": {"id": "6b64abd00cbf_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Bug Prediction\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if args:\n        file_path = Path(args[0])\n        if file_path.exists() and file_path.is_file():\n            Console.info(f\"Analyzing {file_path}...\")\n            predictions = predict_bugs(file_path)\n\n            if predictions:\n                Console.warn(f\"Found {len(predictions)} potential issues\")\n                for pred in predictions:\n                    level_color = {'high': '\\033[91m', 'medium': '\\033[93m', 'low': '\\033[92m'}\n                    nc = '\\033[0m'\n                    print(f\"\\n  {level_color.get(pred.risk_level, '')}{pred.risk_level.upper()}{nc}: {pred.category}\")\n                    print(f\"  Line {pred.line}: {pred.description}\")\n                    if pred.suggestion:\n                        print(f\"  Suggestion: {pred.suggestion}\")\n            else:\n                Conso", "chunk_type": "function", "line_start": 330, "line_end": 362, "language": "python", "name": "main"}, "6b64abd00cbf_func_to_markdown": {"id": "6b64abd00cbf_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n            lines.append(\"## Hotspots\")\n            for hs in self.hotspots[:5]:\n                lines.append(f\"- {hs}\")\n\n        return '\\n'.join(lines)", "chunk_type": "function", "line_start": 42, "line_end": 66, "language": "python", "name": "to_markdown"}, "6b64abd00cbf_func___init__": {"id": "6b64abd00cbf_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def __init__(self, source_lines: List[str]):\n        self.predictions: List[BugPrediction] = []\n        self.source_lines = source_lines\n        self.current_file = \"\"", "chunk_type": "function", "line_start": 157, "line_end": 160, "language": "python", "name": "__init__"}, "6b64abd00cbf_func_visit_If": {"id": "6b64abd00cbf_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_If(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 120, "line_end": 124, "language": "python", "name": "visit_If"}, "6b64abd00cbf_func_visit_For": {"id": "6b64abd00cbf_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_For(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 126, "line_end": 130, "language": "python", "name": "visit_For"}, "6b64abd00cbf_func_visit_While": {"id": "6b64abd00cbf_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_While(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 132, "line_end": 136, "language": "python", "name": "visit_While"}, "6b64abd00cbf_func_visit_ExceptHandler": {"id": "6b64abd00cbf_func_visit_ExceptHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_ExceptHandler(self, node):\n        if node.type is None:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high',\n                category='bare_except',\n                description=\"Bare except catches all exceptions\",\n                confidence=0.95,\n                suggestion=\"Specify exception type: except Exception:\"\n            ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 227, "line_end": 238, "language": "python", "name": "visit_ExceptHandler"}, "6b64abd00cbf_func_visit_BoolOp": {"id": "6b64abd00cbf_func_visit_BoolOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_BoolOp(self, node):\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 142, "line_end": 144, "language": "python", "name": "visit_BoolOp"}, "6b64abd00cbf_func__enter_nesting": {"id": "6b64abd00cbf_func__enter_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def _enter_nesting(self):\n        self.current_nesting += 1\n        self.max_nesting = max(self.max_nesting, self.current_nesting)", "chunk_type": "function", "line_start": 146, "line_end": 148, "language": "python", "name": "_enter_nesting"}, "6b64abd00cbf_func__exit_nesting": {"id": "6b64abd00cbf_func__exit_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def _exit_nesting(self):\n        self.current_nesting -= 1", "chunk_type": "function", "line_start": 150, "line_end": 151, "language": "python", "name": "_exit_nesting"}, "6b64abd00cbf_func_analyze_function": {"id": "6b64abd00cbf_func_analyze_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def analyze_function(self, node: ast.FunctionDef):\n        \"\"\"Analyze a function for bug risks.\"\"\"\n        # Complexity analysis\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        line_count = (node.end_lineno or node.lineno) - node.lineno\n        param_count = len(node.args.args)\n\n        # Check complexity\n        if analyzer.complexity > RISK_PATTERNS['complexity']['threshold']:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high' if analyzer.complexity > 20 else 'medium',\n                category='complexity',\n                description=f\"Cyclomatic complexity {analyzer.complexity} in {node.name}()\",\n                confidence=0.8,\n                suggestion=\"Break into smaller functions\"\n            ))\n\n        # Check nesting\n        if analyzer.max_nesting > RISK_PATTERNS['nesting']['threshold']:\n            self.predictions.append(BugPredicti", "chunk_type": "function", "line_start": 162, "line_end": 217, "language": "python", "name": "analyze_function"}, "6b64abd00cbf_func_visit_FunctionDef": {"id": "6b64abd00cbf_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_FunctionDef(self, node):\n        self.analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 219, "line_end": 221, "language": "python", "name": "visit_FunctionDef"}, "6b64abd00cbf_func_visit_AsyncFunctionDef": {"id": "6b64abd00cbf_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_AsyncFunctionDef(self, node):\n        self.analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 223, "line_end": 225, "language": "python", "name": "visit_AsyncFunctionDef"}, "6b64abd00cbf_func_visit_Global": {"id": "6b64abd00cbf_func_visit_Global", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_Global(self, node):\n        self.predictions.append(BugPrediction(\n            file=self.current_file,\n            line=node.lineno,\n            risk_level='medium',\n            category='global_var',\n            description=f\"Global variable: {', '.join(node.names)}\",\n            confidence=0.6,\n            suggestion=\"Consider using a class or passing as parameter\"\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 240, "line_end": 250, "language": "python", "name": "visit_Global"}, "6b64abd00cbf_class_BugPrediction": {"id": "6b64abd00cbf_class_BugPrediction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "class BugPrediction:\n    \"\"\"A predicted bug.\"\"\"\n    file: str\n    line: int\n    risk_level: str  # 'high', 'medium', 'low'\n    category: str\n    description: str\n    confidence: float\n    suggestion: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 31, "language": "python", "name": "BugPrediction"}, "6b64abd00cbf_class_RiskReport": {"id": "6b64abd00cbf_class_RiskReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "class RiskReport:\n    \"\"\"Risk assessment report.\"\"\"\n    total_risk_score: float\n    risk_level: str\n    predictions: List[BugPrediction] = field(default_factory=list)\n    hotspots: List[str] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n         ", "chunk_type": "class", "line_start": 35, "line_end": 66, "language": "python", "name": "RiskReport"}, "6b64abd00cbf_class_ComplexityAnalyzer": {"id": "6b64abd00cbf_class_ComplexityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "class ComplexityAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code complexity.\"\"\"\n\n    def __init__(self):\n        self.complexity = 1\n        self.max_nesting = 0\n        self.current_nesting = 0\n        self.function_lines = 0\n        self.param_count = 0\n\n    def visit_If(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_For(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_While(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_ExceptHandler(self, node):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_BoolOp(self, node):\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)\n\n    def _enter_nesting(self):\n        self.current_nesting += 1\n ", "chunk_type": "class", "line_start": 110, "line_end": 151, "language": "python", "name": "ComplexityAnalyzer"}, "6b64abd00cbf_class_BugPredictor": {"id": "6b64abd00cbf_class_BugPredictor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\predict.py", "content": "class BugPredictor(ast.NodeVisitor):\n    \"\"\"Predict bugs in code.\"\"\"\n\n    def __init__(self, source_lines: List[str]):\n        self.predictions: List[BugPrediction] = []\n        self.source_lines = source_lines\n        self.current_file = \"\"\n\n    def analyze_function(self, node: ast.FunctionDef):\n        \"\"\"Analyze a function for bug risks.\"\"\"\n        # Complexity analysis\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        line_count = (node.end_lineno or node.lineno) - node.lineno\n        param_count = len(node.args.args)\n\n        # Check complexity\n        if analyzer.complexity > RISK_PATTERNS['complexity']['threshold']:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high' if analyzer.complexity > 20 else 'medium',\n                category='complexity',\n                description=f\"Cyclomatic complexity {analyzer.complexity} in {node.name}()\",\n       ", "chunk_type": "class", "line_start": 154, "line_end": 250, "language": "python", "name": "BugPredictor"}, "116acf913cc4_file": {"id": "116acf913cc4_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "\"\"\"\nPerformance Profiler\n====================\nStatic analysis for performance bottlenecks and code complexity.\n\nUsage:\n    python profile.py [path]\n    python -m scripts.profile src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass PerformanceIssue:\n    \"\"\"A performance finding.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'critical', 'high', 'medium', 'low'\n    category: str\n    title: str\n    description: str\n    complexity: Optional[str] = None  # Big-O notation\n    suggestion: Optional[str] = None\n\n\n@dataclass\nclass PerformanceReport:\n    \"\"\"Complete performance analysis report.\"\"\"\n    issues: List[PerformanceIssue] = field(default_factory=list)\n    complexity_scores: Dict[str, int] = field(default_factory=dict)\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f\"| `{name}` | {score} ({status}) |\")\n            lines.append(\"\")\n\n        if self.issues:\n            lines.extend([\"## Issues\", \"\"])\n\n            for issue in sorted(self.issues, key=lambda x: (\n                {'critical': 0, 'high':", "chunk_type": "file", "line_start": 1, "line_end": 441, "language": "python", "name": "profile.py"}, "116acf913cc4_func_analyze_file": {"id": "116acf913cc4_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "def analyze_file(path: Path) -> Tuple[List[PerformanceIssue], Dict[str, int]]:\n    \"\"\"Analyze a single file for performance issues.\"\"\"\n    issues = []\n    complexity = {}\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues, complexity\n\n    # Run analyzers\n    perf = PerformanceAnalyzer(path)\n    perf.visit(tree)\n    issues.extend(perf.issues)\n    complexity.update(perf.complexity_scores)\n\n    mem = MemoryAnalyzer(path)\n    mem.visit(tree)\n    issues.extend(mem.issues)\n\n    async_analyzer = AsyncAnalyzer(path)\n    async_analyzer.visit(tree)\n    issues.extend(async_analyzer.issues)\n\n    return issues, complexity", "chunk_type": "function", "line_start": 356, "line_end": 379, "language": "python", "name": "analyze_file"}, "116acf913cc4_func_analyze_project": {"id": "116acf913cc4_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> PerformanceReport:\n    \"\"\"Analyze project for performance issues.\"\"\"\n    report = PerformanceReport()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        issues, complexity = analyze_file(path)\n        report.issues.extend(issues)\n        report.complexity_scores.update(complexity)\n\n    return report", "chunk_type": "function", "line_start": 382, "line_end": 399, "language": "python", "name": "analyze_project"}, "116acf913cc4_func_main": {"id": "116acf913cc4_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Performance Profiler\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    high_complexity = sum(1 for s in report.complexity_scores.values() if s > 10)\n\n    if high_complexity > 0:\n        Console.warn(f\"Found {high_complexity} functions with high complexity\")\n\n    Console.info(f\"Found {len(report.issues)} performance issues\")\n\n    return 0", "chunk_type": "function", "line_start": 406, "line_end": 436, "language": "python", "name": "main"}, "116acf913cc4_func_to_markdown": {"id": "116acf913cc4_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f\"| `{name}` | {score} ({status}) |\")\n            lines.append(\"\")\n\n        if self.issues:\n            lines.extend([\"## Issues\", \"\"])\n\n            for issue in sorted(self.issues, key=lambda x: (\n          ", "chunk_type": "function", "line_start": 45, "line_end": 90, "language": "python", "name": "to_markdown"}, "116acf913cc4_func___init__": {"id": "116acf913cc4_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self._in_async = False", "chunk_type": "function", "line_start": 310, "line_end": 313, "language": "python", "name": "__init__"}, "116acf913cc4_func_visit_If": {"id": "116acf913cc4_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_If(self, node: ast.If):\n        self.complexity += 1\n        # Count elif branches\n        for _ in node.orelse:\n            if isinstance(_, ast.If):\n                self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 99, "line_end": 105, "language": "python", "name": "visit_If"}, "116acf913cc4_func_visit_While": {"id": "116acf913cc4_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_While(self, node: ast.While):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 107, "line_end": 109, "language": "python", "name": "visit_While"}, "116acf913cc4_func_visit_For": {"id": "116acf913cc4_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_For(self, node: ast.For):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 111, "line_end": 113, "language": "python", "name": "visit_For"}, "116acf913cc4_func_visit_ExceptHandler": {"id": "116acf913cc4_func_visit_ExceptHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_ExceptHandler(self, node: ast.ExceptHandler):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 115, "line_end": 117, "language": "python", "name": "visit_ExceptHandler"}, "116acf913cc4_func_visit_BoolOp": {"id": "116acf913cc4_func_visit_BoolOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_BoolOp(self, node: ast.BoolOp):\n        # Each and/or adds a decision point\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 119, "line_end": 122, "language": "python", "name": "visit_BoolOp"}, "116acf913cc4_func_visit_comprehension": {"id": "116acf913cc4_func_visit_comprehension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_comprehension(self, node: ast.comprehension):\n        self.complexity += 1\n        self.complexity += len(node.ifs)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 124, "line_end": 127, "language": "python", "name": "visit_comprehension"}, "116acf913cc4_func_visit_FunctionDef": {"id": "116acf913cc4_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 140, "line_end": 142, "language": "python", "name": "visit_FunctionDef"}, "116acf913cc4_func_visit_AsyncFunctionDef": {"id": "116acf913cc4_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        old_in_async = self._in_async\n        self._in_async = True\n        self.generic_visit(node)\n        self._in_async = old_in_async", "chunk_type": "function", "line_start": 315, "line_end": 319, "language": "python", "name": "visit_AsyncFunctionDef"}, "116acf913cc4_func__analyze_function": {"id": "116acf913cc4_func__analyze_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def _analyze_function(self, node):\n        # Calculate complexity\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        func_name = f\"{self.path.stem}.{node.name}\"\n        self.complexity_scores[func_name] = analyzer.complexity\n\n        # Check for high complexity\n        if analyzer.complexity > 15:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='high',\n                category='complexity',\n                title=f\"High cyclomatic complexity: {node.name}\",\n                description=f\"Function has complexity of {analyzer.complexity} (threshold: 15)\",\n                suggestion=\"Break down into smaller functions\"\n            ))\n        elif analyzer.complexity > 10:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='medium',\n                category='complexity',\n              ", "chunk_type": "function", "line_start": 148, "line_end": 190, "language": "python", "name": "_analyze_function"}, "116acf913cc4_func__check_nested_loops": {"id": "116acf913cc4_func__check_nested_loops", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_nested_loops(self, node: ast.For, parent_func):\n        \"\"\"Detect nested loops (O(n^2) or worse).\"\"\"\n        nested = 0\n        for child in ast.walk(node):\n            if isinstance(child, ast.For) and child != node:\n                nested += 1\n\n        if nested >= 2:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='high',\n                category='algorithm',\n                title=\"Deeply nested loops\",\n                description=f\"Found {nested + 1} levels of nested loops\",\n                complexity=f\"O(n^{nested + 1})\",\n                suggestion=\"Consider using sets, dicts, or algorithmic optimizations\"\n            ))\n        elif nested == 1:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='medium',\n                category='algorithm',\n                title=\"Nested loop\",\n        ", "chunk_type": "function", "line_start": 192, "line_end": 220, "language": "python", "name": "_check_nested_loops"}, "116acf913cc4_func__check_list_comprehension": {"id": "116acf913cc4_func__check_list_comprehension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_list_comprehension(self, node: ast.ListComp):\n        \"\"\"Check for expensive list comprehensions.\"\"\"\n        # Check for nested comprehensions\n        for gen in node.generators:\n            if isinstance(gen.iter, ast.ListComp):\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='medium',\n                    category='memory',\n                    title=\"Nested list comprehension\",\n                    description=\"Nested comprehensions create intermediate lists\",\n                    suggestion=\"Consider using generator expressions\"\n                ))", "chunk_type": "function", "line_start": 222, "line_end": 235, "language": "python", "name": "_check_list_comprehension"}, "116acf913cc4_func__check_expensive_calls": {"id": "116acf913cc4_func__check_expensive_calls", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_expensive_calls(self, node: ast.Call):\n        \"\"\"Check for expensive function calls.\"\"\"\n        func_name = self._get_func_name(node.func)\n\n        # String concatenation in loop\n        if func_name == 'join':\n            pass  # join is good\n\n        # len() in loop condition\n        # (would need more context to detect)\n\n        # Regular expression compilation in loop\n        if func_name in ('re.match', 're.search', 're.findall'):\n            # Check if inside a loop\n            pass  # Would need parent context", "chunk_type": "function", "line_start": 237, "line_end": 251, "language": "python", "name": "_check_expensive_calls"}, "116acf913cc4_func__get_func_name": {"id": "116acf913cc4_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\"\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 346, "line_end": 353, "language": "python", "name": "_get_func_name"}, "116acf913cc4_func_visit_Call": {"id": "116acf913cc4_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_Call(self, node: ast.Call):\n        if self._in_async:\n            func_name = self._get_func_name(node.func)\n\n            # Blocking calls in async code\n            blocking = {\n                'time.sleep': 'asyncio.sleep',\n                'requests.get': 'aiohttp.get',\n                'requests.post': 'aiohttp.post',\n                'open': 'aiofiles.open',\n            }\n\n            if func_name in blocking:\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='high',\n                    category='async',\n                    title=f\"Blocking call in async: {func_name}\",\n                    description=f\"{func_name}() blocks the event loop\",\n                    suggestion=f\"Use {blocking[func_name]}() instead\"\n                ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 321, "line_end": 344, "language": "python", "name": "visit_Call"}, "116acf913cc4_class_PerformanceIssue": {"id": "116acf913cc4_class_PerformanceIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceIssue:\n    \"\"\"A performance finding.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'critical', 'high', 'medium', 'low'\n    category: str\n    title: str\n    description: str\n    complexity: Optional[str] = None  # Big-O notation\n    suggestion: Optional[str] = None", "chunk_type": "class", "line_start": 27, "line_end": 36, "language": "python", "name": "PerformanceIssue"}, "116acf913cc4_class_PerformanceReport": {"id": "116acf913cc4_class_PerformanceReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceReport:\n    \"\"\"Complete performance analysis report.\"\"\"\n    issues: List[PerformanceIssue] = field(default_factory=list)\n    complexity_scores: Dict[str, int] = field(default_factory=dict)\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f", "chunk_type": "class", "line_start": 40, "line_end": 90, "language": "python", "name": "PerformanceReport"}, "116acf913cc4_class_ComplexityAnalyzer": {"id": "116acf913cc4_class_ComplexityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "class ComplexityAnalyzer(ast.NodeVisitor):\n    \"\"\"Calculate cyclomatic complexity.\"\"\"\n\n    def __init__(self):\n        self.complexity = 1  # Base complexity\n\n    def visit_If(self, node: ast.If):\n        self.complexity += 1\n        # Count elif branches\n        for _ in node.orelse:\n            if isinstance(_, ast.If):\n                self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_While(self, node: ast.While):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_For(self, node: ast.For):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_ExceptHandler(self, node: ast.ExceptHandler):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_BoolOp(self, node: ast.BoolOp):\n        # Each and/or adds a decision point\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)\n\n    def visit_comprehension(self, node: ast.comprehension):\n        self.complexity += 1\n        sel", "chunk_type": "class", "line_start": 93, "line_end": 127, "language": "python", "name": "ComplexityAnalyzer"}, "116acf913cc4_class_PerformanceAnalyzer": {"id": "116acf913cc4_class_PerformanceAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for performance issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self.complexity_scores: Dict[str, int] = {}\n        self._current_function: Optional[str] = None\n        self._loop_depth = 0\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)\n\n    def _analyze_function(self, node):\n        # Calculate complexity\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        func_name = f\"{self.path.stem}.{node.name}\"\n        self.complexity_scores[func_name] = analyzer.complexity\n\n        # Check for high complexity\n        if analyzer.complexity > 15:\n            self.issues.append(PerformanceIssue(\n                path", "chunk_type": "class", "line_start": 130, "line_end": 260, "language": "python", "name": "PerformanceAnalyzer"}, "116acf913cc4_class_MemoryAnalyzer": {"id": "116acf913cc4_class_MemoryAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "class MemoryAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for memory issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n\n    def visit_Call(self, node: ast.Call):\n        func_name = self._get_func_name(node.func)\n\n        # Check for reading entire files\n        if func_name in ('read', 'readlines'):\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='low',\n                category='memory',\n                title=\"Reading entire file into memory\",\n                description=\"Using read()/readlines() loads entire file\",\n                suggestion=\"Consider iterating line by line for large files\"\n            ))\n\n        # Large list operations\n        if func_name == 'sorted' or func_name == 'list':\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n               ", "chunk_type": "class", "line_start": 263, "line_end": 304, "language": "python", "name": "MemoryAnalyzer"}, "116acf913cc4_class_AsyncAnalyzer": {"id": "116acf913cc4_class_AsyncAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\profile.py", "content": "class AsyncAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze async code for issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self._in_async = False\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        old_in_async = self._in_async\n        self._in_async = True\n        self.generic_visit(node)\n        self._in_async = old_in_async\n\n    def visit_Call(self, node: ast.Call):\n        if self._in_async:\n            func_name = self._get_func_name(node.func)\n\n            # Blocking calls in async code\n            blocking = {\n                'time.sleep': 'asyncio.sleep',\n                'requests.get': 'aiohttp.get',\n                'requests.post': 'aiohttp.post',\n                'open': 'aiofiles.open',\n            }\n\n            if func_name in blocking:\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n               ", "chunk_type": "class", "line_start": 307, "line_end": 353, "language": "python", "name": "AsyncAnalyzer"}, "162830b72e5b_file": {"id": "162830b72e5b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\record.py", "content": "\"\"\"\nContext Recorder\n================\nRecord development actions and context snapshots to memory.\n\nUsage:\n    python mcp.py record \"Action description\"\n    python mcp.py record --snapshot\n\"\"\"\n\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import List, Optional\nimport subprocess\nimport sys\n\nfrom .memory import get_store\nfrom .utils import Console, find_project_root, run_git_command\n\ndef get_git_status(root: Path) -> str:\n    \"\"\"Get concise git status.\"\"\"\n    status = run_git_command(['status', '--short'], cwd=root)\n    if not status:\n        return \"No changes\"\n    return status\n\ndef get_git_diff_stat(root: Path) -> str:\n    \"\"\"Get git diff stats.\"\"\"\n    # Staged changes\n    staged = run_git_command(['diff', '--cached', '--stat'], cwd=root)\n    return staged or \"No staged changes\"\n\ndef analyze_diff(root: Path) -> str:\n    \"\"\"Analyze the staged diff for semantic meaning.\"\"\"\n    diff = run_git_command(['diff', '--cached', '-U0'], cwd=root)\n    if not diff:\n        return \"No staged changes detected.\"\n\n    changes = []\n    current_file = \"\"\n\n    for line in diff.split('\\n'):\n        if line.startswith('diff --git'):\n            # diff --git a/file.py b/file.py\n            parts = line.split()\n            if len(parts) >= 4:\n                current_file = parts[-1].lstrip('b/')\n        elif line.startswith('@@'):\n            # @@ -10,0 +11,5 @@ def new_function():\n            # Try to extract context hint\n            context = line.split('@@')[-1].strip()\n            if context and current_file:\n                changes.append(f\"- {current_file}: {context}\")\n            elif current_file:\n                 changes.append(f\"- {current_file}: (modification)\")\n\n    # Deduplicate and summarize\n    unique_changes = sorted(list(set(changes)))\n    if len(unique_changes) > 10:\n        return \"\\n\".join(unique_changes[:10]) + f\"\\n... ({len(unique_changes) - 10} more changes)\"\n    return \"\\n\".join(unique_changes)\n\ndef record_snapshot(root: Path) -> bool:\n    \"\"\"R", "chunk_type": "file", "line_start": 1, "line_end": 109, "language": "python", "name": "record.py"}, "162830b72e5b_func_get_git_status": {"id": "162830b72e5b_func_get_git_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\record.py", "content": "def get_git_status(root: Path) -> str:\n    \"\"\"Get concise git status.\"\"\"\n    status = run_git_command(['status', '--short'], cwd=root)\n    if not status:\n        return \"No changes\"\n    return status", "chunk_type": "function", "line_start": 20, "line_end": 25, "language": "python", "name": "get_git_status"}, "162830b72e5b_func_get_git_diff_stat": {"id": "162830b72e5b_func_get_git_diff_stat", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\record.py", "content": "def get_git_diff_stat(root: Path) -> str:\n    \"\"\"Get git diff stats.\"\"\"\n    # Staged changes\n    staged = run_git_command(['diff', '--cached', '--stat'], cwd=root)\n    return staged or \"No staged changes\"", "chunk_type": "function", "line_start": 27, "line_end": 31, "language": "python", "name": "get_git_diff_stat"}, "162830b72e5b_func_analyze_diff": {"id": "162830b72e5b_func_analyze_diff", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\record.py", "content": "def analyze_diff(root: Path) -> str:\n    \"\"\"Analyze the staged diff for semantic meaning.\"\"\"\n    diff = run_git_command(['diff', '--cached', '-U0'], cwd=root)\n    if not diff:\n        return \"No staged changes detected.\"\n\n    changes = []\n    current_file = \"\"\n\n    for line in diff.split('\\n'):\n        if line.startswith('diff --git'):\n            # diff --git a/file.py b/file.py\n            parts = line.split()\n            if len(parts) >= 4:\n                current_file = parts[-1].lstrip('b/')\n        elif line.startswith('@@'):\n            # @@ -10,0 +11,5 @@ def new_function():\n            # Try to extract context hint\n            context = line.split('@@')[-1].strip()\n            if context and current_file:\n                changes.append(f\"- {current_file}: {context}\")\n            elif current_file:\n                 changes.append(f\"- {current_file}: (modification)\")\n\n    # Deduplicate and summarize\n    unique_changes = sorted(list(set(changes)))\n    if len(unique_changes) > 10:", "chunk_type": "function", "line_start": 33, "line_end": 61, "language": "python", "name": "analyze_diff"}, "162830b72e5b_func_record_snapshot": {"id": "162830b72e5b_func_record_snapshot", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\record.py", "content": "def record_snapshot(root: Path) -> bool:\n    \"\"\"Record a context snapshot of current state.\"\"\"\n    Console.info(\"Recording context snapshot...\")\n\n    status = get_git_status(root)\n    semantic_summary = analyze_diff(root)\n\n    content = f\"# Context Snapshot\\n\\n## Git Status\\n{status}\\n\\n## Semantic Changes\\n{semantic_summary}\"\n\n    store = get_store()\n    timestamp = datetime.now().isoformat()\n\n    store.remember(\n        key=f\"Snapshot {timestamp}\",\n        value=content,\n        tags=['snapshot', 'auto-context', 'pre-commit']\n    )\n\n    Console.ok(\"Context snapshot recorded\")\n    return True", "chunk_type": "function", "line_start": 63, "line_end": 82, "language": "python", "name": "record_snapshot"}, "162830b72e5b_func_main": {"id": "162830b72e5b_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\record.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--snapshot' in sys.argv:\n        record_snapshot(root)\n        return 0\n\n    if not args:\n        Console.fail(\"Usage: mcp record 'message' OR mcp record --snapshot\")\n        return 1\n\n    message = \" \".join(args)\n    store = get_store()\n    store.remember(\n        key=f\"Action {datetime.now().isoformat()}\",\n        value=message,\n        tags=['user-action']\n    )\n    Console.ok(\"Action recorded\")\n    return 0", "chunk_type": "function", "line_start": 84, "line_end": 105, "language": "python", "name": "main"}, "d053a6a8adec_file": {"id": "d053a6a8adec_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "\"\"\"\nAuto-Refactorer\n===============\nDetect and suggest code refactorings for improved quality.\n\nUsage:\n    python refactor.py [path] [--apply]\n    python -m scripts.refactor src/\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Set\nimport ast\nimport hashlib\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass RefactoringSuggestion:\n    \"\"\"A suggested refactoring.\"\"\"\n    path: Path\n    line_start: int\n    line_end: int\n    severity: str  # 'high', 'medium', 'low'\n    category: str  # 'long_function', 'duplicate', 'complex', 'naming'\n    message: str\n    suggestion: str\n\n\n@dataclass\nclass RefactoringReport:\n    \"\"\"Complete refactoring report.\"\"\"\n    suggestions: List[RefactoringSuggestion] = field(default_factory=list)\n\n    @property\n    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n                lines.append(f\"**Suggestion:** {s.suggestion}\")\n                lines.append(\"\")\n\n        return \"\\n\".join(lines)\n\n\nclass LongFunctionDetector(ast.NodeVisitor):\n    \"\"\"Detect functions ", "chunk_type": "file", "line_start": 1, "line_end": 403, "language": "python", "name": "refactor.py"}, "d053a6a8adec_func_analyze_file": {"id": "d053a6a8adec_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def analyze_file(self, path: Path, tree: ast.Module, source_lines: List[str]):\n        \"\"\"Analyze file for duplicate blocks.\"\"\"\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    start = node.lineno - 1\n                    end = node.end_lineno\n                    if end - start >= self.MIN_LINES:\n                        content = '\\n'.join(source_lines[start:end])\n                        # Normalize whitespace\n                        normalized = ' '.join(content.split())\n                        code_hash = hashlib.md5(normalized.encode()).hexdigest()\n                        self.code_hashes[code_hash].append((path, start + 1, end))", "chunk_type": "function", "line_start": 173, "line_end": 185, "language": "python", "name": "analyze_file"}, "d053a6a8adec_func_analyze_project": {"id": "d053a6a8adec_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> RefactoringReport:\n    \"\"\"Analyze project for refactoring opportunities.\"\"\"\n    report = RefactoringReport()\n    duplicate_detector = DuplicateCodeDetector()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        # Single file analysis\n        issues = analyze_file(path)\n        report.suggestions.extend(issues)\n\n        # Collect for duplicate detection\n        tree = parse_file(path)\n        if tree:\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    source_lines = f.readlines()\n                duplicate_detector.analyze_file(path, tree, source_lines)\n            except Exception:\n                pass\n\n    # Finalize duplicate detection\n    duplicate_detector.finalize()\n    report.suggestions.extend(duplicate_detector.issues)\n\n", "chunk_type": "function", "line_start": 338, "line_end": 370, "language": "python", "name": "analyze_project"}, "d053a6a8adec_func_main": {"id": "d053a6a8adec_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Refactorer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    Console.info(f\"Found {len(report.suggestions)} refactoring suggestions\")\n    Console.info(f\"High priority: {len(report.high_priority)}\")\n\n    return 0", "chunk_type": "function", "line_start": 373, "line_end": 398, "language": "python", "name": "main"}, "d053a6a8adec_func_high_priority": {"id": "d053a6a8adec_func_high_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']", "chunk_type": "function", "line_start": 46, "line_end": 47, "language": "python", "name": "high_priority"}, "d053a6a8adec_func_to_markdown": {"id": "d053a6a8adec_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n                lines.append(f\"**Suggestion:** {s.suggestion}\")\n                lines.append(\"\")\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 49, "line_end": 73, "language": "python", "name": "to_markdown"}, "d053a6a8adec_func___init__": {"id": "d053a6a8adec_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []", "chunk_type": "function", "line_start": 282, "line_end": 284, "language": "python", "name": "__init__"}, "d053a6a8adec_func_visit_FunctionDef": {"id": "d053a6a8adec_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 286, "line_end": 288, "language": "python", "name": "visit_FunctionDef"}, "d053a6a8adec_func_visit_AsyncFunctionDef": {"id": "d053a6a8adec_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 290, "line_end": 292, "language": "python", "name": "visit_AsyncFunctionDef"}, "d053a6a8adec_func__check_function": {"id": "d053a6a8adec_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_function(self, node):\n        if node.end_lineno:\n            length = node.end_lineno - node.lineno\n            if length > self.MAX_LINES:\n                self.issues.append(RefactoringSuggestion(\n                    path=self.path,\n                    line_start=node.lineno,\n                    line_end=node.end_lineno,\n                    severity='high' if length > 100 else 'medium',\n                    category='long_function',\n                    message=f\"Function '{node.name}' is {length} lines (max: {self.MAX_LINES})\",\n                    suggestion=f\"Extract helper functions from '{node.name}'\"\n                ))", "chunk_type": "function", "line_start": 93, "line_end": 105, "language": "python", "name": "_check_function"}, "d053a6a8adec_func_visit_If": {"id": "d053a6a8adec_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_If(self, node: ast.If):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 127, "line_end": 131, "language": "python", "name": "visit_If"}, "d053a6a8adec_func_visit_For": {"id": "d053a6a8adec_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_For(self, node: ast.For):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 133, "line_end": 137, "language": "python", "name": "visit_For"}, "d053a6a8adec_func_visit_While": {"id": "d053a6a8adec_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_While(self, node: ast.While):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 139, "line_end": 143, "language": "python", "name": "visit_While"}, "d053a6a8adec_func_visit_Try": {"id": "d053a6a8adec_func_visit_Try", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_Try(self, node: ast.Try):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 145, "line_end": 149, "language": "python", "name": "visit_Try"}, "d053a6a8adec_func__check_nesting": {"id": "d053a6a8adec_func__check_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_nesting(self, node):\n        if self._nesting_level >= self.MAX_NESTED:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.end_lineno or node.lineno,\n                severity='high',\n                category='deep_nesting',\n                message=f\"Deeply nested code ({self._nesting_level + 1} levels)\",\n                suggestion=\"Extract nested logic into helper functions\"\n            ))", "chunk_type": "function", "line_start": 151, "line_end": 161, "language": "python", "name": "_check_nesting"}, "d053a6a8adec_func_finalize": {"id": "d053a6a8adec_func_finalize", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def finalize(self):\n        \"\"\"Generate issues for duplicates.\"\"\"\n        for code_hash, locations in self.code_hashes.items():\n            if len(locations) > 1:\n                files = list(set(str(loc[0]) for loc in locations))\n                for path, start, end in locations:\n                    self.issues.append(RefactoringSuggestion(\n                        path=path,\n                        line_start=start,\n                        line_end=end,\n                        severity='medium',\n                        category='duplicate_code',\n                        message=f\"Duplicate code found in {len(locations)} locations\",\n                        suggestion=f\"Extract common code into shared function\"\n                    ))", "chunk_type": "function", "line_start": 187, "line_end": 201, "language": "python", "name": "finalize"}, "d053a6a8adec_func_visit_ClassDef": {"id": "d053a6a8adec_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        self._check_class_name(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 215, "line_end": 217, "language": "python", "name": "visit_ClassDef"}, "d053a6a8adec_func__check_function_name": {"id": "d053a6a8adec_func__check_function_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_function_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for camelCase\n        if any(c.isupper() for c in name[1:]) and '_' not in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' uses camelCase\",\n                suggestion=f\"Rename to snake_case: '{self._to_snake_case(name)}'\"\n            ))\n\n        # Check single letter names (except i, j, k, x, y, z)\n        if len(name) == 1 and name not in 'ijkxyz':\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' has ", "chunk_type": "function", "line_start": 219, "line_end": 246, "language": "python", "name": "_check_function_name"}, "d053a6a8adec_func__check_class_name": {"id": "d053a6a8adec_func__check_class_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_class_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for snake_case in class names\n        if '_' in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Class '{name}' uses snake_case\",\n                suggestion=f\"Rename to CamelCase: '{self._to_camel_case(name)}'\"\n            ))", "chunk_type": "function", "line_start": 248, "line_end": 263, "language": "python", "name": "_check_class_name"}, "d053a6a8adec_func__to_snake_case": {"id": "d053a6a8adec_func__to_snake_case", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _to_snake_case(self, name: str) -> str:\n        result = []\n        for i, c in enumerate(name):\n            if c.isupper() and i > 0:\n                result.append('_')\n            result.append(c.lower())\n        return ''.join(result)", "chunk_type": "function", "line_start": 265, "line_end": 271, "language": "python", "name": "_to_snake_case"}, "d053a6a8adec_func__to_camel_case": {"id": "d053a6a8adec_func__to_camel_case", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _to_camel_case(self, name: str) -> str:\n        return ''.join(word.capitalize() for word in name.split('_'))", "chunk_type": "function", "line_start": 273, "line_end": 274, "language": "python", "name": "_to_camel_case"}, "d053a6a8adec_func__check_params": {"id": "d053a6a8adec_func__check_params", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_params(self, node):\n        # Count params excluding self/cls\n        params = [a for a in node.args.args if a.arg not in ('self', 'cls')]\n        if len(params) > self.MAX_PARAMS:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='medium',\n                category='too_many_params',\n                message=f\"Function '{node.name}' has {len(params)} parameters (max: {self.MAX_PARAMS})\",\n                suggestion=\"Consider using a configuration object or dataclass\"\n            ))", "chunk_type": "function", "line_start": 294, "line_end": 306, "language": "python", "name": "_check_params"}, "d053a6a8adec_class_RefactoringSuggestion": {"id": "d053a6a8adec_class_RefactoringSuggestion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "class RefactoringSuggestion:\n    \"\"\"A suggested refactoring.\"\"\"\n    path: Path\n    line_start: int\n    line_end: int\n    severity: str  # 'high', 'medium', 'low'\n    category: str  # 'long_function', 'duplicate', 'complex', 'naming'\n    message: str\n    suggestion: str", "chunk_type": "class", "line_start": 29, "line_end": 37, "language": "python", "name": "RefactoringSuggestion"}, "d053a6a8adec_class_RefactoringReport": {"id": "d053a6a8adec_class_RefactoringReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "class RefactoringReport:\n    \"\"\"Complete refactoring report.\"\"\"\n    suggestions: List[RefactoringSuggestion] = field(default_factory=list)\n\n    @property\n    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n", "chunk_type": "class", "line_start": 41, "line_end": 73, "language": "python", "name": "RefactoringReport"}, "d053a6a8adec_class_LongFunctionDetector": {"id": "d053a6a8adec_class_LongFunctionDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "class LongFunctionDetector(ast.NodeVisitor):\n    \"\"\"Detect functions that are too long.\"\"\"\n\n    MAX_LINES = 50\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node):\n        if node.end_lineno:\n            length = node.end_lineno - node.lineno\n            if length > self.MAX_LINES:\n                self.issues.append(RefactoringSuggestion(\n                    path=self.path,\n                    line_start=node.lineno,\n                    line_end=node.end_lineno,\n                    severity='high' if length > 100 else 'medium',\n                    category='long_function',\n                    message=f\"Function '{node.name}' is {le", "chunk_type": "class", "line_start": 76, "line_end": 105, "language": "python", "name": "LongFunctionDetector"}, "d053a6a8adec_class_ComplexityDetector": {"id": "d053a6a8adec_class_ComplexityDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "class ComplexityDetector(ast.NodeVisitor):\n    \"\"\"Detect overly complex code.\"\"\"\n\n    MAX_NESTED = 4\n    MAX_CONDITIONS = 5\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n        self._nesting_level = 0\n        self._current_function = None\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        old_func = self._current_function\n        self._current_function = node.name\n        self._nesting_level = 0\n        self.generic_visit(node)\n        self._current_function = old_func\n\n    def visit_If(self, node: ast.If):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1\n\n    def visit_For(self, node: ast.For):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1\n\n    def visit_While(self, node: ast.While):\n        self._check_nesting(node)\n        self._ne", "chunk_type": "class", "line_start": 108, "line_end": 161, "language": "python", "name": "ComplexityDetector"}, "d053a6a8adec_class_DuplicateCodeDetector": {"id": "d053a6a8adec_class_DuplicateCodeDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "class DuplicateCodeDetector:\n    \"\"\"Detect duplicate code blocks.\"\"\"\n\n    MIN_LINES = 5\n\n    def __init__(self):\n        self.code_hashes: Dict[str, List[Tuple[Path, int, int]]] = defaultdict(list)\n        self.issues: List[RefactoringSuggestion] = []\n\n    def analyze_file(self, path: Path, tree: ast.Module, source_lines: List[str]):\n        \"\"\"Analyze file for duplicate blocks.\"\"\"\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    start = node.lineno - 1\n                    end = node.end_lineno\n                    if end - start >= self.MIN_LINES:\n                        content = '\\n'.join(source_lines[start:end])\n                        # Normalize whitespace\n                        normalized = ' '.join(content.split())\n                        code_hash = hashlib.md5(normalized.encode()).hexdigest()\n                        self.code_hashes[code_hash].append((path, sta", "chunk_type": "class", "line_start": 164, "line_end": 201, "language": "python", "name": "DuplicateCodeDetector"}, "d053a6a8adec_class_NamingConventionChecker": {"id": "d053a6a8adec_class_NamingConventionChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "class NamingConventionChecker(ast.NodeVisitor):\n    \"\"\"Check naming conventions.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function_name(node)\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef):\n        self._check_class_name(node)\n        self.generic_visit(node)\n\n    def _check_function_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for camelCase\n        if any(c.isupper() for c in name[1:]) and '_' not in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' uses camelCase\",\n                suggestion=f\"Rename to ", "chunk_type": "class", "line_start": 204, "line_end": 274, "language": "python", "name": "NamingConventionChecker"}, "d053a6a8adec_class_ParameterCountChecker": {"id": "d053a6a8adec_class_ParameterCountChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\refactor.py", "content": "class ParameterCountChecker(ast.NodeVisitor):\n    \"\"\"Check for functions with too many parameters.\"\"\"\n\n    MAX_PARAMS = 5\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)\n\n    def _check_params(self, node):\n        # Count params excluding self/cls\n        params = [a for a in node.args.args if a.arg not in ('self', 'cls')]\n        if len(params) > self.MAX_PARAMS:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='medium',\n                category='too_many_params',\n                message=f\"Function '{node.name}' has {len(params)}", "chunk_type": "class", "line_start": 277, "line_end": 306, "language": "python", "name": "ParameterCountChecker"}, "5c4b6fb90916_file": {"id": "5c4b6fb90916_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "\"\"\"\nCode Review Automation\n======================\nPre-commit code review checklist - validates code quality before commit.\n\nUsage:\n    python review.py [path] [--strict]\n    python -m scripts.review [path]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import List, Dict, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    get_staged_files,\n    analyze_module,\n    Console,\n    format_as_markdown_table\n)\n\n\nclass Severity(Enum):\n    \"\"\"Severity level for review issues.\"\"\"\n    ERROR = \"ERROR\"\n    WARNING = \"WARNING\"\n    INFO = \"INFO\"\n\n\n@dataclass\nclass ReviewIssue:\n    \"\"\"A single code review issue.\"\"\"\n    file: Path\n    line: int\n    severity: Severity\n    category: str\n    message: str\n\n\n@dataclass\nclass ReviewReport:\n    \"\"\"Complete code review report.\"\"\"\n    issues: List[ReviewIssue] = field(default_factory=list)\n    files_reviewed: int = 0\n\n    @property\n    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]\n\n    @property\n    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]\n\n    @property\n    def passed(self) -> bool:\n        return len(self.errors) == 0\n\n\n# Review checks\nclass ReviewChecks:\n    \"\"\"Collection of review check functions.\"\"\"\n\n    @staticmethod\n    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n              ", "chunk_type": "file", "line_start": 1, "line_end": 509, "language": "python", "name": "review.py"}, "5c4b6fb90916_func_review_file": {"id": "5c4b6fb90916_func_review_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "def review_file(path: Path, strict: bool = False) -> List[ReviewIssue]:\n    \"\"\"\n    Review a single Python file.\n\n    Args:\n        path: Path to file\n        strict: Enable strict mode (more checks)\n\n    Returns:\n        List of review issues\n    \"\"\"\n    issues = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues\n\n    # Run all checks\n    issues.extend(ReviewChecks.check_docstrings(path, tree))\n    issues.extend(ReviewChecks.check_todo_fixme(path))\n    issues.extend(ReviewChecks.check_naming_conventions(path, tree))\n    issues.extend(ReviewChecks.check_file_length(path))\n    issues.extend(ReviewChecks.check_function_length(path, tree))\n    issues.extend(ReviewChecks.check_unused_imports(path, tree))\n    issues.extend(ReviewChecks.check_security_issues(path, tree))\n\n    if strict:\n        issues.extend(ReviewChecks.check_type_hints(path, tree))\n\n    return issues", "chunk_type": "function", "line_start": 337, "line_end": 366, "language": "python", "name": "review_file"}, "5c4b6fb90916_func_review_project": {"id": "5c4b6fb90916_func_review_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "def review_project(\n    root: Path,\n    staged_only: bool = False,\n    strict: bool = False,\n    exclude_patterns: List[str] = None\n) -> ReviewReport:\n    \"\"\"\n    Review a Python project.\n\n    Args:\n        root: Root directory\n        staged_only: Only review staged files\n        strict: Enable strict mode\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        ReviewReport\n    \"\"\"\n    report = ReviewReport()\n\n    if staged_only:\n        Console.info(\"Reviewing staged files only...\")\n        staged = get_staged_files(cwd=root)\n        files = [root / f for f in staged if f.endswith('.py')]\n    else:\n        Console.info(f\"Reviewing all Python files in {root}...\")\n        files = list(find_python_files(root, exclude_patterns))\n\n    Console.info(f\"Found {len(files)} files to review\")\n    report.files_reviewed = len(files)\n\n    for path in files:\n        issues = review_file(path, strict=strict)\n        report.issues.extend(issues)\n\n    return report", "chunk_type": "function", "line_start": 369, "line_end": 404, "language": "python", "name": "review_project"}, "5c4b6fb90916_func_format_report_console": {"id": "5c4b6fb90916_func_format_report_console", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "def format_report_console(report: ReviewReport) -> None:\n    \"\"\"Print report to console.\"\"\"\n    if not report.issues:\n        Console.ok(\"No issues found\")\n        return\n\n    # Group by file\n    by_file: Dict[Path, List[ReviewIssue]] = {}\n    for issue in report.issues:\n        if issue.file not in by_file:\n            by_file[issue.file] = []\n        by_file[issue.file].append(issue)\n\n    for file, issues in sorted(by_file.items()):\n        print(f\"\\n{file}:\")\n        for issue in sorted(issues, key=lambda x: x.line):\n            severity_color = {\n                Severity.ERROR: Console.fail,\n                Severity.WARNING: Console.warn,\n                Severity.INFO: Console.info\n            }\n            severity_color[issue.severity](f\"  L{issue.line}: [{issue.category}] {issue.message}\")", "chunk_type": "function", "line_start": 407, "line_end": 428, "language": "python", "name": "format_report_console"}, "5c4b6fb90916_func_format_report_markdown": {"id": "5c4b6fb90916_func_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "def format_report_markdown(report: ReviewReport) -> str:\n    \"\"\"Format report as Markdown.\"\"\"\n    lines = [\n        \"# Code Review Report\",\n        \"\",\n        \"## Summary\",\n        \"\",\n        f\"- **Files Reviewed:** {report.files_reviewed}\",\n        f\"- **Total Issues:** {len(report.issues)}\",\n        f\"- **Errors:** {len(report.errors)}\",\n        f\"- **Warnings:** {len(report.warnings)}\",\n        f\"- **Status:** {'PASSED' if report.passed else 'FAILED'}\",\n        \"\",\n    ]\n\n    if report.errors:\n        lines.extend([\n            \"## Errors (Must Fix)\",\n            \"\",\n        ])\n        rows = [[str(i.file), str(i.line), i.category, i.message] for i in report.errors]\n        lines.append(format_as_markdown_table([\"File\", \"Line\", \"Category\", \"Message\"], rows))\n        lines.append(\"\")\n\n    if report.warnings:\n        lines.extend([\n            \"## Warnings\",\n            \"\",\n        ])\n        rows = [[str(i.file), str(i.line), i.category, i.message] for i in report.warnings]\n       ", "chunk_type": "function", "line_start": 431, "line_end": 464, "language": "python", "name": "format_report_markdown"}, "5c4b6fb90916_func_main": {"id": "5c4b6fb90916_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Code Review Automation\")\n\n    # Parse args\n    strict = '--strict' in sys.argv\n    staged_only = '--staged' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Reviewing: {path}\")\n    Console.info(f\"Mode: {'strict' if strict else 'standard'}\")\n\n    report = review_project(path, staged_only=staged_only, strict=strict)\n\n    print()\n    format_report_console(report)\n    print()\n\n    # Summary\n    Console.info(f\"Reviewed {report.files_reviewed} files\")\n    Console.info(f\"Found {len(report.issues)} issues ({len(report.errors)} errors, {len(report.warnings)} warnings)\")\n\n    if report.passed:\n        Console.ok(\"Code review PASSED\")\n        return 0\n    else:\n        Console.fail(\"Cod", "chunk_type": "function", "line_start": 467, "line_end": 504, "language": "python", "name": "main"}, "5c4b6fb90916_func_errors": {"id": "5c4b6fb90916_func_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]", "chunk_type": "function", "line_start": 53, "line_end": 54, "language": "python", "name": "errors"}, "5c4b6fb90916_func_warnings": {"id": "5c4b6fb90916_func_warnings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]", "chunk_type": "function", "line_start": 57, "line_end": 58, "language": "python", "name": "warnings"}, "5c4b6fb90916_func_passed": {"id": "5c4b6fb90916_func_passed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def passed(self) -> bool:\n        return len(self.errors) == 0", "chunk_type": "function", "line_start": 61, "line_end": 62, "language": "python", "name": "passed"}, "5c4b6fb90916_func_check_docstrings": {"id": "5c4b6fb90916_func_check_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.WARNING,\n                        category=\"documentation\",\n                        message=f\"Function '{node.name}' is missing a docstring\"\n                    ))\n\n            elif isinstance(node, ast.ClassDef):\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        ", "chunk_type": "function", "line_start": 70, "line_end": 102, "language": "python", "name": "check_docstrings"}, "5c4b6fb90916_func_check_type_hints": {"id": "5c4b6fb90916_func_check_type_hints", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def check_type_hints(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing type hints.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                # Check return type\n                if node.returns is None and node.name != '__init__':\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.INFO,\n                        category=\"types\",\n                        message=f\"Function '{node.name}' is missing return type hint\"\n                    ))\n\n                # Check argument types\n                for arg in node.args.args:\n                    if arg.arg not in ('self', 'cls') and arg.annotation is None:\n                        issue", "chunk_type": "function", "line_start": 105, "line_end": 136, "language": "python", "name": "check_type_hints"}, "5c4b6fb90916_func_check_todo_fixme": {"id": "5c4b6fb90916_func_check_todo_fixme", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def check_todo_fixme(path: Path) -> List[ReviewIssue]:\n        \"\"\"Check for TODO/FIXME comments.\"\"\"\n        issues = []\n\n        try:\n            with open(path, 'r', encoding='utf-8') as f:\n                for i, line in enumerate(f, 1):\n                    line_upper = line.upper()\n                    if 'TODO' in line_upper:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=i,\n                            severity=Severity.INFO,\n                            category=\"todo\",\n                            message=f\"TODO comment found: {line.strip()[:50]}...\"\n                        ))\n                    elif 'FIXME' in line_upper:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=i,\n                            severity=Severity.WARNING,\n                            category=\"fixme\",\n                            message=f\"FIXME comment found: ", "chunk_type": "function", "line_start": 139, "line_end": 174, "language": "python", "name": "check_todo_fixme"}, "5c4b6fb90916_func_check_naming_conventions": {"id": "5c4b6fb90916_func_check_naming_conventions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def check_naming_conventions(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check naming conventions.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            # Classes should be CamelCase\n            if isinstance(node, ast.ClassDef):\n                if not node.name[0].isupper() or '_' in node.name:\n                    if not node.name.startswith('_'):\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.WARNING,\n                            category=\"naming\",\n                            message=f\"Class '{node.name}' should use CamelCase\"\n                        ))\n\n            # Functions should be snake_case\n            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if not node.name.startswith('_'):\n                    # Check for camelCase (has lowercase followed by uppercase)\n           ", "chunk_type": "function", "line_start": 177, "line_end": 208, "language": "python", "name": "check_naming_conventions"}, "5c4b6fb90916_func_check_file_length": {"id": "5c4b6fb90916_func_check_file_length", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def check_file_length(path: Path, max_lines: int = 500) -> List[ReviewIssue]:\n        \"\"\"Check file length.\"\"\"\n        issues = []\n\n        try:\n            with open(path, 'r', encoding='utf-8') as f:\n                line_count = sum(1 for _ in f)\n\n            if line_count > max_lines:\n                issues.append(ReviewIssue(\n                    file=path,\n                    line=1,\n                    severity=Severity.WARNING,\n                    category=\"complexity\",\n                    message=f\"File has {line_count} lines (max recommended: {max_lines})\"\n                ))\n        except Exception:\n            pass\n\n        return issues", "chunk_type": "function", "line_start": 211, "line_end": 230, "language": "python", "name": "check_file_length"}, "5c4b6fb90916_func_check_function_length": {"id": "5c4b6fb90916_func_check_function_length", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def check_function_length(path: Path, tree: ast.Module, max_lines: int = 50) -> List[ReviewIssue]:\n        \"\"\"Check function length.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    length = node.end_lineno - node.lineno\n                    if length > max_lines:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.WARNING,\n                            category=\"complexity\",\n                            message=f\"Function '{node.name}' is {length} lines (max: {max_lines})\"\n                        ))\n\n        return issues", "chunk_type": "function", "line_start": 233, "line_end": 250, "language": "python", "name": "check_function_length"}, "5c4b6fb90916_func_check_unused_imports": {"id": "5c4b6fb90916_func_check_unused_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def check_unused_imports(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for potentially unused imports.\"\"\"\n        issues = []\n\n        # Collect imports\n        imports = {}\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name.split('.')[0]\n                    imports[name] = node.lineno\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    if alias.name != '*':\n                        name = alias.asname or alias.name\n                        imports[name] = node.lineno\n\n        # Collect all used names\n        used_names = set()\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Name):\n                used_names.add(node.id)\n            elif isinstance(node, ast.Attribute):\n                if isinstance(node.value, ast.Name):\n                    used_names.add", "chunk_type": "function", "line_start": 253, "line_end": 290, "language": "python", "name": "check_unused_imports"}, "5c4b6fb90916_func_check_security_issues": {"id": "5c4b6fb90916_func_check_security_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "    def check_security_issues(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for common security issues.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            # Check for eval/exec\n            if isinstance(node, ast.Call):\n                if isinstance(node.func, ast.Name):\n                    if node.func.id in ('eval', 'exec'):\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.ERROR,\n                            category=\"security\",\n                            message=f\"Use of '{node.func.id}' is a security risk\"\n                        ))\n                    elif node.func.id == 'input':\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.INFO,\n                            category=\"secu", "chunk_type": "function", "line_start": 293, "line_end": 334, "language": "python", "name": "check_security_issues"}, "5c4b6fb90916_class_Severity": {"id": "5c4b6fb90916_class_Severity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "class Severity(Enum):\n    \"\"\"Severity level for review issues.\"\"\"\n    ERROR = \"ERROR\"\n    WARNING = \"WARNING\"\n    INFO = \"INFO\"", "chunk_type": "class", "line_start": 29, "line_end": 33, "language": "python", "name": "Severity"}, "5c4b6fb90916_class_ReviewIssue": {"id": "5c4b6fb90916_class_ReviewIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewIssue:\n    \"\"\"A single code review issue.\"\"\"\n    file: Path\n    line: int\n    severity: Severity\n    category: str\n    message: str", "chunk_type": "class", "line_start": 37, "line_end": 43, "language": "python", "name": "ReviewIssue"}, "5c4b6fb90916_class_ReviewReport": {"id": "5c4b6fb90916_class_ReviewReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewReport:\n    \"\"\"Complete code review report.\"\"\"\n    issues: List[ReviewIssue] = field(default_factory=list)\n    files_reviewed: int = 0\n\n    @property\n    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]\n\n    @property\n    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]\n\n    @property\n    def passed(self) -> bool:\n        return len(self.errors) == 0", "chunk_type": "class", "line_start": 47, "line_end": 62, "language": "python", "name": "ReviewReport"}, "5c4b6fb90916_class_ReviewChecks": {"id": "5c4b6fb90916_class_ReviewChecks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewChecks:\n    \"\"\"Collection of review check functions.\"\"\"\n\n    @staticmethod\n    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.WARNING,\n                        category=\"documentation\",\n                        message=f\"Function '{node.name}' is missing a docstring\"\n                    ))\n\n            elif isinstance(node, ast.ClassDef):\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_d", "chunk_type": "class", "line_start": 66, "line_end": 334, "language": "python", "name": "ReviewChecks"}, "afa269b1fdc0_file": {"id": "afa269b1fdc0_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "\"\"\"\nSecurity Auditor\n================\nDeep security analysis for Python code - OWASP, secrets, injection detection.\n\nUsage:\n    python security.py [path] [--strict]\n    python -m scripts.security src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\nclass Severity(Enum):\n    CRITICAL = \"CRITICAL\"\n    HIGH = \"HIGH\"\n    MEDIUM = \"MEDIUM\"\n    LOW = \"LOW\"\n    INFO = \"INFO\"\n\n\n@dataclass\nclass SecurityIssue:\n    \"\"\"A security finding.\"\"\"\n    path: Path\n    line: int\n    severity: Severity\n    category: str\n    title: str\n    description: str\n    cwe: Optional[str] = None  # CWE identifier\n    fix: Optional[str] = None\n\n\n@dataclass\nclass SecurityReport:\n    \"\"\"Complete security audit report.\"\"\"\n    issues: List[SecurityIssue] = field(default_factory=list)\n    files_scanned: int = 0\n\n    @property\n    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]\n\n    @property\n    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n            return \"\\n\".join(lines)\n\n        # Group by severity\n        for sev in Severity:\n            items = [i f", "chunk_type": "file", "line_start": 1, "line_end": 411, "language": "python", "name": "security.py"}, "afa269b1fdc0_func_check_secrets": {"id": "afa269b1fdc0_func_check_secrets", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "def check_secrets(path: Path, source: str) -> List[SecurityIssue]:\n    \"\"\"Check for hardcoded secrets.\"\"\"\n    issues = []\n    lines = source.split('\\n')\n\n    for i, line in enumerate(lines, 1):\n        # Skip comments\n        stripped = line.strip()\n        if stripped.startswith('#'):\n            continue\n\n        for pattern, title in SECRET_PATTERNS:\n            if re.search(pattern, line):\n                # Exclude obvious non-secrets\n                if 'example' in line.lower() or 'test' in line.lower():\n                    continue\n                if '\"\"' in line or \"''\" in line:  # Empty strings\n                    continue\n                if 'os.environ' in line or 'getenv' in line:\n                    continue\n\n                issues.append(SecurityIssue(\n                    path=path,\n                    line=i,\n                    severity=Severity.CRITICAL,\n                    category=\"Hardcoded Secret\",\n                    title=title,\n                    description=f\"Po", "chunk_type": "function", "line_start": 263, "line_end": 296, "language": "python", "name": "check_secrets"}, "afa269b1fdc0_func_check_sql_injection": {"id": "afa269b1fdc0_func_check_sql_injection", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "def check_sql_injection(path: Path, source: str) -> List[SecurityIssue]:\n    \"\"\"Check for SQL injection patterns.\"\"\"\n    issues = []\n    lines = source.split('\\n')\n\n    for i, line in enumerate(lines, 1):\n        for pattern in SQL_INJECTION_PATTERNS:\n            if re.search(pattern, line, re.IGNORECASE):\n                issues.append(SecurityIssue(\n                    path=path,\n                    line=i,\n                    severity=Severity.HIGH,\n                    category=\"SQL Injection\",\n                    title=\"Potential SQL injection\",\n                    description=\"SQL query appears to use string formatting instead of parameterization\",\n                    cwe=\"CWE-89\",\n                    fix=\"Use parameterized queries with placeholders\"\n                ))\n                break\n\n    return issues", "chunk_type": "function", "line_start": 299, "line_end": 319, "language": "python", "name": "check_sql_injection"}, "afa269b1fdc0_func_audit_file": {"id": "afa269b1fdc0_func_audit_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "def audit_file(path: Path) -> List[SecurityIssue]:\n    \"\"\"Audit a single file for security issues.\"\"\"\n    issues = []\n\n    try:\n        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n            source = f.read()\n    except Exception:\n        return issues\n\n    # AST-based analysis\n    tree = parse_file(path)\n    if tree:\n        analyzer = SecurityAnalyzer(path, source)\n        analyzer.visit(tree)\n        issues.extend(analyzer.issues)\n\n    # Pattern-based checks\n    issues.extend(check_secrets(path, source))\n    issues.extend(check_sql_injection(path, source))\n\n    return issues", "chunk_type": "function", "line_start": 322, "line_end": 343, "language": "python", "name": "audit_file"}, "afa269b1fdc0_func_security_audit": {"id": "afa269b1fdc0_func_security_audit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "def security_audit(\n    root: Path,\n    strict: bool = False,\n    exclude_patterns: List[str] = None\n) -> SecurityReport:\n    \"\"\"Perform security audit on a project.\"\"\"\n    report = SecurityReport()\n\n    Console.info(f\"Security audit of {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    report.files_scanned = len(files)\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    for path in files:\n        issues = audit_file(path)\n\n        # In strict mode, include all issues; otherwise filter INFO\n        if strict:\n            report.issues.extend(issues)\n        else:\n            report.issues.extend([i for i in issues if i.severity != Severity.INFO])\n\n    return report", "chunk_type": "function", "line_start": 346, "line_end": 369, "language": "python", "name": "security_audit"}, "afa269b1fdc0_func_main": {"id": "afa269b1fdc0_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Security Auditor\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    strict = '--strict' in sys.argv\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Auditing: {path}\")\n    Console.info(f\"Mode: {'strict' if strict else 'standard'}\")\n\n    report = security_audit(path, strict=strict)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.critical:\n        Console.fail(f\"CRITICAL: {len(report.critical)} critical issues found!\")\n    elif report.high:\n        Console.warn(f\"HIGH: {len(report.high)} high severity issues found\")\n    elif report.issues:\n        Console.warn(f\"Found {len(report.issues)} security issues\")\n    else:\n        Console.ok(\"No security issues found\")\n\n    return 1 if report.critical or report.high else 0", "chunk_type": "function", "line_start": 372, "line_end": 406, "language": "python", "name": "main"}, "afa269b1fdc0_func_critical": {"id": "afa269b1fdc0_func_critical", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]", "chunk_type": "function", "line_start": 56, "line_end": 57, "language": "python", "name": "critical"}, "afa269b1fdc0_func_high": {"id": "afa269b1fdc0_func_high", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]", "chunk_type": "function", "line_start": 60, "line_end": 61, "language": "python", "name": "high"}, "afa269b1fdc0_func_to_markdown": {"id": "afa269b1fdc0_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n            return \"\\n\".join(lines)\n\n        # Group by severity\n        for sev in Severity:\n            items = [i for i in self.issues if i.severity == sev]\n            if not items:\n                continue\n\n            lines.extend([f\"## {sev.value}\", \"\"])\n\n            for issue in items:\n                lines.append(f\"### {issue.category}: {issue.title}\")\n                lines.append(f\"**File:** `{issue.path}:{is", "chunk_type": "function", "line_start": 63, "line_end": 104, "language": "python", "name": "to_markdown"}, "afa269b1fdc0_func___init__": {"id": "afa269b1fdc0_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def __init__(self, path: Path, source: str):\n        self.path = path\n        self.source = source\n        self.source_lines = source.split('\\n')\n        self.issues: List[SecurityIssue] = []\n        self._imports: Set[str] = set()", "chunk_type": "function", "line_start": 165, "line_end": 170, "language": "python", "name": "__init__"}, "afa269b1fdc0_func_visit_Import": {"id": "afa269b1fdc0_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self._imports.add(alias.name)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 172, "line_end": 175, "language": "python", "name": "visit_Import"}, "afa269b1fdc0_func_visit_ImportFrom": {"id": "afa269b1fdc0_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self._imports.add(node.module)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 177, "line_end": 180, "language": "python", "name": "visit_ImportFrom"}, "afa269b1fdc0_func_visit_Call": {"id": "afa269b1fdc0_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Call(self, node: ast.Call):\n        # Check for dangerous function calls\n        func_name = self._get_func_name(node.func)\n\n        if func_name in DANGEROUS_FUNCTIONS:\n            # Special case: Allow subprocess.Popen/call/run if shell=False is explicit\n            if func_name in ('subprocess.Popen', 'subprocess.call', 'subprocess.run'):\n                is_safe = False\n                for keyword in node.keywords:\n                    if keyword.arg == 'shell':\n                         if isinstance(keyword.value, ast.Constant) and keyword.value.value is False:\n                             is_safe = True\n                if is_safe:\n                    self.generic_visit(node)\n                    return\n\n            title, severity, cwe, desc = DANGEROUS_FUNCTIONS[func_name]\n            self.issues.append(SecurityIssue(\n                path=self.path,\n                line=node.lineno,\n                severity=severity,\n                category=\"Dangerous Function\",\n    ", "chunk_type": "function", "line_start": 182, "line_end": 238, "language": "python", "name": "visit_Call"}, "afa269b1fdc0_func_visit_Assert": {"id": "afa269b1fdc0_func_visit_Assert", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Assert(self, node: ast.Assert):\n        # Asserts are removed in optimized bytecode\n        self.issues.append(SecurityIssue(\n            path=self.path,\n            line=node.lineno,\n            severity=Severity.LOW,\n            category=\"Security Control\",\n            title=\"Assert used for security check\",\n            description=\"Assert statements are removed when Python runs with -O flag\",\n            fix=\"Use proper if/raise for security checks\"\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 240, "line_end": 251, "language": "python", "name": "visit_Assert"}, "afa269b1fdc0_func__get_func_name": {"id": "afa269b1fdc0_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\"\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 253, "line_end": 260, "language": "python", "name": "_get_func_name"}, "afa269b1fdc0_class_Severity": {"id": "afa269b1fdc0_class_Severity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "class Severity(Enum):\n    CRITICAL = \"CRITICAL\"\n    HIGH = \"HIGH\"\n    MEDIUM = \"MEDIUM\"\n    LOW = \"LOW\"\n    INFO = \"INFO\"", "chunk_type": "class", "line_start": 28, "line_end": 33, "language": "python", "name": "Severity"}, "afa269b1fdc0_class_SecurityIssue": {"id": "afa269b1fdc0_class_SecurityIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityIssue:\n    \"\"\"A security finding.\"\"\"\n    path: Path\n    line: int\n    severity: Severity\n    category: str\n    title: str\n    description: str\n    cwe: Optional[str] = None  # CWE identifier\n    fix: Optional[str] = None", "chunk_type": "class", "line_start": 37, "line_end": 46, "language": "python", "name": "SecurityIssue"}, "afa269b1fdc0_class_SecurityReport": {"id": "afa269b1fdc0_class_SecurityReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityReport:\n    \"\"\"Complete security audit report.\"\"\"\n    issues: List[SecurityIssue] = field(default_factory=list)\n    files_scanned: int = 0\n\n    @property\n    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]\n\n    @property\n    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n  ", "chunk_type": "class", "line_start": 50, "line_end": 104, "language": "python", "name": "SecurityReport"}, "afa269b1fdc0_class_SecurityAnalyzer": {"id": "afa269b1fdc0_class_SecurityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for security issues.\"\"\"\n\n    def __init__(self, path: Path, source: str):\n        self.path = path\n        self.source = source\n        self.source_lines = source.split('\\n')\n        self.issues: List[SecurityIssue] = []\n        self._imports: Set[str] = set()\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self._imports.add(alias.name)\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self._imports.add(node.module)\n        self.generic_visit(node)\n\n    def visit_Call(self, node: ast.Call):\n        # Check for dangerous function calls\n        func_name = self._get_func_name(node.func)\n\n        if func_name in DANGEROUS_FUNCTIONS:\n            # Special case: Allow subprocess.Popen/call/run if shell=False is explicit\n            if func_name in ('subprocess.Popen', 'subprocess.call', 'subprocess.run'):\n         ", "chunk_type": "class", "line_start": 162, "line_end": 260, "language": "python", "name": "SecurityAnalyzer"}, "0e6525011779_file": {"id": "0e6525011779_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\setup.py", "content": "\"\"\"\nMCP Setup Commands\n==================\nInstall hooks, profiles, and configure MCP.\n\nUsage:\n    python mcp.py setup --hooks     # Install git hooks\n    python mcp.py setup --profile   # Install shell profile\n    python mcp.py setup --all       # Full setup\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport shutil\nimport subprocess\nimport sys\n\nfrom .utils import Console, find_project_root, get_package_root\nimport importlib\nimport stat\n\n\ndef install_dependencies() -> int:\n    \"\"\"Install required Python dependencies.\"\"\"\n    Console.info(\"Checking dependencies...\")\n\n    # Detect NVIDIA GPU\n    has_gpu = False\n    try:\n        subprocess.run(['nvidia-smi'], capture_output=True, check=True)\n        has_gpu = True\n        Console.ok(\"NVIDIA GPU detected, will use faiss-gpu\")\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        Console.info(\"No NVIDIA GPU detected, using faiss-cpu fallback\")\n\n    faiss_pkg = 'faiss-gpu' if has_gpu else 'faiss-cpu'\n    dependencies = [faiss_pkg, 'watchdog']\n\n    for dep in dependencies:\n        # Check for faiss generically but verify GPU support if needed\n        is_faiss = 'faiss' in dep\n        check_name = 'faiss' if is_faiss else dep.replace('-', '_')\n\n        try:\n            # Check if already installed\n            module = importlib.import_module(check_name)\n\n            # Special check for FAISS GPU support\n            if dep == 'faiss-gpu':\n                try:\n                    import faiss\n                    if faiss.get_num_gpus() > 0:\n                        Console.ok(f\"Dependency already satisfied: {dep} (GPU support verified)\")\n                        continue\n                    else:\n                        Console.warn(\"FAISS installed but NO GPU support found. Upgrading to faiss-gpu...\")\n                        raise ImportError(\"No GPU support\")\n                except Exception:\n                    raise ImportError(\"FAISS GPU check failed\")\n            else:\n                Console.ok(f\"Dependency al", "chunk_type": "file", "line_start": 1, "line_end": 272, "language": "python", "name": "setup.py"}, "0e6525011779_func_install_dependencies": {"id": "0e6525011779_func_install_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\setup.py", "content": "def install_dependencies() -> int:\n    \"\"\"Install required Python dependencies.\"\"\"\n    Console.info(\"Checking dependencies...\")\n\n    # Detect NVIDIA GPU\n    has_gpu = False\n    try:\n        subprocess.run(['nvidia-smi'], capture_output=True, check=True)\n        has_gpu = True\n        Console.ok(\"NVIDIA GPU detected, will use faiss-gpu\")\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        Console.info(\"No NVIDIA GPU detected, using faiss-cpu fallback\")\n\n    faiss_pkg = 'faiss-gpu' if has_gpu else 'faiss-cpu'\n    dependencies = [faiss_pkg, 'watchdog']\n\n    for dep in dependencies:\n        # Check for faiss generically but verify GPU support if needed\n        is_faiss = 'faiss' in dep\n        check_name = 'faiss' if is_faiss else dep.replace('-', '_')\n\n        try:\n            # Check if already installed\n            module = importlib.import_module(check_name)\n\n            # Special check for FAISS GPU support\n            if dep == 'faiss-gpu':\n                try:\n   ", "chunk_type": "function", "line_start": 23, "line_end": 85, "language": "python", "name": "install_dependencies"}, "0e6525011779_func_install_git_hooks": {"id": "0e6525011779_func_install_git_hooks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\setup.py", "content": "def install_git_hooks(project_root: Path = None) -> int:\n    \"\"\"Install MCP git hooks to a project.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    # Find MCP installation\n    # Find MCP installation\n    mcp_root = get_package_root()\n    hooks_source = mcp_root / '.git-hooks'\n\n    if not hooks_source.exists():\n        Console.fail(f\"Hooks not found: {hooks_source}\")\n        return 1\n\n    # Target\n    git_hooks = project_root / '.git' / 'hooks'\n\n    if not (project_root / '.git').exists():\n        Console.fail(\"Not a git repository\")\n        return 1\n\n    git_hooks.mkdir(parents=True, exist_ok=True)\n\n    # Copy hooks\n    hooks = ['pre-commit', 'post-commit', 'commit-msg', 'pre-push', 'post-checkout', 'post-merge']\n    installed = 0\n\n    for hook in hooks:\n        source = hooks_source / hook\n        target = git_hooks / hook\n\n        if source.exists():\n            shutil.copy2(source, target)\n            # Make executable\n            target.chmod(target.sta", "chunk_type": "function", "line_start": 88, "line_end": 126, "language": "python", "name": "install_git_hooks"}, "0e6525011779_func_install_shell_profile": {"id": "0e6525011779_func_install_shell_profile", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\setup.py", "content": "def install_shell_profile() -> int:\n    \"\"\"Install shell startup script to user profile.\"\"\"\n    mcp_root = get_package_root()\n\n    home = Path.home()\n\n    # Detect shell\n    if os.name == 'nt':\n        # PowerShell\n        ps_profile = home / 'Documents' / 'PowerShell' / 'Microsoft.PowerShell_profile.ps1'\n        ps_profile.parent.mkdir(parents=True, exist_ok=True)\n\n        startup_script = mcp_root / 'scripts' / 'mcp-startup.ps1'\n\n        if startup_script.exists():\n            # Add source line to profile\n            source_line = f'. \"{startup_script}\"'\n\n            existing = ps_profile.read_text() if ps_profile.exists() else \"\"\n            if source_line not in existing:\n                with open(ps_profile, 'a') as f:\n                    f.write(f\"\\n# MCP Integration\\n{source_line}\\n\")\n                Console.ok(f\"Added to PowerShell profile: {ps_profile}\")\n            else:\n                Console.ok(\"PowerShell profile already configured\")\n    else:\n        # Bash/Zsh\n        s", "chunk_type": "function", "line_start": 129, "line_end": 169, "language": "python", "name": "install_shell_profile"}, "0e6525011779_func_install_ci_cd": {"id": "0e6525011779_func_install_ci_cd", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\setup.py", "content": "def install_ci_cd(project_root: Path = None) -> int:\n    \"\"\"Auto-create CI/CD if not exists.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    # Check if CI already exists\n    github_ci = project_root / '.github' / 'workflows' / 'ci.yml'\n    gitlab_ci = project_root / '.gitlab-ci.yml'\n\n    if github_ci.exists() or gitlab_ci.exists():\n        Console.ok(\"CI/CD already configured\")\n        return 0\n\n    # Check for .git\n    if not (project_root / '.git').exists():\n        Console.warn(\"Not a git repository, skipping CI setup\")\n        return 0\n\n    # Generate GitHub Action\n    try:\n        from .cicd import write_github_action\n        path = write_github_action(project_root)\n        Console.ok(f\"Created: {path}\")\n    except Exception as e:\n        Console.warn(f\"Could not create CI: {e}\")\n\n    return 0", "chunk_type": "function", "line_start": 172, "line_end": 197, "language": "python", "name": "install_ci_cd"}, "0e6525011779_func_full_setup": {"id": "0e6525011779_func_full_setup", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\setup.py", "content": "def full_setup(project_root: Path = None) -> int:\n    \"\"\"Run full MCP setup.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    Console.header(\"MCP Full Setup\")\n\n    # 0. Install dependencies\n    Console.info(\"Verifying dependencies...\")\n    if install_dependencies() != 0:\n        Console.fail(\"Dependency installation failed, aborting setup.\")\n        return 1\n\n    # 1. Install hooks\n    Console.info(\"Installing git hooks...\")\n    install_git_hooks(project_root)\n\n    # 2. Install shell profile\n    Console.info(\"Installing shell profile...\")\n    install_shell_profile()\n\n    # 3. Create CI/CD\n    Console.info(\"Setting up CI/CD...\")\n    install_ci_cd(project_root)\n\n    # 4. Initial index\n    Console.info(\"Building initial index...\")\n    try:\n        from .index_all import run_all_indexes\n        run_all_indexes(project_root, verbose=False)\n    except Exception:\n        Console.warn(\"Could not build initial index\")\n\n    # 5. Create .mcp directory\n    mcp_dir = pro", "chunk_type": "function", "line_start": 200, "line_end": 242, "language": "python", "name": "full_setup"}, "0e6525011779_func_main": {"id": "0e6525011779_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\setup.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"MCP Setup\")\n\n    if '--hooks' in sys.argv:\n        return install_git_hooks()\n\n    if '--profile' in sys.argv:\n        return install_shell_profile()\n\n    if '--ci' in sys.argv or '--cicd' in sys.argv:\n        return install_ci_cd()\n\n    if '--all' in sys.argv or len(sys.argv) <= 1:\n        return full_setup()\n\n    Console.info(\"Usage:\")\n    Console.info(\"  mcp setup --hooks     Install git hooks\")\n    Console.info(\"  mcp setup --profile   Install shell profile\")\n    Console.info(\"  mcp setup --ci        Create CI/CD pipeline\")\n    Console.info(\"  mcp setup --all       Full setup\")\n\n    return 0", "chunk_type": "function", "line_start": 245, "line_end": 267, "language": "python", "name": "main"}, "e9efe5251ddb_file": {"id": "e9efe5251ddb_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "\"\"\"\nCodebase Summarizer\n===================\nGenerate context summaries for AI agents to quickly understand codebases.\n\nUsage:\n    python summarize.py [path] [--output CODEBASE_SUMMARY.md]\n    python -m scripts.summarize [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport datetime\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    analyze_module,\n    get_git_log,\n    get_changed_files,\n    ModuleInfo,\n    Console,\n    format_as_json\n)\n\n\n@dataclass\nclass CodebaseSummary:\n    \"\"\"Summary of an entire codebase.\"\"\"\n    root: Path\n    total_files: int = 0\n    total_lines: int = 0\n    total_functions: int = 0\n    total_classes: int = 0\n\n    # Structure\n    directory_tree: Dict[str, Any] = field(default_factory=dict)\n    modules: List[ModuleInfo] = field(default_factory=list)\n\n    # Dependencies\n    external_deps: List[str] = field(default_factory=list)\n    internal_deps: Dict[str, List[str]] = field(default_factory=dict)\n\n    # Entry points\n    entry_points: List[str] = field(default_factory=list)\n\n    # Patterns\n    patterns: List[str] = field(default_factory=list)\n\n    # Recent changes\n    recent_changes: List[str] = field(default_factory=list)\n\n\ndef count_lines(path: Path) -> int:\n    \"\"\"Count non-empty lines in a file.\"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            return sum(1 for line in f if line.strip())\n    except Exception:\n        return 0\n\n\ndef build_directory_tree(root: Path, files: List[Path]) -> Dict[str, Any]:\n    \"\"\"\n    Build a hierarchical directory tree structure.\n\n    Args:\n        root: Root directory\n        files: List of file paths\n\n    Returns:\n        Nested dictionary representing directory structure\n    \"\"\"\n    tree: Dict[str, Any] = {}\n\n    for file in files:\n        try:\n            relative = file.relative_to(root)\n            parts = relative.parts\n        except Value", "chunk_type": "file", "line_start": 1, "line_end": 448, "language": "python", "name": "summarize.py"}, "e9efe5251ddb_func_count_lines": {"id": "e9efe5251ddb_func_count_lines", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def count_lines(path: Path) -> int:\n    \"\"\"Count non-empty lines in a file.\"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            return sum(1 for line in f if line.strip())\n    except Exception:\n        return 0", "chunk_type": "function", "line_start": 57, "line_end": 63, "language": "python", "name": "count_lines"}, "e9efe5251ddb_func_build_directory_tree": {"id": "e9efe5251ddb_func_build_directory_tree", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def build_directory_tree(root: Path, files: List[Path]) -> Dict[str, Any]:\n    \"\"\"\n    Build a hierarchical directory tree structure.\n\n    Args:\n        root: Root directory\n        files: List of file paths\n\n    Returns:\n        Nested dictionary representing directory structure\n    \"\"\"\n    tree: Dict[str, Any] = {}\n\n    for file in files:\n        try:\n            relative = file.relative_to(root)\n            parts = relative.parts\n        except ValueError:\n            parts = file.parts\n\n        current = tree\n        for part in parts[:-1]:\n            if part not in current:\n                current[part] = {}\n            current = current[part]\n\n        # Add file with info\n        current[parts[-1]] = {\n            '_type': 'file',\n            '_lines': count_lines(file)\n        }\n\n    return tree", "chunk_type": "function", "line_start": 66, "line_end": 98, "language": "python", "name": "build_directory_tree"}, "e9efe5251ddb_func_format_tree_ascii": {"id": "e9efe5251ddb_func_format_tree_ascii", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def format_tree_ascii(tree: Dict[str, Any], prefix: str = \"\", is_last: bool = True) -> str:\n    \"\"\"Format directory tree as ASCII art.\"\"\"\n    lines = []\n\n    items = sorted(tree.items(), key=lambda x: (x[1].get('_type') != 'file' if isinstance(x[1], dict) else 0, x[0]))\n\n    for i, (name, value) in enumerate(items):\n        if name.startswith('_'):\n            continue\n\n        is_last_item = i == len(items) - 1\n        connector = \"\u2514\u2500\u2500 \" if is_last_item else \"\u251c\u2500\u2500 \"\n\n        if isinstance(value, dict) and value.get('_type') == 'file':\n            line_count = value.get('_lines', 0)\n            lines.append(f\"{prefix}{connector}{name} ({line_count} lines)\")\n        elif isinstance(value, dict):\n            lines.append(f\"{prefix}{connector}{name}/\")\n            extension = \"    \" if is_last_item else \"\u2502   \"\n            lines.append(format_tree_ascii(value, prefix + extension, is_last_item))\n        else:\n            lines.append(f\"{prefix}{connector}{name}\")\n\n    return \"\\n\".join(filter", "chunk_type": "function", "line_start": 101, "line_end": 124, "language": "python", "name": "format_tree_ascii"}, "e9efe5251ddb_func_detect_patterns": {"id": "e9efe5251ddb_func_detect_patterns", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def detect_patterns(modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Detect common patterns in the codebase.\"\"\"\n    patterns = []\n\n    # Check for common patterns\n    all_decorators = set()\n    all_bases = set()\n    all_imports = set()\n\n    for module in modules:\n        for func in module.functions:\n            all_decorators.update(func.decorators)\n        for cls in module.classes:\n            all_bases.update(cls.bases)\n            all_decorators.update(cls.decorators)\n        all_imports.update(module.imports)\n        for mod, names in module.from_imports:\n            all_imports.add(mod)\n\n    # Detect patterns\n    if 'dataclass' in all_decorators or 'dataclasses' in all_imports:\n        patterns.append(\"Uses dataclasses for data structures\")\n\n    if 'pytest' in all_imports or 'unittest' in all_imports:\n        patterns.append(\"Has test infrastructure\")\n\n    if 'flask' in all_imports or 'fastapi' in all_imports:\n        patterns.append(\"Web application (Flask/FastAPI)\")\n\n    if 'dj", "chunk_type": "function", "line_start": 127, "line_end": 180, "language": "python", "name": "detect_patterns"}, "e9efe5251ddb_func_find_entry_points": {"id": "e9efe5251ddb_func_find_entry_points", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def find_entry_points(root: Path, modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Find likely entry points in the codebase.\"\"\"\n    entry_points = []\n\n    for module in modules:\n        # Check for if __name__ == '__main__'\n        try:\n            with open(module.path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                if \"if __name__\" in content and \"__main__\" in content:\n                    relative = module.path.relative_to(root) if module.path.is_relative_to(root) else module.path\n                    entry_points.append(str(relative))\n        except Exception:\n            pass\n\n    # Check for common entry point files\n    common_entry_points = ['main.py', 'app.py', 'cli.py', 'run.py', '__main__.py', 'manage.py']\n    for ep in common_entry_points:\n        for module in modules:\n            if module.path.name == ep:\n                relative = module.path.relative_to(root) if module.path.is_relative_to(root) else module.path\n                if str(relati", "chunk_type": "function", "line_start": 183, "line_end": 207, "language": "python", "name": "find_entry_points"}, "e9efe5251ddb_func_extract_external_deps": {"id": "e9efe5251ddb_func_extract_external_deps", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def extract_external_deps(modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Extract external dependencies from imports.\"\"\"\n    stdlib_modules = {\n        'os', 'sys', 're', 'json', 'pathlib', 'typing', 'collections',\n        'itertools', 'functools', 'datetime', 'time', 'logging', 'ast',\n        'subprocess', 'threading', 'multiprocessing', 'queue', 'socket',\n        'http', 'urllib', 'email', 'html', 'xml', 'configparser',\n        'argparse', 'io', 'string', 'textwrap', 'copy', 'pprint',\n        'dataclasses', 'abc', 'contextlib', 'warnings', 'traceback',\n        'unittest', 'doctest', 'sqlite3', 'csv', 'pickle', 'shelve',\n        'hashlib', 'hmac', 'secrets', 'random', 'math', 'statistics',\n        'fractions', 'decimal', 'struct', 'codecs', 'unicodedata',\n        'locale', 'gettext', 'operator', 'enum', 'graphlib', 'bisect',\n        'heapq', 'array', 'weakref', 'types', 'inspect', 'dis',\n        'gc', 'atexit', 'builtins', 'tempfile', 'shutil', 'glob',\n        'fnmatch', 'linecache', ", "chunk_type": "function", "line_start": 210, "line_end": 241, "language": "python", "name": "extract_external_deps"}, "e9efe5251ddb_func_summarize_codebase": {"id": "e9efe5251ddb_func_summarize_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def summarize_codebase(root: Path, exclude_patterns: List[str] = None) -> CodebaseSummary:\n    \"\"\"\n    Generate a comprehensive summary of a codebase.\n\n    Args:\n        root: Root directory\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        CodebaseSummary object\n    \"\"\"\n    summary = CodebaseSummary(root=root)\n\n    Console.info(f\"Scanning {root}...\")\n\n    # Find all Python files\n    files = list(find_python_files(root, exclude_patterns))\n    summary.total_files = len(files)\n\n    Console.info(f\"Found {len(files)} Python files\")\n\n    # Build directory tree\n    summary.directory_tree = build_directory_tree(root, files)\n\n    # Analyze each module\n    for path in files:\n        module_info = analyze_module(path)\n        if module_info:\n            summary.modules.append(module_info)\n            summary.total_lines += count_lines(path)\n            summary.total_functions += len(module_info.functions)\n            summary.total_classes += len(module_info.classes)\n\n    Consol", "chunk_type": "function", "line_start": 244, "line_end": 292, "language": "python", "name": "summarize_codebase"}, "e9efe5251ddb_func_format_summary_markdown": {"id": "e9efe5251ddb_func_format_summary_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def format_summary_markdown(summary: CodebaseSummary) -> str:\n    \"\"\"Format summary as Markdown.\"\"\"\n\n    lines = [\n        \"# Codebase Summary\",\n        \"\",\n        f\"**Root:** `{summary.root}`\",\n        f\"**Generated:** {datetime.datetime.now().isoformat()}\",\n        \"\",\n        \"## Overview\",\n        \"\",\n        f\"| Metric | Value |\",\n        f\"|--------|-------|\",\n        f\"| Python Files | {summary.total_files} |\",\n        f\"| Total Lines | {summary.total_lines:,} |\",\n        f\"| Functions | {summary.total_functions} |\",\n        f\"| Classes | {summary.total_classes} |\",\n        \"\",\n    ]\n\n    # Directory Structure\n    if summary.directory_tree:\n        lines.extend([\n            \"## Directory Structure\",\n            \"\",\n            \"```\",\n            format_tree_ascii(summary.directory_tree),\n            \"```\",\n            \"\",\n        ])\n\n    # Entry Points\n    if summary.entry_points:\n        lines.extend([\n            \"## Entry Points\",\n            \"\",\n        ])\n        for ep i", "chunk_type": "function", "line_start": 295, "line_end": 399, "language": "python", "name": "format_summary_markdown"}, "e9efe5251ddb_func_main": {"id": "e9efe5251ddb_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Codebase Summarizer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    summary = summarize_codebase(path)\n    markdown = format_summary_markdown(summary)\n\n    # Output\n    if output_file:\n        with open(output_file, 'w', encoding='utf-8') as f:\n            f.write(markdown)\n        Console.ok(f\"Summary written to: {output_file}\")\n    else:\n        # Handle Windows encoding issues\n        try:\n            print(markdown)\n        except UnicodeEncodeError:\n            # Fallback: ", "chunk_type": "function", "line_start": 402, "line_end": 443, "language": "python", "name": "main"}, "e9efe5251ddb_class_CodebaseSummary": {"id": "e9efe5251ddb_class_CodebaseSummary", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\summarize.py", "content": "class CodebaseSummary:\n    \"\"\"Summary of an entire codebase.\"\"\"\n    root: Path\n    total_files: int = 0\n    total_lines: int = 0\n    total_functions: int = 0\n    total_classes: int = 0\n\n    # Structure\n    directory_tree: Dict[str, Any] = field(default_factory=dict)\n    modules: List[ModuleInfo] = field(default_factory=list)\n\n    # Dependencies\n    external_deps: List[str] = field(default_factory=list)\n    internal_deps: Dict[str, List[str]] = field(default_factory=dict)\n\n    # Entry points\n    entry_points: List[str] = field(default_factory=list)\n\n    # Patterns\n    patterns: List[str] = field(default_factory=list)\n\n    # Recent changes\n    recent_changes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 31, "line_end": 54, "language": "python", "name": "CodebaseSummary"}, "5da44adf6e6a_file": {"id": "5da44adf6e6a_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "#!/usr/bin/env python3\n\"\"\"\nTelegram C2 Bridge\nPolls Telegram for user instructions and dispatches them to active agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\nimport time\n\nimport requests\n\n# MCP Path Resolution\nSCRIPTS_DIR = Path(__file__).resolve().parent\nsys.path.append(str(SCRIPTS_DIR))\n\ntry:\n    import agent_comms\nexcept ImportError:\n    pass\n\nCONFIG_FILE = Path(__file__).resolve().parent / \"telegram_config.json\"\n\ndef get_config():\n    if not CONFIG_FILE.exists():\n        return None\n    with open(CONFIG_FILE, \"r\") as f:\n        return json.load(f)\n\ndef poll_telegram(config):\n    # Only the primary host should poll for updates to avoid 409 Conflict\n    # We'll designate Quasar (Windows) as primary, WizardPanda as fallback.\n    hostname = agent_comms.get_hostname().lower()\n    is_windows = os.name == 'nt'\n\n    # Simple logic: If we are on Linux and a Windows agent was seen recently, don't poll.\n    if not is_windows:\n        remotes = agent_comms.AgentPresence.get_remote_status()\n        for host, data in remotes.items():\n            if data.get('hostname', '').lower() == 'quasar' or 'window' in host.lower():\n                age = time.time() - data.get('timestamp', 0)\n                if age < 120: # Quasar was seen in the last 2 minutes\n                    return\n\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    last_update = config.get(\"last_update_id\", 0)\n\n    url = f\"https://api.telegram.org/bot{token}/getUpdates?offset={last_update + 1}&timeout=10\"\n    try:\n        r = requests.get(url, timeout=15)\n        if r.status_code == 200:\n            updates = r.json().get(\"result\", [])\n            for update in updates:\n                last_update = update[\"update_id\"]\n                msg = update.get(\"message\", {})\n                text = msg.get(\"text\", \"\")\n                from_id = msg.get(\"from\", {}).get(\"id\")\n\n                if str(from_id) == str(chat_id):\n                    handle_instruction(text)\n\n      ", "chunk_type": "file", "line_start": 1, "line_end": 195, "language": "python", "name": "telegram_bridge.py"}, "5da44adf6e6a_func_get_config": {"id": "5da44adf6e6a_func_get_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def get_config():\n    if not CONFIG_FILE.exists():\n        return None\n    with open(CONFIG_FILE, \"r\") as f:\n        return json.load(f)", "chunk_type": "function", "line_start": 26, "line_end": 30, "language": "python", "name": "get_config"}, "5da44adf6e6a_func_poll_telegram": {"id": "5da44adf6e6a_func_poll_telegram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def poll_telegram(config):\n    # Only the primary host should poll for updates to avoid 409 Conflict\n    # We'll designate Quasar (Windows) as primary, WizardPanda as fallback.\n    hostname = agent_comms.get_hostname().lower()\n    is_windows = os.name == 'nt'\n\n    # Simple logic: If we are on Linux and a Windows agent was seen recently, don't poll.\n    if not is_windows:\n        remotes = agent_comms.AgentPresence.get_remote_status()\n        for host, data in remotes.items():\n            if data.get('hostname', '').lower() == 'quasar' or 'window' in host.lower():\n                age = time.time() - data.get('timestamp', 0)\n                if age < 120: # Quasar was seen in the last 2 minutes\n                    return\n\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    last_update = config.get(\"last_update_id\", 0)\n\n    url = f\"https://api.telegram.org/bot{token}/getUpdates?offset={last_update + 1}&timeout=10\"\n    try:\n        r = requests.get(url, timeout=15)\n ", "chunk_type": "function", "line_start": 32, "line_end": 72, "language": "python", "name": "poll_telegram"}, "5da44adf6e6a_func_handle_instruction": {"id": "5da44adf6e6a_func_handle_instruction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def handle_instruction(text):\n    print(f\"[BRIDGE] Received instruction: {text}\")\n    target_host = agent_comms.get_hostname().lower()\n\n    if text.lower().startswith(\"to \"):\n        parts = text.split(\":\", 1)\n        if len(parts) == 2:\n            target_host = parts[0].replace(\"to \", \"\").strip().lower()\n            text = parts[1].strip()\n\n    inbox = agent_comms.get_telegram_inbox_dir()\n    msg_id = int(time.time() * 1000)\n\n    # If the user says \"to antigravity\", \"to assistant\", or just \"to me\"\n    if text.lower().startswith(\"to antigravity\") or text.lower().startswith(\"to assistant\"):\n         target_host = \"Antigravity\"\n         if \":\" in text:\n             text = text.split(\":\", 1)[1].strip()\n\n    msg_file = inbox / f\"{target_host}_{msg_id}.json\"\n\n    with open(msg_file, \"w\") as f:\n        json.dump({\"text\": text, \"timestamp\": time.time()}, f, indent=2)", "chunk_type": "function", "line_start": 74, "line_end": 96, "language": "python", "name": "handle_instruction"}, "5da44adf6e6a_func_check_outbox": {"id": "5da44adf6e6a_func_check_outbox", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def check_outbox(config):\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    outbox = agent_comms.get_comms_dir() / \"telegram_outbox\"\n\n    if not outbox.exists():\n        return\n\n    # Use a temp directory outside of the NSync synced tree for processing\n    import tempfile\n    buffer_dir = Path(tempfile.gettempdir()) / \"mcp_telegram_buffer\"\n    if not buffer_dir.exists():\n        buffer_dir.mkdir(parents=True, exist_ok=True)\n\n    for f in outbox.glob(\"*.json\"):\n        if f.is_dir() or f.name.startswith(\".\"): continue\n        try:\n            # Move to local temp buffer first (breaks sync lock)\n            target = buffer_dir / f.name\n            try:\n                # Force replace if target exists (stale)\n                if target.exists(): os.remove(target)\n                os.rename(str(f), str(target))\n            except OSError:\n                continue # Still locked by NSync or Git\n\n            with open(target, \"r\") as mf:\n                data = json.lo", "chunk_type": "function", "line_start": 98, "line_end": 148, "language": "python", "name": "check_outbox"}, "5da44adf6e6a_func_main": {"id": "5da44adf6e6a_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def main():\n    print(\"--- Telegram C2 Bridge ---\")\n\n    # [NEW] PID-based singleton protection\n    import tempfile\n    pid_file = Path(tempfile.gettempdir()) / \"telegram_bridge.pid\"\n    if pid_file.exists():\n        try:\n            with open(pid_file, \"r\") as f:\n                old_pid = int(f.read().strip())\n                if os.name == 'nt':\n                    subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {old_pid}\"], check=True, capture_output=True)\n                else:\n                    os.kill(old_pid, 0)\n                print(f\"[BRIDGE] Service already running (PID {old_pid}). Exiting.\")\n                return 0\n        except:\n            pid_file.unlink()\n\n    with open(pid_file, \"w\") as f:\n        f.write(str(os.getpid()))\n\n    try:\n        config = get_config()\n        if not config:\n            print(\"[FAIL] telegram_config.json missing. Please create it with bot_token and chat_id.\")\n            return 1\n\n        print(f\"[BRIDGE] Configuration loaded. Chat ID: {config.g", "chunk_type": "function", "line_start": 150, "line_end": 191, "language": "python", "name": "main"}, "0b9749c78b9b_file": {"id": "0b9749c78b9b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "\"\"\"\nAuto-Test Implementation Generator\n==================================\nGenerate actual test implementations, not just stubs.\n\nUsage:\n    python mcp.py test-gen [file] --impl\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass FunctionSignature:\n    \"\"\"Function signature info.\"\"\"\n    name: str\n    args: List[Tuple[str, Optional[str]]]  # (name, type_hint)\n    return_type: Optional[str]\n    decorators: List[str]\n    docstring: Optional[str]\n    is_async: bool\n    line_num: int\n\n\nclass SignatureExtractor(ast.NodeVisitor):\n    \"\"\"Extract function signatures.\"\"\"\n\n    def __init__(self):\n        self.functions: List[FunctionSignature] = []\n\n    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)\n\n    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = ast.unparse(node.returns)\n\n        # Get decorators\n        decorators = []\n        for dec in node.decorator_list:\n            if isinstance(dec, ast.Name):\n                decorators.append(dec.id)\n            elif isinstance(dec, ast.Attribute):\n                decorators.append(dec.attr)\n\n        self.functions.append(FunctionSignature(\n            name=node.name", "chunk_type": "file", "line_start": 1, "line_end": 297, "language": "python", "name": "test_gen.py"}, "0b9749c78b9b_func_get_test_value": {"id": "0b9749c78b9b_func_get_test_value", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "def get_test_value(type_hint: Optional[str]) -> str:\n    \"\"\"Get example test value for a type.\"\"\"\n    if not type_hint:\n        return '\"test_value\"'\n\n    type_lower = type_hint.lower()\n\n    if 'int' in type_lower:\n        return '42'\n    elif 'float' in type_lower:\n        return '3.14'\n    elif 'str' in type_lower:\n        return '\"test_string\"'\n    elif 'bool' in type_lower:\n        return 'True'\n    elif 'list' in type_lower:\n        return '[]'\n    elif 'dict' in type_lower:\n        return '{}'\n    elif 'none' in type_lower:\n        return 'None'\n    elif 'path' in type_lower:\n        return 'Path(\".\")'\n    elif 'optional' in type_lower:\n        return 'None'\n    else:\n        return 'None  # TODO: provide test value'", "chunk_type": "function", "line_start": 83, "line_end": 109, "language": "python", "name": "get_test_value"}, "0b9749c78b9b_func_get_assertion": {"id": "0b9749c78b9b_func_get_assertion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "def get_assertion(return_type: Optional[str]) -> str:\n    \"\"\"Get appropriate assertion for return type.\"\"\"\n    if not return_type:\n        return 'assert result is not None'\n\n    type_lower = return_type.lower()\n\n    if 'bool' in type_lower:\n        return 'assert isinstance(result, bool)'\n    elif 'int' in type_lower:\n        return 'assert isinstance(result, int)'\n    elif 'float' in type_lower:\n        return 'assert isinstance(result, (int, float))'\n    elif 'str' in type_lower:\n        return 'assert isinstance(result, str)'\n    elif 'list' in type_lower:\n        return 'assert isinstance(result, list)'\n    elif 'dict' in type_lower:\n        return 'assert isinstance(result, dict)'\n    elif 'none' in type_lower:\n        return 'assert result is None'\n    else:\n        return 'assert result is not None'", "chunk_type": "function", "line_start": 112, "line_end": 134, "language": "python", "name": "get_assertion"}, "0b9749c78b9b_func_generate_test_impl": {"id": "0b9749c78b9b_func_generate_test_impl", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_test_impl(func: FunctionSignature, module_name: str) -> str:\n    \"\"\"Generate full test implementation for a function.\"\"\"\n    lines = []\n\n    # Test function signature\n    async_prefix = 'async ' if func.is_async else ''\n    lines.append(f'{async_prefix}def test_{func.name}():')\n\n    # Docstring\n    if func.docstring:\n        lines.append(f'    \"\"\"Test {func.name}: {func.docstring[:50]}...\"\"\"')\n    else:\n        lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Arrange\n    lines.append('    # Arrange')\n    args_call = []\n    for arg_name, arg_type in func.args:\n        value = get_test_value(arg_type)\n        lines.append(f'    {arg_name} = {value}')\n        args_call.append(arg_name)\n\n    lines.append('')\n    lines.append('    # Act')\n\n    args_str = ', '.join(args_call)\n    if func.is_async:\n        lines.append(f'    result = await {func.name}({args_str})')\n    else:\n        lines.append(f'    result = {func.name}({args_str})')\n\n    lines.append('')\n    lines.", "chunk_type": "function", "line_start": 137, "line_end": 172, "language": "python", "name": "generate_test_impl"}, "0b9749c78b9b_func_generate_edge_case_tests": {"id": "0b9749c78b9b_func_generate_edge_case_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_edge_case_tests(func: FunctionSignature) -> List[str]:\n    \"\"\"Generate edge case tests.\"\"\"\n    tests = []\n\n    for arg_name, arg_type in func.args:\n        if not arg_type:\n            continue\n\n        type_lower = arg_type.lower()\n\n        # None tests for Optional types\n        if 'optional' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_none():\n    \"\"\"Test {func.name} with {arg_name}=None.\"\"\"\n    result = {func.name}({arg_name}=None)\n    assert result is not None or True  # Handle None case'''\n            tests.append(test)\n\n        # Empty tests for collections\n        if 'list' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_empty():\n    \"\"\"Test {func.name} with empty list.\"\"\"\n    result = {func.name}({arg_name}=[])\n    assert result is not None'''\n            tests.append(test)\n\n        if 'str' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_empty_string():\n    \"\"\"Test {func.name} with empty string.", "chunk_type": "function", "line_start": 175, "line_end": 221, "language": "python", "name": "generate_edge_case_tests"}, "0b9749c78b9b_func_generate_test_file": {"id": "0b9749c78b9b_func_generate_test_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_test_file(file_path: Path) -> str:\n    \"\"\"Generate full test file for a module.\"\"\"\n    try:\n        source = file_path.read_text(encoding='utf-8')\n        tree = ast.parse(source)\n    except Exception as e:\n        return f\"# Error parsing {file_path}: {e}\"\n\n    extractor = SignatureExtractor()\n    extractor.visit(tree)\n\n    module_name = file_path.stem\n\n    lines = [\n        '\"\"\"',\n        f'Auto-generated tests for {module_name}',\n        '\"\"\"',\n        '',\n        'import pytest',\n        f'from {module_name} import *',\n        '',\n        '',\n    ]\n\n    for func in extractor.functions:\n        # Main test\n        lines.append(generate_test_impl(func, module_name))\n        lines.append('')\n        lines.append('')\n\n        # Edge case tests\n        edge_tests = generate_edge_case_tests(func)\n        for test in edge_tests[:2]:  # Limit edge cases\n            lines.append(test)\n            lines.append('')\n            lines.append('')\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 224, "line_end": 261, "language": "python", "name": "generate_test_file"}, "0b9749c78b9b_func_main": {"id": "0b9749c78b9b_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Test Generator (Full Implementation)\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.info(\"Usage: mcp test-gen <file.py> [--impl]\")\n        return 1\n\n    file_path = Path(args[0])\n\n    if not file_path.exists():\n        Console.fail(f\"File not found: {file_path}\")\n        return 1\n\n    Console.info(f\"Generating tests for: {file_path}\")\n\n    test_code = generate_test_file(file_path)\n\n    if '--impl' in sys.argv or '--write' in sys.argv:\n        # Write to test file\n        test_file = file_path.parent / f'test_{file_path.name}'\n        test_file.write_text(test_code)\n        Console.ok(f\"Written to: {test_file}\")\n    else:\n        print(test_code)\n\n    return 0", "chunk_type": "function", "line_start": 264, "line_end": 292, "language": "python", "name": "main"}, "0b9749c78b9b_func___init__": {"id": "0b9749c78b9b_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def __init__(self):\n        self.functions: List[FunctionSignature] = []", "chunk_type": "function", "line_start": 34, "line_end": 35, "language": "python", "name": "__init__"}, "0b9749c78b9b_func_visit_FunctionDef": {"id": "0b9749c78b9b_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 37, "line_end": 39, "language": "python", "name": "visit_FunctionDef"}, "0b9749c78b9b_func_visit_AsyncFunctionDef": {"id": "0b9749c78b9b_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 41, "line_end": 43, "language": "python", "name": "visit_AsyncFunctionDef"}, "0b9749c78b9b_func__extract": {"id": "0b9749c78b9b_func__extract", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = ast.unparse(node.returns)\n\n        # Get decorators\n        decorators = []\n        for dec in node.decorator_list:\n            if isinstance(dec, ast.Name):\n                decorators.append(dec.id)\n            elif isinstance(dec, ast.Attribute):\n                decorators.append(dec.attr)\n\n        self.functions.append(FunctionSignature(\n            name=node.name,\n            args=args,\n      ", "chunk_type": "function", "line_start": 45, "line_end": 80, "language": "python", "name": "_extract"}, "0b9749c78b9b_class_FunctionSignature": {"id": "0b9749c78b9b_class_FunctionSignature", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "class FunctionSignature:\n    \"\"\"Function signature info.\"\"\"\n    name: str\n    args: List[Tuple[str, Optional[str]]]  # (name, type_hint)\n    return_type: Optional[str]\n    decorators: List[str]\n    docstring: Optional[str]\n    is_async: bool\n    line_num: int", "chunk_type": "class", "line_start": 20, "line_end": 28, "language": "python", "name": "FunctionSignature"}, "0b9749c78b9b_class_SignatureExtractor": {"id": "0b9749c78b9b_class_SignatureExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\test_gen.py", "content": "class SignatureExtractor(ast.NodeVisitor):\n    \"\"\"Extract function signatures.\"\"\"\n\n    def __init__(self):\n        self.functions: List[FunctionSignature] = []\n\n    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)\n\n    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = a", "chunk_type": "class", "line_start": 31, "line_end": 80, "language": "python", "name": "SignatureExtractor"}, "61d27da1409d_file": {"id": "61d27da1409d_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "\"\"\"\nTODO/FIXME Index\n================\nScan and index all TODOs, FIXMEs, HACKs, and NOTEs in code.\n\nUsage:\n    python mcp.py todos\n    python mcp.py todos --priority high\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport re\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass TodoItem:\n    \"\"\"A TODO/FIXME item.\"\"\"\n    type: str  # TODO, FIXME, HACK, XXX, NOTE\n    message: str\n    file: str\n    line: int\n    author: Optional[str] = None\n    priority: int = 2  # 1=high, 2=medium, 3=low\n    context: str = \"\"\n\n\n# Patterns to detect\nTODO_PATTERNS = [\n    (r'#\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)$', 'python'),\n    (r'//\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)$', 'js'),\n    (r'/\\*\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)\\*/', 'block'),\n]\n\nPRIORITY_MAP = {\n    'FIXME': 1,\n    'XXX': 1,\n    'HACK': 2,\n    'TODO': 2,\n    'NOTE': 3,\n}\n\nPRIORITY_KEYWORDS = {\n    'urgent': 1,\n    'critical': 1,\n    'important': 1,\n    'P0': 1, 'P1': 1,\n    'P2': 2, 'P3': 3,\n    'low': 3,\n    'minor': 3,\n}\n\n\ndef detect_priority(todo_type: str, message: str, author: str = None) -> int:\n    \"\"\"Detect priority from type and message.\"\"\"\n    priority = PRIORITY_MAP.get(todo_type, 2)\n\n    # Check for priority keywords\n    text = (message + (author or '')).lower()\n    for keyword, p in PRIORITY_KEYWORDS.items():\n        if keyword.lower() in text:\n            priority = min(priority, p)\n            break\n\n    # ! at end indicates high priority\n    if message.rstrip().endswith('!'):\n        priority = 1\n\n    return priority\n\n\ndef scan_file(file_path: Path) -> List[TodoItem]:\n    \"\"\"Scan a file for TODOs.\"\"\"\n    todos = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return todos\n\n    for i, li", "chunk_type": "file", "line_start": 1, "line_end": 260, "language": "python", "name": "todo_index.py"}, "61d27da1409d_func_detect_priority": {"id": "61d27da1409d_func_detect_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "def detect_priority(todo_type: str, message: str, author: str = None) -> int:\n    \"\"\"Detect priority from type and message.\"\"\"\n    priority = PRIORITY_MAP.get(todo_type, 2)\n\n    # Check for priority keywords\n    text = (message + (author or '')).lower()\n    for keyword, p in PRIORITY_KEYWORDS.items():\n        if keyword.lower() in text:\n            priority = min(priority, p)\n            break\n\n    # ! at end indicates high priority\n    if message.rstrip().endswith('!'):\n        priority = 1\n\n    return priority", "chunk_type": "function", "line_start": 60, "line_end": 75, "language": "python", "name": "detect_priority"}, "61d27da1409d_func_scan_file": {"id": "61d27da1409d_func_scan_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "def scan_file(file_path: Path) -> List[TodoItem]:\n    \"\"\"Scan a file for TODOs.\"\"\"\n    todos = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return todos\n\n    for i, line in enumerate(lines, 1):\n        for pattern, _ in TODO_PATTERNS:\n            match = re.search(pattern, line, re.IGNORECASE)\n            if match:\n                todo_type = match.group(1).upper()\n                author = match.group(2) if match.lastindex >= 2 else None\n                message = match.group(3) if match.lastindex >= 3 else match.group(2)\n\n                if message:\n                    # Get context (surrounding lines)\n                    context_start = max(0, i - 2)\n                    context_end = min(len(lines), i + 2)\n                    context = ''.join(lines[context_start:context_end])\n\n                    todos.append(TodoItem(\n                        type=todo_type,\n                    ", "chunk_type": "function", "line_start": 78, "line_end": 113, "language": "python", "name": "scan_file"}, "61d27da1409d_func_scan_project": {"id": "61d27da1409d_func_scan_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "def scan_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> List[TodoItem]:\n    \"\"\"Scan entire project for TODOs.\"\"\"\n    all_todos = []\n\n    # Find all code files\n    extensions = ['.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.go', '.rs', '.c', '.cpp', '.h']\n\n    for ext in extensions:\n        for file_path in root.rglob(f'*{ext}'):\n            # Skip excluded\n            if exclude_patterns:\n                skip = False\n                for pattern in exclude_patterns:\n                    if pattern in str(file_path):\n                        skip = True\n                        break\n                if skip:\n                    continue\n\n            todos = scan_file(file_path)\n            all_todos.extend(todos)\n\n    return all_todos", "chunk_type": "function", "line_start": 116, "line_end": 141, "language": "python", "name": "scan_project"}, "61d27da1409d_func_group_by_priority": {"id": "61d27da1409d_func_group_by_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "def group_by_priority(todos: List[TodoItem]) -> Dict[int, List[TodoItem]]:\n    \"\"\"Group TODOs by priority.\"\"\"\n    groups = {1: [], 2: [], 3: []}\n    for todo in todos:\n        groups[todo.priority].append(todo)\n    return groups", "chunk_type": "function", "line_start": 144, "line_end": 149, "language": "python", "name": "group_by_priority"}, "61d27da1409d_func_group_by_type": {"id": "61d27da1409d_func_group_by_type", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "def group_by_type(todos: List[TodoItem]) -> Dict[str, List[TodoItem]]:\n    \"\"\"Group TODOs by type.\"\"\"\n    groups = {}\n    for todo in todos:\n        if todo.type not in groups:\n            groups[todo.type] = []\n        groups[todo.type].append(todo)\n    return groups", "chunk_type": "function", "line_start": 152, "line_end": 159, "language": "python", "name": "group_by_type"}, "61d27da1409d_func_index_todos": {"id": "61d27da1409d_func_index_todos", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "def index_todos(root: Path = None) -> Dict:\n    \"\"\"Build TODO index and save to disk.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(f\"Scanning for TODOs in {root}...\")\n\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    todos = scan_project(root, exclude)\n\n    # Build index\n    index = {\n        \"total\": len(todos),\n        \"by_type\": {},\n        \"by_priority\": {1: 0, 2: 0, 3: 0},\n        \"by_file\": {},\n        \"items\": []\n    }\n\n    for todo in todos:\n        # Count by type\n        if todo.type not in index[\"by_type\"]:\n            index[\"by_type\"][todo.type] = 0\n        index[\"by_type\"][todo.type] += 1\n\n        # Count by priority\n        index[\"by_priority\"][todo.priority] += 1\n\n        # Count by file\n        if todo.file not in index[\"by_file\"]:\n            index[\"by_file\"][todo.file] = 0\n        index[\"by_file\"][todo.file] += 1\n\n        # Store item\n        index[\"items\"].append(asdict(todo))\n\n    # Save index\n    inde", "chunk_type": "function", "line_start": 162, "line_end": 206, "language": "python", "name": "index_todos"}, "61d27da1409d_func_main": {"id": "61d27da1409d_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"TODO/FIXME Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_todos(root)\n        return 0\n\n    # Scan and display\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    todos = scan_project(root, exclude)\n\n    if not todos:\n        Console.ok(\"No TODOs found!\")\n        return 0\n\n    # Filter by priority\n    if '--high' in sys.argv or '--priority' in sys.argv:\n        todos = [t for t in todos if t.priority == 1]\n\n    # Filter by type\n    for todo_type in ['TODO', 'FIXME', 'HACK', 'NOTE']:\n        if f'--{todo_type.lower()}' in sys.argv:\n            todos = [t for t in todos if t.type == todo_type]\n\n    # Group by priority\n    by_priority = group_by_priority(todos)\n\n    # Display\n    priority_names = {1: 'HIGH', 2: 'MEDIUM', 3: 'LOW'}\n    priority_colors = {1: '\\033[91m', 2: '\\033[93m', 3: ", "chunk_type": "function", "line_start": 209, "line_end": 255, "language": "python", "name": "main"}, "61d27da1409d_class_TodoItem": {"id": "61d27da1409d_class_TodoItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\todo_index.py", "content": "class TodoItem:\n    \"\"\"A TODO/FIXME item.\"\"\"\n    type: str  # TODO, FIXME, HACK, XXX, NOTE\n    message: str\n    file: str\n    line: int\n    author: Optional[str] = None\n    priority: int = 2  # 1=high, 2=medium, 3=low\n    context: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 31, "language": "python", "name": "TodoItem"}, "dfb7757a892c_file": {"id": "dfb7757a892c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "\"\"\"\nTree-sitter Utilities\n=====================\nMulti-language code parsing using tree-sitter.\nSupports Python, JavaScript, TypeScript, Go, Rust, Java, C, C++, and more.\n\nUsage:\n    from scripts.treesitter_utils import parse_file, get_functions, get_classes\n\"\"\"\n\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Iterator, Callable\nfrom dataclasses import dataclass, field\n\n# Try to import tree-sitter, fall back gracefully\ntry:\n    import tree_sitter\n    from tree_sitter import Language, Parser, Tree, Node\n    TREE_SITTER_AVAILABLE = True\nexcept ImportError:\n    TREE_SITTER_AVAILABLE = False\n    Tree = Any\n    Node = Any\n\nfrom .utils import Console\n\n\n@dataclass\nclass CodeItem:\n    \"\"\"A code item (function, class, etc).\"\"\"\n    name: str\n    item_type: str  # 'function', 'class', 'method', 'import', 'variable'\n    line_start: int\n    line_end: int\n    signature: str = \"\"\n    docstring: Optional[str] = None\n    language: str = \"\"\n    children: List['CodeItem'] = field(default_factory=list)\n\n\n@dataclass\nclass ParsedFile:\n    \"\"\"Result of parsing a file.\"\"\"\n    path: Path\n    language: str\n    tree: Optional[Any] = None\n    source: bytes = b\"\"\n    functions: List[CodeItem] = field(default_factory=list)\n    classes: List[CodeItem] = field(default_factory=list)\n    imports: List[str] = field(default_factory=list)\n    error: Optional[str] = None\n\n\n# Language detection by extension\nLANGUAGE_MAP = {\n    '.py': 'python',\n    '.js': 'javascript',\n    '.jsx': 'javascript',\n    '.ts': 'typescript',\n    '.tsx': 'typescript',\n    '.go': 'go',\n    '.rs': 'rust',\n    '.java': 'java',\n    '.c': 'c',\n    '.h': 'c',\n    '.cpp': 'cpp',\n    '.cc': 'cpp',\n    '.cxx': 'cpp',\n    '.hpp': 'cpp',\n    '.cs': 'c_sharp',\n    '.rb': 'ruby',\n    '.php': 'php',\n    '.swift': 'swift',\n    '.kt': 'kotlin',\n    '.scala': 'scala',\n    '.lua': 'lua',\n    '.sh': 'bash',\n    '.bash': 'bash',\n    '.json': 'json',\n    '.yaml': 'yaml',\n    '.yml': 'yaml',\n    '.html': 'html',\n    ", "chunk_type": "file", "line_start": 1, "line_end": 432, "language": "python", "name": "treesitter_utils.py"}, "dfb7757a892c_func_detect_language": {"id": "dfb7757a892c_func_detect_language", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def detect_language(path: Path) -> Optional[str]:\n    \"\"\"Detect language from file extension.\"\"\"\n    return LANGUAGE_MAP.get(path.suffix.lower())", "chunk_type": "function", "line_start": 128, "line_end": 130, "language": "python", "name": "detect_language"}, "dfb7757a892c_func_get_parser": {"id": "dfb7757a892c_func_get_parser", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def get_parser(language: str) -> Optional[Any]:\n    \"\"\"Get or create parser for language.\"\"\"\n    if not TREE_SITTER_AVAILABLE:\n        return None\n\n    if language in _parsers:\n        return _parsers[language]\n\n    try:\n        # Try to load language\n        import importlib\n        lang_module = importlib.import_module(f'tree_sitter_{language}')\n        if hasattr(lang_module, 'language'):\n            lang = Language(lang_module.language())\n            parser = Parser(lang)\n            _parsers[language] = parser\n            _languages[language] = lang\n            return parser\n    except ImportError:\n        pass\n    except Exception as e:\n        Console.warn(f\"Could not load tree-sitter-{language}: {e}\")\n\n    return None", "chunk_type": "function", "line_start": 133, "line_end": 156, "language": "python", "name": "get_parser"}, "dfb7757a892c_func_parse_source": {"id": "dfb7757a892c_func_parse_source", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def parse_source(source: bytes, language: str) -> Optional[Tree]:\n    \"\"\"Parse source code into tree.\"\"\"\n    parser = get_parser(language)\n    if parser is None:\n        return None\n\n    return parser.parse(source)", "chunk_type": "function", "line_start": 159, "line_end": 165, "language": "python", "name": "parse_source"}, "dfb7757a892c_func_parse_file": {"id": "dfb7757a892c_func_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def parse_file(path: Path) -> ParsedFile:\n    \"\"\"Parse a source file.\"\"\"\n    result = ParsedFile(path=path, language=\"\")\n\n    # Detect language\n    language = detect_language(path)\n    if not language:\n        result.error = f\"Unknown language for {path.suffix}\"\n        return result\n\n    result.language = language\n\n    # Read file\n    try:\n        with open(path, 'rb') as f:\n            source = f.read()\n        result.source = source\n    except Exception as e:\n        result.error = f\"Could not read file: {e}\"\n        return result\n\n    # Parse with tree-sitter if available\n    if TREE_SITTER_AVAILABLE:\n        tree = parse_source(source, language)\n        if tree:\n            result.tree = tree\n            result.functions = extract_functions(tree, language, source)\n            result.classes = extract_classes(tree, language, source)\n            result.imports = extract_imports(tree, language, source)\n            return result\n\n    # Fallback to Python's ast for Python files\n    if ", "chunk_type": "function", "line_start": 168, "line_end": 203, "language": "python", "name": "parse_file"}, "dfb7757a892c_func__parse_python_fallback": {"id": "dfb7757a892c_func__parse_python_fallback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _parse_python_fallback(path: Path, source: bytes, result: ParsedFile) -> ParsedFile:\n    \"\"\"Fallback parser for Python using stdlib ast.\"\"\"\n    import ast\n\n    try:\n        tree = ast.parse(source.decode('utf-8', errors='ignore'))\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                item = CodeItem(\n                    name=node.name,\n                    item_type='function',\n                    line_start=node.lineno,\n                    line_end=node.end_lineno or node.lineno,\n                    docstring=ast.get_docstring(node),\n                    language='python'\n                )\n                result.functions.append(item)\n\n            elif isinstance(node, ast.ClassDef):\n                item = CodeItem(\n                    name=node.name,\n                    item_type='class',\n                    line_start=node.lineno,\n                    line_end=node.end_lineno or node.lineno,\n                  ", "chunk_type": "function", "line_start": 206, "line_end": 247, "language": "python", "name": "_parse_python_fallback"}, "dfb7757a892c_func_extract_functions": {"id": "dfb7757a892c_func_extract_functions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_functions(tree: Tree, language: str, source: bytes) -> List[CodeItem]:\n    \"\"\"Extract functions from tree.\"\"\"\n    functions = []\n    func_types = FUNCTION_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in func_types:\n            name = _get_node_name(node, language)\n            if name:\n                item = CodeItem(\n                    name=name,\n                    item_type='function',\n                    line_start=node.start_point[0] + 1,\n                    line_end=node.end_point[0] + 1,\n                    signature=_get_signature(node, source),\n                    language=language\n                )\n                functions.append(item)\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return functions", "chunk_type": "function", "line_start": 250, "line_end": 275, "language": "python", "name": "extract_functions"}, "dfb7757a892c_func_extract_classes": {"id": "dfb7757a892c_func_extract_classes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_classes(tree: Tree, language: str, source: bytes) -> List[CodeItem]:\n    \"\"\"Extract classes from tree.\"\"\"\n    classes = []\n    class_types = CLASS_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in class_types:\n            name = _get_node_name(node, language)\n            if name:\n                item = CodeItem(\n                    name=name,\n                    item_type='class',\n                    line_start=node.start_point[0] + 1,\n                    line_end=node.end_point[0] + 1,\n                    language=language\n                )\n                classes.append(item)\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return classes", "chunk_type": "function", "line_start": 278, "line_end": 302, "language": "python", "name": "extract_classes"}, "dfb7757a892c_func_extract_imports": {"id": "dfb7757a892c_func_extract_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_imports(tree: Tree, language: str, source: bytes) -> List[str]:\n    \"\"\"Extract imports from tree.\"\"\"\n    imports = []\n    import_types = IMPORT_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in import_types:\n            # Get the import text\n            import_text = source[node.start_byte:node.end_byte].decode('utf-8', errors='ignore')\n            imports.append(import_text.strip())\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return imports", "chunk_type": "function", "line_start": 305, "line_end": 322, "language": "python", "name": "extract_imports"}, "dfb7757a892c_func__get_node_name": {"id": "dfb7757a892c_func__get_node_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _get_node_name(node: Node, language: str) -> Optional[str]:\n    \"\"\"Extract name from node.\"\"\"\n    # Look for identifier child\n    for child in node.children:\n        if child.type in ('identifier', 'name', 'property_identifier'):\n            return child.text.decode('utf-8', errors='ignore')\n    return None", "chunk_type": "function", "line_start": 325, "line_end": 331, "language": "python", "name": "_get_node_name"}, "dfb7757a892c_func__get_signature": {"id": "dfb7757a892c_func__get_signature", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _get_signature(node: Node, source: bytes) -> str:\n    \"\"\"Get function/method signature.\"\"\"\n    # Get first line\n    start = node.start_byte\n    end = node.end_byte\n    text = source[start:end].decode('utf-8', errors='ignore')\n    first_line = text.split('\\n')[0]\n    return first_line[:100]", "chunk_type": "function", "line_start": 334, "line_end": 341, "language": "python", "name": "_get_signature"}, "dfb7757a892c_func_walk_tree": {"id": "dfb7757a892c_func_walk_tree", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def walk_tree(tree: Tree, callback: Callable[[Node], None]):\n    \"\"\"Walk entire tree calling callback on each node.\"\"\"\n    def visit(node: Node):\n        callback(node)\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)", "chunk_type": "function", "line_start": 344, "line_end": 352, "language": "python", "name": "walk_tree"}, "dfb7757a892c_func_find_nodes": {"id": "dfb7757a892c_func_find_nodes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def find_nodes(tree: Tree, node_types: List[str]) -> List[Node]:\n    \"\"\"Find all nodes of given types.\"\"\"\n    results = []\n\n    def visit(node: Node):\n        if node.type in node_types:\n            results.append(node)\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return results", "chunk_type": "function", "line_start": 355, "line_end": 368, "language": "python", "name": "find_nodes"}, "dfb7757a892c_func_get_node_text": {"id": "dfb7757a892c_func_get_node_text", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def get_node_text(node: Node, source: bytes) -> str:\n    \"\"\"Get text content of node.\"\"\"\n    return source[node.start_byte:node.end_byte].decode('utf-8', errors='ignore')", "chunk_type": "function", "line_start": 371, "line_end": 373, "language": "python", "name": "get_node_text"}, "dfb7757a892c_func_supported_languages": {"id": "dfb7757a892c_func_supported_languages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def supported_languages() -> List[str]:\n    \"\"\"Get list of supported languages.\"\"\"\n    return list(LANGUAGE_MAP.values())", "chunk_type": "function", "line_start": 376, "line_end": 378, "language": "python", "name": "supported_languages"}, "dfb7757a892c_func_is_tree_sitter_available": {"id": "dfb7757a892c_func_is_tree_sitter_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def is_tree_sitter_available() -> bool:\n    \"\"\"Check if tree-sitter is available.\"\"\"\n    return TREE_SITTER_AVAILABLE", "chunk_type": "function", "line_start": 381, "line_end": 383, "language": "python", "name": "is_tree_sitter_available"}, "dfb7757a892c_func_main": {"id": "dfb7757a892c_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Tree-sitter Utilities\")\n\n    if not TREE_SITTER_AVAILABLE:\n        Console.warn(\"tree-sitter not installed, using Python ast fallback\")\n    else:\n        Console.ok(\"tree-sitter available\")\n\n    # Parse arguments\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.info(\"Supported languages:\")\n        for ext, lang in sorted(LANGUAGE_MAP.items()):\n            Console.info(f\"  {ext} -> {lang}\")\n        return 0\n\n    path = Path(args[0])\n    if not path.exists():\n        Console.fail(f\"File not found: {path}\")\n        return 1\n\n    result = parse_file(path)\n\n    print(f\"\\nFile: {result.path}\")\n    print(f\"Language: {result.language}\")\n    print(f\"Functions: {len(result.functions)}\")\n    print(f\"Classes: {len(result.classes)}\")\n    print(f\"Imports: {len(result.imports)}\")\n\n    if result.functions:\n        print(\"\\n## Functions\")\n        for f in result.functions[:10]:\n            print(f\"", "chunk_type": "function", "line_start": 386, "line_end": 427, "language": "python", "name": "main"}, "dfb7757a892c_func_visit": {"id": "dfb7757a892c_func_visit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "    def visit(node: Node):\n        if node.type in node_types:\n            results.append(node)\n        for child in node.children:\n            visit(child)", "chunk_type": "function", "line_start": 359, "line_end": 363, "language": "python", "name": "visit"}, "dfb7757a892c_class_CodeItem": {"id": "dfb7757a892c_class_CodeItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "class CodeItem:\n    \"\"\"A code item (function, class, etc).\"\"\"\n    name: str\n    item_type: str  # 'function', 'class', 'method', 'import', 'variable'\n    line_start: int\n    line_end: int\n    signature: str = \"\"\n    docstring: Optional[str] = None\n    language: str = \"\"\n    children: List['CodeItem'] = field(default_factory=list)", "chunk_type": "class", "line_start": 30, "line_end": 39, "language": "python", "name": "CodeItem"}, "dfb7757a892c_class_ParsedFile": {"id": "dfb7757a892c_class_ParsedFile", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "class ParsedFile:\n    \"\"\"Result of parsing a file.\"\"\"\n    path: Path\n    language: str\n    tree: Optional[Any] = None\n    source: bytes = b\"\"\n    functions: List[CodeItem] = field(default_factory=list)\n    classes: List[CodeItem] = field(default_factory=list)\n    imports: List[str] = field(default_factory=list)\n    error: Optional[str] = None", "chunk_type": "class", "line_start": 43, "line_end": 52, "language": "python", "name": "ParsedFile"}, "516cc8549f7d_file": {"id": "516cc8549f7d_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\trigger_loop.py", "content": "\"\"\"\nAuto-Dev Loop Trigger\n=====================\nTriggers the autonomous development loop if enabled by the user.\n\"\"\"\n\nfrom pathlib import Path\nimport sys\n\nfrom .utils import Console, find_project_root\nimport config.loop_config as loop_config\n\ndef main():\n    \"\"\"Check config and trigger loop if enabled.\"\"\"\n    if not loop_config.ENABLE_AUTO_LOOP:\n        Console.info(\"Auto-Dev Loop: Disabled (User controllable via mcp-global-rules/config/loop_config.py)\")\n        return 0\n\n    # Locate the prompt file\n    root = find_project_root() or Path.cwd()\n    # Check standard location first\n    prompt_path = root / \"mcp-global-rules\" / \"prompts\" / \"auto_dev.md\"\n\n    if not prompt_path.exists():\n        # Fallback to the user's legacy temp file as requested (but preferring permanent)\n        fallback = root / \"ai-script-to-make-it-continue-development.md\"\n        if fallback.exists():\n            prompt_path = fallback\n        else:\n            Console.warn(\"Auto-Dev Loop: Enabled but prompt file not found.\")\n            return 1\n\n    try:\n        content = prompt_path.read_text(encoding='utf-8').strip()\n        Console.header(\"AUTO-DEV LOOP TRIGGERED\")\n        print(\"\\n\" + \"=\"*40)\n        print(\">>> INJECTION START >>>\")\n        print(content)\n        print(\"<<< INJECTION END <<<\")\n        print(\"=\"*40 + \"\\n\")\n        Console.ok(\"Prompt sent to agent stream.\")\n    except Exception as e:\n        Console.fail(f\"Failed to read prompt: {e}\")\n        return 1\n\n    return 0\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n", "chunk_type": "file", "line_start": 1, "line_end": 50, "language": "python", "name": "trigger_loop.py"}, "516cc8549f7d_func_main": {"id": "516cc8549f7d_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\trigger_loop.py", "content": "def main():\n    \"\"\"Check config and trigger loop if enabled.\"\"\"\n    if not loop_config.ENABLE_AUTO_LOOP:\n        Console.info(\"Auto-Dev Loop: Disabled (User controllable via mcp-global-rules/config/loop_config.py)\")\n        return 0\n\n    # Locate the prompt file\n    root = find_project_root() or Path.cwd()\n    # Check standard location first\n    prompt_path = root / \"mcp-global-rules\" / \"prompts\" / \"auto_dev.md\"\n\n    if not prompt_path.exists():\n        # Fallback to the user's legacy temp file as requested (but preferring permanent)\n        fallback = root / \"ai-script-to-make-it-continue-development.md\"\n        if fallback.exists():\n            prompt_path = fallback\n        else:\n            Console.warn(\"Auto-Dev Loop: Enabled but prompt file not found.\")\n            return 1\n\n    try:\n        content = prompt_path.read_text(encoding='utf-8').strip()\n        Console.header(\"AUTO-DEV LOOP TRIGGERED\")\n        print(\"\\n\" + \"=\"*40)\n        print(\">>> INJECTION START >>>\")\n        print", "chunk_type": "function", "line_start": 13, "line_end": 46, "language": "python", "name": "main"}, "c0de5856ab69_file": {"id": "c0de5856ab69_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "\"\"\"\nMCP Global Rules - Shared Utilities\n====================================\nCore utility functions used by all AI agent enhancement tools.\n\nPython 3.11+ compatible, uses only stdlib.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Iterator, Tuple\nimport ast\nimport json\nimport os\nimport subprocess\n\n\n# =============================================================================\n# DATA CLASSES\n# =============================================================================\n\n@dataclass\nclass FunctionInfo:\n    \"\"\"Information about a Python function.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    args: List[str]\n    arg_types: Dict[str, str]\n    return_type: Optional[str]\n    docstring: Optional[str]\n    is_async: bool = False\n    is_method: bool = False\n    decorators: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ClassInfo:\n    \"\"\"Information about a Python class.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    docstring: Optional[str]\n    methods: List[FunctionInfo] = field(default_factory=list)\n    bases: List[str] = field(default_factory=list)\n    decorators: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ModuleInfo:\n    \"\"\"Information about a Python module.\"\"\"\n    path: Path\n    docstring: Optional[str]\n    imports: List[str] = field(default_factory=list)\n    from_imports: List[Tuple[str, List[str]]] = field(default_factory=list)\n    functions: List[FunctionInfo] = field(default_factory=list)\n    classes: List[ClassInfo] = field(default_factory=list)\n    global_vars: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass GitCommit:\n    \"\"\"Information about a git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    date: str\n    message: str\n    body: str = \"\"\n    files_changed: List[str] = field(default_factory=list)\n\n\n# =============================================================================\n# FILE DISC", "chunk_type": "file", "line_start": 1, "line_end": 659, "language": "python", "name": "utils.py"}, "c0de5856ab69_func_find_python_files": {"id": "c0de5856ab69_func_find_python_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def find_python_files(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> Iterator[Path]:\n    \"\"\"\n    Find all Python files in a directory tree.\n\n    Args:\n        root: Root directory to search\n        exclude_patterns: Patterns to exclude (e.g., ['__pycache__', '.venv'])\n\n    Yields:\n        Path objects for each Python file found\n    \"\"\"\n    if exclude_patterns is None:\n        exclude_patterns = [\n            '__pycache__', '.venv', 'venv', '.git', 'node_modules',\n            '.eggs', '*.egg-info', 'dist', 'build', '.tox', '.pytest_cache'\n        ]\n\n    root = Path(root)\n    if not root.exists():\n        return\n\n    for item in root.rglob('*.py'):\n        # Check if any parent directory matches exclude patterns\n        skip = False\n        for part in item.parts:\n            for pattern in exclude_patterns:\n                if pattern.startswith('*'):\n                    if part.endswith(pattern[1:]):\n                        skip = True\n                        break\n       ", "chunk_type": "function", "line_start": 78, "line_end": 118, "language": "python", "name": "find_python_files"}, "c0de5856ab69_func_find_project_root": {"id": "c0de5856ab69_func_find_project_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def find_project_root(start: Path = None) -> Optional[Path]:\n    \"\"\"\n    Find the project root by looking for common markers.\n\n    Args:\n        start: Starting directory (defaults to cwd)\n\n    Returns:\n        Project root path or None\n    \"\"\"\n    # 1. Try environment variable set by mcp.py\n    mcp_root_env = os.environ.get('MCP_ROOT')\n\n    if start is None:\n        start = Path.cwd()\n\n    markers = ['.git', 'pyproject.toml', 'setup.py', 'setup.cfg', '.mcp']\n\n    # helper to check markers\n    def check_dir(d: Path) -> bool:\n        for marker in markers:\n            if (d / marker).exists():\n                return True\n        return False\n\n    # A. Search up from the MCP package location first (Strongest signal)\n    # If mcp-global-rules is inside a project, that's likely the project we want.\n    if mcp_root_env:\n        mcp_root = Path(mcp_root_env).resolve()\n\n        # Check parent of mcp-global-rules (common case)\n        if check_dir(mcp_root.parent):\n            return mcp_root.", "chunk_type": "function", "line_start": 121, "line_end": 176, "language": "python", "name": "find_project_root"}, "c0de5856ab69_func_get_package_root": {"id": "c0de5856ab69_func_get_package_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def get_package_root() -> Path:\n    \"\"\"Get the absolute path to the mcp-global-rules package directory.\"\"\"\n    mcp_root_env = os.environ.get('MCP_ROOT')\n    if mcp_root_env:\n        return Path(mcp_root_env).resolve()\n\n    # Fallback to __file__ resolution\n    return Path(__file__).resolve().parent.parent", "chunk_type": "function", "line_start": 179, "line_end": 186, "language": "python", "name": "get_package_root"}, "c0de5856ab69_func_parse_file": {"id": "c0de5856ab69_func_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def parse_file(path: Path) -> Optional[ast.Module]:\n    \"\"\"\n    Parse a Python file into an AST.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        AST module or None if parsing fails\n    \"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        return ast.parse(source, filename=str(path))\n    except (SyntaxError, UnicodeDecodeError, FileNotFoundError):\n        return None", "chunk_type": "function", "line_start": 193, "line_end": 208, "language": "python", "name": "parse_file"}, "c0de5856ab69_func_get_type_annotation": {"id": "c0de5856ab69_func_get_type_annotation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def get_type_annotation(node: ast.expr) -> str:\n    \"\"\"Convert an AST type annotation to a string.\"\"\"\n    if node is None:\n        return \"\"\n\n    if isinstance(node, ast.Name):\n        return node.id\n    elif isinstance(node, ast.Constant):\n        return repr(node.value)\n    elif isinstance(node, ast.Subscript):\n        base = get_type_annotation(node.value)\n        if isinstance(node.slice, ast.Tuple):\n            args = ', '.join(get_type_annotation(e) for e in node.slice.elts)\n        else:\n            args = get_type_annotation(node.slice)\n        return f\"{base}[{args}]\"\n    elif isinstance(node, ast.Attribute):\n        return f\"{get_type_annotation(node.value)}.{node.attr}\"\n    elif isinstance(node, ast.BinOp) and isinstance(node.op, ast.BitOr):\n        # Union type with | operator\n        left = get_type_annotation(node.left)\n        right = get_type_annotation(node.right)\n        return f\"{left} | {right}\"\n    else:\n        return ast.unparse(node) if hasattr(ast, 'unparse') e", "chunk_type": "function", "line_start": 211, "line_end": 235, "language": "python", "name": "get_type_annotation"}, "c0de5856ab69_func_extract_function_info": {"id": "c0de5856ab69_func_extract_function_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def extract_function_info(node: ast.FunctionDef | ast.AsyncFunctionDef) -> FunctionInfo:\n    \"\"\"\n    Extract information from a function definition node.\n\n    Args:\n        node: AST function definition node\n\n    Returns:\n        FunctionInfo dataclass\n    \"\"\"\n    # Get arguments\n    args = []\n    arg_types = {}\n\n    for arg in node.args.args:\n        arg_name = arg.arg\n        args.append(arg_name)\n        if arg.annotation:\n            arg_types[arg_name] = get_type_annotation(arg.annotation)\n\n    # Get return type\n    return_type = None\n    if node.returns:\n        return_type = get_type_annotation(node.returns)\n\n    # Get docstring\n    docstring = ast.get_docstring(node)\n\n    # Get decorators\n    decorators = []\n    for dec in node.decorator_list:\n        if isinstance(dec, ast.Name):\n            decorators.append(dec.id)\n        elif isinstance(dec, ast.Attribute):\n            decorators.append(f\"{get_type_annotation(dec.value)}.{dec.attr}\")\n        elif isinstance(dec, ast.Call):", "chunk_type": "function", "line_start": 238, "line_end": 289, "language": "python", "name": "extract_function_info"}, "c0de5856ab69_func_extract_class_info": {"id": "c0de5856ab69_func_extract_class_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def extract_class_info(node: ast.ClassDef) -> ClassInfo:\n    \"\"\"\n    Extract information from a class definition node.\n\n    Args:\n        node: AST class definition node\n\n    Returns:\n        ClassInfo dataclass\n    \"\"\"\n    # Get methods\n    methods = []\n    for item in node.body:\n        if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            func_info = extract_function_info(item)\n            func_info.is_method = True\n            methods.append(func_info)\n\n    # Get base classes\n    bases = [get_type_annotation(base) for base in node.bases]\n\n    # Get decorators\n    decorators = []\n    for dec in node.decorator_list:\n        if isinstance(dec, ast.Name):\n            decorators.append(dec.id)\n\n    return ClassInfo(\n        name=node.name,\n        lineno=node.lineno,\n        end_lineno=node.end_lineno or node.lineno,\n        docstring=ast.get_docstring(node),\n        methods=methods,\n        bases=bases,\n        decorators=decorators\n    )", "chunk_type": "function", "line_start": 292, "line_end": 327, "language": "python", "name": "extract_class_info"}, "c0de5856ab69_func_analyze_module": {"id": "c0de5856ab69_func_analyze_module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def analyze_module(path: Path) -> Optional[ModuleInfo]:\n    \"\"\"\n    Analyze a Python module and extract all information.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        ModuleInfo dataclass or None if parsing fails\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return None\n\n    info = ModuleInfo(\n        path=path,\n        docstring=ast.get_docstring(tree)\n    )\n\n    for node in ast.walk(tree):\n        # Imports\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                info.imports.append(alias.name)\n        elif isinstance(node, ast.ImportFrom):\n            if node.module:\n                names = [alias.name for alias in node.names]\n                info.from_imports.append((node.module, names))\n\n    # Top-level items only\n    for node in tree.body:\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            info.functions.append(extract_function_info(node))\n        elif isinstance(node, ast.", "chunk_type": "function", "line_start": 330, "line_end": 370, "language": "python", "name": "analyze_module"}, "c0de5856ab69_func_run_git_command": {"id": "c0de5856ab69_func_run_git_command", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def run_git_command(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"\n    Run a git command and return output.\n\n    Args:\n        args: Git command arguments\n        cwd: Working directory\n\n    Returns:\n        Command output or None if failed\n    \"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd(),\n            timeout=30\n        )\n        if result and result.returncode == 0:\n            return (result.stdout or \"\").strip()\n        return None\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 377, "line_end": 400, "language": "python", "name": "run_git_command"}, "c0de5856ab69_func_get_git_log": {"id": "c0de5856ab69_func_get_git_log", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def get_git_log(\n    count: int = 50,\n    cwd: Path = None\n) -> List[GitCommit]:\n    \"\"\"\n    Get recent git commits.\n\n    Args:\n        count: Number of commits to retrieve\n        cwd: Working directory\n\n    Returns:\n        List of GitCommit objects\n    \"\"\"\n    # Use a delimiter that won't appear in commit messages\n    delimiter = \"---COMMIT_DELIMITER---\"\n    format_str = f\"%H{delimiter}%h{delimiter}%an{delimiter}%ai{delimiter}%s{delimiter}%b\"\n\n    output = run_git_command(\n        ['log', f'-{count}', f'--format={format_str}'],\n        cwd=cwd\n    )\n\n    if not output:\n        return []\n\n    commits = []\n    for entry in output.split('\\n'):\n        if not entry.strip():\n            continue\n\n        parts = entry.split(delimiter)\n        if len(parts) >= 5:\n            commits.append(GitCommit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                date=parts[3],\n                message=parts[4],\n                body=part", "chunk_type": "function", "line_start": 403, "line_end": 445, "language": "python", "name": "get_git_log"}, "c0de5856ab69_func_get_changed_files": {"id": "c0de5856ab69_func_get_changed_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def get_changed_files(since_commit: str = \"HEAD~1\", cwd: Path = None) -> List[str]:\n    \"\"\"\n    Get list of files changed since a commit.\n\n    Args:\n        since_commit: Git reference to compare against\n        cwd: Working directory\n\n    Returns:\n        List of changed file paths\n    \"\"\"\n    output = run_git_command(\n        ['diff', '--name-only', since_commit],\n        cwd=cwd\n    )\n\n    if not output:\n        return []\n\n    return [f for f in output.split('\\n') if f.strip()]", "chunk_type": "function", "line_start": 448, "line_end": 467, "language": "python", "name": "get_changed_files"}, "c0de5856ab69_func_get_staged_files": {"id": "c0de5856ab69_func_get_staged_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def get_staged_files(cwd: Path = None) -> List[str]:\n    \"\"\"Get list of staged files.\"\"\"\n    output = run_git_command(['diff', '--cached', '--name-only'], cwd=cwd)\n    return [f for f in (output or '').split('\\n') if f.strip()]", "chunk_type": "function", "line_start": 470, "line_end": 473, "language": "python", "name": "get_staged_files"}, "c0de5856ab69_func_format_as_json": {"id": "c0de5856ab69_func_format_as_json", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def format_as_json(data: Any, indent: int = 2) -> str:\n    \"\"\"Format data as JSON string.\"\"\"\n    def default_serializer(obj):\n        if isinstance(obj, Path):\n            return str(obj)\n        if hasattr(obj, '__dataclass_fields__'):\n            return {k: getattr(obj, k) for k in obj.__dataclass_fields__}\n        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n\n    return json.dumps(data, indent=indent, default=default_serializer)", "chunk_type": "function", "line_start": 480, "line_end": 489, "language": "python", "name": "format_as_json"}, "c0de5856ab69_func_format_as_markdown_table": {"id": "c0de5856ab69_func_format_as_markdown_table", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def format_as_markdown_table(\n    headers: List[str],\n    rows: List[List[str]]\n) -> str:\n    \"\"\"Format data as a Markdown table.\"\"\"\n    if not headers or not rows:\n        return \"\"\n\n    # Calculate column widths\n    widths = [len(h) for h in headers]\n    for row in rows:\n        for i, cell in enumerate(row):\n            if i < len(widths):\n                widths[i] = max(widths[i], len(str(cell)))\n\n    # Format header\n    header_row = \"| \" + \" | \".join(h.ljust(widths[i]) for i, h in enumerate(headers)) + \" |\"\n    separator = \"|\" + \"|\".join(\"-\" * (w + 2) for w in widths) + \"|\"\n\n    # Format rows\n    data_rows = []\n    for row in rows:\n        cells = []\n        for i, cell in enumerate(row):\n            width = widths[i] if i < len(widths) else len(str(cell))\n            cells.append(str(cell).ljust(width))\n        data_rows.append(\"| \" + \" | \".join(cells) + \" |\")\n\n    return \"\\n\".join([header_row, separator] + data_rows)", "chunk_type": "function", "line_start": 492, "line_end": 520, "language": "python", "name": "format_as_markdown_table"}, "c0de5856ab69_func_get_mcp_data_dir": {"id": "c0de5856ab69_func_get_mcp_data_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def get_mcp_data_dir() -> Optional[Path]:\n    \"\"\"Find the .mcp directory.\"\"\"\n    project_root = find_project_root()\n    if project_root:\n        mcp_dir = project_root / '.mcp'\n        if mcp_dir.exists():\n            return mcp_dir\n    return None", "chunk_type": "function", "line_start": 527, "line_end": 534, "language": "python", "name": "get_mcp_data_dir"}, "c0de5856ab69_func_record_to_memory": {"id": "c0de5856ab69_func_record_to_memory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "def record_to_memory(\n    entry_type: str,\n    content: str,\n    tags: List[str] = None,\n    metadata: Dict[str, Any] = None\n) -> bool:\n    \"\"\"\n    Record an entry to MCP memory.\n\n    Args:\n        entry_type: Type of entry (action, decision, todo, etc.)\n        content: Content of the entry\n        tags: Optional tags\n        metadata: Optional metadata\n\n    Returns:\n        True if successful\n    \"\"\"\n    mcp_data = get_mcp_data_dir()\n    if not mcp_data:\n        return False\n\n    memory_dir = mcp_data / 'memory'\n    if not memory_dir.exists():\n        memory_dir.mkdir(parents=True)\n\n    # Map entry types to files\n    type_files = {\n        'action': 'actions.json',\n        'decision': 'decisions.json',\n        'todo': 'todos.json',\n        'milestone': 'milestones.json',\n        'session': 'sessions.json'\n    }\n\n    filename = type_files.get(entry_type, 'actions.json')\n    filepath = memory_dir / filename\n\n    # Load existing entries\n    entries = []\n    if filepath.exists():\n       ", "chunk_type": "function", "line_start": 537, "line_end": 602, "language": "python", "name": "record_to_memory"}, "c0de5856ab69_func_check_dir": {"id": "c0de5856ab69_func_check_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def check_dir(d: Path) -> bool:\n        for marker in markers:\n            if (d / marker).exists():\n                return True\n        return False", "chunk_type": "function", "line_start": 140, "line_end": 144, "language": "python", "name": "check_dir"}, "c0de5856ab69_func_default_serializer": {"id": "c0de5856ab69_func_default_serializer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def default_serializer(obj):\n        if isinstance(obj, Path):\n            return str(obj)\n        if hasattr(obj, '__dataclass_fields__'):\n            return {k: getattr(obj, k) for k in obj.__dataclass_fields__}\n        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")", "chunk_type": "function", "line_start": 482, "line_end": 487, "language": "python", "name": "default_serializer"}, "c0de5856ab69_func__supports_color": {"id": "c0de5856ab69_func__supports_color", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def _supports_color(cls) -> bool:\n        \"\"\"Check if terminal supports color.\"\"\"\n        import sys\n        return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()", "chunk_type": "function", "line_start": 623, "line_end": 626, "language": "python", "name": "_supports_color"}, "c0de5856ab69_func__color": {"id": "c0de5856ab69_func__color", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def _color(cls, text: str, color: str) -> str:\n        \"\"\"Apply color to text.\"\"\"\n        if not cls._supports_color():\n            return text\n        return f\"{cls.COLORS.get(color, '')}{text}{cls.COLORS['reset']}\"", "chunk_type": "function", "line_start": 629, "line_end": 633, "language": "python", "name": "_color"}, "c0de5856ab69_func_info": {"id": "c0de5856ab69_func_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def info(cls, msg: str):\n        \"\"\"Print info message.\"\"\"\n        print(f\"{cls._color('[INFO]', 'blue')} {msg}\")", "chunk_type": "function", "line_start": 636, "line_end": 638, "language": "python", "name": "info"}, "c0de5856ab69_func_ok": {"id": "c0de5856ab69_func_ok", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def ok(cls, msg: str):\n        \"\"\"Print success message.\"\"\"\n        print(f\"{cls._color('[OK]', 'green')} {msg}\")", "chunk_type": "function", "line_start": 641, "line_end": 643, "language": "python", "name": "ok"}, "c0de5856ab69_func_warn": {"id": "c0de5856ab69_func_warn", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def warn(cls, msg: str):\n        \"\"\"Print warning message.\"\"\"\n        print(f\"{cls._color('[WARNING]', 'yellow')} {msg}\")", "chunk_type": "function", "line_start": 646, "line_end": 648, "language": "python", "name": "warn"}, "c0de5856ab69_func_fail": {"id": "c0de5856ab69_func_fail", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def fail(cls, msg: str):\n        \"\"\"Print failure message.\"\"\"\n        print(f\"{cls._color('[FAIL]', 'red')} {msg}\")", "chunk_type": "function", "line_start": 651, "line_end": 653, "language": "python", "name": "fail"}, "c0de5856ab69_func_header": {"id": "c0de5856ab69_func_header", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "    def header(cls, msg: str):\n        \"\"\"Print header.\"\"\"\n        print(f\"\\n{cls._color('=== ' + msg + ' ===', 'cyan')}\\n\")", "chunk_type": "function", "line_start": 656, "line_end": 658, "language": "python", "name": "header"}, "c0de5856ab69_class_FunctionInfo": {"id": "c0de5856ab69_class_FunctionInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "class FunctionInfo:\n    \"\"\"Information about a Python function.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    args: List[str]\n    arg_types: Dict[str, str]\n    return_type: Optional[str]\n    docstring: Optional[str]\n    is_async: bool = False\n    is_method: bool = False\n    decorators: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 24, "line_end": 35, "language": "python", "name": "FunctionInfo"}, "c0de5856ab69_class_ClassInfo": {"id": "c0de5856ab69_class_ClassInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "class ClassInfo:\n    \"\"\"Information about a Python class.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    docstring: Optional[str]\n    methods: List[FunctionInfo] = field(default_factory=list)\n    bases: List[str] = field(default_factory=list)\n    decorators: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 39, "line_end": 47, "language": "python", "name": "ClassInfo"}, "c0de5856ab69_class_ModuleInfo": {"id": "c0de5856ab69_class_ModuleInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "class ModuleInfo:\n    \"\"\"Information about a Python module.\"\"\"\n    path: Path\n    docstring: Optional[str]\n    imports: List[str] = field(default_factory=list)\n    from_imports: List[Tuple[str, List[str]]] = field(default_factory=list)\n    functions: List[FunctionInfo] = field(default_factory=list)\n    classes: List[ClassInfo] = field(default_factory=list)\n    global_vars: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 51, "line_end": 59, "language": "python", "name": "ModuleInfo"}, "c0de5856ab69_class_GitCommit": {"id": "c0de5856ab69_class_GitCommit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "class GitCommit:\n    \"\"\"Information about a git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    date: str\n    message: str\n    body: str = \"\"\n    files_changed: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 63, "line_end": 71, "language": "python", "name": "GitCommit"}, "c0de5856ab69_class_Console": {"id": "c0de5856ab69_class_Console", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\utils.py", "content": "class Console:\n    \"\"\"Simple console output with colors.\"\"\"\n\n    COLORS = {\n        'red': '\\033[0;31m',\n        'green': '\\033[0;32m',\n        'yellow': '\\033[1;33m',\n        'blue': '\\033[0;34m',\n        'cyan': '\\033[0;36m',\n        'bold': '\\033[1m',\n        'reset': '\\033[0m'\n    }\n\n    @classmethod\n    def _supports_color(cls) -> bool:\n        \"\"\"Check if terminal supports color.\"\"\"\n        import sys\n        return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()\n\n    @classmethod\n    def _color(cls, text: str, color: str) -> str:\n        \"\"\"Apply color to text.\"\"\"\n        if not cls._supports_color():\n            return text\n        return f\"{cls.COLORS.get(color, '')}{text}{cls.COLORS['reset']}\"\n\n    @classmethod\n    def info(cls, msg: str):\n        \"\"\"Print info message.\"\"\"\n        print(f\"{cls._color('[INFO]', 'blue')} {msg}\")\n\n    @classmethod\n    def ok(cls, msg: str):\n        \"\"\"Print success message.\"\"\"\n        print(f\"{cls._color('[OK]', 'green')} {msg}\")\n\n    @cla", "chunk_type": "class", "line_start": 609, "line_end": 658, "language": "python", "name": "Console"}, "7af811a5ed42_file": {"id": "7af811a5ed42_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "\"\"\"\nVector Store\n=============\nLocal FAISS-based vector database for semantic code search.\n\nUsage:\n    from scripts.vector_store import VectorStore\n\n    store = VectorStore(path)\n    store.index_codebase(root)\n    results = store.search(\"authentication handler\", k=10)\n\"\"\"\n\nimport json\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass, field, asdict\nimport hashlib\n\nfrom .utils import Console, find_python_files, find_project_root\nfrom .embeddings import embed_text, embed_texts, cosine_similarity, embedding_dimension\n\n\n# Try to import FAISS\ntry:\n    import faiss\n    FAISS_AVAILABLE = True\nexcept ImportError:\n    FAISS_AVAILABLE = False\n\n# Try numpy\ntry:\n    import numpy as np\n    NUMPY_AVAILABLE = True\nexcept ImportError:\n    NUMPY_AVAILABLE = False\n\n\n@dataclass\nclass CodeChunk:\n    \"\"\"A chunk of code with metadata.\"\"\"\n    id: str\n    path: str\n    content: str\n    chunk_type: str  # 'function', 'class', 'file', 'block'\n    line_start: int\n    line_end: int\n    language: str = \"\"\n    name: str = \"\"\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result.\"\"\"\n    chunk: CodeChunk\n    score: float\n    rank: int\n\n\nclass VectorStore:\n    \"\"\"Local vector store for semantic code search.\"\"\"\n\n    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}\n\n    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n", "chunk_type": "file", "line_start": 1, "line_end": 386, "language": "python", "name": "vector_store.py"}, "7af811a5ed42_func_main": {"id": "7af811a5ed42_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Vector Store\")\n\n    if FAISS_AVAILABLE:\n        Console.ok(\"FAISS available\")\n    else:\n        Console.warn(\"FAISS not available, using brute force search\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if len(args) < 1:\n        Console.info(\"Usage: python vector_store.py <command> [args]\")\n        Console.info(\"Commands:\")\n        Console.info(\"  index <path>     Index codebase\")\n        Console.info(\"  search <query>   Search index\")\n        return 1\n\n    command = args[0]\n    store = VectorStore()\n\n    if command == 'index':\n        root = find_project_root() or Path.cwd()\n        path = Path(args[1]) if len(args) > 1 else root\n        store.index_codebase(path)\n\n    elif command == 'search':\n        query = ' '.join(args[1:]) if len(args) > 1 else ''\n        if not query:\n            Console.fail(\"No query provided\")\n            return 1\n\n        # Load existing index\n        if not store.load():\n    ", "chunk_type": "function", "line_start": 336, "line_end": 381, "language": "python", "name": "main"}, "7af811a5ed42_func___init__": {"id": "7af811a5ed42_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}", "chunk_type": "function", "line_start": 64, "line_end": 75, "language": "python", "name": "__init__"}, "7af811a5ed42_func_index_codebase": {"id": "7af811a5ed42_func_index_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n        Console.info(f\"Found {len(files)} files\")\n\n        chunks = []\n        for path in files:\n            file_chunks = self._extract_chunks(path)\n            chunks.extend(file_chunks)\n\n        Console.info(f\"Extracted {len(chunks)} code chunks\")\n\n        if not chunks:\n            return 0\n\n        # Generate embeddings\n        Console.info(\"Generating embeddings...\")\n        texts = [c.content[:1000] for c in chunks]  # Limit text length\n        embeddings = embed_texts(texts)\n\n        # Store chunks and embeddings\n        for chunk, emb in zip(chunks, embeddings):\n            self.chunks[chunk.id] = chunk\n            self.embeddings[chunk.id] = emb\n\n        # Build FAISS index if available\n        if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n  ", "chunk_type": "function", "line_start": 77, "line_end": 112, "language": "python", "name": "index_codebase"}, "7af811a5ed42_func__extract_chunks": {"id": "7af811a5ed42_func__extract_chunks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _extract_chunks(self, path: Path) -> List[CodeChunk]:\n        \"\"\"Extract code chunks from file.\"\"\"\n        chunks = []\n\n        try:\n            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n                content = f.read()\n        except Exception:\n            return chunks\n\n        # Detect language\n        ext = path.suffix.lower()\n        lang_map = {'.py': 'python', '.js': 'javascript', '.ts': 'typescript',\n                    '.go': 'go', '.rs': 'rust', '.java': 'java'}\n        language = lang_map.get(ext, 'unknown')\n\n        # Create file-level chunk\n        file_id = hashlib.md5(str(path).encode()).hexdigest()[:12]\n        chunks.append(CodeChunk(\n            id=f\"{file_id}_file\",\n            path=str(path),\n            content=content[:2000],  # First 2000 chars\n            chunk_type='file',\n            line_start=1,\n            line_end=content.count('\\n') + 1,\n            language=language,\n            name=path.name\n        ))\n\n        # Try to ex", "chunk_type": "function", "line_start": 114, "line_end": 179, "language": "python", "name": "_extract_chunks"}, "7af811a5ed42_func__build_faiss_index": {"id": "7af811a5ed42_func__build_faiss_index", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _build_faiss_index(self):\n        \"\"\"Build FAISS index from embeddings.\"\"\"\n        if not self.embeddings:\n            return\n\n        dim = len(next(iter(self.embeddings.values())))\n\n        # Create index\n        self._faiss_index = faiss.IndexFlatIP(dim)  # Inner product = cosine for normalized\n\n        # Add vectors\n        ids = list(self.embeddings.keys())\n        vectors = np.array([self.embeddings[id] for id in ids], dtype='float32')\n\n        # Normalize for cosine similarity\n        faiss.normalize_L2(vectors)\n\n        self._faiss_index.add(vectors)\n\n        # Build ID mappings\n        for idx, id in enumerate(ids):\n            self._id_to_idx[id] = idx\n            self._idx_to_id[idx] = id", "chunk_type": "function", "line_start": 181, "line_end": 203, "language": "python", "name": "_build_faiss_index"}, "7af811a5ed42_func_search": {"id": "7af811a5ed42_func_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def search(self, query: str, k: int = 10) -> List[SearchResult]:\n        \"\"\"Search for code matching query.\"\"\"\n        if not self.embeddings:\n            return []\n\n        # Generate query embedding\n        query_emb = embed_text(query)\n        if query_emb is None:\n            return []\n\n        # Use FAISS if available\n        if self._faiss_index is not None and NUMPY_AVAILABLE:\n            return self._faiss_search(query_emb, k)\n\n        # Fallback to brute force\n        return self._brute_force_search(query_emb, k)", "chunk_type": "function", "line_start": 205, "line_end": 220, "language": "python", "name": "search"}, "7af811a5ed42_func__faiss_search": {"id": "7af811a5ed42_func__faiss_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _faiss_search(self, query_emb: List[float], k: int) -> List[SearchResult]:\n        \"\"\"Search using FAISS.\"\"\"\n        query_vec = np.array([query_emb], dtype='float32')\n        faiss.normalize_L2(query_vec)\n\n        k = min(k, len(self.embeddings))\n        distances, indices = self._faiss_index.search(query_vec, k)\n\n        results = []\n        for rank, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n            if idx < 0:\n                continue\n            chunk_id = self._idx_to_id.get(int(idx))\n            if chunk_id and chunk_id in self.chunks:\n                results.append(SearchResult(\n                    chunk=self.chunks[chunk_id],\n                    score=float(dist),\n                    rank=rank + 1\n                ))\n\n        return results", "chunk_type": "function", "line_start": 222, "line_end": 242, "language": "python", "name": "_faiss_search"}, "7af811a5ed42_func__brute_force_search": {"id": "7af811a5ed42_func__brute_force_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _brute_force_search(self, query_emb: List[float], k: int) -> List[SearchResult]:\n        \"\"\"Brute force cosine similarity search.\"\"\"\n        scores = []\n\n        for chunk_id, emb in self.embeddings.items():\n            score = cosine_similarity(query_emb, emb)\n            scores.append((chunk_id, score))\n\n        # Sort by score descending\n        scores.sort(key=lambda x: x[1], reverse=True)\n\n        results = []\n        for rank, (chunk_id, score) in enumerate(scores[:k]):\n            if chunk_id in self.chunks:\n                results.append(SearchResult(\n                    chunk=self.chunks[chunk_id],\n                    score=score,\n                    rank=rank + 1\n                ))\n\n        return results", "chunk_type": "function", "line_start": 244, "line_end": 264, "language": "python", "name": "_brute_force_search"}, "7af811a5ed42_func_save": {"id": "7af811a5ed42_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def save(self):\n        \"\"\"Save index to disk.\"\"\"\n        self.index_path.mkdir(parents=True, exist_ok=True)\n\n        # Save chunks\n        chunks_file = self.index_path / \"chunks.json\"\n        with open(chunks_file, 'w', encoding='utf-8') as f:\n            json.dump({k: asdict(v) for k, v in self.chunks.items()}, f)\n\n        # Save embeddings\n        emb_file = self.index_path / \"embeddings.json\"\n        with open(emb_file, 'w', encoding='utf-8') as f:\n            json.dump(self.embeddings, f)\n\n        Console.ok(f\"Index saved to {self.index_path}\")", "chunk_type": "function", "line_start": 266, "line_end": 280, "language": "python", "name": "save"}, "7af811a5ed42_func_load": {"id": "7af811a5ed42_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def load(self) -> bool:\n        \"\"\"Load index from disk.\"\"\"\n        chunks_file = self.index_path / \"chunks.json\"\n        emb_file = self.index_path / \"embeddings.json\"\n\n        if not chunks_file.exists() or not emb_file.exists():\n            return False\n\n        try:\n            with open(chunks_file, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                self.chunks = {k: CodeChunk(**v) for k, v in data.items()}\n\n            with open(emb_file, 'r', encoding='utf-8') as f:\n                self.embeddings = json.load(f)\n\n            if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n                self._build_faiss_index()\n\n            Console.ok(f\"Loaded {len(self.chunks)} chunks from index\")\n            return True\n\n        except Exception as e:\n            Console.warn(f\"Could not load index: {e}\")\n            return False", "chunk_type": "function", "line_start": 282, "line_end": 306, "language": "python", "name": "load"}, "7af811a5ed42_func_update": {"id": "7af811a5ed42_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def update(self, changed_files: List[Path]):\n        \"\"\"Update index for changed files.\"\"\"\n        for path in changed_files:\n            # Remove old chunks for this file\n            to_remove = [k for k, v in self.chunks.items() if v.path == str(path)]\n            for k in to_remove:\n                del self.chunks[k]\n                if k in self.embeddings:\n                    del self.embeddings[k]\n\n            # Re-index file\n            if path.exists():\n                new_chunks = self._extract_chunks(path)\n                if new_chunks:\n                    texts = [c.content[:1000] for c in new_chunks]\n                    embeddings = embed_texts(texts)\n\n                    for chunk, emb in zip(new_chunks, embeddings):\n                        self.chunks[chunk.id] = chunk\n                        self.embeddings[chunk.id] = emb\n\n        # Rebuild FAISS index\n        if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n            self._build_faiss_index()\n\n        self.save()", "chunk_type": "function", "line_start": 308, "line_end": 333, "language": "python", "name": "update"}, "7af811a5ed42_class_CodeChunk": {"id": "7af811a5ed42_class_CodeChunk", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "class CodeChunk:\n    \"\"\"A chunk of code with metadata.\"\"\"\n    id: str\n    path: str\n    content: str\n    chunk_type: str  # 'function', 'class', 'file', 'block'\n    line_start: int\n    line_end: int\n    language: str = \"\"\n    name: str = \"\"", "chunk_type": "class", "line_start": 41, "line_end": 50, "language": "python", "name": "CodeChunk"}, "7af811a5ed42_class_SearchResult": {"id": "7af811a5ed42_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "class SearchResult:\n    \"\"\"A search result.\"\"\"\n    chunk: CodeChunk\n    score: float\n    rank: int", "chunk_type": "class", "line_start": 54, "line_end": 58, "language": "python", "name": "SearchResult"}, "7af811a5ed42_class_VectorStore": {"id": "7af811a5ed42_class_VectorStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\vector_store.py", "content": "class VectorStore:\n    \"\"\"Local vector store for semantic code search.\"\"\"\n\n    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}\n\n    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n        Console.info(f\"Found {len(files)} files\")\n\n        chunks = []\n        for path in files:\n            file_chunks = self._extract_chunks(path)\n            chunks.extend(file_chunks)\n\n ", "chunk_type": "class", "line_start": 61, "line_end": 333, "language": "python", "name": "VectorStore"}, "d381a5b85eb8_file": {"id": "d381a5b85eb8_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\warm.py", "content": "\"\"\"\nWarm-Up Command\n===============\nPre-warm all indexes for faster AI agent responses.\n\nUsage:\n    python mcp.py warm\n\"\"\"\n\nfrom pathlib import Path\nimport sys\nimport time\n\nfrom .utils import Console, find_project_root\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n\ndef warm_all(root: Path = None) -> dict:\n    \"\"\"Pre-warm all indexes and caches.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.header(\"Warming Indexes\")\n    Console.info(f\"Project: {root}\")\n\n    start_time = time.time()\n    results = {}\n\n    # Define warm-up tasks\n    tasks = {\n        'semantic': ('vector_store', 'VectorStore', 'index_codebase'),\n        'todos': ('todo_index', 'index_todos', None),\n        'impact': ('impact', 'save_impact_graph', None),\n        'docs': ('doc_index', 'index_documentation', None),\n        'config': ('config_index', 'index_configs', None),\n        'context': ('autocontext', 'warm_context', None),\n    }\n\n    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' / 'vector_index')\n                getattr(instance, method)(root)\n            else:\n                # Direct function\n                func = getattr(module, func_or_class)\n                func(root)\n\n            return name, 'ok', None\n        except Exception as e:\n            return name, 'error', str(e)\n\n    # Run tasks in parallel\n    Console.info(\"Running warm-up tasks...\")\n\n    with ThreadPoolExecutor(max_workers=4) as executor:\n        futures = {}\n        for name, (module, func, method) in tasks.items():\n            future = executor.submit(run_task, name, module, func, method)\n            futures[future] = name\n\n        for future in as_completed(futures):\n            name, status, error = future.", "chunk_type": "file", "line_start": 1, "line_end": 117, "language": "python", "name": "warm.py"}, "d381a5b85eb8_func_warm_all": {"id": "d381a5b85eb8_func_warm_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\warm.py", "content": "def warm_all(root: Path = None) -> dict:\n    \"\"\"Pre-warm all indexes and caches.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.header(\"Warming Indexes\")\n    Console.info(f\"Project: {root}\")\n\n    start_time = time.time()\n    results = {}\n\n    # Define warm-up tasks\n    tasks = {\n        'semantic': ('vector_store', 'VectorStore', 'index_codebase'),\n        'todos': ('todo_index', 'index_todos', None),\n        'impact': ('impact', 'save_impact_graph', None),\n        'docs': ('doc_index', 'index_documentation', None),\n        'config': ('config_index', 'index_configs', None),\n        'context': ('autocontext', 'warm_context', None),\n    }\n\n    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' /", "chunk_type": "function", "line_start": 18, "line_end": 83, "language": "python", "name": "warm_all"}, "d381a5b85eb8_func_main": {"id": "d381a5b85eb8_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\warm.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    root = find_project_root() or Path.cwd()\n\n    if '--quick' in sys.argv:\n        # Quick warm - just semantic and todos\n        Console.header(\"Quick Warm\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(root / '.mcp' / 'vector_index')\n            store.index_codebase(root)\n            Console.ok(\"Semantic index warmed\")\n        except Exception:\n            pass\n\n        try:\n            from .todo_index import index_todos\n            index_todos(root)\n            Console.ok(\"TODO index warmed\")\n        except Exception:\n            pass\n\n        return 0\n\n    warm_all(root)\n    return 0", "chunk_type": "function", "line_start": 86, "line_end": 112, "language": "python", "name": "main"}, "d381a5b85eb8_func_run_task": {"id": "d381a5b85eb8_func_run_task", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\warm.py", "content": "    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' / 'vector_index')\n                getattr(instance, method)(root)\n            else:\n                # Direct function\n                func = getattr(module, func_or_class)\n                func(root)\n\n            return name, 'ok', None\n        except Exception as e:\n            return name, 'error', str(e)", "chunk_type": "function", "line_start": 38, "line_end": 55, "language": "python", "name": "run_task"}, "3976aafea7a2_file": {"id": "3976aafea7a2_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "\"\"\"\nFile System Watcher\n===================\nBackground process for live semantic index updates.\n\nUsage:\n    python mcp.py watch           # Start watching\n    python mcp.py watch --stop    # Stop watching\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, Set, Optional\nimport hashlib\nimport json\nimport os\nimport sys\nimport time\n\nfrom .utils import Console, find_python_files, find_project_root\nimport signal\n\n\n# Try watchdog for efficient file watching\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileModifiedEvent\n    WATCHDOG_AVAILABLE = True\nexcept ImportError:\n    WATCHDOG_AVAILABLE = False\n\n\n@dataclass\nclass WatcherState:\n    \"\"\"State of the file watcher.\"\"\"\n    pid_file: Path\n    index_path: Path\n    debounce_ms: int = 500\n    save_interval_s: int = 30\n    running: bool = False\n\n\nclass CodeChangeHandler:\n    \"\"\"Handles file changes for indexing.\"\"\"\n\n    def __init__(self, root: Path, state: WatcherState):\n        self.root = root\n        self.state = state\n        self.pending_files: Set[Path] = set()\n        self.last_change_time: float = 0\n        self.file_hashes: Dict[str, str] = {}\n\n    def on_modified(self, path: Path):\n        \"\"\"Handle file modification.\"\"\"\n        if not path.suffix == '.py':\n            return\n\n        # Check if file actually changed (not just touched)\n        current_hash = self._get_file_hash(path)\n        if self.file_hashes.get(str(path)) == current_hash:\n            return\n\n        self.file_hashes[str(path)] = current_hash\n        self.pending_files.add(path)\n        self.last_change_time = time.time()\n\n    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n            return \"\"\n\n    def process_pending(self) -> int:\n        \"\"\"Process ", "chunk_type": "file", "line_start": 1, "line_end": 291, "language": "python", "name": "watcher.py"}, "3976aafea7a2_func_poll_watch": {"id": "3976aafea7a2_func_poll_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "def poll_watch(root: Path, state: WatcherState):\n    \"\"\"Polling-based file watcher (fallback).\"\"\"\n    handler = CodeChangeHandler(root, state)\n    last_save = time.time()\n\n    # Initial scan\n    Console.info(\"Initial file scan...\")\n    for path in find_python_files(root):\n        handler.file_hashes[str(path)] = handler._get_file_hash(path)\n    Console.ok(f\"Tracking {len(handler.file_hashes)} files\")\n\n    Console.info(f\"Watching {root} (polling mode)...\")\n    Console.info(\"Press Ctrl+C to stop\")\n\n    while state.running:\n        # Check for changes\n        for path in find_python_files(root):\n            current_hash = handler._get_file_hash(path)\n            if handler.file_hashes.get(str(path)) != current_hash:\n                handler.on_modified(path)\n\n        # Process pending\n        handler.process_pending()\n\n        # Periodic save\n        if time.time() - last_save > state.save_interval_s:\n            last_save = time.time()\n\n        time.sleep(1)", "chunk_type": "function", "line_start": 120, "line_end": 148, "language": "python", "name": "poll_watch"}, "3976aafea7a2_func_watchdog_watch": {"id": "3976aafea7a2_func_watchdog_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "def watchdog_watch(root: Path, state: WatcherState):\n    \"\"\"Watchdog-based efficient file watching.\"\"\"\n    handler = CodeChangeHandler(root, state)\n    watchdog_handler = WatchdogHandler(handler)\n\n    observer = Observer()\n    observer.schedule(watchdog_handler, str(root), recursive=True)\n    observer.start()\n\n    Console.info(f\"Watching {root} (watchdog mode)...\")\n    Console.info(\"Press Ctrl+C to stop\")\n\n    try:\n        while state.running:\n            handler.process_pending()\n            time.sleep(0.5)\n    finally:\n        observer.stop()\n        observer.join()", "chunk_type": "function", "line_start": 151, "line_end": 169, "language": "python", "name": "watchdog_watch"}, "3976aafea7a2_func_start_watch": {"id": "3976aafea7a2_func_start_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "def start_watch(root: Path = None, background: bool = False):\n    \"\"\"Start the file watcher.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    mcp_dir = root / '.mcp'\n    mcp_dir.mkdir(exist_ok=True)\n\n    state = WatcherState(\n        pid_file=mcp_dir / 'watcher.pid',\n        index_path=mcp_dir / 'vector_index',\n        running=True\n    )\n\n    # Check if already running\n    if state.pid_file.exists():\n        try:\n            pid = int(state.pid_file.read_text().strip())\n            # Check if process exists\n            os.kill(pid, 0)\n            Console.warn(f\"Watcher already running (PID {pid})\")\n            return 1\n        except (ProcessLookupError, ValueError):\n            state.pid_file.unlink()\n\n    # Write PID\n    state.pid_file.write_text(str(os.getpid()))\n\n    # Handle shutdown\n    def shutdown(signum, frame):\n        Console.info(\"Stopping watcher...\")\n        state.running = False\n        if state.pid_file.exists():\n            state.pid_file.unlink()\n\n    sign", "chunk_type": "function", "line_start": 172, "line_end": 219, "language": "python", "name": "start_watch"}, "3976aafea7a2_func_stop_watch": {"id": "3976aafea7a2_func_stop_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "def stop_watch(root: Path = None):\n    \"\"\"Stop the file watcher.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    pid_file = root / '.mcp' / 'watcher.pid'\n\n    if not pid_file.exists():\n        Console.warn(\"No watcher running\")\n        return 1\n\n    try:\n        pid = int(pid_file.read_text().strip())\n        os.kill(pid, signal.SIGTERM)\n        Console.ok(f\"Stopped watcher (PID {pid})\")\n        pid_file.unlink()\n        return 0\n    except ProcessLookupError:\n        Console.warn(\"Watcher process not found\")\n        pid_file.unlink()\n        return 1\n    except Exception as e:\n        Console.fail(f\"Could not stop watcher: {e}\")\n        return 1", "chunk_type": "function", "line_start": 222, "line_end": 243, "language": "python", "name": "stop_watch"}, "3976aafea7a2_func_get_watch_status": {"id": "3976aafea7a2_func_get_watch_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "def get_watch_status(root: Path = None) -> Optional[int]:\n    \"\"\"Get watcher PID if running.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    pid_file = root / '.mcp' / 'watcher.pid'\n\n    if not pid_file.exists():\n        return None\n\n    try:\n        pid = int(pid_file.read_text().strip())\n        os.kill(pid, 0)  # Check if process exists\n        return pid\n    except (ProcessLookupError, ValueError):\n        return None", "chunk_type": "function", "line_start": 246, "line_end": 259, "language": "python", "name": "get_watch_status"}, "3976aafea7a2_func_main": {"id": "3976aafea7a2_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"File Watcher\")\n\n    if WATCHDOG_AVAILABLE:\n        Console.ok(\"watchdog available (efficient mode)\")\n    else:\n        Console.warn(\"watchdog not installed, using polling\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if '--stop' in sys.argv:\n        return stop_watch()\n\n    if '--status' in sys.argv:\n        pid = get_watch_status()\n        if pid:\n            Console.ok(f\"Watcher running (PID {pid})\")\n        else:\n            Console.info(\"Watcher not running\")\n        return 0\n\n    # Start watching\n    path = Path(args[0]) if args else None\n    return start_watch(path)", "chunk_type": "function", "line_start": 262, "line_end": 286, "language": "python", "name": "main"}, "3976aafea7a2_func___init__": {"id": "3976aafea7a2_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "        def __init__(self, change_handler: CodeChangeHandler):\n            self.change_handler = change_handler", "chunk_type": "function", "line_start": 108, "line_end": 109, "language": "python", "name": "__init__"}, "3976aafea7a2_func_on_modified": {"id": "3976aafea7a2_func_on_modified", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "        def on_modified(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "function", "line_start": 111, "line_end": 113, "language": "python", "name": "on_modified"}, "3976aafea7a2_func__get_file_hash": {"id": "3976aafea7a2_func__get_file_hash", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n            return \"\"", "chunk_type": "function", "line_start": 68, "line_end": 74, "language": "python", "name": "_get_file_hash"}, "3976aafea7a2_func_process_pending": {"id": "3976aafea7a2_func_process_pending", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "    def process_pending(self) -> int:\n        \"\"\"Process pending files if debounce period passed.\"\"\"\n        if not self.pending_files:\n            return 0\n\n        # Check debounce\n        elapsed_ms = (time.time() - self.last_change_time) * 1000\n        if elapsed_ms < self.state.debounce_ms:\n            return 0\n\n        # Process files\n        files = list(self.pending_files)\n        self.pending_files.clear()\n\n        Console.info(f\"Updating index for {len(files)} files...\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(self.state.index_path)\n            store.load()\n            store.update(files)\n            Console.ok(f\"Index updated\")\n            return len(files)\n        except Exception as e:\n            Console.warn(f\"Index update failed: {e}\")\n            return 0", "chunk_type": "function", "line_start": 76, "line_end": 101, "language": "python", "name": "process_pending"}, "3976aafea7a2_func_shutdown": {"id": "3976aafea7a2_func_shutdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "    def shutdown(signum, frame):\n        Console.info(\"Stopping watcher...\")\n        state.running = False\n        if state.pid_file.exists():\n            state.pid_file.unlink()", "chunk_type": "function", "line_start": 200, "line_end": 204, "language": "python", "name": "shutdown"}, "3976aafea7a2_func_on_created": {"id": "3976aafea7a2_func_on_created", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "        def on_created(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "function", "line_start": 115, "line_end": 117, "language": "python", "name": "on_created"}, "3976aafea7a2_class_WatcherState": {"id": "3976aafea7a2_class_WatcherState", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "class WatcherState:\n    \"\"\"State of the file watcher.\"\"\"\n    pid_file: Path\n    index_path: Path\n    debounce_ms: int = 500\n    save_interval_s: int = 30\n    running: bool = False", "chunk_type": "class", "line_start": 35, "line_end": 41, "language": "python", "name": "WatcherState"}, "3976aafea7a2_class_CodeChangeHandler": {"id": "3976aafea7a2_class_CodeChangeHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "class CodeChangeHandler:\n    \"\"\"Handles file changes for indexing.\"\"\"\n\n    def __init__(self, root: Path, state: WatcherState):\n        self.root = root\n        self.state = state\n        self.pending_files: Set[Path] = set()\n        self.last_change_time: float = 0\n        self.file_hashes: Dict[str, str] = {}\n\n    def on_modified(self, path: Path):\n        \"\"\"Handle file modification.\"\"\"\n        if not path.suffix == '.py':\n            return\n\n        # Check if file actually changed (not just touched)\n        current_hash = self._get_file_hash(path)\n        if self.file_hashes.get(str(path)) == current_hash:\n            return\n\n        self.file_hashes[str(path)] = current_hash\n        self.pending_files.add(path)\n        self.last_change_time = time.time()\n\n    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n  ", "chunk_type": "class", "line_start": 44, "line_end": 101, "language": "python", "name": "CodeChangeHandler"}, "3976aafea7a2_class_WatchdogHandler": {"id": "3976aafea7a2_class_WatchdogHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\watcher.py", "content": "    class WatchdogHandler(FileSystemEventHandler):\n        \"\"\"Watchdog event handler.\"\"\"\n\n        def __init__(self, change_handler: CodeChangeHandler):\n            self.change_handler = change_handler\n\n        def on_modified(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))\n\n        def on_created(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "class", "line_start": 105, "line_end": 117, "language": "python", "name": "WatchdogHandler"}, "9add2409e992_file": {"id": "9add2409e992_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\scripts\\__init__.py", "content": "\"\"\"\nMCP Global Rules - Scripts Package\n==================================\nAI Agent Enhancement Tools for autonomous development.\n\"\"\"\n\nfrom .utils import (\n    FunctionInfo,\n    ClassInfo,\n    ModuleInfo,\n    GitCommit,\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    get_git_log,\n    get_changed_files,\n    get_staged_files,\n    format_as_json,\n    format_as_markdown_table,\n    record_to_memory,\n    Console\n)\n\n__version__ = \"2.0.0\"\n__all__ = [\n    'FunctionInfo',\n    'ClassInfo',\n    'ModuleInfo',\n    'GitCommit',\n    'find_python_files',\n    'find_project_root',\n    'parse_file',\n    'analyze_module',\n    'get_git_log',\n    'get_changed_files',\n    'get_staged_files',\n    'format_as_json',\n    'format_as_markdown_table',\n    'record_to_memory',\n    'Console'\n]\n", "chunk_type": "file", "line_start": 1, "line_end": 43, "language": "python", "name": "__init__.py"}, "fb5476268afd_file": {"id": "fb5476268afd_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "\"\"\"\nTests for MCP Global Rules Scripts\n==================================\nComprehensive test suite for all AI agent enhancement tools.\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport tempfile\n\nimport pytest\n\n# Create a sample Python file for testing\nSAMPLE_PYTHON_CODE = '''\n\"\"\"Sample module for testing.\"\"\"\n\nimport os\nimport sys\nfrom pathlib import Path\n\n\nclass SampleClass:\n    \"\"\"A sample class.\"\"\"\n\n    def __init__(self, name: str):\n        self.name = name\n\n    def get_name(self) -> str:\n        \"\"\"Get the name.\"\"\"\n        return self.name\n\n\ndef sample_function(arg1: str, arg2: int = 10) -> bool:\n    \"\"\"\n    Sample function with docstring.\n\n    Args:\n        arg1: First argument\n        arg2: Second argument\n\n    Returns:\n        True if successful\n    \"\"\"\n    return True\n\n\ndef undocumented_function(x, y):\n    # This function has no docstring\n    return x + y\n\n\nCONSTANT_VALUE = 42\nunused_variable = \"not used\"\n'''\n\nSAMPLE_CODE_NO_DOCS = '''\nimport json\n\nclass NoDocClass:\n    def __init__(self):\n        self.value = 1\n\n    def method(self):\n        return self.value\n\ndef no_doc_function():\n    return True\n'''\n\n\n@pytest.fixture\ndef temp_project():\n    \"\"\"Create a temporary project directory with sample files.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        project_dir = Path(tmpdir)\n\n        # Create sample files\n        (project_dir / \"sample.py\").write_text(SAMPLE_PYTHON_CODE)\n        (project_dir / \"no_docs.py\").write_text(SAMPLE_CODE_NO_DOCS)\n\n        # Create src directory\n        (project_dir / \"src\").mkdir()\n        (project_dir / \"src\" / \"__init__.py\").write_text(\"\")\n        (project_dir / \"src\" / \"module.py\").write_text(SAMPLE_PYTHON_CODE)\n\n        yield project_dir\n\n\nclass TestUtils:\n    \"\"\"Tests for utils.py module.\"\"\"\n\n    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >=", "chunk_type": "file", "line_start": 1, "line_end": 330, "language": "python", "name": "test_scripts.py"}, "fb5476268afd_func_temp_project": {"id": "fb5476268afd_func_temp_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "def temp_project():\n    \"\"\"Create a temporary project directory with sample files.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        project_dir = Path(tmpdir)\n\n        # Create sample files\n        (project_dir / \"sample.py\").write_text(SAMPLE_PYTHON_CODE)\n        (project_dir / \"no_docs.py\").write_text(SAMPLE_CODE_NO_DOCS)\n\n        # Create src directory\n        (project_dir / \"src\").mkdir()\n        (project_dir / \"src\" / \"__init__.py\").write_text(\"\")\n        (project_dir / \"src\" / \"module.py\").write_text(SAMPLE_PYTHON_CODE)\n\n        yield project_dir", "chunk_type": "function", "line_start": 72, "line_end": 86, "language": "python", "name": "temp_project"}, "fb5476268afd_func_test_find_python_files": {"id": "fb5476268afd_func_test_find_python_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >= 2:\n            raise AssertionError(\"Should have found at least 2 files\")\n        if not any(f.name == \"sample.py\" for f in files):\n            raise AssertionError(\"Should have found sample.py\")", "chunk_type": "function", "line_start": 92, "line_end": 100, "language": "python", "name": "test_find_python_files"}, "fb5476268afd_func_test_parse_file": {"id": "fb5476268afd_func_test_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_file(self, temp_project):\n        \"\"\"Test parsing Python file.\"\"\"\n        from scripts.utils import parse_file\n\n        tree = parse_file(temp_project / \"sample.py\")\n        if tree is None:\n            raise AssertionError(\"Tree should not be None\")", "chunk_type": "function", "line_start": 102, "line_end": 108, "language": "python", "name": "test_parse_file"}, "fb5476268afd_func_test_analyze_module": {"id": "fb5476268afd_func_test_analyze_module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_module(self, temp_project):\n        \"\"\"Test analyzing module.\"\"\"\n        from scripts.utils import analyze_module\n\n        info = analyze_module(temp_project / \"sample.py\")\n        if info is None:\n            raise AssertionError(\"Info should not be None\")\n        if not len(info.functions) >= 2:\n            raise AssertionError(\"Should identify at least 2 functions\")\n        if not len(info.classes) >= 1:\n            raise AssertionError(\"Should identify at least 1 class\")", "chunk_type": "function", "line_start": 110, "line_end": 120, "language": "python", "name": "test_analyze_module"}, "fb5476268afd_func_test_format_as_markdown_table": {"id": "fb5476268afd_func_test_format_as_markdown_table", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_as_markdown_table(self):\n        \"\"\"Test markdown table formatting.\"\"\"\n        from scripts.utils import format_as_markdown_table\n\n        table = format_as_markdown_table(\n            [\"Name\", \"Value\"],\n            [[\"foo\", \"bar\"], [\"baz\", \"qux\"]]\n        )\n        if \"Name\" not in table:\n            raise AssertionError(\"Table should contain header 'Name'\")\n        if \"foo\" not in table:\n            raise AssertionError(\"Table should contain value 'foo'\")", "chunk_type": "function", "line_start": 122, "line_end": 133, "language": "python", "name": "test_format_as_markdown_table"}, "fb5476268afd_func_test_detect_dead_code": {"id": "fb5476268afd_func_test_detect_dead_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_detect_dead_code(self, temp_project):\n        \"\"\"Test dead code detection.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not report.total_issues >= 0:\n            raise AssertionError(\"Total issues should be non-negative\")", "chunk_type": "function", "line_start": 139, "line_end": 147, "language": "python", "name": "test_detect_dead_code"}, "fb5476268afd_func_test_report_to_markdown": {"id": "fb5476268afd_func_test_report_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_report_to_markdown(self, temp_project):\n        \"\"\"Test report conversion to markdown.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        markdown = report.to_markdown()\n        if \"Dead Code Report\" not in markdown:\n            raise AssertionError(\"Markdown should contain 'Dead Code Report'\")", "chunk_type": "function", "line_start": 149, "line_end": 156, "language": "python", "name": "test_report_to_markdown"}, "fb5476268afd_func_test_analyze_file_for_docstrings": {"id": "fb5476268afd_func_test_analyze_file_for_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_file_for_docstrings(self, temp_project):\n        \"\"\"Test docstring analysis.\"\"\"\n        from scripts.auto_docs import analyze_file_for_docstrings\n\n        suggestions = analyze_file_for_docstrings(temp_project / \"no_docs.py\")\n        if not len(suggestions) >= 2:\n            raise AssertionError(\"Should find at least 2 suggestions\")", "chunk_type": "function", "line_start": 162, "line_end": 168, "language": "python", "name": "test_analyze_file_for_docstrings"}, "fb5476268afd_func_test_generate_function_docstring": {"id": "fb5476268afd_func_test_generate_function_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_generate_function_docstring(self):\n        \"\"\"Test docstring generation.\"\"\"\n        from scripts.auto_docs import generate_function_docstring\n        from scripts.utils import FunctionInfo\n        import ast\n\n        # Create a mock function node\n        code = \"def test_func(arg1: str, arg2: int) -> bool: pass\"\n        tree = ast.parse(code)\n        node = tree.body[0]\n\n        docstring = generate_function_docstring(node, \"    \")\n        if '\"\"\"' not in docstring:\n            raise AssertionError(\"Docstring should contain quotes\")\n        if 'Args:' not in docstring:\n            raise AssertionError(\"Docstring should contain Args section\")", "chunk_type": "function", "line_start": 170, "line_end": 185, "language": "python", "name": "test_generate_function_docstring"}, "fb5476268afd_func_test_generate_test_function": {"id": "fb5476268afd_func_test_generate_test_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_generate_test_function(self):\n        \"\"\"Test test function generation.\"\"\"\n        from scripts.auto_test import generate_test_function\n        from scripts.utils import FunctionInfo\n\n        func = FunctionInfo(\n            name=\"my_function\",\n            lineno=1,\n            end_lineno=10,\n            args=[\"arg1\", \"arg2\"],\n            arg_types={\"arg1\": \"str\", \"arg2\": \"int\"},\n            return_type=\"bool\",\n            docstring=\"Test function.\"\n        )\n\n        test_code = generate_test_function(func, \"mymodule\")\n        if \"def test_my_function\" not in test_code:\n            raise AssertionError(\"Should generate test function definition\")\n        if \"assert\" not in test_code:\n            raise AssertionError(\"Should contain assertion in generated code\")", "chunk_type": "function", "line_start": 191, "line_end": 210, "language": "python", "name": "test_generate_test_function"}, "fb5476268afd_func_test_summarize_codebase": {"id": "fb5476268afd_func_test_summarize_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_summarize_codebase(self, temp_project):\n        \"\"\"Test codebase summarization.\"\"\"\n        from scripts.summarize import summarize_codebase\n\n        summary = summarize_codebase(temp_project)\n        if not summary.total_files >= 2:\n            raise AssertionError(\"Should handle at least 2 files\")\n        if not summary.total_functions >= 2:\n            raise AssertionError(\"Should handle at least 2 functions\")", "chunk_type": "function", "line_start": 216, "line_end": 224, "language": "python", "name": "test_summarize_codebase"}, "fb5476268afd_func_test_format_summary_markdown": {"id": "fb5476268afd_func_test_format_summary_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_summary_markdown(self, temp_project):\n        \"\"\"Test summary markdown formatting.\"\"\"\n        from scripts.summarize import summarize_codebase, format_summary_markdown\n\n        summary = summarize_codebase(temp_project)\n        markdown = format_summary_markdown(summary)\n        if \"# Codebase Summary\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "function", "line_start": 226, "line_end": 233, "language": "python", "name": "test_format_summary_markdown"}, "fb5476268afd_func_test_parse_commit_message": {"id": "fb5476268afd_func_test_parse_commit_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_commit_message(self):\n        \"\"\"Test commit message parsing.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat(auth): add login functionality\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.commit_type != \"feat\":\n            raise AssertionError(\"Commit type should be feat\")\n        if entry.scope != \"auth\":\n            raise AssertionError(\"Scope should be auth\")\n        if \"login\" not in entry.description:\n            raise AssertionError(\"Description should contain login\")", "chunk_type": "function", "line_start": 239, "line_end": 251, "language": "python", "name": "test_parse_commit_message"}, "fb5476268afd_func_test_parse_commit_message_breaking": {"id": "fb5476268afd_func_test_parse_commit_message_breaking", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_commit_message_breaking(self):\n        \"\"\"Test breaking change detection.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat!: breaking change\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.breaking != True:\n            raise AssertionError(\"Should detect breaking change\")", "chunk_type": "function", "line_start": 253, "line_end": 261, "language": "python", "name": "test_parse_commit_message_breaking"}, "fb5476268afd_func_test_analyze_dependencies": {"id": "fb5476268afd_func_test_analyze_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_dependencies(self, temp_project):\n        \"\"\"Test dependency analysis.\"\"\"\n        from scripts.deps import analyze_dependencies\n\n        report = analyze_dependencies(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not len(report.modules) >= 2:\n            raise AssertionError(\"Should find at least 2 modules\")", "chunk_type": "function", "line_start": 267, "line_end": 275, "language": "python", "name": "test_analyze_dependencies"}, "fb5476268afd_func_test_format_report_markdown": {"id": "fb5476268afd_func_test_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_report_markdown(self, temp_project):\n        \"\"\"Test dependency report markdown.\"\"\"\n        from scripts.deps import analyze_dependencies, format_report_markdown\n\n        report = analyze_dependencies(temp_project)\n        markdown = format_report_markdown(report)\n        if \"# Dependency Analysis\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "function", "line_start": 277, "line_end": 284, "language": "python", "name": "test_format_report_markdown"}, "fb5476268afd_func_test_review_file": {"id": "fb5476268afd_func_test_review_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_review_file(self, temp_project):\n        \"\"\"Test file review.\"\"\"\n        from scripts.review import review_file\n\n        issues = review_file(temp_project / \"no_docs.py\")\n        if not len(issues) >= 1:\n            raise AssertionError(\"Should find missing docstrings\")", "chunk_type": "function", "line_start": 290, "line_end": 296, "language": "python", "name": "test_review_file"}, "fb5476268afd_func_test_review_project": {"id": "fb5476268afd_func_test_review_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_review_project(self, temp_project):\n        \"\"\"Test project review.\"\"\"\n        from scripts.review import review_project\n\n        report = review_project(temp_project)\n        if not report.files_reviewed >= 2:\n            raise AssertionError(\"Should review at least 2 files\")", "chunk_type": "function", "line_start": 298, "line_end": 304, "language": "python", "name": "test_review_project"}, "fb5476268afd_func_test_security_check": {"id": "fb5476268afd_func_test_security_check", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_security_check(self):\n        \"\"\"Test security issue detection.\"\"\"\n        from scripts.review import ReviewChecks\n        import ast\n\n        code = '''\ntest_val = \"mock\" + \"_\" + \"credential\"\neval(user_input)\n'''\n        tree = ast.parse(code)\n\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write(code)\n            f.flush()\n\n            issues = ReviewChecks.check_security_issues(Path(f.name), tree)\n            if not len(issues) >= 1:\n                raise AssertionError(\"Should find security issue\")\n\n            os.unlink(f.name)", "chunk_type": "function", "line_start": 306, "line_end": 325, "language": "python", "name": "test_security_check"}, "fb5476268afd_class_TestUtils": {"id": "fb5476268afd_class_TestUtils", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestUtils:\n    \"\"\"Tests for utils.py module.\"\"\"\n\n    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >= 2:\n            raise AssertionError(\"Should have found at least 2 files\")\n        if not any(f.name == \"sample.py\" for f in files):\n            raise AssertionError(\"Should have found sample.py\")\n\n    def test_parse_file(self, temp_project):\n        \"\"\"Test parsing Python file.\"\"\"\n        from scripts.utils import parse_file\n\n        tree = parse_file(temp_project / \"sample.py\")\n        if tree is None:\n            raise AssertionError(\"Tree should not be None\")\n\n    def test_analyze_module(self, temp_project):\n        \"\"\"Test analyzing module.\"\"\"\n        from scripts.utils import analyze_module\n\n        info = analyze_module(temp_project / \"sample.py\")\n        if info is None:\n            raise AssertionEr", "chunk_type": "class", "line_start": 89, "line_end": 133, "language": "python", "name": "TestUtils"}, "fb5476268afd_class_TestDeadCode": {"id": "fb5476268afd_class_TestDeadCode", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestDeadCode:\n    \"\"\"Tests for dead_code.py module.\"\"\"\n\n    def test_detect_dead_code(self, temp_project):\n        \"\"\"Test dead code detection.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not report.total_issues >= 0:\n            raise AssertionError(\"Total issues should be non-negative\")\n\n    def test_report_to_markdown(self, temp_project):\n        \"\"\"Test report conversion to markdown.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        markdown = report.to_markdown()\n        if \"Dead Code Report\" not in markdown:\n            raise AssertionError(\"Markdown should contain 'Dead Code Report'\")", "chunk_type": "class", "line_start": 136, "line_end": 156, "language": "python", "name": "TestDeadCode"}, "fb5476268afd_class_TestAutoDocs": {"id": "fb5476268afd_class_TestAutoDocs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestAutoDocs:\n    \"\"\"Tests for auto_docs.py module.\"\"\"\n\n    def test_analyze_file_for_docstrings(self, temp_project):\n        \"\"\"Test docstring analysis.\"\"\"\n        from scripts.auto_docs import analyze_file_for_docstrings\n\n        suggestions = analyze_file_for_docstrings(temp_project / \"no_docs.py\")\n        if not len(suggestions) >= 2:\n            raise AssertionError(\"Should find at least 2 suggestions\")\n\n    def test_generate_function_docstring(self):\n        \"\"\"Test docstring generation.\"\"\"\n        from scripts.auto_docs import generate_function_docstring\n        from scripts.utils import FunctionInfo\n        import ast\n\n        # Create a mock function node\n        code = \"def test_func(arg1: str, arg2: int) -> bool: pass\"\n        tree = ast.parse(code)\n        node = tree.body[0]\n\n        docstring = generate_function_docstring(node, \"    \")\n        if '\"\"\"' not in docstring:\n            raise AssertionError(\"Docstring should contain quotes\")\n        if 'Args:' not in doc", "chunk_type": "class", "line_start": 159, "line_end": 185, "language": "python", "name": "TestAutoDocs"}, "fb5476268afd_class_TestAutoTest": {"id": "fb5476268afd_class_TestAutoTest", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestAutoTest:\n    \"\"\"Tests for auto_test.py module.\"\"\"\n\n    def test_generate_test_function(self):\n        \"\"\"Test test function generation.\"\"\"\n        from scripts.auto_test import generate_test_function\n        from scripts.utils import FunctionInfo\n\n        func = FunctionInfo(\n            name=\"my_function\",\n            lineno=1,\n            end_lineno=10,\n            args=[\"arg1\", \"arg2\"],\n            arg_types={\"arg1\": \"str\", \"arg2\": \"int\"},\n            return_type=\"bool\",\n            docstring=\"Test function.\"\n        )\n\n        test_code = generate_test_function(func, \"mymodule\")\n        if \"def test_my_function\" not in test_code:\n            raise AssertionError(\"Should generate test function definition\")\n        if \"assert\" not in test_code:\n            raise AssertionError(\"Should contain assertion in generated code\")", "chunk_type": "class", "line_start": 188, "line_end": 210, "language": "python", "name": "TestAutoTest"}, "fb5476268afd_class_TestSummarize": {"id": "fb5476268afd_class_TestSummarize", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestSummarize:\n    \"\"\"Tests for summarize.py module.\"\"\"\n\n    def test_summarize_codebase(self, temp_project):\n        \"\"\"Test codebase summarization.\"\"\"\n        from scripts.summarize import summarize_codebase\n\n        summary = summarize_codebase(temp_project)\n        if not summary.total_files >= 2:\n            raise AssertionError(\"Should handle at least 2 files\")\n        if not summary.total_functions >= 2:\n            raise AssertionError(\"Should handle at least 2 functions\")\n\n    def test_format_summary_markdown(self, temp_project):\n        \"\"\"Test summary markdown formatting.\"\"\"\n        from scripts.summarize import summarize_codebase, format_summary_markdown\n\n        summary = summarize_codebase(temp_project)\n        markdown = format_summary_markdown(summary)\n        if \"# Codebase Summary\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "class", "line_start": 213, "line_end": 233, "language": "python", "name": "TestSummarize"}, "fb5476268afd_class_TestChangelog": {"id": "fb5476268afd_class_TestChangelog", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestChangelog:\n    \"\"\"Tests for changelog.py module.\"\"\"\n\n    def test_parse_commit_message(self):\n        \"\"\"Test commit message parsing.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat(auth): add login functionality\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.commit_type != \"feat\":\n            raise AssertionError(\"Commit type should be feat\")\n        if entry.scope != \"auth\":\n            raise AssertionError(\"Scope should be auth\")\n        if \"login\" not in entry.description:\n            raise AssertionError(\"Description should contain login\")\n\n    def test_parse_commit_message_breaking(self):\n        \"\"\"Test breaking change detection.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat!: breaking change\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entr", "chunk_type": "class", "line_start": 236, "line_end": 261, "language": "python", "name": "TestChangelog"}, "fb5476268afd_class_TestDeps": {"id": "fb5476268afd_class_TestDeps", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestDeps:\n    \"\"\"Tests for deps.py module.\"\"\"\n\n    def test_analyze_dependencies(self, temp_project):\n        \"\"\"Test dependency analysis.\"\"\"\n        from scripts.deps import analyze_dependencies\n\n        report = analyze_dependencies(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not len(report.modules) >= 2:\n            raise AssertionError(\"Should find at least 2 modules\")\n\n    def test_format_report_markdown(self, temp_project):\n        \"\"\"Test dependency report markdown.\"\"\"\n        from scripts.deps import analyze_dependencies, format_report_markdown\n\n        report = analyze_dependencies(temp_project)\n        markdown = format_report_markdown(report)\n        if \"# Dependency Analysis\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "class", "line_start": 264, "line_end": 284, "language": "python", "name": "TestDeps"}, "fb5476268afd_class_TestReview": {"id": "fb5476268afd_class_TestReview", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestReview:\n    \"\"\"Tests for review.py module.\"\"\"\n\n    def test_review_file(self, temp_project):\n        \"\"\"Test file review.\"\"\"\n        from scripts.review import review_file\n\n        issues = review_file(temp_project / \"no_docs.py\")\n        if not len(issues) >= 1:\n            raise AssertionError(\"Should find missing docstrings\")\n\n    def test_review_project(self, temp_project):\n        \"\"\"Test project review.\"\"\"\n        from scripts.review import review_project\n\n        report = review_project(temp_project)\n        if not report.files_reviewed >= 2:\n            raise AssertionError(\"Should review at least 2 files\")\n\n    def test_security_check(self):\n        \"\"\"Test security issue detection.\"\"\"\n        from scripts.review import ReviewChecks\n        import ast\n\n        code = '''\ntest_val = \"mock\" + \"_\" + \"credential\"\neval(user_input)\n'''\n        tree = ast.parse(code)\n\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write(co", "chunk_type": "class", "line_start": 287, "line_end": 325, "language": "python", "name": "TestReview"}, "47d54c6307ee_file": {"id": "47d54c6307ee_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global-rules\\tests\\__init__.py", "content": "\"\"\"Tests package.\"\"\"\n", "chunk_type": "file", "line_start": 1, "line_end": 2, "language": "python", "name": "__init__.py"}, "a28df67ef5eb_file": {"id": "a28df67ef5eb_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Agent Collaboration Layer (ACL)\nEnables secure, bidirectional communication and presence tracking between AI agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport socket\nimport sys\nimport time\n\n# Configuration - Shared with NSync\nWINDOWS_NSYNC = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\")\nLINUX_NSYNC = Path(\"/home/p4nd4pr0t0c01/Projects/NSync\")\n\ndef get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC\n\ndef get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir\n\ndef get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox\n\ndef get_hostname():\n    return socket.gethostname()\n\nclass AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.lo", "chunk_type": "file", "line_start": 1, "line_end": 216, "language": "python", "name": "agent_comms.py"}, "a28df67ef5eb_func_get_nsync_path": {"id": "a28df67ef5eb_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC", "chunk_type": "function", "line_start": 18, "line_end": 19, "language": "python", "name": "get_nsync_path"}, "a28df67ef5eb_func_get_comms_dir": {"id": "a28df67ef5eb_func_get_comms_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir", "chunk_type": "function", "line_start": 21, "line_end": 25, "language": "python", "name": "get_comms_dir"}, "a28df67ef5eb_func_get_mailbox_dir": {"id": "a28df67ef5eb_func_get_mailbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox", "chunk_type": "function", "line_start": 27, "line_end": 31, "language": "python", "name": "get_mailbox_dir"}, "a28df67ef5eb_func_get_hostname": {"id": "a28df67ef5eb_func_get_hostname", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def get_hostname():\n    return socket.gethostname()", "chunk_type": "function", "line_start": 33, "line_end": 34, "language": "python", "name": "get_hostname"}, "a28df67ef5eb_func_send_message": {"id": "a28df67ef5eb_func_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def send_message(recipient: str, msg_type: str, content: dict):\n    \"\"\"Sends an encrypted-in-transit message via NSync mailbox.\"\"\"\n    mailbox = get_mailbox_dir()\n    msg_id = int(time.time() * 1000)\n    msg_file = mailbox / f\"{recipient}_{get_hostname()}_{msg_id}.json\"\n\n    payload = {\n        \"id\": msg_id,\n        \"from\": get_hostname(),\n        \"to\": recipient,\n        \"type\": msg_type,\n        \"content\": content,\n        \"timestamp\": time.time()\n    }\n\n    with open(msg_file, \"w\") as f:\n        json.dump(payload, f, indent=2)\n    print(f\"[COMMS] Message sent to {recipient}: {msg_type}\")\n\n    # Trigger NSync to propagate the message\n    try:\n        mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n        subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n    except:\n        pass\n    return msg_file", "chunk_type": "function", "line_start": 72, "line_end": 97, "language": "python", "name": "send_message"}, "a28df67ef5eb_func_listen_for_messages": {"id": "a28df67ef5eb_func_listen_for_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def listen_for_messages():\n    \"\"\"Polls for messages addressed to this host.\"\"\"\n    mailbox = get_mailbox_dir()\n    hostname = get_hostname()\n\n    messages = []\n    for f in mailbox.glob(f\"{hostname}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            # Mark as read/processed by deleting\n            f.unlink()\n        except Exception as e:\n            print(f\"[WARN] Failed to read message {f}: {e}\")\n\n    return messages", "chunk_type": "function", "line_start": 99, "line_end": 115, "language": "python", "name": "listen_for_messages"}, "a28df67ef5eb_func_show_status": {"id": "a28df67ef5eb_func_show_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def show_status():\n    \"\"\"Displays local and remote agent status.\"\"\"\n    local = AgentPresence.update()\n    print(\"--- Local Agent Priority ---\")\n    print(f\"Host:   {local['hostname']}\")\n    print(f\"Status: {local['status']}\")\n    print(f\"Task:   {local['current_task']}\")\n    print(f\"Sync:   {local['last_seen']}\")\n\n    print(\"\\n--- Remote Agents ---\")\n    remotes = AgentPresence.get_remote_status()\n    if not remotes:\n        print(\"No remote agents detected yet.\")\n    for host, data in remotes.items():\n        age = time.time() - data['timestamp']\n        active_str = \"[ACTIVE]\" if age < 60 else \"[OFFLINE/STALE]\"\n        print(f\"Host:   {host} {active_str}\")\n        print(f\"Status: {data['status']}\")\n        print(f\"Task:   {data['current_task']}\")\n        print(f\"Last heartbeat: {int(age)}s ago\")\n        print(\"-\" * 20)", "chunk_type": "function", "line_start": 117, "line_end": 137, "language": "python", "name": "show_status"}, "a28df67ef5eb_func_show_help": {"id": "a28df67ef5eb_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def show_help():\n    print(\"MCP Agent Collaboration Layer (ACL)\")\n    print(\"Usage: mcp comms <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  status                Check local and remote agent presence\")\n    print(\"  send <host> <type> <msg> Send a message to a specific agent\")\n    print(\"  listen                Poll and display unread messages\")\n    print(\"  ping <host>           Quick verification of remote agent life\")\n    print(\"  heartbeat <status> <task> Update local presence info\")\n    print(\"  collaborate           Enter autonomous agent-to-agent team mode\")", "chunk_type": "function", "line_start": 139, "line_end": 148, "language": "python", "name": "show_help"}, "a28df67ef5eb_func_autonomous_loop": {"id": "a28df67ef5eb_func_autonomous_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def autonomous_loop():\n    \"\"\"Autonomous execution loop for AI agents.\"\"\"\n    hostname = get_hostname()\n    print(f\"[AUTONOMOUS] Agent {hostname} entered collaboration mode.\")\n    AgentPresence.update(\"active\", \"autonomous collaboration\")\n\n    try:\n        while True:\n            msgs = listen_for_messages()\n            for m in msgs:\n                print(f\"\\n[RECEIVED] From: {m['from']} | Type: {m['type']}\")\n                print(f\"Content: {m['content']}\")\n\n                # If it's a task, execute it and report back\n                if m['type'] == \"task\" or m['type'] == \"instruction\":\n                    task_text = m['content'].get('text', '')\n                    print(f\"[EXEC] Starting task: {task_text}\")\n                    # In a real scenario, the agent would use the LLM to process this.\n                    # For now, we simulate acknowledgment.\n                    send_message(m['from'], \"ack\", {\"text\": f\"Task received and processing: {task_text}\"})\n\n            time.sleep(5)", "chunk_type": "function", "line_start": 150, "line_end": 175, "language": "python", "name": "autonomous_loop"}, "a28df67ef5eb_func_main": {"id": "a28df67ef5eb_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"status\":\n        show_status()\n    elif cmd == \"send\" and len(args) >= 3:\n        send_message(args[0], args[1], {\"text\": \" \".join(args[2:])})\n    elif cmd == \"listen\":\n        msgs = listen_for_messages()\n        if not msgs:\n            print(\"No new messages.\")\n        for m in msgs:\n            print(f\"\\n[FROM: {m['from']}] [TYPE: {m['type']}]\")\n            print(f\"Content: {m['content']}\")\n    elif cmd == \"ping\" and args:\n        remotes = AgentPresence.get_remote_status()\n        if args[0] in remotes:\n            age = time.time() - remotes[args[0]]['timestamp']\n            if age < 60:\n                print(f\"[OK] {args[0]} is ALIVE (Age: {int(age)}s)\")\n                return 0\n        print(f\"[FAIL] {args[0]} is UNREACHABLE or STALE\")\n        return 1\n    elif cmd == \"heartbeat\" and len(args) >= 2:\n        AgentPresence.update(args[0], args[", "chunk_type": "function", "line_start": 177, "line_end": 212, "language": "python", "name": "main"}, "a28df67ef5eb_func_update": {"id": "a28df67ef5eb_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data", "chunk_type": "function", "line_start": 39, "line_end": 57, "language": "python", "name": "update"}, "a28df67ef5eb_func_get_remote_status": {"id": "a28df67ef5eb_func_get_remote_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.load(pf)\n                except:\n                    pass\n        return remote_status", "chunk_type": "function", "line_start": 60, "line_end": 70, "language": "python", "name": "get_remote_status"}, "a28df67ef5eb_class_AgentPresence": {"id": "a28df67ef5eb_class_AgentPresence", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\agent_comms.py", "content": "class AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n       ", "chunk_type": "class", "line_start": 36, "line_end": 70, "language": "python", "name": "AgentPresence"}, "0b70ee90005f_file": {"id": "0b70ee90005f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\mcp.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Tools Runner\n================\nSingle entry point for all MCP AI enhancement tools.\n\nWorks correctly regardless of:\n- How it's invoked (relative path, absolute path, symlink)\n- Current working directory\n- Installation location in project\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\nimport importlib\n\n# =============================================================================\n# CRITICAL: Resolve the ACTUAL location of this script\n# =============================================================================\n\ndef get_package_root():\n    \"\"\"\n    Get the absolute path to the mcp-global-rules directory.\n    Handles symlinks, relative paths, and various invocation methods.\n    \"\"\"\n    # Method 1: Use __file__ (works in most cases)\n    if '__file__' in dir():\n        script_path = Path(__file__).resolve()\n        return script_path.parent\n\n    # Method 2: Use sys.argv[0] (when __file__ isn't available)\n    if sys.argv:\n        script_path = Path(sys.argv[0]).resolve()\n        if script_path.name == 'mcp.py':\n            return script_path.parent\n\n    # Method 3: Search common locations\n    cwd = Path.cwd()\n\n    # Check if mcp-global-rules is in current directory\n    if (cwd / 'mcp-global-rules' / 'mcp.py').exists():\n        return cwd / 'mcp-global-rules'\n\n    # Check if we're inside mcp-global-rules\n    if (cwd / 'mcp.py').exists() and (cwd / 'scripts').exists():\n        return cwd\n\n    # Check parent directories\n    for parent in cwd.parents:\n        if (parent / 'mcp-global-rules' / 'mcp.py').exists():\n            return parent / 'mcp-global-rules'\n\n    return None\n\n\n# Get MCP root and add to path\nMCP_ROOT = get_package_root()\n\nif MCP_ROOT is None:\n    print(\"[FAIL] Cannot find mcp-global-rules directory\")\n    print(\"Make sure you're running from a project with mcp-global-rules installed\")\n    sys.exit(1)\n\n# Add MCP root to path for imports\nif str(MCP_ROOT) not in sys.path:\n    sys.path.insert(0, str(MCP_ROOT))\n\n# Sto", "chunk_type": "file", "line_start": 1, "line_end": 252, "language": "python", "name": "mcp.py"}, "0b70ee90005f_func_get_package_root": {"id": "0b70ee90005f_func_get_package_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\mcp.py", "content": "def get_package_root():\n    \"\"\"\n    Get the absolute path to the mcp-global-rules directory.\n    Handles symlinks, relative paths, and various invocation methods.\n    \"\"\"\n    # Method 1: Use __file__ (works in most cases)\n    if '__file__' in dir():\n        script_path = Path(__file__).resolve()\n        return script_path.parent\n\n    # Method 2: Use sys.argv[0] (when __file__ isn't available)\n    if sys.argv:\n        script_path = Path(sys.argv[0]).resolve()\n        if script_path.name == 'mcp.py':\n            return script_path.parent\n\n    # Method 3: Search common locations\n    cwd = Path.cwd()\n\n    # Check if mcp-global-rules is in current directory\n    if (cwd / 'mcp-global-rules' / 'mcp.py').exists():\n        return cwd / 'mcp-global-rules'\n\n    # Check if we're inside mcp-global-rules\n    if (cwd / 'mcp.py').exists() and (cwd / 'scripts').exists():\n        return cwd\n\n    # Check parent directories\n    for parent in cwd.parents:\n        if (parent / 'mcp-global-rules' / 'mcp.py')", "chunk_type": "function", "line_start": 24, "line_end": 56, "language": "python", "name": "get_package_root"}, "0b70ee90005f_func_show_help": {"id": "0b70ee90005f_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\mcp.py", "content": "def show_help():\n    \"\"\"Show help message.\"\"\"\n    print(\"\"\"\nMCP AI Enhancement Tools (48 Commands)\n=======================================\n\nUsage: python3 mcp-global-rules/mcp.py <command> [args...]\n\nCode Quality:\n    review [path] [--strict]    Code review automation\n    docs [path] [--write]       Generate missing docstrings\n    test [path]                 Generate pytest test stubs\n    deadcode [path]             Find unused code\n    fix [path] [--safe --apply] Auto-fix issues\n\nAnalysis:\n    deps [path]                 Dependency analysis\n    profile [path]              Performance/complexity\n    security [path]             Security audit\n    errors [path]               Error handling\n    architecture [path]         Architecture validation\n\nIntelligence:\n    context \"query\" [path]      Smart context extraction\n    find \"query\" [path]         Natural language search\n    refactor [path]             Suggest refactorings\n\nIndexes:\n    index-all                   Full reindex (all 7)\n   ", "chunk_type": "function", "line_start": 75, "line_end": 137, "language": "python", "name": "show_help"}, "0b70ee90005f_func_main": {"id": "0b70ee90005f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\mcp.py", "content": "def main():\n    \"\"\"Main entry point.\"\"\"\n    if len(sys.argv) < 2 or sys.argv[1] in ('help', '-h', '--help'):\n        show_help()\n        return 0\n\n    command = sys.argv[1]\n    args = sys.argv[2:]\n\n    if command not in COMMANDS:\n        print(f\"[FAIL] Unknown command: {command}\")\n        show_help()\n        return 1\n\n    module_name = COMMANDS[command]\n\n    try:\n        # Import the module\n        module = importlib.import_module(f'scripts.{module_name}')\n\n        # Update sys.argv for the module\n        sys.argv = [f'scripts/{module_name}.py'] + args\n\n        if hasattr(module, 'main'):\n            return module.main() or 0\n        else:\n            print(f\"[FAIL] Module {module_name} has no main function\")\n            return 1\n\n    except ImportError as e:\n        print(f\"[FAIL] Could not import {module_name}: {e}\")\n        print(f\"MCP_ROOT: {MCP_ROOT}\")\n        print(f\"sys.path: {sys.path[:3]}\")\n        return 1\n    except Exception as e:\n        print(f\"[FAIL] Error running {comma", "chunk_type": "function", "line_start": 209, "line_end": 247, "language": "python", "name": "main"}, "583a1d190429_file": {"id": "583a1d190429_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Model Priority Manager\nManages model selection based on user preference and availability.\nPriority 1: Gemini 3 Flash\nPriority 2: Claude Opus (Latest/4.5 Thinking)\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\n# Configuration Path\nCONFIG_PATH = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules/model_preferences.json\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules/model_preferences.json\")\n\nDEFAULT_PRIORITY = [\n    \"Gemini 3 Flash\",\n    \"Claude Opus (4.5 Thinking)\",\n    \"GPT-4o\"\n]\n\ndef get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n\ndef save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)\n\ndef get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])\n\ndef switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]\n\ndef main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n", "chunk_type": "file", "line_start": 1, "line_end": 73, "language": "python", "name": "model_manager.py"}, "583a1d190429_func_get_preferences": {"id": "583a1d190429_func_get_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}", "chunk_type": "function", "line_start": 23, "line_end": 27, "language": "python", "name": "get_preferences"}, "583a1d190429_func_save_preferences": {"id": "583a1d190429_func_save_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)", "chunk_type": "function", "line_start": 29, "line_end": 31, "language": "python", "name": "save_preferences"}, "583a1d190429_func_get_current_model": {"id": "583a1d190429_func_get_current_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])", "chunk_type": "function", "line_start": 33, "line_end": 35, "language": "python", "name": "get_current_model"}, "583a1d190429_func_switch_model": {"id": "583a1d190429_func_switch_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]", "chunk_type": "function", "line_start": 37, "line_end": 52, "language": "python", "name": "switch_model"}, "583a1d190429_func_main": {"id": "583a1d190429_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\model_manager.py", "content": "def main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n        save_preferences(prefs)\n        print(\"[MODEL] Preferences reset to defaults.\")\n    return 0", "chunk_type": "function", "line_start": 54, "line_end": 69, "language": "python", "name": "main"}, "7b8554cacf46_file": {"id": "7b8554cacf46_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\config\\loop_config.py", "content": "\"\"\"\nAuto-Dev Loop Configuration\n===========================\nWARNING: THIS FILE CONTROLS AN INFINITE AUTONOMOUS LOOP.\n\nRules:\n1. ONLY the USER is allowed to change this file.\n2. AI Agents must NEVER modify this file.\n3. If set to True, the system will trigger a new development cycle after every commit.\n\nTo stop the loop, set ENABLE_AUTO_LOOP = False manually.\n\"\"\"\n\n# START USER CONFIGURATION\nENABLE_AUTO_LOOP = True\n# END USER CONFIGURATION\n", "chunk_type": "file", "line_start": 1, "line_end": 17, "language": "python", "name": "loop_config.py"}, "33f43d92f80a_file": {"id": "33f43d92f80a_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\config\\__init__.py", "content": "\"\"\"\nConfiguration Package\n=====================\n\"\"\"\n", "chunk_type": "file", "line_start": 1, "line_end": 5, "language": "python", "name": "__init__.py"}, "432dab03ba52_file": {"id": "432dab03ba52_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Agent Collaboration Layer (ACL)\nEnables secure, bidirectional communication and presence tracking between AI agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport socket\nimport subprocess\nimport sys\nimport time\n\n# Configuration - Shared with NSync\nWINDOWS_NSYNC = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/NSync\")\nLINUX_NSYNC = Path(\"/home/p4nd4pr0t0c01/Projects/NSync\")\n\ndef get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC\n\ndef get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir\n\ndef get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox\n\ndef get_telegram_inbox_dir() -> Path:\n    inbox = get_comms_dir() / \"telegram_inbox\"\n    if not inbox.exists():\n        inbox.mkdir(parents=True, exist_ok=True)\n    return inbox\n\ndef get_hostname():\n    # Allow override for specifically identifying the IDE agent session\n    identity = os.environ.get(\"AGENT_IDENTITY\")\n    if identity:\n        return identity\n    return socket.gethostname()\n\nclass AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        exc", "chunk_type": "file", "line_start": 1, "line_end": 364, "language": "python", "name": "agent_comms.py"}, "432dab03ba52_func_get_nsync_path": {"id": "432dab03ba52_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_nsync_path() -> Path:\n    return WINDOWS_NSYNC if os.name == 'nt' else LINUX_NSYNC", "chunk_type": "function", "line_start": 19, "line_end": 20, "language": "python", "name": "get_nsync_path"}, "432dab03ba52_func_get_comms_dir": {"id": "432dab03ba52_func_get_comms_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_comms_dir() -> Path:\n    comms_dir = get_nsync_path() / \".nsync_agents\"\n    if not comms_dir.exists():\n        comms_dir.mkdir(parents=True, exist_ok=True)\n    return comms_dir", "chunk_type": "function", "line_start": 22, "line_end": 26, "language": "python", "name": "get_comms_dir"}, "432dab03ba52_func_get_mailbox_dir": {"id": "432dab03ba52_func_get_mailbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_mailbox_dir() -> Path:\n    mailbox = get_comms_dir() / \"messages\"\n    if not mailbox.exists():\n        mailbox.mkdir(parents=True, exist_ok=True)\n    return mailbox", "chunk_type": "function", "line_start": 28, "line_end": 32, "language": "python", "name": "get_mailbox_dir"}, "432dab03ba52_func_get_telegram_inbox_dir": {"id": "432dab03ba52_func_get_telegram_inbox_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_telegram_inbox_dir() -> Path:\n    inbox = get_comms_dir() / \"telegram_inbox\"\n    if not inbox.exists():\n        inbox.mkdir(parents=True, exist_ok=True)\n    return inbox", "chunk_type": "function", "line_start": 34, "line_end": 38, "language": "python", "name": "get_telegram_inbox_dir"}, "432dab03ba52_func_get_hostname": {"id": "432dab03ba52_func_get_hostname", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def get_hostname():\n    # Allow override for specifically identifying the IDE agent session\n    identity = os.environ.get(\"AGENT_IDENTITY\")\n    if identity:\n        return identity\n    return socket.gethostname()", "chunk_type": "function", "line_start": 40, "line_end": 45, "language": "python", "name": "get_hostname"}, "432dab03ba52_func_send_message": {"id": "432dab03ba52_func_send_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def send_message(recipient: str, msg_type: str, content: dict):\n    \"\"\"Sends an encrypted-in-transit message via NSync mailbox.\"\"\"\n    mailbox = get_mailbox_dir()\n    msg_id = int(time.time() * 1000)\n    msg_file = mailbox / f\"{recipient}_{get_hostname()}_{msg_id}.json\"\n\n    payload = {\n        \"id\": msg_id,\n        \"from\": get_hostname(),\n        \"to\": recipient,\n        \"type\": msg_type,\n        \"content\": content,\n        \"timestamp\": time.time()\n    }\n\n    with open(msg_file, \"w\") as f:\n        json.dump(payload, f, indent=2)\n    print(f\"[COMMS] Message sent to {recipient}: {msg_type}\")\n\n    # Trigger NSync to propagate the message\n    try:\n        mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n        subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n    except:\n        pass\n    return msg_file", "chunk_type": "function", "line_start": 83, "line_end": 108, "language": "python", "name": "send_message"}, "432dab03ba52_func_listen_for_messages": {"id": "432dab03ba52_func_listen_for_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def listen_for_messages():\n    \"\"\"Polls for messages addressed to this host.\"\"\"\n    mailbox = get_mailbox_dir()\n    hostname = get_hostname()\n\n    messages = []\n    for f in mailbox.glob(f\"{hostname}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            # Mark as read/processed by deleting\n            f.unlink()\n        except Exception as e:\n            print(f\"[WARN] Failed to read message {f}: {e}\")\n\n    return messages", "chunk_type": "function", "line_start": 110, "line_end": 126, "language": "python", "name": "listen_for_messages"}, "432dab03ba52_func_listen_for_telegram_messages": {"id": "432dab03ba52_func_listen_for_telegram_messages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def listen_for_telegram_messages():\n    \"\"\"Polls for Telegram messages. Background agents wait for Antigravity priority.\"\"\"\n    inbox = get_telegram_inbox_dir()\n    hostname = get_hostname()\n    agent_identity = os.getenv(\"AGENT_IDENTITY\", hostname)  # Use AGENT_IDENTITY if set, else hostname\n\n    messages = []\n\n    # Priority 1: Messages directly for me (based on AGENT_IDENTITY)\n    for f in inbox.glob(f\"{agent_identity}_*.json\"):\n        try:\n            with open(f, \"r\") as mf:\n                msg = json.load(mf)\n                messages.append(msg)\n            f.unlink()\n        except: pass\n\n    # Skip fallback logic if I AM Antigravity (I already checked)\n    if agent_identity.lower() == \"antigravity\":\n        return messages\n\n    # Priority 2: Fallback for Antigravity (Background Agents only)\n    # Background agents (Quasar/wizardpanda) only take Antigravity messages if stale\n    for f in inbox.glob(\"Antigravity_*.json\"):\n        try:\n            # Check how old the message is\n ", "chunk_type": "function", "line_start": 128, "line_end": 181, "language": "python", "name": "listen_for_telegram_messages"}, "432dab03ba52_func_notify_user_telegram": {"id": "432dab03ba52_func_notify_user_telegram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def notify_user_telegram(text: str):\n    \"\"\"Sends a notification back to the user via the Telegram Bridge.\"\"\"\n    # The bridge will watch this directory for outgoing alerts\n    outbox = get_comms_dir() / \"telegram_outbox\"\n    if not outbox.exists():\n        outbox.mkdir(parents=True, exist_ok=True)\n\n    msg_id = int(time.time() * 1000)\n    msg_file = outbox / f\"out_{msg_id}.json\"\n\n    with open(msg_file, \"w\") as f:\n        json.dump({\"text\": text, \"from\": get_hostname(), \"timestamp\": time.time()}, f, indent=2)\n    print(f\"[COMMS] Notification queued for Telegram: {text[:50]}...\")", "chunk_type": "function", "line_start": 183, "line_end": 195, "language": "python", "name": "notify_user_telegram"}, "432dab03ba52_func_show_status": {"id": "432dab03ba52_func_show_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def show_status():\n    \"\"\"Displays local and remote agent status.\"\"\"\n    hostname = get_hostname()\n    presence_file = get_comms_dir() / f\"{hostname}.json\"\n    local = {}\n    if presence_file.exists():\n        with open(presence_file, \"r\") as f:\n            local = json.load(f)\n    else:\n        local = AgentPresence.update() # Create if missing\n\n    print(\"--- Local Agent Priority ---\")\n    print(f\"Host:   {local.get('hostname', hostname)}\")\n    print(f\"Status: {local.get('status', 'unknown')}\")\n    print(f\"Task:   {local.get('current_task', 'unknown')}\")\n    print(f\"Sync:   {local.get('last_seen', 'unknown')}\")\n\n    print(\"\\n--- Remote Agents ---\")\n    remotes = AgentPresence.get_remote_status()\n    if not remotes:\n        print(\"No remote agents detected yet.\")\n    for host, data in remotes.items():\n        age = time.time() - data['timestamp']\n        active_str = \"[ACTIVE]\" if age < 60 else \"[OFFLINE/STALE]\"\n        print(f\"Host:   {host} {active_str}\")\n        print(f\"Status: {da", "chunk_type": "function", "line_start": 197, "line_end": 225, "language": "python", "name": "show_status"}, "432dab03ba52_func_show_help": {"id": "432dab03ba52_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def show_help():\n    print(\"MCP Agent Collaboration Layer (ACL)\")\n    print(\"Usage: mcp comms <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  status                Check local and remote agent presence\")\n    print(\"  send <host> <type> <msg> Send a message to a specific agent\")\n    print(\"  listen                Poll and display unread messages\")\n    print(\"  ping <host>           Quick verification of remote agent life\")\n    print(\"  heartbeat <status> <task> Update local presence info\")\n    print(\"  collaborate           Enter autonomous agent-to-agent team mode\")", "chunk_type": "function", "line_start": 227, "line_end": 236, "language": "python", "name": "show_help"}, "432dab03ba52_func_handle_telegram_instruction": {"id": "432dab03ba52_func_handle_telegram_instruction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def handle_telegram_instruction(text):\n    \"\"\"Parses telegram text and tries to execute as an MCP command or route to Antigravity.\"\"\"\n    print(f\"[EXEC] Parsing Telegram Task: {text}\")\n\n    # Check if this is the \"Antigravity\" agent (IDE session)\n    # If so, send to Antigravity automation instead of running MCP commands\n    hostname = get_hostname().lower()\n    agent_identity = os.getenv(\"AGENT_IDENTITY\", \"\").lower()\n\n    # Route to Antigravity IDE automation if AGENT_IDENTITY is set to \"Antigravity\"\n    if agent_identity == \"antigravity\":\n        try:\n            # Import antigravity automation module\n            antigravity_path = Path(__file__).resolve().parent / \"antigravity_automation.py\"\n            if antigravity_path.exists():\n                import importlib.util\n                spec = importlib.util.spec_from_file_location(\"antigravity_automation\", antigravity_path)\n                ag_module = importlib.util.module_from_spec(spec)\n                spec.loader.exec_module(ag_m", "chunk_type": "function", "line_start": 238, "line_end": 294, "language": "python", "name": "handle_telegram_instruction"}, "432dab03ba52_func_autonomous_loop": {"id": "432dab03ba52_func_autonomous_loop", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def autonomous_loop():\n    \"\"\"Autonomous execution loop for AI agents.\"\"\"\n    hostname = get_hostname()\n    print(f\"[AUTONOMOUS] Agent {hostname} entered collaboration mode.\")\n    AgentPresence.update(\"active\", \"autonomous collaboration\")\n\n    try:\n        while True:\n            msgs = listen_for_messages()\n            for m in msgs:\n                print(f\"\\n[RECEIVED] From: {m['from']} | Type: {m['type']}\")\n                if m['type'] == \"task\" or m['type'] == \"instruction\":\n                    task_text = m['content'].get('text', '')\n                    result = handle_telegram_instruction(task_text)\n                    send_message(m['from'], \"result\", {\"text\": result})\n\n            # Check for Telegram instructions\n            t_msgs = listen_for_telegram_messages()\n            for tm in t_msgs:\n                print(f\"\\n[TELEGRAM] Instruction received: {tm['text']}\")\n                result = handle_telegram_instruction(tm['text'])\n                notify_user_telegram(f\"Result f", "chunk_type": "function", "line_start": 296, "line_end": 323, "language": "python", "name": "autonomous_loop"}, "432dab03ba52_func_main": {"id": "432dab03ba52_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"status\":\n        show_status()\n    elif cmd == \"send\" and len(args) >= 3:\n        send_message(args[0], args[1], {\"text\": \" \".join(args[2:])})\n    elif cmd == \"listen\":\n        msgs = listen_for_messages()\n        if not msgs:\n            print(\"No new messages.\")\n        for m in msgs:\n            print(f\"\\n[FROM: {m['from']}] [TYPE: {m['type']}]\")\n            print(f\"Content: {m['content']}\")\n    elif cmd == \"ping\" and args:\n        remotes = AgentPresence.get_remote_status()\n        if args[0] in remotes:\n            age = time.time() - remotes[args[0]]['timestamp']\n            if age < 60:\n                print(f\"[OK] {args[0]} is ALIVE (Age: {int(age)}s)\")\n                return 0\n        print(f\"[FAIL] {args[0]} is UNREACHABLE or STALE\")\n        return 1\n    elif cmd == \"heartbeat\" and len(args) >= 2:\n        AgentPresence.update(args[0], args[", "chunk_type": "function", "line_start": 325, "line_end": 360, "language": "python", "name": "main"}, "432dab03ba52_func_update": {"id": "432dab03ba52_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data", "chunk_type": "function", "line_start": 50, "line_end": 68, "language": "python", "name": "update"}, "432dab03ba52_func_get_remote_status": {"id": "432dab03ba52_func_get_remote_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n                    with open(f, \"r\") as pf:\n                        remote_status[f.stem] = json.load(pf)\n                except:\n                    pass\n        return remote_status", "chunk_type": "function", "line_start": 71, "line_end": 81, "language": "python", "name": "get_remote_status"}, "432dab03ba52_class_AgentPresence": {"id": "432dab03ba52_class_AgentPresence", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_comms.py", "content": "class AgentPresence:\n    \"\"\"Manages local agent presence and heartbeats.\"\"\"\n    @staticmethod\n    def update(status=\"active\", task=\"monitoring\"):\n        presence_file = get_comms_dir() / f\"{get_hostname()}.json\"\n        data = {\n            \"hostname\": get_hostname(),\n            \"timestamp\": time.time(),\n            \"status\": status,\n            \"current_task\": task,\n            \"last_seen\": time.ctime()\n        }\n        with open(presence_file, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        # Trigger NSync to propagate the heartbeat\n        try:\n            mcp_py = Path(__file__).parents[1] / \"mcp.py\"\n            subprocess.run([sys.executable, str(mcp_py), \"nsync\", \"sync\"], capture_output=True)\n        except:\n            pass\n        return data\n\n    @staticmethod\n    def get_remote_status():\n        comms_dir = get_comms_dir()\n        remote_status = {}\n        for f in comms_dir.glob(\"*.json\"):\n            if f.stem != get_hostname():\n                try:\n       ", "chunk_type": "class", "line_start": 47, "line_end": 81, "language": "python", "name": "AgentPresence"}, "b04d0d53f4a8_file": {"id": "b04d0d53f4a8_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Autonomous Agent Launcher\nEnsures the mcp comms collaborate loop stays running in the background.\nAuto-restarts on failure.\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport subprocess\nimport sys\nimport time\n\nimport signal\n\nPID_FILE = Path(\"/tmp/agent_launcher.pid\") if os.name != 'nt' else Path(os.environ.get('TEMP', 'C:/Temp')) / \"agent_launcher.pid\"\n\ndef is_already_running():\n    if PID_FILE.exists():\n        try:\n            with open(PID_FILE, \"r\") as f:\n                pid = int(f.read().strip())\n            # Check if process exists\n            if os.name != 'nt':\n                os.kill(pid, 0)\n            else:\n                # Windows check\n                subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {pid}\"], capture_output=True, check=True)\n            return True\n        except:\n            PID_FILE.unlink(missing_ok=True)\n    return False\n\ndef write_pid():\n    with open(PID_FILE, \"w\") as f:\n        f.write(str(os.getpid()))\n\ndef get_mcp_py():\n    script_dir = Path(__file__).resolve().parent\n    mcp_py = script_dir.parent / \"mcp.py\"\n    return str(mcp_py)\n\ndef run_collaboration():\n    mcp_py = get_mcp_py()\n    script_dir = Path(__file__).resolve().parent\n    telegram_bridge_py = script_dir / \"telegram_bridge.py\"\n    telegram_config = script_dir / \"telegram_config.json\"\n\n    print(f\"[LAUNCHER] Starting autonomous collaboration loop...\")\n\n    t_process = None\n\n    while True:\n        try:\n            # Check/Start Telegram Bridge if configured\n            if telegram_config.exists():\n                if t_process is None or t_process.poll() is not None:\n                    action = \"Starting\" if t_process is None else \"Restarting\"\n                    print(f\"[LAUNCHER] Telegram configuration found. {action} Bridge...\")\n                    t_process = subprocess.Popen([sys.executable, str(telegram_bridge_py)], shell=False)\n\n            # Run mcp comms collaborate\n            process = subprocess.Popen([sys.executable, mcp_p", "chunk_type": "file", "line_start": 1, "line_end": 97, "language": "python", "name": "agent_launcher.py"}, "b04d0d53f4a8_func_is_already_running": {"id": "b04d0d53f4a8_func_is_already_running", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def is_already_running():\n    if PID_FILE.exists():\n        try:\n            with open(PID_FILE, \"r\") as f:\n                pid = int(f.read().strip())\n            # Check if process exists\n            if os.name != 'nt':\n                os.kill(pid, 0)\n            else:\n                # Windows check\n                subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {pid}\"], capture_output=True, check=True)\n            return True\n        except:\n            PID_FILE.unlink(missing_ok=True)\n    return False", "chunk_type": "function", "line_start": 18, "line_end": 32, "language": "python", "name": "is_already_running"}, "b04d0d53f4a8_func_write_pid": {"id": "b04d0d53f4a8_func_write_pid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def write_pid():\n    with open(PID_FILE, \"w\") as f:\n        f.write(str(os.getpid()))", "chunk_type": "function", "line_start": 34, "line_end": 36, "language": "python", "name": "write_pid"}, "b04d0d53f4a8_func_get_mcp_py": {"id": "b04d0d53f4a8_func_get_mcp_py", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def get_mcp_py():\n    script_dir = Path(__file__).resolve().parent\n    mcp_py = script_dir.parent / \"mcp.py\"\n    return str(mcp_py)", "chunk_type": "function", "line_start": 38, "line_end": 41, "language": "python", "name": "get_mcp_py"}, "b04d0d53f4a8_func_run_collaboration": {"id": "b04d0d53f4a8_func_run_collaboration", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\agent_launcher.py", "content": "def run_collaboration():\n    mcp_py = get_mcp_py()\n    script_dir = Path(__file__).resolve().parent\n    telegram_bridge_py = script_dir / \"telegram_bridge.py\"\n    telegram_config = script_dir / \"telegram_config.json\"\n\n    print(f\"[LAUNCHER] Starting autonomous collaboration loop...\")\n\n    t_process = None\n\n    while True:\n        try:\n            # Check/Start Telegram Bridge if configured\n            if telegram_config.exists():\n                if t_process is None or t_process.poll() is not None:\n                    action = \"Starting\" if t_process is None else \"Restarting\"\n                    print(f\"[LAUNCHER] Telegram configuration found. {action} Bridge...\")\n                    t_process = subprocess.Popen([sys.executable, str(telegram_bridge_py)], shell=False)\n\n            # Run mcp comms collaborate\n            process = subprocess.Popen([sys.executable, mcp_py, \"comms\", \"collaborate\"], shell=False)\n\n            # Monitoring loop\n            while process.poll() is None:\n      ", "chunk_type": "function", "line_start": 43, "line_end": 85, "language": "python", "name": "run_collaboration"}, "4e5d9834f9d6_file": {"id": "4e5d9834f9d6_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity IDE Automation Bridge\nAutomates typing messages into the Antigravity IDE chat interface using Playwright.\n\nThis module integrates with telegram_bridge.py and agent_comms.py to enable\nTelegram \u2192 Antigravity \u2192 Telegram message flow.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Optional\nimport json\nimport os\nimport sys\nimport time\n\n# Playwright will be imported dynamically to handle installation\ntry:\n    from playwright.sync_api import sync_playwright, Page, Browser, TimeoutError as PlaywrightTimeoutError\n    PLAYWRIGHT_AVAILABLE = True\nexcept ImportError:\n    PLAYWRIGHT_AVAILABLE = False\n    print(\"[WARNING] Playwright not installed. Run: pip install playwright && playwright install chromium\")\n\n# MCP Path Resolution\nSCRIPTS_DIR = Path(__file__).resolve().parent\nsys.path.append(str(SCRIPTS_DIR))\n\ntry:\n    import agent_comms\nexcept ImportError:\n    agent_comms = None\n\n\nclass AntigravityBridge:\n    \"\"\"Manages automation of Antigravity IDE chat interface.\"\"\"\n\n    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")\n\n    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigravity is an Electron app, so we'll use Playwright's Chromium DevTools Protocol\n  ", "chunk_type": "file", "line_start": 1, "line_end": 525, "language": "python", "name": "antigravity_automation.py"}, "4e5d9834f9d6_func_handle_antigravity_message": {"id": "4e5d9834f9d6_func_handle_antigravity_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def handle_antigravity_message(message_text: str) -> str:\n    \"\"\"\n    Main handler for processing Telegram messages destined for Antigravity.\n\n    Args:\n        message_text: The instruction from Telegram\n\n    Returns:\n        str: The response from Antigravity agent\n    \"\"\"\n    print(f\"[ANTIGRAVITY] Processing message: {message_text}\")\n\n    bridge = AntigravityBridge()\n\n    try:\n        response = bridge.send_message_to_agent(message_text, timeout_seconds=60)\n\n        if response:\n            return response\n        else:\n            return \"[ERROR] Failed to get response from Antigravity. Ensure the IDE is running with remote debugging enabled.\"\n\n    finally:\n        bridge.close()", "chunk_type": "function", "line_start": 436, "line_end": 459, "language": "python", "name": "handle_antigravity_message"}, "4e5d9834f9d6_func_install_playwright": {"id": "4e5d9834f9d6_func_install_playwright", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def install_playwright():\n    \"\"\"Helper function to install Playwright if needed.\"\"\"\n    import subprocess\n\n    print(\"[INFO] Installing Playwright...\")\n    try:\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"playwright\"], check=True)\n        subprocess.run([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\"], check=True)\n        print(\"[OK] Playwright installed successfully\")\n        return True\n    except Exception as e:\n        print(f\"[FAIL] Failed to install Playwright: {e}\")\n        return False", "chunk_type": "function", "line_start": 462, "line_end": 474, "language": "python", "name": "install_playwright"}, "4e5d9834f9d6_func_test_connection": {"id": "4e5d9834f9d6_func_test_connection", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "def test_connection():\n    \"\"\"Test the connection to Antigravity IDE.\"\"\"\n    print(\"=== Antigravity Connection Test ===\")\n\n    if not PLAYWRIGHT_AVAILABLE:\n        print(\"[INFO] Playwright not available. Attempting to install...\")\n        if install_playwright():\n            print(\"[INFO] Please restart this script after installation completes.\")\n            return\n\n    bridge = AntigravityBridge()\n\n    if bridge.connect_to_antigravity():\n        print(\"[OK] Successfully connected to Antigravity IDE\")\n\n        # Test sending a simple message\n        test_msg = \"Hello! This is a test message from the Telegram bridge.\"\n        print(f\"\\n[TEST] Sending test message: {test_msg}\")\n\n        response = bridge.send_message_to_agent(test_msg, timeout_seconds=30)\n\n        if response:\n            print(f\"\\n[SUCCESS] Received response:\\n{response}\")\n        else:\n            print(\"\\n[FAIL] No response received\")\n    else:\n        print(\"[FAIL] Could not connect to Antigravity\")\n        print(\"\\n", "chunk_type": "function", "line_start": 477, "line_end": 511, "language": "python", "name": "test_connection"}, "4e5d9834f9d6_func___init__": {"id": "4e5d9834f9d6_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")", "chunk_type": "function", "line_start": 38, "line_end": 54, "language": "python", "name": "__init__"}, "4e5d9834f9d6_func_connect_to_antigravity": {"id": "4e5d9834f9d6_func_connect_to_antigravity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigravity is an Electron app, so we'll use Playwright's Chromium DevTools Protocol\n        to connect to the existing instance.\n\n        Returns:\n            bool: True if successfully connected, False otherwise\n        \"\"\"\n        if not PLAYWRIGHT_AVAILABLE:\n            print(\"[FAIL] Playwright is not installed.\")\n            return False\n\n        try:\n            self.playwright = sync_playwright().start()\n\n            # Antigravity IDE typically runs on a CDP endpoint\n            # We need to find the CDP debugging port\n            # Default for Electron apps is often http://localhost:9222\n\n            # Try common debugging ports for Electron apps\n            debugging_ports = [9222, 9223, 9224, 8315, 8316]\n\n            for port in debugging_ports:\n                try:\n                    cdp_url = f\"http://localhost:{port}\"\n                    pr", "chunk_type": "function", "line_start": 56, "line_end": 127, "language": "python", "name": "connect_to_antigravity"}, "4e5d9834f9d6_func_verify_workspace": {"id": "4e5d9834f9d6_func_verify_workspace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def verify_workspace(self) -> bool:\n        \"\"\"\n        Verifies that Antigravity is open in the correct workspace directory.\n\n        Returns:\n            bool: True if in correct workspace, False otherwise\n        \"\"\"\n        if not self.page:\n            return False\n\n        try:\n            # Check if title bar or status bar shows the correct workspace path\n            # Method 1: Check window title\n            title = self.page.title()\n            workspace_name = str(self.workspace_path.name)\n\n            print(f\"[DEBUG] Window title: {title}\")\n            print(f\"[DEBUG] Expected workspace: {workspace_name} or {self.workspace_path}\")\n\n            if workspace_name in title or str(self.workspace_path) in title:\n                print(f\"[OK] Antigravity is in correct workspace: {workspace_name}\")\n                return True\n\n            # Method 2: Execute JavaScript to get workspace path from VS Code API\n            try:\n                current_workspace = self.page.evaluate(", "chunk_type": "function", "line_start": 129, "line_end": 180, "language": "python", "name": "verify_workspace"}, "4e5d9834f9d6_func_open_workspace": {"id": "4e5d9834f9d6_func_open_workspace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def open_workspace(self) -> bool:\n        \"\"\"\n        Opens the correct workspace directory in Antigravity.\n\n        Returns:\n            bool: True if workspace opened successfully, False otherwise\n        \"\"\"\n        if not self.page:\n            return False\n\n        try:\n            print(f\"[INFO] Opening workspace: {self.workspace_path}\")\n\n            # First, press Escape to close any open dialogs\n            self.page.keyboard.press(\"Escape\")\n            time.sleep(0.5)\n\n            # Click \"Open Folder\" button if on Launchpad\n            try:\n                open_folder_button = self.page.query_selector('text=\"Open Folder\"')\n                if open_folder_button:\n                    print(\"[INFO] Clicking 'Open Folder' button on Launchpad\")\n                    open_folder_button.click()\n                    time.sleep(2)\n                else:\n                    # Try keyboard shortcut: Ctrl+K Ctrl+O\n                    print(\"[INFO] Using Ctrl+K Ctrl+O to open folder\")\n    ", "chunk_type": "function", "line_start": 182, "line_end": 245, "language": "python", "name": "open_workspace"}, "4e5d9834f9d6_func_send_message_to_agent": {"id": "4e5d9834f9d6_func_send_message_to_agent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def send_message_to_agent(self, message: str, timeout_seconds: int = 30) -> Optional[str]:\n        \"\"\"\n        Types a message into Antigravity's agent chat interface and retrieves the response.\n\n        Args:\n            message: The message text to send\n            timeout_seconds: Maximum time to wait for response\n\n        Returns:\n            str: The agent's response, or None if failed\n        \"\"\"\n        if not self.page:\n            if not self.connect_to_antigravity():\n                return None\n\n        try:\n            # Click the \"Open Agent Manager\" button to open the agent panel\n            print(\"[INFO] Looking for 'Open Agent Manager' button...\")\n            try:\n                # Try to find and click the Open Agent Manager button\n                agent_button = self.page.query_selector('text=\"Open Agent Manager\"')\n                if agent_button and agent_button.is_visible():\n                    print(\"[INFO] Clicking 'Open Agent Manager' button...\")\n              ", "chunk_type": "function", "line_start": 247, "line_end": 420, "language": "python", "name": "send_message_to_agent"}, "4e5d9834f9d6_func_close": {"id": "4e5d9834f9d6_func_close", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "    def close(self):\n        \"\"\"Cleanup resources.\"\"\"\n        if self.browser:\n            try:\n                self.browser.close()\n            except:\n                pass\n        if self.playwright:\n            try:\n                self.playwright.stop()\n            except:\n                pass", "chunk_type": "function", "line_start": 422, "line_end": 433, "language": "python", "name": "close"}, "4e5d9834f9d6_class_AntigravityBridge": {"id": "4e5d9834f9d6_class_AntigravityBridge", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\antigravity_automation.py", "content": "class AntigravityBridge:\n    \"\"\"Manages automation of Antigravity IDE chat interface.\"\"\"\n\n    def __init__(self, workspace_path: Optional[str] = None):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.conversation_active = False\n\n        # Workspace paths for Quasar (Windows) and WizardPanda (Linux)\n        if workspace_path:\n            self.workspace_path = Path(workspace_path)\n        else:\n            # Auto-detect based on hostname\n            if os.name == 'nt':  # Windows - Quasar\n                self.workspace_path = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_\")\n            else:  # Linux - WizardPanda\n                self.workspace_path = Path(\"/home/p4nd4pr0t0c01/Projects/_BLANK_\")\n\n        print(f\"[INFO] Workspace path set to: {self.workspace_path}\")\n\n    def connect_to_antigravity(self) -> bool:\n        \"\"\"\n        Attempts to connect to a running Antigravity IDE instance.\n\n        Antigrav", "chunk_type": "class", "line_start": 35, "line_end": 433, "language": "python", "name": "AntigravityBridge"}, "74ade2f9943f_file": {"id": "74ade2f9943f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "\"\"\"\nAPI Documentation Generator\n===========================\nGenerate OpenAPI specs and markdown docs from Flask/FastAPI code.\n\nUsage:\n    python api_docs.py [path] [--output api.md]\n    python -m scripts.api_docs src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Any\nimport ast\nimport json\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass APIEndpoint:\n    \"\"\"An API endpoint definition.\"\"\"\n    path: str\n    method: str\n    function_name: str\n    file_path: Path\n    line_number: int\n    docstring: Optional[str] = None\n    parameters: List[Dict[str, Any]] = field(default_factory=list)\n    request_body: Optional[Dict[str, Any]] = None\n    responses: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass APIDocumentation:\n    \"\"\"Complete API documentation.\"\"\"\n    title: str = \"API Documentation\"\n    version: str = \"1.0.0\"\n    endpoints: List[APIEndpoint] = field(default_factory=list)\n\n    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"openapi\": \"3.0.0\",\n            \"info\": {\n                \"title\": self.title,\n                \"version\": self.version\n          ", "chunk_type": "file", "line_start": 1, "line_end": 400, "language": "python", "name": "api_docs.py"}, "74ade2f9943f_func_analyze_file": {"id": "74ade2f9943f_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "def analyze_file(path: Path) -> List[APIEndpoint]:\n    \"\"\"Analyze a file for API endpoints.\"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return []\n\n    endpoints = []\n\n    # Detect framework\n    source = ''.join(source_lines)\n\n    if 'flask' in source.lower() or 'Flask' in source:\n        extractor = FlaskRouteExtractor(path, source_lines)\n        extractor.visit(tree)\n        endpoints.extend(extractor.endpoints)\n\n    if 'fastapi' in source.lower() or 'FastAPI' in source:\n        extractor = FastAPIRouteExtractor(path, source_lines)\n        extractor.visit(tree)\n        endpoints.extend(extractor.endpoints)\n\n    return endpoints", "chunk_type": "function", "line_start": 299, "line_end": 326, "language": "python", "name": "analyze_file"}, "74ade2f9943f_func_generate_api_docs": {"id": "74ade2f9943f_func_generate_api_docs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "def generate_api_docs(\n    root: Path,\n    title: str = \"API Documentation\",\n    exclude_patterns: List[str] = None\n) -> APIDocumentation:\n    \"\"\"Generate API documentation for a project.\"\"\"\n    docs = APIDocumentation(title=title)\n\n    Console.info(f\"Scanning {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        endpoints = analyze_file(path)\n        docs.endpoints.extend(endpoints)\n\n    Console.info(f\"Found {len(docs.endpoints)} API endpoints\")\n\n    return docs", "chunk_type": "function", "line_start": 329, "line_end": 348, "language": "python", "name": "generate_api_docs"}, "74ade2f9943f_func_main": {"id": "74ade2f9943f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"API Documentation Generator\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n    output_format = 'markdown'\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n        if arg == '--json':\n            output_format = 'json'\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    docs = generate_api_docs(path)\n\n    if len(docs.endpoints) == 0:\n        Console.warn(\"No API endpoints found (Flask/FastAPI)\")\n        return 0\n\n    if output_format == 'json':\n        content = json.dumps(docs.to_openapi(), indent=2)\n    else:\n        content = docs.to_markdown()\n\n    if output_file:\n        with open(output_fi", "chunk_type": "function", "line_start": 351, "line_end": 395, "language": "python", "name": "main"}, "74ade2f9943f_func_to_openapi": {"id": "74ade2f9943f_func_to_openapi", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"openapi\": \"3.0.0\",\n            \"info\": {\n                \"title\": self.title,\n                \"version\": self.version\n            },\n            \"paths\": paths\n        }", "chunk_type": "function", "line_start": 48, "line_end": 75, "language": "python", "name": "to_openapi"}, "74ade2f9943f_func_to_markdown": {"id": "74ade2f9943f_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Convert to markdown documentation.\"\"\"\n        lines = [\n            f\"# {self.title}\",\n            \"\",\n            f\"**Version:** {self.version}\",\n            \"\",\n            \"## Endpoints\",\n            \"\",\n        ]\n\n        # Group by path\n        by_path: Dict[str, List[APIEndpoint]] = {}\n        for ep in self.endpoints:\n            if ep.path not in by_path:\n                by_path[ep.path] = []\n            by_path[ep.path].append(ep)\n\n        for path, endpoints in sorted(by_path.items()):\n            lines.append(f\"### `{path}`\")\n            lines.append(\"\")\n\n            for ep in endpoints:\n                lines.append(f\"#### {ep.method} `{path}`\")\n                lines.append(\"\")\n                lines.append(f\"**Handler:** `{ep.function_name}`\")\n                lines.append(f\"**Source:** `{ep.file_path}:{ep.line_number}`\")\n                lines.append(\"\")\n\n                if ep.docstring:\n                    lines.append(ep.docstrin", "chunk_type": "function", "line_start": 77, "line_end": 119, "language": "python", "name": "to_markdown"}, "74ade2f9943f_func___init__": {"id": "74ade2f9943f_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []", "chunk_type": "function", "line_start": 227, "line_end": 230, "language": "python", "name": "__init__"}, "74ade2f9943f_func_visit_Assign": {"id": "74ade2f9943f_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        # Detect Flask app = Flask(__name__)\n        if isinstance(node.value, ast.Call):\n            if isinstance(node.value.func, ast.Name):\n                if node.value.func.id == 'Flask':\n                    for target in node.targets:\n                        if isinstance(target, ast.Name):\n                            self._app_names.add(target.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 133, "line_end": 141, "language": "python", "name": "visit_Assign"}, "74ade2f9943f_func_visit_FunctionDef": {"id": "74ade2f9943f_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 232, "line_end": 234, "language": "python", "name": "visit_FunctionDef"}, "74ade2f9943f_func_visit_AsyncFunctionDef": {"id": "74ade2f9943f_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 236, "line_end": 238, "language": "python", "name": "visit_AsyncFunctionDef"}, "74ade2f9943f_func__check_decorators": {"id": "74ade2f9943f_func__check_decorators", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _check_decorators(self, node):\n        for decorator in node.decorator_list:\n            endpoint = self._parse_fastapi_decorator(decorator, node)\n            if endpoint:\n                self.endpoints.append(endpoint)", "chunk_type": "function", "line_start": 240, "line_end": 244, "language": "python", "name": "_check_decorators"}, "74ade2f9943f_func__parse_flask_decorator": {"id": "74ade2f9943f_func__parse_flask_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _parse_flask_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.route('/path', methods=['GET'])\n        if isinstance(decorator, ast.Call):\n            if isinstance(decorator.func, ast.Attribute):\n                if decorator.func.attr == 'route':\n                    path = self._get_path_arg(decorator)\n                    methods = self._get_methods_arg(decorator)\n                    if path:\n                        for method in methods:\n                            return APIEndpoint(\n                                path=path,\n                                method=method,\n                                function_name=func_node.name,\n                                file_path=self.path,\n                                line_number=func_node.lineno,\n                                docstring=ast.get_docstring(func_node),\n                                parameters=self._extract_params(path),\n                                responses={\"200\": {\"descripti", "chunk_type": "function", "line_start": 157, "line_end": 191, "language": "python", "name": "_parse_flask_decorator"}, "74ade2f9943f_func__get_path_arg": {"id": "74ade2f9943f_func__get_path_arg", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _get_path_arg(self, call: ast.Call) -> Optional[str]:\n        if call.args and isinstance(call.args[0], ast.Constant):\n            return call.args[0].value\n        return None", "chunk_type": "function", "line_start": 265, "line_end": 268, "language": "python", "name": "_get_path_arg"}, "74ade2f9943f_func__get_methods_arg": {"id": "74ade2f9943f_func__get_methods_arg", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _get_methods_arg(self, call: ast.Call) -> List[str]:\n        for keyword in call.keywords:\n            if keyword.arg == 'methods':\n                if isinstance(keyword.value, ast.List):\n                    return [\n                        elt.value.upper() if isinstance(elt, ast.Constant) else 'GET'\n                        for elt in keyword.value.elts\n                    ]\n        return ['GET']", "chunk_type": "function", "line_start": 198, "line_end": 206, "language": "python", "name": "_get_methods_arg"}, "74ade2f9943f_func__extract_params": {"id": "74ade2f9943f_func__extract_params", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _extract_params(self, path: str, func_node) -> List[Dict]:\n        \"\"\"Extract parameters from path and function signature.\"\"\"\n        params = []\n\n        # Path parameters: {id}\n        for match in re.findall(r'\\{(\\w+)\\}', path):\n            params.append({\n                \"name\": match,\n                \"in\": \"path\",\n                \"required\": True,\n                \"schema\": {\"type\": \"string\"}\n            })\n\n        # Query parameters from function args\n        skip = {'request', 'response', 'db', 'session'}\n        path_params = {p['name'] for p in params}\n\n        for arg in func_node.args.args:\n            if arg.arg not in skip and arg.arg not in path_params:\n                params.append({\n                    \"name\": arg.arg,\n                    \"in\": \"query\",\n                    \"required\": arg.annotation is not None,\n                    \"schema\": {\"type\": \"string\"}\n                })\n\n        return params", "chunk_type": "function", "line_start": 270, "line_end": 296, "language": "python", "name": "_extract_params"}, "74ade2f9943f_func__parse_fastapi_decorator": {"id": "74ade2f9943f_func__parse_fastapi_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "    def _parse_fastapi_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.get(\"/path\"), @router.post(\"/path\")\n        if isinstance(decorator, ast.Call):\n            if isinstance(decorator.func, ast.Attribute):\n                if decorator.func.attr in self.METHODS:\n                    path = self._get_path_arg(decorator)\n                    if path:\n                        return APIEndpoint(\n                            path=path,\n                            method=decorator.func.attr.upper(),\n                            function_name=func_node.name,\n                            file_path=self.path,\n                            line_number=func_node.lineno,\n                            docstring=ast.get_docstring(func_node),\n                            parameters=self._extract_params(path, func_node)\n                        )\n\n        return None", "chunk_type": "function", "line_start": 246, "line_end": 263, "language": "python", "name": "_parse_fastapi_decorator"}, "74ade2f9943f_class_APIEndpoint": {"id": "74ade2f9943f_class_APIEndpoint", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "class APIEndpoint:\n    \"\"\"An API endpoint definition.\"\"\"\n    path: str\n    method: str\n    function_name: str\n    file_path: Path\n    line_number: int\n    docstring: Optional[str] = None\n    parameters: List[Dict[str, Any]] = field(default_factory=list)\n    request_body: Optional[Dict[str, Any]] = None\n    responses: Dict[str, Any] = field(default_factory=dict)", "chunk_type": "class", "line_start": 28, "line_end": 38, "language": "python", "name": "APIEndpoint"}, "74ade2f9943f_class_APIDocumentation": {"id": "74ade2f9943f_class_APIDocumentation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "class APIDocumentation:\n    \"\"\"Complete API documentation.\"\"\"\n    title: str = \"API Documentation\"\n    version: str = \"1.0.0\"\n    endpoints: List[APIEndpoint] = field(default_factory=list)\n\n    def to_openapi(self) -> Dict[str, Any]:\n        \"\"\"Convert to OpenAPI 3.0 spec.\"\"\"\n        paths: Dict[str, Dict] = {}\n\n        for endpoint in self.endpoints:\n            if endpoint.path not in paths:\n                paths[endpoint.path] = {}\n\n            method = endpoint.method.lower()\n            paths[endpoint.path][method] = {\n                \"summary\": endpoint.function_name,\n                \"description\": endpoint.docstring or \"\",\n                \"operationId\": endpoint.function_name,\n                \"parameters\": endpoint.parameters,\n                \"responses\": endpoint.responses or {\"200\": {\"description\": \"Success\"}}\n            }\n\n            if endpoint.request_body:\n                paths[endpoint.path][method][\"requestBody\"] = endpoint.request_body\n\n        return {\n            \"o", "chunk_type": "class", "line_start": 42, "line_end": 119, "language": "python", "name": "APIDocumentation"}, "74ade2f9943f_class_FlaskRouteExtractor": {"id": "74ade2f9943f_class_FlaskRouteExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "class FlaskRouteExtractor(ast.NodeVisitor):\n    \"\"\"Extract routes from Flask applications.\"\"\"\n\n    METHODS = {'get', 'post', 'put', 'delete', 'patch', 'options', 'head'}\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []\n        self._app_names: set = set()\n\n    def visit_Assign(self, node: ast.Assign):\n        # Detect Flask app = Flask(__name__)\n        if isinstance(node.value, ast.Call):\n            if isinstance(node.value.func, ast.Name):\n                if node.value.func.id == 'Flask':\n                    for target in node.targets:\n                        if isinstance(target, ast.Name):\n                            self._app_names.add(target.id)\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.Async", "chunk_type": "class", "line_start": 122, "line_end": 219, "language": "python", "name": "FlaskRouteExtractor"}, "74ade2f9943f_class_FastAPIRouteExtractor": {"id": "74ade2f9943f_class_FastAPIRouteExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\api_docs.py", "content": "class FastAPIRouteExtractor(ast.NodeVisitor):\n    \"\"\"Extract routes from FastAPI applications.\"\"\"\n\n    METHODS = {'get', 'post', 'put', 'delete', 'patch', 'options', 'head'}\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.endpoints: List[APIEndpoint] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_decorators(node)\n        self.generic_visit(node)\n\n    def _check_decorators(self, node):\n        for decorator in node.decorator_list:\n            endpoint = self._parse_fastapi_decorator(decorator, node)\n            if endpoint:\n                self.endpoints.append(endpoint)\n\n    def _parse_fastapi_decorator(self, decorator, func_node) -> Optional[APIEndpoint]:\n        # @app.get(\"/path\"), @router.post(\"/path\")\n        if isinstan", "chunk_type": "class", "line_start": 222, "line_end": 296, "language": "python", "name": "FastAPIRouteExtractor"}, "4d464fe66bbb_file": {"id": "4d464fe66bbb_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "\"\"\"\nArchitecture Validator\n======================\nEnforce architectural patterns and layer separation.\n\nUsage:\n    python architecture.py [path] [--config arch.json]\n    python -m scripts.architecture src/\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set, Tuple\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass LayerRule:\n    \"\"\"A layer dependency rule.\"\"\"\n    layer: str\n    can_depend_on: List[str]\n    patterns: List[str]  # Path patterns for this layer\n\n\n@dataclass\nclass ArchViolation:\n    \"\"\"An architecture violation.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'error', 'warning'\n    category: str\n    message: str\n    from_layer: Optional[str] = None\n    to_layer: Optional[str] = None\n\n\n@dataclass\nclass ArchReport:\n    \"\"\"Architecture analysis report.\"\"\"\n    violations: List[ArchViolation] = field(default_factory=list)\n    layer_mapping: Dict[str, str] = field(default_factory=dict)\n    dependencies: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_layers:\n                if from_layer and to_layer:\n                    lines.appen", "chunk_type": "file", "line_start": 1, "line_end": 353, "language": "python", "name": "architecture.py"}, "4d464fe66bbb_func_detect_layer": {"id": "4d464fe66bbb_func_detect_layer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "def detect_layer(path: Path, rules: List[LayerRule]) -> Optional[str]:\n    \"\"\"Detect the layer a module belongs to based on path patterns.\"\"\"\n    name = path.stem.lower()\n    parts = [p.lower() for p in path.parts]\n\n    for rule in rules:\n        for pattern in rule.patterns:\n            # Convert glob to regex\n            regex = pattern.replace('*', '.*')\n            if re.search(regex, name) or any(re.search(regex, p) for p in parts):\n                return rule.layer\n\n    return None", "chunk_type": "function", "line_start": 140, "line_end": 152, "language": "python", "name": "detect_layer"}, "4d464fe66bbb_func_analyze_file": {"id": "4d464fe66bbb_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "def analyze_file(\n    path: Path,\n    rules: List[LayerRule]\n) -> Tuple[Optional[str], List[ArchViolation], Set[str]]:\n    \"\"\"Analyze a file for architecture violations.\"\"\"\n    violations = []\n    imports = set()\n\n    layer = detect_layer(path, rules)\n\n    tree = parse_file(path)\n    if tree is None:\n        return layer, violations, imports\n\n    # Import analysis\n    import_analyzer = ImportAnalyzer(path, layer, rules)\n    import_analyzer.visit(tree)\n    violations.extend(import_analyzer.violations)\n    imports = import_analyzer.imports\n\n    # Naming conventions\n    naming = NamingConventionChecker(path, layer)\n    naming.check(tree)\n    violations.extend(naming.violations)\n\n    return layer, violations, imports", "chunk_type": "function", "line_start": 246, "line_end": 271, "language": "python", "name": "analyze_file"}, "4d464fe66bbb_func_analyze_architecture": {"id": "4d464fe66bbb_func_analyze_architecture", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "def analyze_architecture(\n    root: Path,\n    rules: List[LayerRule] = None,\n    exclude_patterns: List[str] = None\n) -> ArchReport:\n    \"\"\"Analyze project architecture.\"\"\"\n    if rules is None:\n        rules = DEFAULT_RULES\n\n    report = ArchReport()\n\n    Console.info(f\"Analyzing architecture in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        layer, violations, imports = analyze_file(path, rules)\n\n        # Track layer mapping\n        report.layer_mapping[str(path)] = layer or 'unknown'\n\n        # Track violations\n        report.violations.extend(violations)\n\n        # Track dependencies\n        if layer:\n            for imp in imports:\n                for rule in rules:\n                    for pattern in rule.patterns:\n                        regex = pattern.replace('*', '.*')\n                        if re.search(regex, imp.lower()):\n                            report.depende", "chunk_type": "function", "line_start": 274, "line_end": 309, "language": "python", "name": "analyze_architecture"}, "4d464fe66bbb_func_main": {"id": "4d464fe66bbb_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Architecture Validator\")\n\n    # Parse args\n    strict = '--strict' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_architecture(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.errors:\n        Console.fail(f\"Found {len(report.errors)} architecture violations\")\n        return 1\n    elif report.violations:\n        if strict:\n            Console.fail(f\"Found {len(report.violations)} warnings (strict mode)\")\n            return 1\n        else:\n            Console.warn(f\"Found {len(report.violations)} warnings\")\n    else:\n        Console.ok(\"Architecture is clean\")\n\n    return 0", "chunk_type": "function", "line_start": 312, "line_end": 348, "language": "python", "name": "main"}, "4d464fe66bbb_func_errors": {"id": "4d464fe66bbb_func_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']", "chunk_type": "function", "line_start": 55, "line_end": 56, "language": "python", "name": "errors"}, "4d464fe66bbb_func_to_markdown": {"id": "4d464fe66bbb_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_layers:\n                if from_layer and to_layer:\n                    lines.append(f'    {from_layer} --> {to_layer}')\n\n        lines.extend([\"```\", \"\"])\n\n        # Summary\n        lines.extend([\n            \"## Summary\",\n            \"\",\n            f\"- **Modules analyzed:** {len(self.layer_mapping)}\",\n            f\"- **Violations:** {len(self.violations)}\",\n            f\"- **Errors:** {len(self.errors)}", "chunk_type": "function", "line_start": 58, "line_end": 107, "language": "python", "name": "to_markdown"}, "4d464fe66bbb_func___init__": {"id": "4d464fe66bbb_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def __init__(self, path: Path, layer: Optional[str]):\n        self.path = path\n        self.layer = layer\n        self.violations: List[ArchViolation] = []", "chunk_type": "function", "line_start": 219, "line_end": 222, "language": "python", "name": "__init__"}, "4d464fe66bbb_func_visit_Import": {"id": "4d464fe66bbb_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self.imports.add(alias.name)\n            self._check_import(alias.name, node.lineno)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 165, "line_end": 169, "language": "python", "name": "visit_Import"}, "4d464fe66bbb_func_visit_ImportFrom": {"id": "4d464fe66bbb_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self.imports.add(node.module)\n            self._check_import(node.module, node.lineno)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 171, "line_end": 175, "language": "python", "name": "visit_ImportFrom"}, "4d464fe66bbb_func__check_import": {"id": "4d464fe66bbb_func__check_import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def _check_import(self, module: str, lineno: int):\n        if not self.layer:\n            return\n\n        # Get allowed dependencies for current layer\n        allowed = set()\n        for rule in self.rules:\n            if rule.layer == self.layer:\n                allowed = set(rule.can_depend_on)\n                break\n\n        # Check if import violates layer rules\n        module_lower = module.lower()\n        for rule in self.rules:\n            for pattern in rule.patterns:\n                regex = pattern.replace('*', '.*')\n                if re.search(regex, module_lower):\n                    imported_layer = rule.layer\n\n                    if imported_layer != self.layer and imported_layer not in allowed:\n                        self.violations.append(ArchViolation(\n                            path=self.path,\n                            line=lineno,\n                            severity='error',\n                            category='Layer Violation',\n                            m", "chunk_type": "function", "line_start": 177, "line_end": 206, "language": "python", "name": "_check_import"}, "4d464fe66bbb_func_check": {"id": "4d464fe66bbb_func_check", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "    def check(self, tree: ast.Module):\n        if not self.layer or self.layer not in self.CONVENTIONS:\n            return\n\n        expected = self.CONVENTIONS[self.layer]\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.ClassDef):\n                if node.name.startswith('_') or node.name == 'Config':\n                    continue\n\n                # Check if class name follows convention\n                if not any(node.name.endswith(suffix) for suffix in expected):\n                    self.violations.append(ArchViolation(\n                        path=self.path,\n                        line=node.lineno,\n                        severity='warning',\n                        category='Naming Convention',\n                        message=f\"Class '{node.name}' in '{self.layer}' layer should end with: {', '.join(expected)}\"\n                    ))", "chunk_type": "function", "line_start": 224, "line_end": 243, "language": "python", "name": "check"}, "4d464fe66bbb_class_LayerRule": {"id": "4d464fe66bbb_class_LayerRule", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class LayerRule:\n    \"\"\"A layer dependency rule.\"\"\"\n    layer: str\n    can_depend_on: List[str]\n    patterns: List[str]  # Path patterns for this layer", "chunk_type": "class", "line_start": 28, "line_end": 32, "language": "python", "name": "LayerRule"}, "4d464fe66bbb_class_ArchViolation": {"id": "4d464fe66bbb_class_ArchViolation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class ArchViolation:\n    \"\"\"An architecture violation.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'error', 'warning'\n    category: str\n    message: str\n    from_layer: Optional[str] = None\n    to_layer: Optional[str] = None", "chunk_type": "class", "line_start": 36, "line_end": 44, "language": "python", "name": "ArchViolation"}, "4d464fe66bbb_class_ArchReport": {"id": "4d464fe66bbb_class_ArchReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class ArchReport:\n    \"\"\"Architecture analysis report.\"\"\"\n    violations: List[ArchViolation] = field(default_factory=list)\n    layer_mapping: Dict[str, str] = field(default_factory=dict)\n    dependencies: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def errors(self) -> List[ArchViolation]:\n        return [v for v in self.violations if v.severity == 'error']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Architecture Analysis\",\n            \"\",\n            \"## Layer Structure\",\n            \"\",\n            \"```mermaid\",\n            \"graph TD\",\n        ]\n\n        # Add layer nodes\n        layers_seen = set()\n        for layer in self.layer_mapping.values():\n            if layer and layer not in layers_seen:\n                lines.append(f'    {layer}[\"{layer}\"]')\n                layers_seen.add(layer)\n\n        # Add dependencies\n        for from_layer, to_layers in self.dependencies.items():\n            for to_layer in to_lay", "chunk_type": "class", "line_start": 48, "line_end": 107, "language": "python", "name": "ArchReport"}, "4d464fe66bbb_class_ImportAnalyzer": {"id": "4d464fe66bbb_class_ImportAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class ImportAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze imports for architecture violations.\"\"\"\n\n    def __init__(self, path: Path, layer: Optional[str], rules: List[LayerRule]):\n        self.path = path\n        self.layer = layer\n        self.rules = rules\n        self.violations: List[ArchViolation] = []\n        self.imports: Set[str] = set()\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self.imports.add(alias.name)\n            self._check_import(alias.name, node.lineno)\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self.imports.add(node.module)\n            self._check_import(node.module, node.lineno)\n        self.generic_visit(node)\n\n    def _check_import(self, module: str, lineno: int):\n        if not self.layer:\n            return\n\n        # Get allowed dependencies for current layer\n        allowed = set()\n        for rule in self.rules:\n            if rule.la", "chunk_type": "class", "line_start": 155, "line_end": 206, "language": "python", "name": "ImportAnalyzer"}, "4d464fe66bbb_class_NamingConventionChecker": {"id": "4d464fe66bbb_class_NamingConventionChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\architecture.py", "content": "class NamingConventionChecker:\n    \"\"\"Check naming conventions by layer.\"\"\"\n\n    CONVENTIONS = {\n        'controller': ['Controller', 'Handler', 'View', 'Router', 'Api', 'Manager'],\n        'service': ['Service', 'Manager', 'Logic', 'Settings', 'Response'],\n        'repository': ['Repository', 'Repo', 'DAO', 'Dal'],\n        'model': ['Model', 'Entity', 'Schema', 'DTO', 'Base', 'Create', 'Read', 'Update', 'Item', 'Info', 'Status', 'Payload', 'Login', 'Response', 'Request', 'Analytics', 'Performance', 'Risk', 'Grade', 'Token', 'WithStudent', 'Account', 'Institution', 'Classroom', 'Assignment', 'Announcement', 'Subscription', 'Transaction', 'GameSave', 'BugReport', 'Product', 'Permission', 'Enrollment', 'Submission', 'Condition', 'Link', 'Jurisdiction', 'Log', 'Message', 'Cache', 'Category', 'Image', 'Review', 'Question', 'Option', 'Answer', 'Module', 'Progress', 'Type'],\n    }\n\n    def __init__(self, path: Path, layer: Optional[str]):\n        self.path = path\n        self.layer = layer\n ", "chunk_type": "class", "line_start": 209, "line_end": 243, "language": "python", "name": "NamingConventionChecker"}, "cac9639ac7a8_file": {"id": "cac9639ac7a8_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "\"\"\"\nast-grep Wrapper\n================\nStructural code search and transformation using ast-grep.\n\nUsage:\n    from scripts.astgrep import search_pattern, apply_fix\n\"\"\"\n\nimport json\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass, field\n\nfrom .utils import Console, find_python_files\n\n\n# Check if ast-grep is available\ndef _find_astgrep() -> Optional[str]:\n    \"\"\"Find ast-grep binary.\"\"\"\n    for name in ['ast-grep', 'sg']:\n        try:\n            result = subprocess.run(\n                [name, '--version'],\n                capture_output=True,\n                text=True\n            )\n            if result.returncode == 0:\n                return name\n        except FileNotFoundError:\n            continue\n    return None\n\n\nASTGREP_BIN = _find_astgrep()\nASTGREP_AVAILABLE = ASTGREP_BIN is not None\n\n\n@dataclass\nclass PatternMatch:\n    \"\"\"A pattern match result.\"\"\"\n    path: Path\n    line: int\n    column: int\n    text: str\n    matched_text: str\n    pattern: str\n\n\n@dataclass\nclass PatternRule:\n    \"\"\"A pattern rule for search/fix.\"\"\"\n    id: str\n    pattern: str\n    message: str\n    fix: Optional[str] = None\n    severity: str = \"warning\"\n    language: str = \"python\"\n\n\n# Built-in patterns for common issues\nBUILTIN_PATTERNS = {\n    'python': [\n        PatternRule(\n            id='bare-except',\n            pattern='except:',\n            message='Bare except catches all exceptions',\n            fix='except Exception:',\n            severity='error'\n        ),\n        PatternRule(\n            id='print-statement',\n            pattern='print($$$ARGS)',\n            message='Consider using logging instead of print',\n            severity='warning'\n        ),\n        PatternRule(\n            id='mutable-default',\n            pattern='def $FN($$$ARGS, $ARG=[]):',\n            message='Mutable default argument',\n            severity='error'\n        ),\n        PatternRule(\n            id='hardcoded-passw", "chunk_type": "file", "line_start": 1, "line_end": 395, "language": "python", "name": "astgrep.py"}, "cac9639ac7a8_func__find_astgrep": {"id": "cac9639ac7a8_func__find_astgrep", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _find_astgrep() -> Optional[str]:\n    \"\"\"Find ast-grep binary.\"\"\"\n    for name in ['ast-grep', 'sg']:\n        try:\n            result = subprocess.run(\n                [name, '--version'],\n                capture_output=True,\n                text=True\n            )\n            if result.returncode == 0:\n                return name\n        except FileNotFoundError:\n            continue\n    return None", "chunk_type": "function", "line_start": 22, "line_end": 35, "language": "python", "name": "_find_astgrep"}, "cac9639ac7a8_func_search_pattern": {"id": "cac9639ac7a8_func_search_pattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def search_pattern(\n    pattern: str,\n    path: Path,\n    language: str = \"python\"\n) -> List[PatternMatch]:\n    \"\"\"Search for pattern in code.\"\"\"\n    results = []\n\n    if ASTGREP_AVAILABLE:\n        return _astgrep_search(pattern, path, language)\n\n    # Fallback to regex-based search\n    return _regex_search(pattern, path)", "chunk_type": "function", "line_start": 157, "line_end": 169, "language": "python", "name": "search_pattern"}, "cac9639ac7a8_func__astgrep_search": {"id": "cac9639ac7a8_func__astgrep_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _astgrep_search(\n    pattern: str,\n    path: Path,\n    language: str\n) -> List[PatternMatch]:\n    \"\"\"Search using ast-grep.\"\"\"\n    results = []\n\n    try:\n        cmd = [\n            ASTGREP_BIN,\n            '--pattern', pattern,\n            '--json',\n            str(path)\n        ]\n\n        if language:\n            cmd.extend(['--lang', language])\n\n        proc = subprocess.run(cmd, capture_output=True, text=True)\n\n        if proc.returncode == 0 and proc.stdout:\n            for line in proc.stdout.strip().split('\\n'):\n                if line:\n                    try:\n                        match = json.loads(line)\n                        results.append(PatternMatch(\n                            path=Path(match.get('file', '')),\n                            line=match.get('range', {}).get('start', {}).get('line', 0),\n                            column=match.get('range', {}).get('start', {}).get('column', 0),\n                            text=match.get('text', ''),\n                   ", "chunk_type": "function", "line_start": 172, "line_end": 212, "language": "python", "name": "_astgrep_search"}, "cac9639ac7a8_func__regex_search": {"id": "cac9639ac7a8_func__regex_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _regex_search(pattern: str, path: Path) -> List[PatternMatch]:\n    \"\"\"Fallback regex-based search.\"\"\"\n    results = []\n\n    # Convert ast-grep pattern to rough regex\n    regex = pattern\n    regex = re.escape(regex)\n    regex = regex.replace(r'\\$\\$\\$', '.*')  # $$$ matches anything\n    regex = regex.replace(r'\\$', r'\\w+')     # $ matches identifier\n\n    try:\n        files = [path] if path.is_file() else list(path.rglob('*.py'))\n\n        for file_path in files:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    for i, line in enumerate(f, 1):\n                        if re.search(regex, line):\n                            results.append(PatternMatch(\n                                path=file_path,\n                                line=i,\n                                column=0,\n                                text=line.strip(),\n                                matched_text=line.strip(),\n                                pattern=pattern\n ", "chunk_type": "function", "line_start": 215, "line_end": 247, "language": "python", "name": "_regex_search"}, "cac9639ac7a8_func_apply_fix": {"id": "cac9639ac7a8_func_apply_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def apply_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    language: str = \"python\",\n    dry_run: bool = True\n) -> int:\n    \"\"\"Apply fix pattern to files.\"\"\"\n    fixed = 0\n\n    if ASTGREP_AVAILABLE:\n        return _astgrep_fix(pattern, replacement, path, language, dry_run)\n\n    # Fallback to regex\n    return _regex_fix(pattern, replacement, path, dry_run)", "chunk_type": "function", "line_start": 250, "line_end": 264, "language": "python", "name": "apply_fix"}, "cac9639ac7a8_func__astgrep_fix": {"id": "cac9639ac7a8_func__astgrep_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _astgrep_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    language: str,\n    dry_run: bool\n) -> int:\n    \"\"\"Apply fix using ast-grep.\"\"\"\n    cmd = [\n        ASTGREP_BIN,\n        '--pattern', pattern,\n        '--rewrite', replacement,\n    ]\n\n    if not dry_run:\n        cmd.append('--update-all')\n\n    cmd.extend(['--lang', language, str(path)])\n\n    try:\n        proc = subprocess.run(cmd, capture_output=True, text=True)\n        # Count matches\n        return proc.stdout.count('\\n')\n    except Exception:\n        return 0", "chunk_type": "function", "line_start": 267, "line_end": 291, "language": "python", "name": "_astgrep_fix"}, "cac9639ac7a8_func__regex_fix": {"id": "cac9639ac7a8_func__regex_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def _regex_fix(\n    pattern: str,\n    replacement: str,\n    path: Path,\n    dry_run: bool\n) -> int:\n    \"\"\"Fallback regex-based fix.\"\"\"\n    fixed = 0\n\n    # Convert patterns\n    regex = pattern.replace('$$$', '(.*)').replace('$', r'(\\w+)')\n    repl = replacement.replace('$$$', r'\\1').replace('$', r'\\1')\n\n    files = [path] if path.is_file() else list(path.rglob('*.py'))\n\n    for file_path in files:\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n\n            new_content, count = re.subn(regex, repl, content)\n\n            if count > 0:\n                fixed += count\n                if not dry_run:\n                    with open(file_path, 'w', encoding='utf-8') as f:\n                        f.write(new_content)\n        except Exception:\n            pass\n\n    return fixed", "chunk_type": "function", "line_start": 294, "line_end": 324, "language": "python", "name": "_regex_fix"}, "cac9639ac7a8_func_run_rules": {"id": "cac9639ac7a8_func_run_rules", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def run_rules(\n    rules: List[PatternRule],\n    path: Path\n) -> List[PatternMatch]:\n    \"\"\"Run multiple pattern rules.\"\"\"\n    all_matches = []\n\n    for rule in rules:\n        matches = search_pattern(rule.pattern, path, rule.language)\n        for match in matches:\n            match.pattern = f\"{rule.id}: {rule.message}\"\n        all_matches.extend(matches)\n\n    return all_matches", "chunk_type": "function", "line_start": 327, "line_end": 340, "language": "python", "name": "run_rules"}, "cac9639ac7a8_func_get_builtin_rules": {"id": "cac9639ac7a8_func_get_builtin_rules", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def get_builtin_rules(language: str = \"python\") -> List[PatternRule]:\n    \"\"\"Get built-in rules for language.\"\"\"\n    return BUILTIN_PATTERNS.get(language, [])", "chunk_type": "function", "line_start": 343, "line_end": 345, "language": "python", "name": "get_builtin_rules"}, "cac9639ac7a8_func_is_astgrep_available": {"id": "cac9639ac7a8_func_is_astgrep_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def is_astgrep_available() -> bool:\n    \"\"\"Check if ast-grep is available.\"\"\"\n    return ASTGREP_AVAILABLE", "chunk_type": "function", "line_start": 348, "line_end": 350, "language": "python", "name": "is_astgrep_available"}, "cac9639ac7a8_func_main": {"id": "cac9639ac7a8_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"ast-grep Wrapper\")\n\n    if ASTGREP_AVAILABLE:\n        Console.ok(f\"ast-grep available: {ASTGREP_BIN}\")\n    else:\n        Console.warn(\"ast-grep not found, using regex fallback\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if len(args) < 2:\n        Console.info(\"Usage: python astgrep.py <pattern> <path>\")\n        Console.info(\"\\nBuilt-in rules:\")\n        for lang, rules in BUILTIN_PATTERNS.items():\n            Console.info(f\"\\n  {lang}:\")\n            for rule in rules:\n                Console.info(f\"    - {rule.id}: {rule.message}\")\n        return 1\n\n    pattern = args[0]\n    path = Path(args[1])\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Pattern: {pattern}\")\n    Console.info(f\"Path: {path}\")\n\n    matches = search_pattern(pattern, path)\n\n    Console.info(f\"Found {len(matches)} matches\")\n\n    for match in matches[:20]:\n        print(f\"  {", "chunk_type": "function", "line_start": 353, "line_end": 390, "language": "python", "name": "main"}, "cac9639ac7a8_class_PatternMatch": {"id": "cac9639ac7a8_class_PatternMatch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "class PatternMatch:\n    \"\"\"A pattern match result.\"\"\"\n    path: Path\n    line: int\n    column: int\n    text: str\n    matched_text: str\n    pattern: str", "chunk_type": "class", "line_start": 43, "line_end": 50, "language": "python", "name": "PatternMatch"}, "cac9639ac7a8_class_PatternRule": {"id": "cac9639ac7a8_class_PatternRule", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\astgrep.py", "content": "class PatternRule:\n    \"\"\"A pattern rule for search/fix.\"\"\"\n    id: str\n    pattern: str\n    message: str\n    fix: Optional[str] = None\n    severity: str = \"warning\"\n    language: str = \"python\"", "chunk_type": "class", "line_start": 54, "line_end": 61, "language": "python", "name": "PatternRule"}, "ec6f0a371273_file": {"id": "ec6f0a371273_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "\"\"\"\nAuto-Context Loader\n===================\nAutomatically load relevant code context for AI agents.\n\nUsage:\n    python mcp.py context --auto      # Get auto-loaded context\n    python mcp.py context --recent    # Context from recent files\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport os\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ContextCache:\n    \"\"\"Cache of context state.\"\"\"\n    recent_files: List[str] = field(default_factory=list)\n    hot_files: Dict[str, int] = field(default_factory=dict)  # path -> access count\n    last_query: str = \"\"\n    last_task: str = \"\"\n    timestamp: str = \"\"\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)\n\n\n@dataclass\nclass ContextResult:\n    \"\"\"Result of context loading.\"\"\"\n    files: List[Tuple[str, str]]  # (path, content summary)\n    token_count: int\n    source: str  # 'recent', 'semantic', 'dependency'\n\n\ndef get_cache_path(root: Path = None) -> Path:\n    \"\"\"Get path to context cache.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    return root / '.mcp' / 'memory' / 'context_cache.json'\n\n\ndef load_cache(root: Path = None) -> ContextCache:\n    \"\"\"Load context cache from disk.\"\"\"\n    cache_path = get_cache_path(root)\n\n    if cache_path.exists():\n        try:\n            with open(cache_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                return ContextCache.from_dict(data)\n        except Exception:\n            pass\n\n    return ContextCache()\n\n\ndef save_cache(cache: ContextCache, root: Path = None):\n    \"\"\"Save context cache to disk.\"\"\"\n    cache_path = get_cache_path(root)\n    cache_path.parent.mkdir(parents=True, exist_ok=True)\n\n    cache.timestamp = datetime.utcnow().isoformat() + 'Z'\n\n    ", "chunk_type": "file", "line_start": 1, "line_end": 391, "language": "python", "name": "autocontext.py"}, "ec6f0a371273_func_get_cache_path": {"id": "ec6f0a371273_func_get_cache_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_cache_path(root: Path = None) -> Path:\n    \"\"\"Get path to context cache.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    return root / '.mcp' / 'memory' / 'context_cache.json'", "chunk_type": "function", "line_start": 48, "line_end": 51, "language": "python", "name": "get_cache_path"}, "ec6f0a371273_func_load_cache": {"id": "ec6f0a371273_func_load_cache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def load_cache(root: Path = None) -> ContextCache:\n    \"\"\"Load context cache from disk.\"\"\"\n    cache_path = get_cache_path(root)\n\n    if cache_path.exists():\n        try:\n            with open(cache_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                return ContextCache.from_dict(data)\n        except Exception:\n            pass\n\n    return ContextCache()", "chunk_type": "function", "line_start": 54, "line_end": 66, "language": "python", "name": "load_cache"}, "ec6f0a371273_func_save_cache": {"id": "ec6f0a371273_func_save_cache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def save_cache(cache: ContextCache, root: Path = None):\n    \"\"\"Save context cache to disk.\"\"\"\n    cache_path = get_cache_path(root)\n    cache_path.parent.mkdir(parents=True, exist_ok=True)\n\n    cache.timestamp = datetime.utcnow().isoformat() + 'Z'\n\n    with open(cache_path, 'w', encoding='utf-8') as f:\n        json.dump(cache.to_dict(), f, indent=2)", "chunk_type": "function", "line_start": 69, "line_end": 77, "language": "python", "name": "save_cache"}, "ec6f0a371273_func_track_file_access": {"id": "ec6f0a371273_func_track_file_access", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def track_file_access(path: Path, root: Path = None):\n    \"\"\"Track that a file was accessed.\"\"\"\n    cache = load_cache(root)\n\n    path_str = str(path)\n\n    # Update recent files (max 20)\n    if path_str in cache.recent_files:\n        cache.recent_files.remove(path_str)\n    cache.recent_files.insert(0, path_str)\n    cache.recent_files = cache.recent_files[:20]\n\n    # Update hot files\n    cache.hot_files[path_str] = cache.hot_files.get(path_str, 0) + 1\n\n    save_cache(cache, root)", "chunk_type": "function", "line_start": 80, "line_end": 95, "language": "python", "name": "track_file_access"}, "ec6f0a371273_func_get_recent_context": {"id": "ec6f0a371273_func_get_recent_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_recent_context(\n    limit: int = 5,\n    max_lines: int = 50,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from recently accessed files.\"\"\"\n    cache = load_cache(root)\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    for file_path in cache.recent_files[:limit]:\n        path = Path(file_path)\n        if not path.is_absolute():\n            path = root / path\n\n        if path.exists():\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    lines = f.readlines()[:max_lines]\n                    content = ''.join(lines)\n                    files.append((str(path), content))\n                    token_count += len(content.split())\n            except Exception:\n                pass\n\n    return ContextResult(files=files, token_count=token_count, source='recent')", "chunk_type": "function", "line_start": 98, "line_end": 125, "language": "python", "name": "get_recent_context"}, "ec6f0a371273_func_get_hot_context": {"id": "ec6f0a371273_func_get_hot_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_hot_context(\n    limit: int = 5,\n    max_lines: int = 50,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from most frequently accessed files.\"\"\"\n    cache = load_cache(root)\n    root = root or find_project_root() or Path.cwd()\n\n    # Sort by access count\n    sorted_files = sorted(cache.hot_files.items(), key=lambda x: x[1], reverse=True)\n\n    files = []\n    token_count = 0\n\n    for file_path, _ in sorted_files[:limit]:\n        path = Path(file_path)\n        if not path.is_absolute():\n            path = root / path\n\n        if path.exists():\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    lines = f.readlines()[:max_lines]\n                    content = ''.join(lines)\n                    files.append((str(path), content))\n                    token_count += len(content.split())\n            except Exception:\n                pass\n\n    return ContextResult(files=files, token_count=token_count, source='hot')", "chunk_type": "function", "line_start": 128, "line_end": 158, "language": "python", "name": "get_hot_context"}, "ec6f0a371273_func_get_semantic_context": {"id": "ec6f0a371273_func_get_semantic_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_semantic_context(\n    query: str,\n    limit: int = 5,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context via semantic search.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n\n        if store.load():\n            results = store.search(query, k=limit)\n\n            for result in results:\n                files.append((result.chunk.path, result.chunk.content))\n                token_count += len(result.chunk.content.split())\n    except Exception:\n        pass\n\n    # Update cache with query\n    cache = load_cache(root)\n    cache.last_query = query\n    save_cache(cache, root)\n\n    return ContextResult(files=files, token_count=token_count, source='semantic')", "chunk_type": "function", "line_start": 161, "line_end": 190, "language": "python", "name": "get_semantic_context"}, "ec6f0a371273_func_get_dependency_context": {"id": "ec6f0a371273_func_get_dependency_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_dependency_context(\n    file_path: Path,\n    root: Path = None\n) -> ContextResult:\n    \"\"\"Get context from file dependencies (imports).\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    files = []\n    token_count = 0\n\n    try:\n        from .treesitter_utils import parse_file\n        parsed = parse_file(file_path)\n\n        for imp in parsed.imports:\n            # Try to resolve import to file\n            parts = imp.replace('from ', '').replace('import ', '').split()[0].split('.')\n\n            for i in range(len(parts), 0, -1):\n                possible_path = root / '/'.join(parts[:i]) + '.py'\n                if possible_path.exists():\n                    try:\n                        with open(possible_path, 'r', encoding='utf-8') as f:\n                            content = f.read()[:2000]\n                            files.append((str(possible_path), content))\n                            token_count += len(content.split())\n                    except Exception:\n       ", "chunk_type": "function", "line_start": 193, "line_end": 225, "language": "python", "name": "get_dependency_context"}, "ec6f0a371273_func_get_project_map": {"id": "ec6f0a371273_func_get_project_map", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_project_map(root: Path, budget: int) -> str:\n    \"\"\"Layer 1: Get high-level project map.\"\"\"\n    summary_path = root / \"CODEBASE_SUMMARY.md\"\n    if summary_path.exists():\n        try:\n            content = summary_path.read_text(encoding='utf-8')\n            # Extract Directory Structure section\n            if \"## Directory Structure\" in content:\n                structure = content.split(\"## Directory Structure\")[1].split(\"##\")[0]\n                return f\"# Project Map\\n{structure[:budget]}\"\n            return content[:budget]\n        except Exception:\n            pass\n    return \"\"", "chunk_type": "function", "line_start": 230, "line_end": 243, "language": "python", "name": "get_project_map"}, "ec6f0a371273_func_get_auto_context": {"id": "ec6f0a371273_func_get_auto_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def get_auto_context(\n    task: str = \"\",\n    token_budget: int = 8000, # Increased default for deep context\n    root: Path = None\n) -> str:\n    \"\"\"Get hierarchically layered context for AI agent.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    # Budget Allocation\n    budget_map = int(token_budget * 0.05)\n    budget_mem = int(token_budget * 0.10)\n    budget_active = int(token_budget * 0.40)\n    budget_semantic = token_budget - (budget_map + budget_mem + budget_active)\n\n    layers = []\n\n    # Layer 1: Project Map\n    project_map = get_project_map(root, budget_map)\n    if project_map:\n        layers.append(project_map)\n\n    # Layer 2: Memory\n    memories = []\n    try:\n        from .memory import get_store\n        store = get_store()\n        recent_mems = store.recall(task) if task else store.list_all()\n        recent_mems.sort(key=lambda m: m.updated or m.created, reverse=True)\n\n        mem_tokens_used = 0\n        for mem in recent_mems[:5]:\n            encoded = f\"[{mem.key", "chunk_type": "function", "line_start": 245, "line_end": 337, "language": "python", "name": "get_auto_context"}, "ec6f0a371273_func_update_task": {"id": "ec6f0a371273_func_update_task", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def update_task(task: str, root: Path = None):\n    \"\"\"Update current task in cache.\"\"\"\n    cache = load_cache(root)\n    cache.last_task = task\n    save_cache(cache, root)", "chunk_type": "function", "line_start": 342, "line_end": 346, "language": "python", "name": "update_task"}, "ec6f0a371273_func_main": {"id": "ec6f0a371273_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Context Loader\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    root = find_project_root() or Path.cwd()\n\n    if '--recent' in sys.argv:\n        result = get_recent_context(root=root)\n        Console.info(f\"Recent files: {len(result.files)}\")\n        for path, _ in result.files:\n            print(f\"  - {path}\")\n        return 0\n\n    if '--hot' in sys.argv:\n        result = get_hot_context(root=root)\n        Console.info(f\"Hot files: {len(result.files)}\")\n        for path, _ in result.files:\n            print(f\"  - {path}\")\n        return 0\n\n    if '--auto' in sys.argv or not args:\n        task = ' '.join(args) if args else \"\"\n        context = get_auto_context(task=task, root=root)\n        print(context)\n        return 0\n\n    # Semantic search with query\n    query = ' '.join(args)\n    result = get_semantic_context(query, root=root)\n\n    Console.info(f\"Found {len(result.files)} relevant files for: {quer", "chunk_type": "function", "line_start": 349, "line_end": 386, "language": "python", "name": "main"}, "ec6f0a371273_func_to_dict": {"id": "ec6f0a371273_func_to_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "    def to_dict(self) -> dict:\n        return asdict(self)", "chunk_type": "function", "line_start": 32, "line_end": 33, "language": "python", "name": "to_dict"}, "ec6f0a371273_func_from_dict": {"id": "ec6f0a371273_func_from_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)", "chunk_type": "function", "line_start": 36, "line_end": 37, "language": "python", "name": "from_dict"}, "ec6f0a371273_class_ContextCache": {"id": "ec6f0a371273_class_ContextCache", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "class ContextCache:\n    \"\"\"Cache of context state.\"\"\"\n    recent_files: List[str] = field(default_factory=list)\n    hot_files: Dict[str, int] = field(default_factory=dict)  # path -> access count\n    last_query: str = \"\"\n    last_task: str = \"\"\n    timestamp: str = \"\"\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'ContextCache':\n        return cls(**data)", "chunk_type": "class", "line_start": 24, "line_end": 37, "language": "python", "name": "ContextCache"}, "ec6f0a371273_class_ContextResult": {"id": "ec6f0a371273_class_ContextResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\autocontext.py", "content": "class ContextResult:\n    \"\"\"Result of context loading.\"\"\"\n    files: List[Tuple[str, str]]  # (path, content summary)\n    token_count: int\n    source: str  # 'recent', 'semantic', 'dependency'", "chunk_type": "class", "line_start": 41, "line_end": 45, "language": "python", "name": "ContextResult"}, "55362c6d5301_file": {"id": "55362c6d5301_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "\"\"\"\nAuto-Docstring Generator\n========================\nAutomatically add missing docstrings to Python functions and classes.\n\nUsage:\n    python auto_docs.py [path] [--write]\n    python -m scripts.auto_docs [path] [--write]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    get_type_annotation,\n    Console\n)\n\n\n@dataclass\nclass DocstringSuggestion:\n    \"\"\"A suggested docstring for a function or class.\"\"\"\n    path: Path\n    name: str\n    lineno: int\n    node_type: str  # 'function', 'class', 'method'\n    docstring: str\n    indent: str\n\n\ndef generate_function_docstring(\n    node: ast.FunctionDef | ast.AsyncFunctionDef,\n    indent: str = \"    \"\n) -> str:\n    \"\"\"\n    Generate a Google-style docstring for a function.\n\n    Args:\n        node: AST function node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - brief description\n    if node.name.startswith('_'):\n        lines[0] += f\"Private {'async ' if isinstance(node, ast.AsyncFunctionDef) else ''}function {node.name}.\"\n    else:\n        # Try to generate a meaningful description from the name\n        name_parts = node.name.split('_')\n        if name_parts[0] in ('get', 'fetch', 'retrieve'):\n            desc = f\"Get {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('set', 'update'):\n            desc = f\"Set {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('is', 'has', 'can', 'should'):\n            desc = f\"Check if {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'create':\n            desc = f\"Create {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'delete':\n            desc = f\"Delete {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] == 'process':\n            desc = f\"Process {' '.join(name_parts[1:])}.\"\n        elif name_parts[", "chunk_type": "file", "line_start": 1, "line_end": 451, "language": "python", "name": "auto_docs.py"}, "55362c6d5301_func_generate_function_docstring": {"id": "55362c6d5301_func_generate_function_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_function_docstring(\n    node: ast.FunctionDef | ast.AsyncFunctionDef,\n    indent: str = \"    \"\n) -> str:\n    \"\"\"\n    Generate a Google-style docstring for a function.\n\n    Args:\n        node: AST function node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - brief description\n    if node.name.startswith('_'):\n        lines[0] += f\"Private {'async ' if isinstance(node, ast.AsyncFunctionDef) else ''}function {node.name}.\"\n    else:\n        # Try to generate a meaningful description from the name\n        name_parts = node.name.split('_')\n        if name_parts[0] in ('get', 'fetch', 'retrieve'):\n            desc = f\"Get {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('set', 'update'):\n            desc = f\"Set {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] in ('is', 'has', 'can', 'should'):\n            desc = f\"Check if {' '.join(name_parts[1:])}.\"\n        elif name_parts[0] ", "chunk_type": "function", "line_start": 37, "line_end": 141, "language": "python", "name": "generate_function_docstring"}, "55362c6d5301_func__generate_param_description": {"id": "55362c6d5301_func__generate_param_description", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def _generate_param_description(name: str, type_hint: str) -> str:\n    \"\"\"Generate a description for a parameter based on its name.\"\"\"\n    # Common patterns\n    if name in ('path', 'filepath', 'file_path'):\n        return \"Path to the file.\"\n    elif name in ('root', 'root_dir', 'directory', 'dir'):\n        return \"Root directory.\"\n    elif name in ('data', 'content'):\n        return \"Input data.\"\n    elif name in ('name', 'filename'):\n        return \"The name.\"\n    elif name in ('key', 'id', 'identifier'):\n        return \"Unique identifier.\"\n    elif name in ('value', 'val'):\n        return \"The value.\"\n    elif name in ('config', 'settings', 'options'):\n        return \"Configuration options.\"\n    elif name in ('callback', 'func', 'function'):\n        return \"Callback function.\"\n    elif name in ('timeout', 'delay'):\n        return \"Timeout in seconds.\"\n    elif name in ('count', 'limit', 'max', 'min'):\n        return f\"The {name} value.\"\n    elif name.startswith('is_') or name.starts", "chunk_type": "function", "line_start": 144, "line_end": 174, "language": "python", "name": "_generate_param_description"}, "55362c6d5301_func_generate_class_docstring": {"id": "55362c6d5301_func_generate_class_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_class_docstring(node: ast.ClassDef, indent: str = \"    \") -> str:\n    \"\"\"\n    Generate a Google-style docstring for a class.\n\n    Args:\n        node: AST class node\n        indent: Indentation to use\n\n    Returns:\n        Generated docstring string\n    \"\"\"\n    lines = ['\"\"\"']\n\n    # First line - class description\n    name_parts = []\n    for i, char in enumerate(node.name):\n        if char.isupper() and i > 0:\n            name_parts.append(' ')\n        name_parts.append(char.lower())\n\n    desc = ''.join(name_parts).capitalize()\n    lines[0] += f\"{desc} class.\"\n\n    # Check for __init__ to get attributes\n    init_method = None\n    for item in node.body:\n        if isinstance(item, ast.FunctionDef) and item.name == '__init__':\n            init_method = item\n            break\n\n    # Extract attributes from __init__\n    if init_method:\n        attrs = []\n        for stmt in ast.walk(init_method):\n            if isinstance(stmt, ast.Assign):\n                for target in stmt.ta", "chunk_type": "function", "line_start": 177, "line_end": 226, "language": "python", "name": "generate_class_docstring"}, "55362c6d5301_func_analyze_file_for_docstrings": {"id": "55362c6d5301_func_analyze_file_for_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def analyze_file_for_docstrings(path: Path) -> List[DocstringSuggestion]:\n    \"\"\"\n    Analyze a file for missing docstrings.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        List of docstring suggestions\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return []\n\n    analyzer = DocstringAnalyzer(path, source_lines)\n    analyzer.visit(tree)\n\n    return analyzer.suggestions", "chunk_type": "function", "line_start": 307, "line_end": 330, "language": "python", "name": "analyze_file_for_docstrings"}, "55362c6d5301_func_add_docstrings_to_file": {"id": "55362c6d5301_func_add_docstrings_to_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def add_docstrings_to_file(path: Path, suggestions: List[DocstringSuggestion]) -> str:\n    \"\"\"\n    Add docstrings to a file.\n\n    Args:\n        path: Path to Python file\n        suggestions: List of docstring suggestions for this file\n\n    Returns:\n        Modified source code\n    \"\"\"\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n\n    # Sort suggestions by line number in reverse order\n    # so we can insert from bottom to top without affecting line numbers\n    sorted_suggestions = sorted(suggestions, key=lambda s: s.lineno, reverse=True)\n\n    for suggestion in sorted_suggestions:\n        # Find the line with the function/class definition\n        def_line = suggestion.lineno - 1  # Convert to 0-indexed\n\n        # Find where to insert (after the definition line and any decorators)\n        insert_line = def_line + 1\n\n        # Skip past the colon and any existing pass/... statements\n        while insert_line < len(lines):\n            line = lines[insert_li", "chunk_type": "function", "line_start": 333, "line_end": 370, "language": "python", "name": "add_docstrings_to_file"}, "55362c6d5301_func_generate_docstrings": {"id": "55362c6d5301_func_generate_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def generate_docstrings(\n    root: Path,\n    write: bool = False,\n    exclude_patterns: List[str] = None\n) -> Tuple[int, int]:\n    \"\"\"\n    Generate docstrings for all Python files in a directory.\n\n    Args:\n        root: Root directory\n        write: Whether to write changes to files\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        Tuple of (files_with_missing, total_missing)\n    \"\"\"\n    all_suggestions: List[DocstringSuggestion] = []\n    files_with_missing = 0\n\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        suggestions = analyze_file_for_docstrings(path)\n        if suggestions:\n            files_with_missing += 1\n            all_suggestions.extend(suggestions)\n\n            if write:\n                # Group suggestions by file\n                modified = add_docstrings_to_file(path, suggestions)\n                ", "chunk_type": "function", "line_start": 373, "line_end": 410, "language": "python", "name": "generate_docstrings"}, "55362c6d5301_func_main": {"id": "55362c6d5301_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Docstring Generator\")\n\n    # Parse args\n    write = '--write' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Write mode: {'ON' if write else 'OFF (use --write to apply changes)'}\")\n\n    files_with_missing, total_missing = generate_docstrings(path, write=write)\n\n    print()\n    if total_missing > 0:\n        Console.warn(f\"Found {total_missing} missing docstrings in {files_with_missing} files\")\n        if write:\n            Console.ok(\"Docstrings have been added\")\n        else:\n            Console.info(\"Run with --write to add docstrings\")\n    else:\n        Console.ok(\"All functions and classes have docstrings\")\n\n    return 0 if tot", "chunk_type": "function", "line_start": 413, "line_end": 446, "language": "python", "name": "main"}, "55362c6d5301_func___init__": {"id": "55362c6d5301_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.suggestions: List[DocstringSuggestion] = []\n        self._class_stack: List[str] = []", "chunk_type": "function", "line_start": 232, "line_end": 236, "language": "python", "name": "__init__"}, "55362c6d5301_func__get_indent": {"id": "55362c6d5301_func__get_indent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def _get_indent(self, lineno: int) -> str:\n        \"\"\"Get the indentation of a line.\"\"\"\n        if lineno <= 0 or lineno > len(self.source_lines):\n            return \"    \"\n        line = self.source_lines[lineno - 1]\n        return line[:len(line) - len(line.lstrip())]", "chunk_type": "function", "line_start": 238, "line_end": 243, "language": "python", "name": "_get_indent"}, "55362c6d5301_func_visit_FunctionDef": {"id": "55362c6d5301_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 245, "line_end": 247, "language": "python", "name": "visit_FunctionDef"}, "55362c6d5301_func_visit_AsyncFunctionDef": {"id": "55362c6d5301_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 249, "line_end": 251, "language": "python", "name": "visit_AsyncFunctionDef"}, "55362c6d5301_func__check_function": {"id": "55362c6d5301_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def _check_function(self, node: ast.FunctionDef | ast.AsyncFunctionDef):\n        \"\"\"Check if a function needs a docstring.\"\"\"\n        # Skip private and dunder methods\n        if node.name.startswith('__') and node.name.endswith('__'):\n            return\n\n        # Check if docstring exists\n        if ast.get_docstring(node):\n            return\n\n        # Get indentation for the docstring\n        body_indent = self._get_indent(node.lineno) + \"    \"\n\n        # Generate docstring\n        docstring = generate_function_docstring(node, body_indent)\n\n        node_type = 'method' if self._class_stack else 'function'\n\n        self.suggestions.append(DocstringSuggestion(\n            path=self.path,\n            name=node.name,\n            lineno=node.lineno,\n            node_type=node_type,\n            docstring=docstring,\n            indent=body_indent\n        ))", "chunk_type": "function", "line_start": 253, "line_end": 278, "language": "python", "name": "_check_function"}, "55362c6d5301_func_visit_ClassDef": {"id": "55362c6d5301_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        \"\"\"Check if a class needs a docstring.\"\"\"\n        # Skip private classes\n        if node.name.startswith('_'):\n            self.generic_visit(node)\n            return\n\n        # Check if docstring exists\n        if not ast.get_docstring(node):\n            body_indent = self._get_indent(node.lineno) + \"    \"\n            docstring = generate_class_docstring(node, body_indent)\n\n            self.suggestions.append(DocstringSuggestion(\n                path=self.path,\n                name=node.name,\n                lineno=node.lineno,\n                node_type='class',\n                docstring=docstring,\n                indent=body_indent\n            ))\n\n        # Visit methods\n        self._class_stack.append(node.name)\n        self.generic_visit(node)\n        self._class_stack.pop()", "chunk_type": "function", "line_start": 280, "line_end": 304, "language": "python", "name": "visit_ClassDef"}, "55362c6d5301_class_DocstringSuggestion": {"id": "55362c6d5301_class_DocstringSuggestion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "class DocstringSuggestion:\n    \"\"\"A suggested docstring for a function or class.\"\"\"\n    path: Path\n    name: str\n    lineno: int\n    node_type: str  # 'function', 'class', 'method'\n    docstring: str\n    indent: str", "chunk_type": "class", "line_start": 27, "line_end": 34, "language": "python", "name": "DocstringSuggestion"}, "55362c6d5301_class_DocstringAnalyzer": {"id": "55362c6d5301_class_DocstringAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_docs.py", "content": "class DocstringAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze a module for missing docstrings.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.suggestions: List[DocstringSuggestion] = []\n        self._class_stack: List[str] = []\n\n    def _get_indent(self, lineno: int) -> str:\n        \"\"\"Get the indentation of a line.\"\"\"\n        if lineno <= 0 or lineno > len(self.source_lines):\n            return \"    \"\n        line = self.source_lines[lineno - 1]\n        return line[:len(line) - len(line.lstrip())]\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node: ast.FunctionDef | ast.AsyncFunctionDef):\n        \"\"\"Check if a function needs a docstring.\"\"\"\n        # Ski", "chunk_type": "class", "line_start": 229, "line_end": 304, "language": "python", "name": "DocstringAnalyzer"}, "d1b9c003951d_file": {"id": "d1b9c003951d_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "\"\"\"\nAuto-Learning Integration\n=========================\nAutomatic recording of tool outcomes for continuous improvement.\n\nUsage:\n    Import and wrap tool functions for auto-learning.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any, Callable, Optional\nimport functools\nimport sys\nimport traceback\n\n# Import learning system\ntry:\n    from .learning import get_store, record_feedback, record_error as _record_error\nexcept ImportError:\n    # Fallback if not running as module\n    def record_feedback(*args, **kwargs): pass\n    def _record_error(*args, **kwargs): pass\n\n\ndef auto_learn(tool_name: str):\n    \"\"\"Decorator to auto-record tool outcomes.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper\n    return decorator\n\n\ndef record_error(\n    error_type: str,\n    pattern: str,\n    fix: str = \"\",\n    context: str = \"\"\n):\n    \"\"\"Record an error for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_error(error_type, pattern, fix, context)\n    except Exception:\n        pass  # Silent fail for learning\n\n\ndef record_correction(before: str, after: str, context: str = \"\"):\n    \"\"\"Record a user correction for learning.\"\"\"\n    try:\n        from .learning import get_sto", "chunk_type": "file", "line_start": 1, "line_end": 138, "language": "python", "name": "auto_learn.py"}, "d1b9c003951d_func_auto_learn": {"id": "d1b9c003951d_func_auto_learn", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def auto_learn(tool_name: str):\n    \"\"\"Decorator to auto-record tool outcomes.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper\n    return decorator", "chunk_type": "function", "line_start": 25, "line_end": 51, "language": "python", "name": "auto_learn"}, "d1b9c003951d_func_record_error": {"id": "d1b9c003951d_func_record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def record_error(\n    error_type: str,\n    pattern: str,\n    fix: str = \"\",\n    context: str = \"\"\n):\n    \"\"\"Record an error for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_error(error_type, pattern, fix, context)\n    except Exception:\n        pass  # Silent fail for learning", "chunk_type": "function", "line_start": 54, "line_end": 66, "language": "python", "name": "record_error"}, "d1b9c003951d_func_record_correction": {"id": "d1b9c003951d_func_record_correction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def record_correction(before: str, after: str, context: str = \"\"):\n    \"\"\"Record a user correction for learning.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        store.record_feedback(\n            action='correction',\n            outcome='applied',\n            context=f\"Before: {before[:50]}... After: {after[:50]}...\",\n            details={'before': before, 'after': after}\n        )\n    except Exception:\n        pass", "chunk_type": "function", "line_start": 69, "line_end": 81, "language": "python", "name": "record_correction"}, "d1b9c003951d_func_suggest_from_history": {"id": "d1b9c003951d_func_suggest_from_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def suggest_from_history(error_type: str, pattern: str) -> Optional[str]:\n    \"\"\"Get fix suggestion from learning history.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        return store.suggest_fix(error_type, pattern)\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 84, "line_end": 91, "language": "python", "name": "suggest_from_history"}, "d1b9c003951d_func_get_success_rate": {"id": "d1b9c003951d_func_get_success_rate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def get_success_rate(tool_name: str) -> float:\n    \"\"\"Get success rate for a tool.\"\"\"\n    try:\n        from .learning import get_store\n        store = get_store()\n        return store.get_action_success_rate(tool_name)\n    except Exception:\n        return 0.5  # Unknown", "chunk_type": "function", "line_start": 94, "line_end": 101, "language": "python", "name": "get_success_rate"}, "d1b9c003951d_func_main": {"id": "d1b9c003951d_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    from .utils import Console\n    Console.header(\"Auto-Learning Status\")\n\n    try:\n        from .learning import get_store\n        store = get_store()\n\n        analysis = store.analyze_patterns()\n\n        print(f\"\\nTotal feedback: {analysis['total_feedback']}\")\n        print(f\"Error patterns: {analysis['total_errors']}\")\n\n        print(\"\\n## Tool Success Rates\")\n        for action, data in analysis.get('action_outcomes', {}).items():\n            rate = data['success_rate'] * 100\n            status = \"\u2713\" if rate > 80 else \"!\" if rate > 50 else \"\u2717\"\n            print(f\"  {status} {action}: {rate:.0f}% ({data['count']} uses)\")\n\n        print(\"\\n## Common Errors\")\n        for err in analysis.get('common_errors', [])[:5]:\n            print(f\"  - [{err['type']}] {err['pattern'][:40]}...\")\n            if err.get('fix'):\n                print(f\"    Fix: {err['fix'][:40]}...\")\n\n    except Exception as e:\n        print(f\"Error loading learning data: {e}\")\n\n", "chunk_type": "function", "line_start": 104, "line_end": 133, "language": "python", "name": "main"}, "d1b9c003951d_func_decorator": {"id": "d1b9c003951d_func_decorator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise\n\n        return wrapper", "chunk_type": "function", "line_start": 27, "line_end": 50, "language": "python", "name": "decorator"}, "d1b9c003951d_func_record_feedback": {"id": "d1b9c003951d_func_record_feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def record_feedback(*args, **kwargs): pass", "chunk_type": "function", "line_start": 21, "line_end": 21, "language": "python", "name": "record_feedback"}, "d1b9c003951d_func__record_error": {"id": "d1b9c003951d_func__record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "    def _record_error(*args, **kwargs): pass", "chunk_type": "function", "line_start": 22, "line_end": 22, "language": "python", "name": "_record_error"}, "d1b9c003951d_func_wrapper": {"id": "d1b9c003951d_func_wrapper", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_learn.py", "content": "        def wrapper(*args, **kwargs) -> Any:\n            try:\n                result = func(*args, **kwargs)\n\n                # Record success\n                context = f\"args={args[:2]}\" if args else \"\"\n                record_feedback(tool_name, 'success', context)\n\n                return result\n            except Exception as e:\n                # Record failure\n                tb = traceback.format_exc()\n                record_error(\n                    error_type=type(e).__name__,\n                    pattern=str(e)[:100],\n                    fix=\"\",\n                    context=f\"Tool: {tool_name}\"\n                )\n                record_feedback(tool_name, 'failure', str(e)[:100])\n                raise", "chunk_type": "function", "line_start": 29, "line_end": 48, "language": "python", "name": "wrapper"}, "8987bf116e2c_file": {"id": "8987bf116e2c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "\"\"\"\nAuto-Test Generator\n===================\nAutomatically generate pytest test stubs for Python functions and classes.\n\nUsage:\n    python auto_test.py [path] [--output-dir tests/]\n    python -m scripts.auto_test [path]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    FunctionInfo,\n    ClassInfo,\n    Console\n)\n\n\n@dataclass\nclass TestSuite:\n    \"\"\"Generated test suite for a module.\"\"\"\n    module_path: Path\n    module_name: str\n    test_imports: List[str] = field(default_factory=list)\n    test_functions: List[str] = field(default_factory=list)\n    test_classes: List[str] = field(default_factory=list)\n\n\ndef generate_test_function(func: FunctionInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test function for a given function.\n\n    Args:\n        func: Function information\n        module_name: Name of the module containing the function\n\n    Returns:\n        Test function source code\n    \"\"\"\n    lines = []\n\n    # Generate test function name\n    test_name = f\"test_{func.name}\"\n\n    # Add docstring\n    lines.append(f\"def {test_name}():\")\n    lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Generate basic test structure\n    if func.args:\n        # Generate sample arguments\n        lines.append(\"    # Arrange\")\n        for arg in func.args:\n            if arg in ('self', 'cls'):\n                continue\n\n            arg_type = func.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"    {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"    # Act\")\n\n        # Generate function call\n        call_args = [a for a in func.args if a not in ('self', 'cls')]\n        if call_args:\n            args_str = \", \".join(call_args)\n            lines.append(f\"    result = {module_name}.{func.name}({ar", "chunk_type": "file", "line_start": 1, "line_end": 439, "language": "python", "name": "auto_test.py"}, "8987bf116e2c_func_generate_test_function": {"id": "8987bf116e2c_func_generate_test_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_function(func: FunctionInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test function for a given function.\n\n    Args:\n        func: Function information\n        module_name: Name of the module containing the function\n\n    Returns:\n        Test function source code\n    \"\"\"\n    lines = []\n\n    # Generate test function name\n    test_name = f\"test_{func.name}\"\n\n    # Add docstring\n    lines.append(f\"def {test_name}():\")\n    lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Generate basic test structure\n    if func.args:\n        # Generate sample arguments\n        lines.append(\"    # Arrange\")\n        for arg in func.args:\n            if arg in ('self', 'cls'):\n                continue\n\n            arg_type = func.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"    {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"    # Act\")\n\n        # Generate function call\n     ", "chunk_type": "function", "line_start": 38, "line_end": 98, "language": "python", "name": "generate_test_function"}, "8987bf116e2c_func_generate_edge_case_tests": {"id": "8987bf116e2c_func_generate_edge_case_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_edge_case_tests(func: FunctionInfo, module_name: str) -> List[str]:\n    \"\"\"\n    Generate edge case tests for a function.\n\n    Args:\n        func: Function information\n        module_name: Module name\n\n    Returns:\n        List of edge case test functions\n    \"\"\"\n    tests = []\n\n    for arg in func.args:\n        if arg in ('self', 'cls'):\n            continue\n\n        arg_type = func.arg_types.get(arg, '')\n\n        # Test with None if Optional\n        if 'Optional' in arg_type or 'None' in arg_type:\n            test_lines = [\n                f\"def test_{func.name}_with_{arg}_none():\",\n                f'    \"\"\"Test {func.name} with None {arg}.\"\"\"',\n                f\"    # This should handle None gracefully\",\n                f\"    try:\",\n                f\"        result = {module_name}.{func.name}({arg}=None)\",\n                f\"        # Assert expected behavior with None\",\n                f\"    except (TypeError, ValueError) as e:\",\n                f\"        pass  # Expecte", "chunk_type": "function", "line_start": 101, "line_end": 148, "language": "python", "name": "generate_edge_case_tests"}, "8987bf116e2c_func_generate_test_class": {"id": "8987bf116e2c_func_generate_test_class", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_class(cls: ClassInfo, module_name: str) -> str:\n    \"\"\"\n    Generate a pytest test class.\n\n    Args:\n        cls: Class information\n        module_name: Module name\n\n    Returns:\n        Test class source code\n    \"\"\"\n    lines = []\n\n    test_class_name = f\"Test{cls.name}\"\n\n    lines.append(f\"class {test_class_name}:\")\n    lines.append(f'    \"\"\"Tests for {cls.name} class.\"\"\"')\n    lines.append(\"\")\n\n    # Add fixture for class instance\n    lines.append(\"    @pytest.fixture\")\n    lines.append(\"    def instance(self):\")\n    lines.append(f'        \"\"\"Create a {cls.name} instance for testing.\"\"\"')\n    lines.append(f\"        return {module_name}.{cls.name}()  # TODO: Add constructor args\")\n    lines.append(\"\")\n\n    # Add test for instantiation\n    lines.append(\"    def test_instantiation(self):\")\n    lines.append(f'        \"\"\"Test {cls.name} can be instantiated.\"\"\"')\n    lines.append(f\"        obj = {module_name}.{cls.name}()  # TODO: Add constructor args\")\n    lines.append", "chunk_type": "function", "line_start": 151, "line_end": 193, "language": "python", "name": "generate_test_class"}, "8987bf116e2c_func__generate_method_test": {"id": "8987bf116e2c_func__generate_method_test", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _generate_method_test(method: FunctionInfo, class_name: str) -> List[str]:\n    \"\"\"Generate test for a class method.\"\"\"\n    lines = []\n\n    lines.append(f\"    def test_{method.name}(self, instance):\")\n    lines.append(f'        \"\"\"Test {class_name}.{method.name} method.\"\"\"')\n\n    # Generate method call\n    call_args = [a for a in method.args if a not in ('self', 'cls')]\n    if call_args:\n        lines.append(\"        # Arrange\")\n        for arg in call_args:\n            arg_type = method.arg_types.get(arg, '')\n            sample_value = _get_sample_value(arg, arg_type)\n            lines.append(f\"        {arg} = {sample_value}\")\n\n        lines.append(\"\")\n        lines.append(\"        # Act\")\n        args_str = \", \".join(call_args)\n        lines.append(f\"        result = instance.{method.name}({args_str})\")\n    else:\n        lines.append(\"        # Act\")\n        lines.append(f\"        result = instance.{method.name}()\")\n\n    lines.append(\"\")\n    lines.append(\"        # Assert\")\n    li", "chunk_type": "function", "line_start": 196, "line_end": 225, "language": "python", "name": "_generate_method_test"}, "8987bf116e2c_func__get_sample_value": {"id": "8987bf116e2c_func__get_sample_value", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _get_sample_value(arg_name: str, arg_type: str) -> str:\n    \"\"\"Get a sample value for a parameter.\"\"\"\n    type_lower = arg_type.lower()\n\n    if 'str' in type_lower:\n        return f'\"test_{arg_name}\"'\n    elif 'int' in type_lower:\n        return \"42\"\n    elif 'float' in type_lower:\n        return \"3.14\"\n    elif 'bool' in type_lower:\n        return \"True\"\n    elif 'list' in type_lower:\n        return \"[]\"\n    elif 'dict' in type_lower:\n        return \"{}\"\n    elif 'path' in type_lower or 'path' in arg_name.lower():\n        return 'Path(\".\")'\n    elif 'none' in type_lower:\n        return \"None\"\n    else:\n        # Try to infer from name\n        if 'path' in arg_name.lower():\n            return 'Path(\".\")'\n        elif 'name' in arg_name.lower():\n            return '\"test_name\"'\n        elif 'id' in arg_name.lower():\n            return '\"test_id\"'\n        elif 'count' in arg_name.lower() or 'num' in arg_name.lower():\n            return \"10\"\n        elif 'flag' in arg_name.lower() or ", "chunk_type": "function", "line_start": 228, "line_end": 261, "language": "python", "name": "_get_sample_value"}, "8987bf116e2c_func__generate_assertion": {"id": "8987bf116e2c_func__generate_assertion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def _generate_assertion(return_type: str) -> str:\n    \"\"\"Generate an assertion based on return type.\"\"\"\n    type_lower = return_type.lower()\n\n    if 'bool' in type_lower:\n        return \"assert isinstance(result, bool)\"\n    elif 'str' in type_lower:\n        return \"assert isinstance(result, str)\"\n    elif 'int' in type_lower:\n        return \"assert isinstance(result, int)\"\n    elif 'float' in type_lower:\n        return \"assert isinstance(result, (int, float))\"\n    elif 'list' in type_lower:\n        return \"assert isinstance(result, list)\"\n    elif 'dict' in type_lower:\n        return \"assert isinstance(result, dict)\"\n    elif 'none' in type_lower:\n        return \"assert result is None\"\n    elif 'optional' in type_lower:\n        return \"# Result may be None\"\n    else:\n        return \"assert result is not None  # TODO: Add specific assertion\"", "chunk_type": "function", "line_start": 264, "line_end": 285, "language": "python", "name": "_generate_assertion"}, "8987bf116e2c_func_generate_test_file": {"id": "8987bf116e2c_func_generate_test_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_test_file(module_path: Path, output_dir: Path = None) -> Optional[Path]:\n    \"\"\"\n    Generate a test file for a Python module.\n\n    Args:\n        module_path: Path to the module\n        output_dir: Output directory for test files\n\n    Returns:\n        Path to generated test file, or None if no tests generated\n    \"\"\"\n    module_info = analyze_module(module_path)\n    if module_info is None:\n        return None\n\n    # Skip if no public functions or classes\n    public_functions = [f for f in module_info.functions if not f.name.startswith('_')]\n    public_classes = [c for c in module_info.classes if not c.name.startswith('_')]\n\n    if not public_functions and not public_classes:\n        return None\n\n    # Generate module name\n    module_name = module_path.stem\n\n    # Build test file content\n    lines = [\n        '\"\"\"',\n        f'Tests for {module_name} module.',\n        '\"\"\"',\n        '',\n        'import pytest',\n        'from pathlib import Path',\n        '',\n        f'# Impo", "chunk_type": "function", "line_start": 288, "line_end": 363, "language": "python", "name": "generate_test_file"}, "8987bf116e2c_func_generate_tests": {"id": "8987bf116e2c_func_generate_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def generate_tests(\n    root: Path,\n    output_dir: Path = None,\n    exclude_patterns: List[str] = None\n) -> int:\n    \"\"\"\n    Generate tests for all Python files in a directory.\n\n    Args:\n        root: Root directory\n        output_dir: Output directory for tests\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        Number of test files generated\n    \"\"\"\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    generated = 0\n\n    for path in files:\n        # Skip test files\n        if path.name.startswith('test_') or 'tests' in path.parts:\n            continue\n\n        test_path = generate_test_file(path, output_dir)\n        if test_path:\n            Console.ok(f\"Generated: {test_path}\")\n            generated += 1\n\n    return generated", "chunk_type": "function", "line_start": 366, "line_end": 399, "language": "python", "name": "generate_tests"}, "8987bf116e2c_func_main": {"id": "8987bf116e2c_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Test Generator\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_dir = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output-dir' and i + 1 < len(sys.argv):\n            output_dir = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    generated = generate_tests(path, output_dir)\n\n    print()\n    if generated > 0:\n        Console.ok(f\"Generated {generated} test files\")\n    else:\n        Console.info(\"No new test files generated (all modules already have tests or no public code found)\")\n\n    return 0", "chunk_type": "function", "line_start": 402, "line_end": 434, "language": "python", "name": "main"}, "8987bf116e2c_class_TestSuite": {"id": "8987bf116e2c_class_TestSuite", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\auto_test.py", "content": "class TestSuite:\n    \"\"\"Generated test suite for a module.\"\"\"\n    module_path: Path\n    module_name: str\n    test_imports: List[str] = field(default_factory=list)\n    test_functions: List[str] = field(default_factory=list)\n    test_classes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 29, "line_end": 35, "language": "python", "name": "TestSuite"}, "955668a2e97f_file": {"id": "955668a2e97f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "\"\"\"\nChangelog Generator\n===================\nAuto-generate changelogs from git commits using conventional commit format.\n\nUsage:\n    python changelog.py [--since v1.0.0] [--output CHANGELOG.md]\n    python -m scripts.changelog\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport re\nimport sys\n\nfrom .utils import (\n    find_project_root,\n    get_git_log,\n    run_git_command,\n    GitCommit,\n    Console\n)\n\n\n@dataclass\nclass ChangelogEntry:\n    \"\"\"A single changelog entry.\"\"\"\n    commit_type: str\n    scope: Optional[str]\n    description: str\n    commit_hash: str\n    breaking: bool = False\n    issues: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ChangelogVersion:\n    \"\"\"A version section in the changelog.\"\"\"\n    version: str\n    date: str\n    entries: Dict[str, List[ChangelogEntry]] = field(default_factory=lambda: defaultdict(list))\n    breaking_changes: List[str] = field(default_factory=list)\n\n\n# Conventional commit types\nCOMMIT_TYPES = {\n    'feat': 'Features',\n    'fix': 'Bug Fixes',\n    'docs': 'Documentation',\n    'style': 'Styles',\n    'refactor': 'Code Refactoring',\n    'perf': 'Performance Improvements',\n    'test': 'Tests',\n    'build': 'Build System',\n    'ci': 'CI/CD',\n    'chore': 'Chores',\n    'revert': 'Reverts',\n}\n\n# Regex for parsing conventional commits\nCONVENTIONAL_COMMIT_PATTERN = re.compile(\n    r'^(?P<type>feat|fix|docs|style|refactor|perf|test|build|ci|chore|revert)'\n    r'(?:\\((?P<scope>[^)]+)\\))?'\n    r'(?P<breaking>!)?'\n    r':\\s*'\n    r'(?P<description>.+)$',\n    re.IGNORECASE\n)\n\n# Pattern for issue references\nISSUE_PATTERN = re.compile(r'#(\\d+)')\n\n\ndef parse_commit_message(message: str) -> Optional[ChangelogEntry]:\n    \"\"\"\n    Parse a conventional commit message.\n\n    Args:\n        message: Commit message\n\n    Returns:\n        ChangelogEntry or None if not conventional format\n    \"\"\"\n    match = CONVENTIONAL_COMMIT_PATTERN.mat", "chunk_type": "file", "line_start": 1, "line_end": 368, "language": "python", "name": "changelog.py"}, "955668a2e97f_func_parse_commit_message": {"id": "955668a2e97f_func_parse_commit_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def parse_commit_message(message: str) -> Optional[ChangelogEntry]:\n    \"\"\"\n    Parse a conventional commit message.\n\n    Args:\n        message: Commit message\n\n    Returns:\n        ChangelogEntry or None if not conventional format\n    \"\"\"\n    match = CONVENTIONAL_COMMIT_PATTERN.match(message.strip())\n    if not match:\n        return None\n\n    groups = match.groupdict()\n\n    # Extract issue references\n    issues = ISSUE_PATTERN.findall(message)\n\n    return ChangelogEntry(\n        commit_type=groups['type'].lower(),\n        scope=groups['scope'],\n        description=groups['description'].strip(),\n        commit_hash=\"\",  # Will be set later\n        breaking=bool(groups['breaking']),\n        issues=issues\n    )", "chunk_type": "function", "line_start": 76, "line_end": 102, "language": "python", "name": "parse_commit_message"}, "955668a2e97f_func_get_git_tags": {"id": "955668a2e97f_func_get_git_tags", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def get_git_tags() -> List[Tuple[str, str]]:\n    \"\"\"Get all git tags with their dates.\"\"\"\n    output = run_git_command(['tag', '-l', '--format=%(refname:short)|%(creatordate:short)'])\n    if not output:\n        return []\n\n    tags = []\n    for line in output.split('\\n'):\n        if '|' in line:\n            tag, date = line.split('|', 1)\n            tags.append((tag.strip(), date.strip()))\n\n    return tags", "chunk_type": "function", "line_start": 105, "line_end": 117, "language": "python", "name": "get_git_tags"}, "955668a2e97f_func_get_commits_since_tag": {"id": "955668a2e97f_func_get_commits_since_tag", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def get_commits_since_tag(tag: str = None, cwd: Path = None) -> List[GitCommit]:\n    \"\"\"Get commits since a specific tag.\"\"\"\n    if tag:\n        args = ['log', f'{tag}..HEAD', '--format=%H|%h|%an|%ai|%s|%b', '--no-merges']\n    else:\n        args = ['log', '--format=%H|%h|%an|%ai|%s|%b', '--no-merges', '-100']\n\n    output = run_git_command(args, cwd=cwd)\n    if not output:\n        return []\n\n    commits = []\n    for entry in output.split('\\n'):\n        if not entry.strip():\n            continue\n\n        parts = entry.split('|')\n        if len(parts) >= 5:\n            commits.append(GitCommit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                date=parts[3],\n                message=parts[4],\n                body=parts[5] if len(parts) > 5 else \"\"\n            ))\n\n    return commits", "chunk_type": "function", "line_start": 120, "line_end": 147, "language": "python", "name": "get_commits_since_tag"}, "955668a2e97f_func_generate_changelog": {"id": "955668a2e97f_func_generate_changelog", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def generate_changelog(\n    cwd: Path = None,\n    since_tag: str = None,\n    version: str = \"Unreleased\"\n) -> ChangelogVersion:\n    \"\"\"\n    Generate changelog from git commits.\n\n    Args:\n        cwd: Working directory\n        since_tag: Tag to start from\n        version: Version number for this release\n\n    Returns:\n        ChangelogVersion object\n    \"\"\"\n    commits = get_commits_since_tag(since_tag, cwd)\n\n    import datetime\n    changelog = ChangelogVersion(\n        version=version,\n        date=datetime.datetime.now().strftime('%Y-%m-%d')\n    )\n\n    for commit in commits:\n        entry = parse_commit_message(commit.message)\n        if entry:\n            entry.commit_hash = commit.short_hash\n\n            # Add to appropriate category\n            changelog.entries[entry.commit_type].append(entry)\n\n            # Track breaking changes\n            if entry.breaking or 'BREAKING CHANGE' in commit.body:\n                changelog.breaking_changes.append(\n                    f\"{entry.descr", "chunk_type": "function", "line_start": 150, "line_end": 197, "language": "python", "name": "generate_changelog"}, "955668a2e97f_func_format_changelog_markdown": {"id": "955668a2e97f_func_format_changelog_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def format_changelog_markdown(\n    changelog: ChangelogVersion,\n    include_hash: bool = True,\n    repo_url: str = None\n) -> str:\n    \"\"\"\n    Format changelog as Markdown.\n\n    Args:\n        changelog: ChangelogVersion object\n        include_hash: Whether to include commit hashes\n        repo_url: Repository URL for linking\n\n    Returns:\n        Markdown formatted changelog\n    \"\"\"\n    lines = [\n        f\"## [{changelog.version}] - {changelog.date}\",\n        \"\",\n    ]\n\n    # Breaking changes first\n    if changelog.breaking_changes:\n        lines.extend([\n            \"### BREAKING CHANGES\",\n            \"\",\n        ])\n        for change in changelog.breaking_changes:\n            lines.append(f\"- {change}\")\n        lines.append(\"\")\n\n    # Categorized changes\n    category_order = ['feat', 'fix', 'perf', 'refactor', 'docs', 'test', 'build', 'ci', 'chore', 'other']\n\n    for category in category_order:\n        entries = changelog.entries.get(category, [])\n        if not entries:\n            c", "chunk_type": "function", "line_start": 200, "line_end": 273, "language": "python", "name": "format_changelog_markdown"}, "955668a2e97f_func_update_changelog_file": {"id": "955668a2e97f_func_update_changelog_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def update_changelog_file(\n    changelog_path: Path,\n    new_content: str,\n    prepend: bool = True\n) -> None:\n    \"\"\"\n    Update a changelog file with new content.\n\n    Args:\n        changelog_path: Path to CHANGELOG.md\n        new_content: New content to add\n        prepend: Whether to prepend (True) or append\n    \"\"\"\n    header = \"# Changelog\\n\\nAll notable changes to this project will be documented in this file.\\n\\n\"\n\n    if changelog_path.exists():\n        with open(changelog_path, 'r', encoding='utf-8') as f:\n            existing = f.read()\n\n        # Remove header if present\n        if existing.startswith(\"# Changelog\"):\n            lines = existing.split('\\n')\n            # Find first version heading\n            for i, line in enumerate(lines):\n                if line.startswith('## '):\n                    existing = '\\n'.join(lines[i:])\n                    break\n\n        if prepend:\n            content = header + new_content + \"\\n\" + existing\n        else:\n            content ", "chunk_type": "function", "line_start": 276, "line_end": 312, "language": "python", "name": "update_changelog_file"}, "955668a2e97f_func_main": {"id": "955668a2e97f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Changelog Generator\")\n\n    # Parse args\n    since_tag = None\n    output_file = None\n    version = \"Unreleased\"\n\n    args = sys.argv[1:]\n    i = 0\n    while i < len(args):\n        if args[i] == '--since' and i + 1 < len(args):\n            since_tag = args[i + 1]\n            i += 2\n        elif args[i] == '--output' and i + 1 < len(args):\n            output_file = Path(args[i + 1])\n            i += 2\n        elif args[i] == '--version' and i + 1 < len(args):\n            version = args[i + 1]\n            i += 2\n        else:\n            i += 1\n\n    # Find project root\n    cwd = find_project_root() or Path.cwd()\n\n    Console.info(f\"Analyzing: {cwd}\")\n    if since_tag:\n        Console.info(f\"Since tag: {since_tag}\")\n\n    # Generate changelog\n    changelog = generate_changelog(cwd, since_tag, version)\n\n    # Count entries\n    total_entries = sum(len(entries) for entries in changelog.entries.values())\n    Console.info(f\"Found {total_e", "chunk_type": "function", "line_start": 315, "line_end": 363, "language": "python", "name": "main"}, "955668a2e97f_class_ChangelogEntry": {"id": "955668a2e97f_class_ChangelogEntry", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "class ChangelogEntry:\n    \"\"\"A single changelog entry.\"\"\"\n    commit_type: str\n    scope: Optional[str]\n    description: str\n    commit_hash: str\n    breaking: bool = False\n    issues: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 28, "line_end": 35, "language": "python", "name": "ChangelogEntry"}, "955668a2e97f_class_ChangelogVersion": {"id": "955668a2e97f_class_ChangelogVersion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\changelog.py", "content": "class ChangelogVersion:\n    \"\"\"A version section in the changelog.\"\"\"\n    version: str\n    date: str\n    entries: Dict[str, List[ChangelogEntry]] = field(default_factory=lambda: defaultdict(list))\n    breaking_changes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 39, "line_end": 44, "language": "python", "name": "ChangelogVersion"}, "3ab57bedf970_file": {"id": "3ab57bedf970_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "\"\"\"\nCI/CD Pipeline Generator\n========================\nGenerate CI/CD pipelines for various providers.\n\nUsage:\n    python mcp.py github-action\n    python mcp.py pipeline --gitlab\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ProjectType:\n    \"\"\"Detected project type.\"\"\"\n    language: str\n    framework: Optional[str]\n    package_manager: str\n    test_command: str\n    lint_command: str\n    has_docker: bool\n\n\n# GitHub Actions Templates\nGITHUB_PYTHON = '''name: Python CI\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: ['3.11']\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install pytest pytest-cov flake8 mypy\n\n    - name: Lint with flake8\n      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n\n    - name: Type check with mypy\n      run: mypy . --ignore-missing-imports || true\n\n    - name: Test with pytest\n      run: pytest --cov=. --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        files: ./coverage.xml\n'''\n\nGITHUB_NODE = '''name: Node.js CI\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: ['18.x', '20.x']\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ matrix.node-version }}\n ", "chunk_type": "file", "line_start": 1, "line_end": 369, "language": "python", "name": "cicd.py"}, "3ab57bedf970_func_detect_project_type": {"id": "3ab57bedf970_func_detect_project_type", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def detect_project_type(root: Path) -> ProjectType:\n    \"\"\"Detect project type from files.\"\"\"\n    # Check for Python\n    has_requirements = (root / 'requirements.txt').exists()\n    has_setup_py = (root / 'setup.py').exists()\n    has_pyproject = (root / 'pyproject.toml').exists()\n\n    # Check for Node\n    has_package_json = (root / 'package.json').exists()\n\n    # Check for Docker\n    has_docker = (root / 'Dockerfile').exists()\n\n    if has_requirements or has_setup_py or has_pyproject:\n        framework = None\n        if has_pyproject:\n            content = (root / 'pyproject.toml').read_text()\n            if 'fastapi' in content.lower():\n                framework = 'fastapi'\n            elif 'django' in content.lower():\n                framework = 'django'\n            elif 'flask' in content.lower():\n                framework = 'flask'\n\n        return ProjectType(\n            language='python',\n            framework=framework,\n            package_manager='pip',\n            test_command=", "chunk_type": "function", "line_start": 220, "line_end": 284, "language": "python", "name": "detect_project_type"}, "3ab57bedf970_func_generate_github_action": {"id": "3ab57bedf970_func_generate_github_action", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def generate_github_action(project_type: ProjectType) -> str:\n    \"\"\"Generate GitHub Actions workflow.\"\"\"\n    if project_type.has_docker:\n        return GITHUB_DOCKER\n\n    if project_type.language == 'python':\n        return GITHUB_PYTHON\n\n    if project_type.language == 'node':\n        return GITHUB_NODE\n\n    return GITHUB_PYTHON  # Default", "chunk_type": "function", "line_start": 287, "line_end": 298, "language": "python", "name": "generate_github_action"}, "3ab57bedf970_func_generate_gitlab_ci": {"id": "3ab57bedf970_func_generate_gitlab_ci", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def generate_gitlab_ci(project_type: ProjectType) -> str:\n    \"\"\"Generate GitLab CI config.\"\"\"\n    if project_type.language == 'python':\n        return GITLAB_PYTHON\n\n    if project_type.language == 'node':\n        return GITLAB_NODE\n\n    return GITLAB_PYTHON  # Default", "chunk_type": "function", "line_start": 301, "line_end": 309, "language": "python", "name": "generate_gitlab_ci"}, "3ab57bedf970_func_write_github_action": {"id": "3ab57bedf970_func_write_github_action", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def write_github_action(root: Path) -> Path:\n    \"\"\"Write GitHub Actions workflow to file.\"\"\"\n    project_type = detect_project_type(root)\n    content = generate_github_action(project_type)\n\n    workflow_dir = root / '.github' / 'workflows'\n    workflow_dir.mkdir(parents=True, exist_ok=True)\n\n    workflow_file = workflow_dir / 'ci.yml'\n    workflow_file.write_text(content)\n\n    return workflow_file", "chunk_type": "function", "line_start": 312, "line_end": 323, "language": "python", "name": "write_github_action"}, "3ab57bedf970_func_write_gitlab_ci": {"id": "3ab57bedf970_func_write_gitlab_ci", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def write_gitlab_ci(root: Path) -> Path:\n    \"\"\"Write GitLab CI config to file.\"\"\"\n    project_type = detect_project_type(root)\n    content = generate_gitlab_ci(project_type)\n\n    ci_file = root / '.gitlab-ci.yml'\n    ci_file.write_text(content)\n\n    return ci_file", "chunk_type": "function", "line_start": 326, "line_end": 334, "language": "python", "name": "write_gitlab_ci"}, "3ab57bedf970_func_main": {"id": "3ab57bedf970_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"CI/CD Generator\")\n\n    root = find_project_root() or Path.cwd()\n    project_type = detect_project_type(root)\n\n    Console.info(f\"Detected: {project_type.language}\")\n    if project_type.framework:\n        Console.info(f\"Framework: {project_type.framework}\")\n    if project_type.has_docker:\n        Console.info(\"Docker: Yes\")\n\n    if '--gitlab' in sys.argv:\n        path = write_gitlab_ci(root)\n        Console.ok(f\"Generated: {path}\")\n        return 0\n\n    if '--print' in sys.argv:\n        content = generate_github_action(project_type)\n        print(content)\n        return 0\n\n    # Default: GitHub Actions\n    path = write_github_action(root)\n    Console.ok(f\"Generated: {path}\")\n\n    return 0", "chunk_type": "function", "line_start": 337, "line_end": 364, "language": "python", "name": "main"}, "3ab57bedf970_class_ProjectType": {"id": "3ab57bedf970_class_ProjectType", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cicd.py", "content": "class ProjectType:\n    \"\"\"Detected project type.\"\"\"\n    language: str\n    framework: Optional[str]\n    package_manager: str\n    test_command: str\n    lint_command: str\n    has_docker: bool", "chunk_type": "class", "line_start": 21, "line_end": 28, "language": "python", "name": "ProjectType"}, "13d4cc6109b8_file": {"id": "13d4cc6109b8_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "\"\"\"\nConfig Index\n=============\nIndex configuration files, env vars, and settings.\n\nUsage:\n    python mcp.py config-index\n    python mcp.py config-index --env\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport json\nimport os\nimport re\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass ConfigItem:\n    \"\"\"A configuration item.\"\"\"\n    name: str\n    value: Optional[str]\n    source: str  # file path\n    type: str  # 'env', 'json', 'yaml', 'ini', 'toml'\n    line: int = 0\n\n\n# Patterns for finding env var usage in code\nENV_PATTERNS = [\n    r'os\\.environ\\[[\\'\"]([\\w_]+)[\\'\"]\\]',\n    r'os\\.environ\\.get\\([\\'\"]([\\w_]+)[\\'\"]',\n    r'os\\.getenv\\([\\'\"]([\\w_]+)[\\'\"]',\n    r'config\\[[\\'\"]([\\w_]+)[\\'\"]\\]',\n    r'settings\\.([\\w_]+)',\n    r'process\\.env\\.([\\w_]+)',\n    r'\\$\\{([\\w_]+)\\}',\n]\n\n\ndef find_config_files(root: Path) -> List[Path]:\n    \"\"\"Find configuration files.\"\"\"\n    patterns = [\n        '.env', '.env.*', 'config.json', 'config.yaml', 'config.yml',\n        'settings.json', 'settings.yaml', 'settings.yml', 'settings.py',\n        'pyproject.toml', 'setup.cfg', 'requirements.txt',\n        'package.json', 'tsconfig.json',\n        '*.ini', '*.toml', '*.conf'\n    ]\n\n    files = []\n\n    for pattern in patterns:\n        for path in root.glob(pattern):\n            if path.is_file() and '.git' not in str(path):\n                files.append(path)\n        for path in root.glob(f'**/{pattern}'):\n            if path.is_file() and '.git' not in str(path) and 'node_modules' not in str(path):\n                files.append(path)\n\n    return list(set(files))\n\n\ndef parse_env_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse .env file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    if '=' in line:\n        ", "chunk_type": "file", "line_start": 1, "line_end": 247, "language": "python", "name": "config_index.py"}, "13d4cc6109b8_func_find_config_files": {"id": "13d4cc6109b8_func_find_config_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def find_config_files(root: Path) -> List[Path]:\n    \"\"\"Find configuration files.\"\"\"\n    patterns = [\n        '.env', '.env.*', 'config.json', 'config.yaml', 'config.yml',\n        'settings.json', 'settings.yaml', 'settings.yml', 'settings.py',\n        'pyproject.toml', 'setup.cfg', 'requirements.txt',\n        'package.json', 'tsconfig.json',\n        '*.ini', '*.toml', '*.conf'\n    ]\n\n    files = []\n\n    for pattern in patterns:\n        for path in root.glob(pattern):\n            if path.is_file() and '.git' not in str(path):\n                files.append(path)\n        for path in root.glob(f'**/{pattern}'):\n            if path.is_file() and '.git' not in str(path) and 'node_modules' not in str(path):\n                files.append(path)\n\n    return list(set(files))", "chunk_type": "function", "line_start": 44, "line_end": 64, "language": "python", "name": "find_config_files"}, "13d4cc6109b8_func_parse_env_file": {"id": "13d4cc6109b8_func_parse_env_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def parse_env_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse .env file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for i, line in enumerate(f, 1):\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    if '=' in line:\n                        name, _, value = line.partition('=')\n                        items.append(ConfigItem(\n                            name=name.strip(),\n                            value=value.strip().strip('\"\\''),\n                            source=str(file_path),\n                            type='env',\n                            line=i\n                        ))\n    except Exception:\n        pass\n\n    return items", "chunk_type": "function", "line_start": 67, "line_end": 88, "language": "python", "name": "parse_env_file"}, "13d4cc6109b8_func_parse_json_file": {"id": "13d4cc6109b8_func_parse_json_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def parse_json_file(file_path: Path) -> List[ConfigItem]:\n    \"\"\"Parse JSON config file.\"\"\"\n    items = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n\n        def extract(obj, prefix=''):\n            for key, value in obj.items() if isinstance(obj, dict) else []:\n                full_key = f\"{prefix}.{key}\" if prefix else key\n                if isinstance(value, dict):\n                    extract(value, full_key)\n                else:\n                    items.append(ConfigItem(\n                        name=full_key,\n                        value=str(value)[:50] if value is not None else None,\n                        source=str(file_path),\n                        type='json'\n                    ))\n\n        extract(data)\n    except Exception:\n        pass\n\n    return items", "chunk_type": "function", "line_start": 91, "line_end": 116, "language": "python", "name": "parse_json_file"}, "13d4cc6109b8_func_find_env_usage_in_file": {"id": "13d4cc6109b8_func_find_env_usage_in_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def find_env_usage_in_file(file_path: Path) -> Set[str]:\n    \"\"\"Find env var usage in a code file.\"\"\"\n    env_vars = set()\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n\n        for pattern in ENV_PATTERNS:\n            matches = re.findall(pattern, content)\n            env_vars.update(matches)\n    except Exception:\n        pass\n\n    return env_vars", "chunk_type": "function", "line_start": 119, "line_end": 133, "language": "python", "name": "find_env_usage_in_file"}, "13d4cc6109b8_func_index_configs": {"id": "13d4cc6109b8_func_index_configs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def index_configs(root: Path = None) -> Dict:\n    \"\"\"Build configuration index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Indexing configuration...\")\n\n    index = {\n        \"config_files\": [],\n        \"env_vars\": {},\n        \"env_usage\": {},\n        \"missing_vars\": []\n    }\n\n    # Find and parse config files\n    config_files = find_config_files(root)\n\n    for config_path in config_files:\n        index[\"config_files\"].append(str(config_path.relative_to(root)))\n\n        if config_path.name.startswith('.env'):\n            items = parse_env_file(config_path)\n            for item in items:\n                index[\"env_vars\"][item.name] = {\n                    \"source\": item.source,\n                    \"has_value\": item.value is not None and item.value != ''\n                }\n        elif config_path.suffix == '.json':\n            items = parse_json_file(config_path)\n\n    # Find env var usage in code\n    all_used = set()\n    extensions = ['.py', '.js', '.ts']\n\n", "chunk_type": "function", "line_start": 136, "line_end": 196, "language": "python", "name": "index_configs"}, "13d4cc6109b8_func_get_env_vars_for_file": {"id": "13d4cc6109b8_func_get_env_vars_for_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def get_env_vars_for_file(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Get env vars used by a specific file.\"\"\"\n    return list(find_env_usage_in_file(file_path))", "chunk_type": "function", "line_start": 199, "line_end": 201, "language": "python", "name": "get_env_vars_for_file"}, "13d4cc6109b8_func_main": {"id": "13d4cc6109b8_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Config Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_configs(root)\n        return 0\n\n    if '--env' in sys.argv:\n        index = index_configs(root)\n        print(\"\\n## Defined Environment Variables\")\n        for name, info in index[\"env_vars\"].items():\n            status = \"\u2713\" if info[\"has_value\"] else \"\u2717\"\n            print(f\"  {status} {name}\")\n        return 0\n\n    if '--missing' in sys.argv:\n        index = index_configs(root)\n        if index[\"missing_vars\"]:\n            Console.warn(\"Used but not defined:\")\n            for var in index[\"missing_vars\"]:\n                print(f\"  - {var}\")\n        else:\n            Console.ok(\"All used env vars are defined!\")\n        return 0\n\n    if args:\n        file_path = Path(args[0])\n        vars_used = get_env_vars_for_file(file_path)\n        Console.info(f\"Env vars used", "chunk_type": "function", "line_start": 204, "line_end": 242, "language": "python", "name": "main"}, "13d4cc6109b8_func_extract": {"id": "13d4cc6109b8_func_extract", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "        def extract(obj, prefix=''):\n            for key, value in obj.items() if isinstance(obj, dict) else []:\n                full_key = f\"{prefix}.{key}\" if prefix else key\n                if isinstance(value, dict):\n                    extract(value, full_key)\n                else:\n                    items.append(ConfigItem(\n                        name=full_key,\n                        value=str(value)[:50] if value is not None else None,\n                        source=str(file_path),\n                        type='json'\n                    ))", "chunk_type": "function", "line_start": 99, "line_end": 110, "language": "python", "name": "extract"}, "13d4cc6109b8_class_ConfigItem": {"id": "13d4cc6109b8_class_ConfigItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\config_index.py", "content": "class ConfigItem:\n    \"\"\"A configuration item.\"\"\"\n    name: str\n    value: Optional[str]\n    source: str  # file path\n    type: str  # 'env', 'json', 'yaml', 'ini', 'toml'\n    line: int = 0", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "ConfigItem"}, "baaf0f010cae_file": {"id": "baaf0f010cae_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "\"\"\"\nSmart Context Loader\n====================\nExtract relevant context from codebases for AI agents with token budgets.\n\nUsage:\n    python context.py \"query\" [path] [--tokens 4000]\n    python -m scripts.context \"authentication\" src/\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport math\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    get_changed_files,\n    run_git_command,\n    Console\n)\n\n\n@dataclass\nclass ContextItem:\n    \"\"\"A piece of context from the codebase.\"\"\"\n    path: Path\n    content: str\n    relevance_score: float\n    item_type: str  # 'function', 'class', 'file', 'docstring'\n    line_start: int\n    line_end: int\n    tokens: int  # Estimated token count\n\n\n@dataclass\nclass ContextResult:\n    \"\"\"Result of context extraction.\"\"\"\n    query: str\n    items: List[ContextItem] = field(default_factory=list)\n    total_tokens: int = 0\n    files_scanned: int = 0\n\n    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)\n\n\ndef estimate_tokens(text: str) -> int:\n    \"\"\"Estimate token count (rough: 4 chars per token).\"\"\"\n    return len(text) // 4\n\n\ndef tokenize_query(query: str) -> List[str]:\n    \"\"\"Tokenize query into searchable terms", "chunk_type": "file", "line_start": 1, "line_end": 382, "language": "python", "name": "context.py"}, "baaf0f010cae_func_estimate_tokens": {"id": "baaf0f010cae_func_estimate_tokens", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def estimate_tokens(text: str) -> int:\n    \"\"\"Estimate token count (rough: 4 chars per token).\"\"\"\n    return len(text) // 4", "chunk_type": "function", "line_start": 76, "line_end": 78, "language": "python", "name": "estimate_tokens"}, "baaf0f010cae_func_tokenize_query": {"id": "baaf0f010cae_func_tokenize_query", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def tokenize_query(query: str) -> List[str]:\n    \"\"\"Tokenize query into searchable terms.\"\"\"\n    # Convert to lowercase and split on non-alphanumeric\n    terms = re.findall(r'[a-z0-9]+', query.lower())\n\n    # Expand common abbreviations\n    expansions = {\n        'auth': ['authentication', 'authorize', 'authorization'],\n        'db': ['database', 'connection'],\n        'api': ['endpoint', 'route', 'handler'],\n        'cfg': ['config', 'configuration', 'settings'],\n        'msg': ['message', 'notification'],\n        'err': ['error', 'exception'],\n        'req': ['request', 'require'],\n        'res': ['response', 'result'],\n    }\n\n    expanded = list(terms)\n    for term in terms:\n        if term in expansions:\n            expanded.extend(expansions[term])\n\n    return expanded", "chunk_type": "function", "line_start": 81, "line_end": 103, "language": "python", "name": "tokenize_query"}, "baaf0f010cae_func_calculate_tf_idf": {"id": "baaf0f010cae_func_calculate_tf_idf", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def calculate_tf_idf(\n    terms: List[str],\n    document: str,\n    all_documents: List[str]\n) -> float:\n    \"\"\"Calculate TF-IDF relevance score.\"\"\"\n    doc_lower = document.lower()\n\n    # Term frequency in this document\n    tf_scores = []\n    for term in terms:\n        tf = doc_lower.count(term)\n        if tf > 0:\n            tf_scores.append(1 + math.log(tf))\n        else:\n            tf_scores.append(0)\n\n    if not tf_scores or sum(tf_scores) == 0:\n        return 0.0\n\n    # Inverse document frequency\n    idf_scores = []\n    for term in terms:\n        docs_with_term = sum(1 for doc in all_documents if term in doc.lower())\n        if docs_with_term > 0:\n            idf = math.log(len(all_documents) / docs_with_term)\n            idf_scores.append(idf)\n        else:\n            idf_scores.append(0)\n\n    # Combined TF-IDF\n    score = sum(tf * idf for tf, idf in zip(tf_scores, idf_scores))\n    return score", "chunk_type": "function", "line_start": 106, "line_end": 138, "language": "python", "name": "calculate_tf_idf"}, "baaf0f010cae_func_get_recent_files": {"id": "baaf0f010cae_func_get_recent_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def get_recent_files(root: Path, limit: int = 10) -> List[Path]:\n    \"\"\"Get recently modified files from git.\"\"\"\n    output = run_git_command(\n        ['log', '--name-only', '--format=', '-n', '50'],\n        cwd=root\n    )\n\n    if not output:\n        return []\n\n    recent = []\n    seen = set()\n    for line in output.split('\\n'):\n        line = line.strip()\n        if line and line.endswith('.py') and line not in seen:\n            path = root / line\n            if path.exists():\n                recent.append(path)\n                seen.add(line)\n            if len(recent) >= limit:\n                break\n\n    return recent", "chunk_type": "function", "line_start": 141, "line_end": 163, "language": "python", "name": "get_recent_files"}, "baaf0f010cae_func_extract_function_context": {"id": "baaf0f010cae_func_extract_function_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def extract_function_context(\n    path: Path,\n    tree: ast.Module,\n    source_lines: List[str]\n) -> List[Tuple[str, int, int, str]]:\n    \"\"\"Extract function definitions with context.\"\"\"\n    results = []\n\n    for node in ast.walk(tree):\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Get function signature and docstring\n            start = node.lineno - 1\n            end = node.end_lineno if node.end_lineno else start + 1\n\n            # Include signature + docstring + first few lines\n            content_lines = source_lines[start:min(end, start + 20)]\n            content = '\\n'.join(content_lines)\n\n            results.append((node.name, start + 1, end, content))\n\n    return results", "chunk_type": "function", "line_start": 166, "line_end": 186, "language": "python", "name": "extract_function_context"}, "baaf0f010cae_func_extract_class_context": {"id": "baaf0f010cae_func_extract_class_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def extract_class_context(\n    path: Path,\n    tree: ast.Module,\n    source_lines: List[str]\n) -> List[Tuple[str, int, int, str]]:\n    \"\"\"Extract class definitions with context.\"\"\"\n    results = []\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.ClassDef):\n            start = node.lineno - 1\n            end = node.end_lineno if node.end_lineno else start + 1\n\n            # Include class definition + docstring + method signatures\n            content_lines = source_lines[start:min(end, start + 30)]\n            content = '\\n'.join(content_lines)\n\n            results.append((node.name, start + 1, end, content))\n\n    return results", "chunk_type": "function", "line_start": 189, "line_end": 208, "language": "python", "name": "extract_class_context"}, "baaf0f010cae_func_load_context": {"id": "baaf0f010cae_func_load_context", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def load_context(\n    query: str,\n    root: Path,\n    token_budget: int = 4000,\n    exclude_patterns: List[str] = None\n) -> ContextResult:\n    \"\"\"\n    Load relevant context for a query.\n\n    Args:\n        query: Search query\n        root: Root directory\n        token_budget: Maximum tokens to return\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        ContextResult with relevant items\n    \"\"\"\n    result = ContextResult(query=query)\n\n    Console.info(f\"Searching for context: '{query}'\")\n\n    # Tokenize query\n    terms = tokenize_query(query)\n    Console.info(f\"Search terms: {', '.join(terms)}\")\n\n    # Get all Python files\n    files = list(find_python_files(root, exclude_patterns))\n    result.files_scanned = len(files)\n\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    # Get recent files for priority boost\n    recent_files = set(get_recent_files(root))\n\n    # Load all file contents for IDF calculation\n    all_contents = []\n    file_data = []\n\n    for path in files:\n", "chunk_type": "function", "line_start": 211, "line_end": 333, "language": "python", "name": "load_context"}, "baaf0f010cae_func_main": {"id": "baaf0f010cae_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Smart Context Loader\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    token_budget = 4000\n    for i, arg in enumerate(sys.argv):\n        if arg == '--tokens' and i + 1 < len(sys.argv):\n            try:\n                token_budget = int(sys.argv[i + 1])\n            except ValueError:\n                pass\n\n    if not args:\n        Console.fail(\"Usage: mcp context <query> [path] [--tokens N]\")\n        print(\"\\nExamples:\")\n        print('  mcp context \"authentication\"')\n        print('  mcp context \"database connection\" src/')\n        print('  mcp context \"api handler\" --tokens 8000')\n        return 1\n\n    query = args[0]\n\n    if len(args) > 1:\n        path = Path(args[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Root: {path}\")\n    Console.info(f\"Token budget: {toke", "chunk_type": "function", "line_start": 336, "line_end": 377, "language": "python", "name": "main"}, "baaf0f010cae_func_to_markdown": {"id": "baaf0f010cae_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 51, "line_end": 73, "language": "python", "name": "to_markdown"}, "baaf0f010cae_class_ContextItem": {"id": "baaf0f010cae_class_ContextItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "class ContextItem:\n    \"\"\"A piece of context from the codebase.\"\"\"\n    path: Path\n    content: str\n    relevance_score: float\n    item_type: str  # 'function', 'class', 'file', 'docstring'\n    line_start: int\n    line_end: int\n    tokens: int  # Estimated token count", "chunk_type": "class", "line_start": 32, "line_end": 40, "language": "python", "name": "ContextItem"}, "baaf0f010cae_class_ContextResult": {"id": "baaf0f010cae_class_ContextResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\context.py", "content": "class ContextResult:\n    \"\"\"Result of context extraction.\"\"\"\n    query: str\n    items: List[ContextItem] = field(default_factory=list)\n    total_tokens: int = 0\n    files_scanned: int = 0\n\n    def to_markdown(self) -> str:\n        \"\"\"Format context as markdown.\"\"\"\n        lines = [\n            f\"# Context for: {self.query}\",\n            \"\",\n            f\"**Files scanned:** {self.files_scanned}\",\n            f\"**Total tokens:** {self.total_tokens}\",\n            f\"**Items found:** {len(self.items)}\",\n            \"\",\n        ]\n\n        for item in self.items:\n            lines.extend([\n                f\"## {item.item_type.title()}: {item.path}:{item.line_start}\",\n                f\"**Relevance:** {item.relevance_score:.2f}\",\n                \"\",\n                \"```python\",\n                item.content,\n                \"```\",\n                \"\",\n            ])\n\n        return \"\\n\".join(lines)", "chunk_type": "class", "line_start": 44, "line_end": 73, "language": "python", "name": "ContextResult"}, "72dfe907d0dc_file": {"id": "72dfe907d0dc_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "\"\"\"\nCoverage Index\n==============\nTrack and index test coverage data.\n\nUsage:\n    python mcp.py coverage [file]\n    python mcp.py coverage --uncovered\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass CoverageData:\n    \"\"\"Coverage data for a file.\"\"\"\n    file: str\n    covered_lines: List[int] = field(default_factory=list)\n    uncovered_lines: List[int] = field(default_factory=list)\n    total_lines: int = 0\n    coverage_pct: float = 0.0\n\n\ndef load_coverage_file(coverage_path: Path) -> Optional[Dict]:\n    \"\"\"Load coverage data from .coverage or coverage.json.\"\"\"\n    # Try JSON format\n    json_path = coverage_path.parent / 'coverage.json'\n    if json_path.exists():\n        try:\n            with open(json_path, 'r') as f:\n                return json.load(f)\n        except Exception:\n            pass\n\n    # Try coverage.py format\n    if coverage_path.exists():\n        try:\n            import sqlite3\n            conn = sqlite3.connect(str(coverage_path))\n            cursor = conn.cursor()\n\n            # Query coverage data\n            cursor.execute(\"SELECT file_id, path FROM file\")\n            files = {row[0]: row[1] for row in cursor.fetchall()}\n\n            cursor.execute(\"SELECT file_id, lineno FROM line_bits\")\n            lines = {}\n            for file_id, lineno in cursor.fetchall():\n                if file_id not in lines:\n                    lines[file_id] = []\n                lines[file_id].append(lineno)\n\n            conn.close()\n\n            return {\n                \"files\": {files[fid]: {\"covered\": lns} for fid, lns in lines.items() if fid in files}\n            }\n        except Exception:\n            pass\n\n    return None\n\n\ndef get_file_coverage(file_path: Path, root: Path = None) -> Optional[CoverageData]:\n    \"\"\"Get coverage data for a specific file.\"\"\"\n    root = root or find_project_root() or Path.cwd()", "chunk_type": "file", "line_start": 1, "line_end": 275, "language": "python", "name": "coverage_index.py"}, "72dfe907d0dc_func_load_coverage_file": {"id": "72dfe907d0dc_func_load_coverage_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def load_coverage_file(coverage_path: Path) -> Optional[Dict]:\n    \"\"\"Load coverage data from .coverage or coverage.json.\"\"\"\n    # Try JSON format\n    json_path = coverage_path.parent / 'coverage.json'\n    if json_path.exists():\n        try:\n            with open(json_path, 'r') as f:\n                return json.load(f)\n        except Exception:\n            pass\n\n    # Try coverage.py format\n    if coverage_path.exists():\n        try:\n            import sqlite3\n            conn = sqlite3.connect(str(coverage_path))\n            cursor = conn.cursor()\n\n            # Query coverage data\n            cursor.execute(\"SELECT file_id, path FROM file\")\n            files = {row[0]: row[1] for row in cursor.fetchall()}\n\n            cursor.execute(\"SELECT file_id, lineno FROM line_bits\")\n            lines = {}\n            for file_id, lineno in cursor.fetchall():\n                if file_id not in lines:\n                    lines[file_id] = []\n                lines[file_id].append(lineno)\n\n        ", "chunk_type": "function", "line_start": 30, "line_end": 67, "language": "python", "name": "load_coverage_file"}, "72dfe907d0dc_func_get_file_coverage": {"id": "72dfe907d0dc_func_get_file_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def get_file_coverage(file_path: Path, root: Path = None) -> Optional[CoverageData]:\n    \"\"\"Get coverage data for a specific file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    coverage_path = root / '.coverage'\n\n    data = load_coverage_file(coverage_path)\n    if not data:\n        return None\n\n    file_key = str(file_path.relative_to(root)) if file_path.is_absolute() else str(file_path)\n\n    for key, file_data in data.get('files', {}).items():\n        if file_key in key or key.endswith(file_key):\n            covered = file_data.get('covered', file_data.get('executed_lines', []))\n            total = file_data.get('total', len(covered) + len(file_data.get('missing', [])))\n            missing = file_data.get('missing', file_data.get('uncovered', []))\n\n            pct = (len(covered) / total * 100) if total > 0 else 0\n\n            return CoverageData(\n                file=file_key,\n                covered_lines=covered,\n                uncovered_lines=missing,\n              ", "chunk_type": "function", "line_start": 70, "line_end": 97, "language": "python", "name": "get_file_coverage"}, "72dfe907d0dc_func_get_tests_for_file": {"id": "72dfe907d0dc_func_get_tests_for_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def get_tests_for_file(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Find tests that likely cover a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    tests = []\n    file_name = file_path.stem\n\n    # Look for test files\n    for test_file in root.rglob('test_*.py'):\n        if file_name in test_file.stem or file_name in test_file.read_text(errors='ignore'):\n            tests.append(str(test_file.relative_to(root)))\n\n    for test_file in root.rglob('*_test.py'):\n        if file_name in test_file.stem:\n            tests.append(str(test_file.relative_to(root)))\n\n    # Check tests/ directory\n    tests_dir = root / 'tests'\n    if tests_dir.exists():\n        for test_file in tests_dir.rglob('*.py'):\n            if file_name in test_file.stem:\n                tests.append(str(test_file.relative_to(root)))\n\n    return list(set(tests))", "chunk_type": "function", "line_start": 100, "line_end": 123, "language": "python", "name": "get_tests_for_file"}, "72dfe907d0dc_func_suggest_tests_needed": {"id": "72dfe907d0dc_func_suggest_tests_needed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def suggest_tests_needed(file_path: Path, root: Path = None) -> List[str]:\n    \"\"\"Suggest what tests are needed for a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    suggestions = []\n    file_name = file_path.stem\n\n    existing_tests = get_tests_for_file(file_path, root)\n\n    if not existing_tests:\n        suggestions.append(f\"Create test file: tests/test_{file_name}.py\")\n\n    # Check coverage\n    coverage = get_file_coverage(file_path, root)\n    if coverage and coverage.uncovered_lines:\n        suggestions.append(f\"Add tests for uncovered lines: {coverage.uncovered_lines[:10]}\")\n\n    # Check for public functions without tests\n    try:\n        import ast\n        with open(file_path, 'r', encoding='utf-8') as f:\n            tree = ast.parse(f.read())\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef) and not node.name.startswith('_'):\n                test_name = f\"test_{node.name}\"\n                # Check if test exists\n             ", "chunk_type": "function", "line_start": 126, "line_end": 167, "language": "python", "name": "suggest_tests_needed"}, "72dfe907d0dc_func_index_coverage": {"id": "72dfe907d0dc_func_index_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def index_coverage(root: Path = None) -> Dict:\n    \"\"\"Build coverage index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    coverage_path = root / '.coverage'\n\n    Console.info(\"Indexing coverage data...\")\n\n    data = load_coverage_file(coverage_path)\n    if not data:\n        Console.warn(\"No coverage data found. Run pytest --cov first.\")\n        return {}\n\n    index = {\n        \"total_files\": 0,\n        \"covered_files\": 0,\n        \"average_coverage\": 0.0,\n        \"files\": {}\n    }\n\n    total_pct = 0.0\n\n    for file_key, file_data in data.get('files', {}).items():\n        covered = len(file_data.get('covered', file_data.get('executed_lines', [])))\n        missing = len(file_data.get('missing', file_data.get('uncovered', [])))\n        total = covered + missing\n\n        pct = (covered / total * 100) if total > 0 else 0\n\n        index[\"files\"][file_key] = {\n            \"covered\": covered,\n            \"missing\": missing,\n            \"total\": total,\n            \"percentage\": rou", "chunk_type": "function", "line_start": 170, "line_end": 222, "language": "python", "name": "index_coverage"}, "72dfe907d0dc_func_main": {"id": "72dfe907d0dc_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Coverage Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_coverage(root)\n        return 0\n\n    if '--suggest' in sys.argv and args:\n        file_path = Path(args[0])\n        suggestions = suggest_tests_needed(file_path, root)\n        Console.info(f\"Test suggestions for {file_path.name}:\")\n        for s in suggestions:\n            print(f\"  - {s}\")\n        return 0\n\n    if args:\n        file_path = Path(args[0])\n        coverage = get_file_coverage(file_path, root)\n\n        if coverage:\n            print(f\"Coverage: {coverage.coverage_pct:.1f}%\")\n            print(f\"Covered lines: {len(coverage.covered_lines)}\")\n            if coverage.uncovered_lines:\n                print(f\"Uncovered: {coverage.uncovered_lines[:20]}\")\n        else:\n            Console.warn(\"No coverage data for this file\")\n\n        tests = get_tests_", "chunk_type": "function", "line_start": 225, "line_end": 270, "language": "python", "name": "main"}, "72dfe907d0dc_class_CoverageData": {"id": "72dfe907d0dc_class_CoverageData", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\coverage_index.py", "content": "class CoverageData:\n    \"\"\"Coverage data for a file.\"\"\"\n    file: str\n    covered_lines: List[int] = field(default_factory=list)\n    uncovered_lines: List[int] = field(default_factory=list)\n    total_lines: int = 0\n    coverage_pct: float = 0.0", "chunk_type": "class", "line_start": 21, "line_end": 27, "language": "python", "name": "CoverageData"}, "06a32ad21e7c_file": {"id": "06a32ad21e7c_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP Cybersecurity Tool Wrapper\nIntegrates 70+ security tools from wizardpanda into the MCP CLI.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\nimport os\nimport subprocess\nimport sys\n\n# Tool Categories\nCATEGORIES = {\n    \"Network\": [\"nmap\", \"masscan\", \"arp-scan\", \"netdiscover\", \"fping\", \"hping3\"],\n    \"Web\": [\"gobuster\", \"dirb\", \"dirbuster\", \"nikto\", \"sqlmap\", \"wfuzz\", \"commix\"],\n    \"Exploitation\": [\"msfconsole\", \"msfvenom\", \"searchsploit\", \"beef-xss\", \"social-engineer-toolkit\"],\n    \"Password\": [\"hydra\", \"john\", \"hashcat\", \"medusa\", \"ncrack\"],\n    \"Wireless\": [\"aircrack-ng\", \"airmon-ng\", \"airodump-ng\", \"aireplay-ng\", \"reaver\", \"bully\", \"wifite\"],\n    \"Forensics\": [\"autopsy\", \"binwalk\", \"foremost\", \"scalpel\", \"chkrootkit\", \"rkhunter\"],\n    \"OSINT\": [\"theHarvester\", \"recon-ng\", \"whois\", \"dig\", \"nslookup\"],\n    \"Reverse\": [\"gdb\", \"radare2\", \"ghidra\", \"cutter\", \"objdump\"],\n    \"Post-Exploitation\": [\"impacket\", \"powersploit\", \"bloodhound\", \"mimikatz\"]\n}\n\n# Special Environment Paths\nCYBERSEC_ENV = Path.home() / \"cybersec-env\"\nCYBERSEC_BIN = CYBERSEC_ENV / \"bin\"\n\ndef get_impacket_tools() -> List[str]:\n    \"\"\"List tools available in the Impacket virtualenv.\"\"\"\n    if not CYBERSEC_BIN.exists():\n        return []\n    return [f.name for f in CYBERSEC_BIN.iterdir() if f.is_file() and f.name.endswith(\".py\")]\n\ndef show_help():\n    \"\"\"Show help for the cybersec command.\"\"\"\n    print(\"MCP Cybersecurity Tool Wrapper\")\n    print(\"Usage: mcp cybersec <category|tool|list> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  list              List all tool categories and available tools\")\n    print(\"  help <tool>       Show help for a specific tool\")\n    print(\"  <tool> [args]     Execute a specific tool (e.g., mcp cybersec nmap -sV target)\")\n    print(\"\\nCategories:\")\n    for cat in CATEGORIES:\n        print(f\"  {cat}\")\n\ndef list_tools():\n    \"\"\"List all tools organized by category.\"\"\"\n    print(\"Available Cybersecurity Tools:\")\n    for cat,", "chunk_type": "file", "line_start": 1, "line_end": 120, "language": "python", "name": "cybersec.py"}, "06a32ad21e7c_func_get_impacket_tools": {"id": "06a32ad21e7c_func_get_impacket_tools", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def get_impacket_tools() -> List[str]:\n    \"\"\"List tools available in the Impacket virtualenv.\"\"\"\n    if not CYBERSEC_BIN.exists():\n        return []\n    return [f.name for f in CYBERSEC_BIN.iterdir() if f.is_file() and f.name.endswith(\".py\")]", "chunk_type": "function", "line_start": 30, "line_end": 34, "language": "python", "name": "get_impacket_tools"}, "06a32ad21e7c_func_show_help": {"id": "06a32ad21e7c_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def show_help():\n    \"\"\"Show help for the cybersec command.\"\"\"\n    print(\"MCP Cybersecurity Tool Wrapper\")\n    print(\"Usage: mcp cybersec <category|tool|list> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  list              List all tool categories and available tools\")\n    print(\"  help <tool>       Show help for a specific tool\")\n    print(\"  <tool> [args]     Execute a specific tool (e.g., mcp cybersec nmap -sV target)\")\n    print(\"\\nCategories:\")\n    for cat in CATEGORIES:\n        print(f\"  {cat}\")", "chunk_type": "function", "line_start": 36, "line_end": 46, "language": "python", "name": "show_help"}, "06a32ad21e7c_func_list_tools": {"id": "06a32ad21e7c_func_list_tools", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def list_tools():\n    \"\"\"List all tools organized by category.\"\"\"\n    print(\"Available Cybersecurity Tools:\")\n    for cat, tools in CATEGORIES.items():\n        print(f\"\\n[{cat}]\")\n        print(\", \".join(tools))\n\n    impacket_tools = get_impacket_tools()\n    if impacket_tools:\n        print(\"\\n[Impacket (Auto-activates VENV)]\")\n        # Split into manageable chunks for display\n        for i in range(0, len(impacket_tools), 5):\n            print(\", \".join(impacket_tools[i:i+5]))", "chunk_type": "function", "line_start": 48, "line_end": 60, "language": "python", "name": "list_tools"}, "06a32ad21e7c_func_run_tool": {"id": "06a32ad21e7c_func_run_tool", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def run_tool(tool_name: str, args: List[str]):\n    \"\"\"Run a specific tool, handling env activation if needed.\"\"\"\n\n    # Check if it's an impacket tool\n    impacket_tools = get_impacket_tools()\n    if tool_name in impacket_tools or tool_name.replace(\".py\", \"\") in [t.replace(\".py\", \"\") for t in impacket_tools]:\n        if not tool_name.endswith(\".py\"):\n            tool_name += \".py\"\n\n        python_bin = CYBERSEC_BIN / \"python3\"\n        tool_path = CYBERSEC_BIN / tool_name\n\n        if not python_bin.exists() or not tool_path.exists():\n            print(f\"[FAIL] Impacket tool {tool_name} not found or venv invalid.\")\n            return 1\n\n        cmd = [str(python_bin), str(tool_path)] + args\n        print(f\"[EXEC] Running Impacket tool: {' '.join(cmd)}\")\n    else:\n        # Check if tool is in PATH\n        from shutil import which\n        if not which(tool_name):\n            print(f\"[FAIL] Tool '{tool_name}' not found in system PATH.\")\n            print(\"Tip: Use 'mcp cybersec list' to se", "chunk_type": "function", "line_start": 62, "line_end": 98, "language": "python", "name": "run_tool"}, "06a32ad21e7c_func_main": {"id": "06a32ad21e7c_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\cybersec.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"list\":\n        list_tools()\n    elif cmd == \"help\" and args:\n        run_tool(args[0], [\"--help\"])\n    elif cmd in CATEGORIES:\n        print(f\"Tools in category '{cmd}':\")\n        print(\", \".join(CATEGORIES[cmd]))\n    else:\n        return run_tool(cmd, args)", "chunk_type": "function", "line_start": 100, "line_end": 116, "language": "python", "name": "main"}, "2da1ef9acf9d_file": {"id": "2da1ef9acf9d_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "\"\"\"\nDead Code Detector\n==================\nFind unused functions, classes, imports, and variables in Python code.\n\nUsage:\n    python dead_code.py [path]\n    python -m scripts.dead_code [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Set, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass DeadCodeReport:\n    \"\"\"Report of detected dead code.\"\"\"\n    unused_imports: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_functions: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_classes: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_variables: List[Tuple[Path, int, str]] = field(default_factory=list)\n\n    @property\n    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))\n\n    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_imports]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Import\"], rows))\n            lines.append(\"\")\n\n        if self.unused_functions:\n            lines.append(\"## Unused Functions\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_functions]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Function\"], rows))\n            lines.append(\"\")\n\n        if self.unused_classe", "chunk_type": "file", "line_start": 1, "line_end": 287, "language": "python", "name": "dead_code.py"}, "2da1ef9acf9d_func_analyze_file": {"id": "2da1ef9acf9d_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "def analyze_file(path: Path) -> Tuple[Dict[str, Dict[str, int]], Set[str]]:\n    \"\"\"\n    Analyze a single file for definitions and usages.\n\n    Returns:\n        Tuple of (definitions dict, used names set)\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return {}, set()\n\n    # Collect definitions\n    def_collector = DefinitionCollector(path)\n    def_collector.visit(tree)\n\n    # Collect usages\n    usage_collector = UsageCollector()\n    usage_collector.visit(tree)\n\n    definitions = {\n        'imports': def_collector.imports,\n        'functions': def_collector.functions,\n        'classes': def_collector.classes,\n        'variables': def_collector.variables\n    }\n\n    return definitions, usage_collector.used_names", "chunk_type": "function", "line_start": 156, "line_end": 182, "language": "python", "name": "analyze_file"}, "2da1ef9acf9d_func_detect_dead_code": {"id": "2da1ef9acf9d_func_detect_dead_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "def detect_dead_code(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> DeadCodeReport:\n    \"\"\"\n    Detect dead code in a Python project.\n\n    Args:\n        root: Root directory to analyze\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        DeadCodeReport with findings\n    \"\"\"\n    report = DeadCodeReport()\n\n    # Collect all definitions and usages across the project\n    all_definitions: Dict[Path, Dict[str, Dict[str, int]]] = {}\n    all_usages: Set[str] = set()\n\n    # Known always-used names (builtins, common patterns)\n    always_used = {\n        'self', 'cls', 'args', 'kwargs',\n        'main', 'setup', 'teardown',\n        '__all__', '__version__', '__name__', '__main__'\n    }\n    all_usages.update(always_used)\n\n    Console.info(f\"Scanning for Python files in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        definitions, usages = analyze_file(path)\n     ", "chunk_type": "function", "line_start": 185, "line_end": 254, "language": "python", "name": "detect_dead_code"}, "2da1ef9acf9d_func_main": {"id": "2da1ef9acf9d_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Dead Code Detector\")\n\n    # Get path from args or use project root\n    if len(sys.argv) > 1:\n        path = Path(sys.argv[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = detect_dead_code(path)\n\n    print(report.to_markdown())\n\n    if report.total_issues > 0:\n        Console.warn(f\"Found {report.total_issues} potential dead code issues\")\n    else:\n        Console.ok(\"No dead code detected\")\n\n    return report.total_issues", "chunk_type": "function", "line_start": 257, "line_end": 282, "language": "python", "name": "main"}, "2da1ef9acf9d_func_total_issues": {"id": "2da1ef9acf9d_func_total_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))", "chunk_type": "function", "line_start": 36, "line_end": 38, "language": "python", "name": "total_issues"}, "2da1ef9acf9d_func_to_markdown": {"id": "2da1ef9acf9d_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_imports]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Import\"], rows))\n            lines.append(\"\")\n\n        if self.unused_functions:\n            lines.append(\"## Unused Functions\\n\")\n            rows = [[str(p), str(line), name] for p, line, name in self.unused_functions]\n            lines.append(format_as_markdown_table([\"File\", \"Line\", \"Function\"], rows))\n            lines.append(\"\")\n\n        if self.unused_classes:\n            lines.append(\"## Unused Classes\\n\")\n            rows = [[str", "chunk_type": "function", "line_start": 40, "line_end": 74, "language": "python", "name": "to_markdown"}, "2da1ef9acf9d_func___init__": {"id": "2da1ef9acf9d_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def __init__(self):\n        self.used_names: Set[str] = set()", "chunk_type": "function", "line_start": 134, "line_end": 135, "language": "python", "name": "__init__"}, "2da1ef9acf9d_func_visit_Import": {"id": "2da1ef9acf9d_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            name = alias.asname or alias.name.split('.')[0]\n            self.imports[name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 88, "line_end": 92, "language": "python", "name": "visit_Import"}, "2da1ef9acf9d_func_visit_ImportFrom": {"id": "2da1ef9acf9d_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        for alias in node.names:\n            if alias.name != '*':\n                name = alias.asname or alias.name\n                self.imports[name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 94, "line_end": 99, "language": "python", "name": "visit_ImportFrom"}, "2da1ef9acf9d_func_visit_FunctionDef": {"id": "2da1ef9acf9d_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 101, "line_end": 104, "language": "python", "name": "visit_FunctionDef"}, "2da1ef9acf9d_func_visit_AsyncFunctionDef": {"id": "2da1ef9acf9d_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.name] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 106, "line_end": 109, "language": "python", "name": "visit_AsyncFunctionDef"}, "2da1ef9acf9d_func_visit_ClassDef": {"id": "2da1ef9acf9d_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        if not node.name.startswith('_'):\n            self.classes[node.name] = node.lineno\n\n        old_in_class = self._in_class\n        self._in_class = True\n        self.generic_visit(node)\n        self._in_class = old_in_class", "chunk_type": "function", "line_start": 111, "line_end": 118, "language": "python", "name": "visit_ClassDef"}, "2da1ef9acf9d_func_visit_Assign": {"id": "2da1ef9acf9d_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        if not self._in_class:\n            for target in node.targets:\n                if isinstance(target, ast.Name) and not target.id.startswith('_'):\n                    # Skip common constants/configs\n                    if target.id.isupper():\n                        continue\n                    self.variables[target.id] = node.lineno\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 120, "line_end": 128, "language": "python", "name": "visit_Assign"}, "2da1ef9acf9d_func_visit_Name": {"id": "2da1ef9acf9d_func_visit_Name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Name(self, node: ast.Name):\n        self.used_names.add(node.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 137, "line_end": 139, "language": "python", "name": "visit_Name"}, "2da1ef9acf9d_func_visit_Attribute": {"id": "2da1ef9acf9d_func_visit_Attribute", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Attribute(self, node: ast.Attribute):\n        # Track the base name\n        if isinstance(node.value, ast.Name):\n            self.used_names.add(node.value.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 141, "line_end": 145, "language": "python", "name": "visit_Attribute"}, "2da1ef9acf9d_func_visit_Call": {"id": "2da1ef9acf9d_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "    def visit_Call(self, node: ast.Call):\n        if isinstance(node.func, ast.Name):\n            self.used_names.add(node.func.id)\n        elif isinstance(node.func, ast.Attribute):\n            if isinstance(node.func.value, ast.Name):\n                self.used_names.add(node.func.value.id)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 147, "line_end": 153, "language": "python", "name": "visit_Call"}, "2da1ef9acf9d_class_DeadCodeReport": {"id": "2da1ef9acf9d_class_DeadCodeReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "class DeadCodeReport:\n    \"\"\"Report of detected dead code.\"\"\"\n    unused_imports: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_functions: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_classes: List[Tuple[Path, int, str]] = field(default_factory=list)\n    unused_variables: List[Tuple[Path, int, str]] = field(default_factory=list)\n\n    @property\n    def total_issues(self) -> int:\n        return (len(self.unused_imports) + len(self.unused_functions) +\n                len(self.unused_classes) + len(self.unused_variables))\n\n    def to_markdown(self) -> str:\n        \"\"\"Convert report to markdown format.\"\"\"\n        lines = [\"# Dead Code Report\\n\"]\n\n        if self.total_issues == 0:\n            lines.append(\"No dead code detected.\\n\")\n            return \"\\n\".join(lines)\n\n        lines.append(f\"**Total issues found: {self.total_issues}**\\n\")\n\n        if self.unused_imports:\n            lines.append(\"## Unused Imports\\n\")\n            rows = [[str(p", "chunk_type": "class", "line_start": 28, "line_end": 74, "language": "python", "name": "DeadCodeReport"}, "2da1ef9acf9d_class_DefinitionCollector": {"id": "2da1ef9acf9d_class_DefinitionCollector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "class DefinitionCollector(ast.NodeVisitor):\n    \"\"\"Collect all definitions in a module.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.imports: Dict[str, int] = {}  # name -> lineno\n        self.functions: Dict[str, int] = {}\n        self.classes: Dict[str, int] = {}\n        self.variables: Dict[str, int] = {}\n        self._in_class = False\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            name = alias.asname or alias.name.split('.')[0]\n            self.imports[name] = node.lineno\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        for alias in node.names:\n            if alias.name != '*':\n                name = alias.asname or alias.name\n                self.imports[name] = node.lineno\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        if not self._in_class and not node.name.startswith('_'):\n            self.functions[node.", "chunk_type": "class", "line_start": 77, "line_end": 128, "language": "python", "name": "DefinitionCollector"}, "2da1ef9acf9d_class_UsageCollector": {"id": "2da1ef9acf9d_class_UsageCollector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\dead_code.py", "content": "class UsageCollector(ast.NodeVisitor):\n    \"\"\"Collect all name usages in a module.\"\"\"\n\n    def __init__(self):\n        self.used_names: Set[str] = set()\n\n    def visit_Name(self, node: ast.Name):\n        self.used_names.add(node.id)\n        self.generic_visit(node)\n\n    def visit_Attribute(self, node: ast.Attribute):\n        # Track the base name\n        if isinstance(node.value, ast.Name):\n            self.used_names.add(node.value.id)\n        self.generic_visit(node)\n\n    def visit_Call(self, node: ast.Call):\n        if isinstance(node.func, ast.Name):\n            self.used_names.add(node.func.id)\n        elif isinstance(node.func, ast.Attribute):\n            if isinstance(node.func.value, ast.Name):\n                self.used_names.add(node.func.value.id)\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 131, "line_end": 153, "language": "python", "name": "UsageCollector"}, "db46047d6094_file": {"id": "db46047d6094_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "\"\"\"\nDependency Analyzer\n===================\nAnalyze and visualize project dependencies, detect circular imports.\n\nUsage:\n    python deps.py [path] [--output deps.md]\n    python -m scripts.deps [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Set, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass DependencyInfo:\n    \"\"\"Dependency information for a module.\"\"\"\n    path: Path\n    module_name: str\n    imports: Set[str] = field(default_factory=set)\n    from_imports: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps\n\n\n@dataclass\nclass DependencyReport:\n    \"\"\"Report of dependency analysis.\"\"\"\n    modules: Dict[str, DependencyInfo] = field(default_factory=dict)\n    external_deps: Set[str] = field(default_factory=set)\n    internal_deps: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n    circular_deps: List[Tuple[str, str]] = field(default_factory=list)\n    missing_deps: List[Tuple[str, str]] = field(default_factory=list)\n\n\n# Standard library modules\nSTDLIB_MODULES = {\n    'abc', 'aifc', 'argparse', 'array', 'ast', 'asyncio', 'atexit',\n    'base64', 'bdb', 'binascii', 'bisect', 'builtins', 'bz2',\n    'calendar', 'cgi', 'cgitb', 'chunk', 'cmath', 'cmd', 'code',\n    'codecs', 'codeop', 'collections', 'colorsys', 'compileall',\n    'concurrent', 'configparser', 'contextlib', 'copy', 'copyreg',\n    'cProfile', 'crypt', 'csv', 'ctypes', 'curses',\n    'dataclasses', 'datetime', 'dbm', 'decimal', 'difflib', 'dis',\n    'distutils', 'doctest',\n    'email', 'encodings', 'enum', 'errno',\n    'faulthandler', 'fcntl', 'filecmp', '", "chunk_type": "file", "line_start": 1, "line_end": 367, "language": "python", "name": "deps.py"}, "db46047d6094_func_analyze_imports": {"id": "db46047d6094_func_analyze_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def analyze_imports(path: Path) -> Optional[DependencyInfo]:\n    \"\"\"\n    Analyze imports in a Python file.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        DependencyInfo or None if parsing fails\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return None\n\n    info = DependencyInfo(\n        path=path,\n        module_name=path.stem\n    )\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                info.imports.add(alias.name.split('.')[0])\n        elif isinstance(node, ast.ImportFrom):\n            if node.module:\n                base_module = node.module.split('.')[0]\n                info.imports.add(base_module)\n                for alias in node.names:\n                    info.from_imports[node.module].add(alias.name)\n\n    return info", "chunk_type": "function", "line_start": 99, "line_end": 129, "language": "python", "name": "analyze_imports"}, "db46047d6094_func_path_to_module_name": {"id": "db46047d6094_func_path_to_module_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def path_to_module_name(path: Path, root: Path) -> str:\n    \"\"\"Convert a file path to a module name.\"\"\"\n    try:\n        relative = path.relative_to(root)\n        parts = list(relative.with_suffix('').parts)\n        return '.'.join(parts)\n    except ValueError:\n        return path.stem", "chunk_type": "function", "line_start": 132, "line_end": 139, "language": "python", "name": "path_to_module_name"}, "db46047d6094_func_analyze_dependencies": {"id": "db46047d6094_func_analyze_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def analyze_dependencies(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> DependencyReport:\n    \"\"\"\n    Analyze dependencies in a Python project.\n\n    Args:\n        root: Root directory\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        DependencyReport\n    \"\"\"\n    report = DependencyReport()\n\n    Console.info(f\"Scanning {root} for Python files...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    # Build module name mapping\n    module_names = set()\n    for path in files:\n        module_name = path_to_module_name(path, root)\n        module_names.add(module_name.split('.')[0])\n\n    # Analyze each file\n    for path in files:\n        info = analyze_imports(path)\n        if info:\n            module_name = path_to_module_name(path, root)\n            report.modules[module_name] = info\n\n            # Categorize dependencies\n            for dep in info.all_dependencies:\n                base_dep =", "chunk_type": "function", "line_start": 142, "line_end": 204, "language": "python", "name": "analyze_dependencies"}, "db46047d6094_func_generate_mermaid_diagram": {"id": "db46047d6094_func_generate_mermaid_diagram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def generate_mermaid_diagram(report: DependencyReport, max_nodes: int = 20) -> str:\n    \"\"\"\n    Generate a Mermaid diagram of dependencies.\n\n    Args:\n        report: DependencyReport\n        max_nodes: Maximum number of nodes to show\n\n    Returns:\n        Mermaid diagram code\n    \"\"\"\n    lines = [\"```mermaid\", \"graph LR\"]\n\n    # Track nodes we've added\n    nodes_added = set()\n    edges_added = set()\n\n    # Add internal dependencies\n    for module, deps in list(report.internal_deps.items())[:max_nodes]:\n        base_module = module.split('.')[0]\n\n        if base_module not in nodes_added:\n            lines.append(f'    {base_module}[\"{base_module}\"]')\n            nodes_added.add(base_module)\n\n        for dep in list(deps)[:5]:  # Limit edges per node\n            base_dep = dep.split('.')[0]\n\n            if base_dep not in nodes_added and len(nodes_added) < max_nodes:\n                lines.append(f'    {base_dep}[\"{base_dep}\"]')\n                nodes_added.add(base_dep)\n\n            edg", "chunk_type": "function", "line_start": 207, "line_end": 250, "language": "python", "name": "generate_mermaid_diagram"}, "db46047d6094_func_format_report_markdown": {"id": "db46047d6094_func_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def format_report_markdown(report: DependencyReport) -> str:\n    \"\"\"Format dependency report as Markdown.\"\"\"\n    lines = [\n        \"# Dependency Analysis\",\n        \"\",\n        \"## Summary\",\n        \"\",\n        f\"- **Internal Modules:** {len(report.modules)}\",\n        f\"- **External Dependencies:** {len(report.external_deps)}\",\n        f\"- **Circular Dependencies:** {len(report.circular_deps)}\",\n        \"\",\n    ]\n\n    # External dependencies\n    if report.external_deps:\n        lines.extend([\n            \"## External Dependencies\",\n            \"\",\n            \"These packages need to be installed:\",\n            \"\",\n        ])\n        for dep in sorted(report.external_deps):\n            lines.append(f\"- `{dep}`\")\n        lines.append(\"\")\n\n    # Circular dependencies (warning)\n    if report.circular_deps:\n        lines.extend([\n            \"## Circular Dependencies [WARNING]\",\n            \"\",\n            \"The following modules have circular imports:\",\n            \"\",\n        ])\n        for", "chunk_type": "function", "line_start": 253, "line_end": 316, "language": "python", "name": "format_report_markdown"}, "db46047d6094_func_main": {"id": "db46047d6094_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Dependency Analyzer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_dependencies(path)\n    markdown = format_report_markdown(report)\n\n    # Output\n    if output_file:\n        with open(output_file, 'w', encoding='utf-8') as f:\n            f.write(markdown)\n        Console.ok(f\"Report written to: {output_file}\")\n    else:\n        print(markdown)\n\n    # Summary\n    if report.circular_deps:\n        Console.warn(f\"Found {len(report.circular_deps)} circular dependenc", "chunk_type": "function", "line_start": 319, "line_end": 362, "language": "python", "name": "main"}, "db46047d6094_func_all_dependencies": {"id": "db46047d6094_func_all_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps", "chunk_type": "function", "line_start": 36, "line_end": 40, "language": "python", "name": "all_dependencies"}, "db46047d6094_class_DependencyInfo": {"id": "db46047d6094_class_DependencyInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "class DependencyInfo:\n    \"\"\"Dependency information for a module.\"\"\"\n    path: Path\n    module_name: str\n    imports: Set[str] = field(default_factory=set)\n    from_imports: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n\n    @property\n    def all_dependencies(self) -> Set[str]:\n        \"\"\"Get all dependencies.\"\"\"\n        deps = set(self.imports)\n        deps.update(self.from_imports.keys())\n        return deps", "chunk_type": "class", "line_start": 28, "line_end": 40, "language": "python", "name": "DependencyInfo"}, "db46047d6094_class_DependencyReport": {"id": "db46047d6094_class_DependencyReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\deps.py", "content": "class DependencyReport:\n    \"\"\"Report of dependency analysis.\"\"\"\n    modules: Dict[str, DependencyInfo] = field(default_factory=dict)\n    external_deps: Set[str] = field(default_factory=set)\n    internal_deps: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))\n    circular_deps: List[Tuple[str, str]] = field(default_factory=list)\n    missing_deps: List[Tuple[str, str]] = field(default_factory=list)", "chunk_type": "class", "line_start": 44, "line_end": 50, "language": "python", "name": "DependencyReport"}, "f58dc211874d_file": {"id": "f58dc211874d_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "\"\"\"\nDocumentation Coverage Checker\n==============================\nMeasure documentation coverage and identify undocumented code.\n\nUsage:\n    python doc_coverage.py [path] [--format google]\n    python -m scripts.doc_coverage src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass CoverageItem:\n    \"\"\"A single item that should have documentation.\"\"\"\n    path: Path\n    name: str\n    line: int\n    item_type: str  # 'function', 'class', 'method', 'module'\n    has_docstring: bool\n    docstring_valid: bool = True\n    issues: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass CoverageReport:\n    \"\"\"Documentation coverage report.\"\"\"\n    items: List[CoverageItem] = field(default_factory=list)\n\n    @property\n    def total(self) -> int:\n        return len(self.items)\n\n    @property\n    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)\n\n    @property\n    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)\n\n    @property\n    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0\n\n    @property\n    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]\n\n    @property\n    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Metric | Value |\",\n            f\"|--------|-------|\",\n            f\"| Total Items | {self.total} |\",\n            f\"| Documented | {self.documented} |\",\n            f\"| Covera", "chunk_type": "file", "line_start": 1, "line_end": 319, "language": "python", "name": "doc_coverage.py"}, "f58dc211874d_func_analyze_file": {"id": "f58dc211874d_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def analyze_file(path: Path, validator: DocstringValidator) -> List[CoverageItem]:\n    \"\"\"Analyze documentation coverage in a file.\"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return []\n\n    analyzer = CoverageAnalyzer(path, validator)\n    analyzer.visit(tree)\n\n    return analyzer.items", "chunk_type": "function", "line_start": 241, "line_end": 250, "language": "python", "name": "analyze_file"}, "f58dc211874d_func_check_coverage": {"id": "f58dc211874d_func_check_coverage", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def check_coverage(\n    root: Path,\n    doc_format: str = 'google',\n    exclude_patterns: List[str] = None\n) -> CoverageReport:\n    \"\"\"Check documentation coverage in a project.\"\"\"\n    report = CoverageReport()\n    validator = DocstringValidator(doc_format)\n\n    Console.info(f\"Checking documentation coverage in {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        items = analyze_file(path, validator)\n        report.items.extend(items)\n\n    return report", "chunk_type": "function", "line_start": 253, "line_end": 271, "language": "python", "name": "check_coverage"}, "f58dc211874d_func_main": {"id": "f58dc211874d_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Documentation Coverage Checker\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    doc_format = 'google'\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--format' and i + 1 < len(sys.argv):\n            doc_format = sys.argv[i + 1]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Format: {doc_format}\")\n\n    report = check_coverage(path, doc_format)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.coverage_percent >= 80:\n        Console.ok(f\"Coverage: {report.coverage_percent:.1f}%\")\n    elif report.coverage_percent >= 50:\n        Console.warn(f\"Coverage: {report.coverage_percent:.1f}% (target: 80%)\")\n    else:\n        Console.fail(f\"Coverage: {report.coverage_percent:.1f}", "chunk_type": "function", "line_start": 274, "line_end": 310, "language": "python", "name": "main"}, "f58dc211874d_func_total": {"id": "f58dc211874d_func_total", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def total(self) -> int:\n        return len(self.items)", "chunk_type": "function", "line_start": 45, "line_end": 46, "language": "python", "name": "total"}, "f58dc211874d_func_documented": {"id": "f58dc211874d_func_documented", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)", "chunk_type": "function", "line_start": 49, "line_end": 50, "language": "python", "name": "documented"}, "f58dc211874d_func_valid": {"id": "f58dc211874d_func_valid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)", "chunk_type": "function", "line_start": 53, "line_end": 54, "language": "python", "name": "valid"}, "f58dc211874d_func_coverage_percent": {"id": "f58dc211874d_func_coverage_percent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0", "chunk_type": "function", "line_start": 57, "line_end": 58, "language": "python", "name": "coverage_percent"}, "f58dc211874d_func_undocumented": {"id": "f58dc211874d_func_undocumented", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]", "chunk_type": "function", "line_start": 61, "line_end": 62, "language": "python", "name": "undocumented"}, "f58dc211874d_func_invalid": {"id": "f58dc211874d_func_invalid", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]", "chunk_type": "function", "line_start": 65, "line_end": 66, "language": "python", "name": "invalid"}, "f58dc211874d_func_to_markdown": {"id": "f58dc211874d_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Metric | Value |\",\n            f\"|--------|-------|\",\n            f\"| Total Items | {self.total} |\",\n            f\"| Documented | {self.documented} |\",\n            f\"| Coverage | {self.coverage_percent:.1f}% |\",\n            f\"| Valid Format | {self.valid} |\",\n            \"\",\n        ]\n\n        # Coverage bar\n        filled = int(self.coverage_percent / 5)\n        bar = \"[\" + \"#\" * filled + \"-\" * (20 - filled) + \"]\"\n        lines.append(f\"**Coverage:** {bar} {self.coverage_percent:.1f}%\")\n        lines.append(\"\")\n\n        # Undocumented items\n        if self.undocumented:\n            lines.append(\"## Undocumented Items\")\n            lines.append(\"\")\n\n            # Group by type\n            by_type: Dict[str, List[CoverageItem]] = {}\n            for item in self.undocumented:\n                if item.item_type not in b", "chunk_type": "function", "line_start": 68, "line_end": 120, "language": "python", "name": "to_markdown"}, "f58dc211874d_func___init__": {"id": "f58dc211874d_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def __init__(self, path: Path, validator: DocstringValidator):\n        self.path = path\n        self.validator = validator\n        self.items: List[CoverageItem] = []\n        self._in_class = False", "chunk_type": "function", "line_start": 163, "line_end": 167, "language": "python", "name": "__init__"}, "f58dc211874d_func_validate": {"id": "f58dc211874d_func_validate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def validate(self, docstring: str, node) -> Tuple[bool, List[str]]:\n        \"\"\"Validate docstring format.\"\"\"\n        issues = []\n\n        if not docstring or not docstring.strip():\n            return False, [\"Empty docstring\"]\n\n        lines = docstring.strip().split('\\n')\n\n        # Check first line\n        first_line = lines[0].strip()\n        if not first_line:\n            issues.append(\"First line is empty\")\n        elif not first_line.endswith('.') and not first_line.endswith('!'):\n            issues.append(\"First line should end with period\")\n\n        # Check for function-specific requirements\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Check Args section if function has parameters\n            params = [a.arg for a in node.args.args if a.arg not in ('self', 'cls')]\n            if params and 'Args:' not in docstring and 'Parameters:' not in docstring:\n                issues.append(f\"Missing Args section for: {', '.join(params)}\")\n\n      ", "chunk_type": "function", "line_start": 129, "line_end": 157, "language": "python", "name": "validate"}, "f58dc211874d_func_visit_Module": {"id": "f58dc211874d_func_visit_Module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_Module(self, node: ast.Module):\n        # Check module docstring\n        docstring = ast.get_docstring(node)\n        self.items.append(CoverageItem(\n            path=self.path,\n            name=self.path.stem,\n            line=1,\n            item_type='module',\n            has_docstring=docstring is not None\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 169, "line_end": 179, "language": "python", "name": "visit_Module"}, "f58dc211874d_func_visit_FunctionDef": {"id": "f58dc211874d_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 181, "line_end": 183, "language": "python", "name": "visit_FunctionDef"}, "f58dc211874d_func_visit_AsyncFunctionDef": {"id": "f58dc211874d_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 185, "line_end": 187, "language": "python", "name": "visit_AsyncFunctionDef"}, "f58dc211874d_func__check_function": {"id": "f58dc211874d_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def _check_function(self, node):\n        # Skip private/magic methods\n        if node.name.startswith('_') and not node.name.startswith('__init__'):\n            return\n\n        docstring = ast.get_docstring(node)\n        item_type = 'method' if self._in_class else 'function'\n\n        item = CoverageItem(\n            path=self.path,\n            name=node.name,\n            line=node.lineno,\n            item_type=item_type,\n            has_docstring=docstring is not None\n        )\n\n        if docstring:\n            valid, issues = self.validator.validate(docstring, node)\n            item.docstring_valid = valid\n            item.issues = issues\n\n        self.items.append(item)", "chunk_type": "function", "line_start": 189, "line_end": 210, "language": "python", "name": "_check_function"}, "f58dc211874d_func_visit_ClassDef": {"id": "f58dc211874d_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        # Skip private classes\n        if node.name.startswith('_'):\n            self.generic_visit(node)\n            return\n\n        docstring = ast.get_docstring(node)\n        item = CoverageItem(\n            path=self.path,\n            name=node.name,\n            line=node.lineno,\n            item_type='class',\n            has_docstring=docstring is not None\n        )\n\n        if docstring:\n            valid, issues = self.validator.validate(docstring, node)\n            item.docstring_valid = valid\n            item.issues = issues\n\n        self.items.append(item)\n\n        # Visit methods\n        old_in_class = self._in_class\n        self._in_class = True\n        self.generic_visit(node)\n        self._in_class = old_in_class", "chunk_type": "function", "line_start": 212, "line_end": 238, "language": "python", "name": "visit_ClassDef"}, "f58dc211874d_class_CoverageItem": {"id": "f58dc211874d_class_CoverageItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageItem:\n    \"\"\"A single item that should have documentation.\"\"\"\n    path: Path\n    name: str\n    line: int\n    item_type: str  # 'function', 'class', 'method', 'module'\n    has_docstring: bool\n    docstring_valid: bool = True\n    issues: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 28, "line_end": 36, "language": "python", "name": "CoverageItem"}, "f58dc211874d_class_CoverageReport": {"id": "f58dc211874d_class_CoverageReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageReport:\n    \"\"\"Documentation coverage report.\"\"\"\n    items: List[CoverageItem] = field(default_factory=list)\n\n    @property\n    def total(self) -> int:\n        return len(self.items)\n\n    @property\n    def documented(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring)\n\n    @property\n    def valid(self) -> int:\n        return sum(1 for i in self.items if i.has_docstring and i.docstring_valid)\n\n    @property\n    def coverage_percent(self) -> float:\n        return (self.documented / self.total * 100) if self.total > 0 else 0\n\n    @property\n    def undocumented(self) -> List[CoverageItem]:\n        return [i for i in self.items if not i.has_docstring]\n\n    @property\n    def invalid(self) -> List[CoverageItem]:\n        return [i for i in self.items if i.has_docstring and not i.docstring_valid]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Documentation Coverage Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n      ", "chunk_type": "class", "line_start": 40, "line_end": 120, "language": "python", "name": "CoverageReport"}, "f58dc211874d_class_DocstringValidator": {"id": "f58dc211874d_class_DocstringValidator", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class DocstringValidator:\n    \"\"\"Validate docstring format.\"\"\"\n\n    def __init__(self, format: str = 'google'):\n        self.format = format\n\n    def validate(self, docstring: str, node) -> Tuple[bool, List[str]]:\n        \"\"\"Validate docstring format.\"\"\"\n        issues = []\n\n        if not docstring or not docstring.strip():\n            return False, [\"Empty docstring\"]\n\n        lines = docstring.strip().split('\\n')\n\n        # Check first line\n        first_line = lines[0].strip()\n        if not first_line:\n            issues.append(\"First line is empty\")\n        elif not first_line.endswith('.') and not first_line.endswith('!'):\n            issues.append(\"First line should end with period\")\n\n        # Check for function-specific requirements\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            # Check Args section if function has parameters\n            params = [a.arg for a in node.args.args if a.arg not in ('self', 'cls')]\n            if params and 'Args:", "chunk_type": "class", "line_start": 123, "line_end": 157, "language": "python", "name": "DocstringValidator"}, "f58dc211874d_class_CoverageAnalyzer": {"id": "f58dc211874d_class_CoverageAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_coverage.py", "content": "class CoverageAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze documentation coverage.\"\"\"\n\n    def __init__(self, path: Path, validator: DocstringValidator):\n        self.path = path\n        self.validator = validator\n        self.items: List[CoverageItem] = []\n        self._in_class = False\n\n    def visit_Module(self, node: ast.Module):\n        # Check module docstring\n        docstring = ast.get_docstring(node)\n        self.items.append(CoverageItem(\n            path=self.path,\n            name=self.path.stem,\n            line=1,\n            item_type='module',\n            has_docstring=docstring is not None\n        ))\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node):\n        # Skip private/magic methods\n        if", "chunk_type": "class", "line_start": 160, "line_end": 238, "language": "python", "name": "CoverageAnalyzer"}, "6bd80aa052fd_file": {"id": "6bd80aa052fd_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "\"\"\"\nDocumentation Index\n====================\nIndex READMEs, docstrings, and module summaries.\n\nUsage:\n    python mcp.py doc-index\n    python mcp.py doc-index --search \"api\"\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport ast\nimport json\nimport re\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass DocItem:\n    \"\"\"A documentation item.\"\"\"\n    type: str  # 'readme', 'module', 'class', 'function'\n    name: str\n    path: str\n    summary: str\n    full_text: str = \"\"\n\n\ndef extract_module_docstring(file_path: Path) -> Optional[str]:\n    \"\"\"Extract module docstring from a Python file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n        return ast.get_docstring(tree)\n    except Exception:\n        return None\n\n\ndef extract_docstrings(file_path: Path) -> List[DocItem]:\n    \"\"\"Extract all docstrings from a file.\"\"\"\n    docs = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n    except Exception:\n        return docs\n\n    # Module docstring\n    module_doc = ast.get_docstring(tree)\n    if module_doc:\n        docs.append(DocItem(\n            type='module',\n            name=file_path.stem,\n            path=str(file_path),\n            summary=module_doc.split('\\n')[0][:100],\n            full_text=module_doc[:500]\n        ))\n\n    # Function and class docstrings\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            doc = ast.get_docstring(node)\n            if doc:\n                docs.append(DocItem(\n                    type='function',\n                    name=node.name,\n                    path=str(file_path),\n                    summary=doc.split('\\n')[0][:100],\n                    full_text=doc[:500]\n                ))\n        elif isinstance(node, ast.ClassDef):\n", "chunk_type": "file", "line_start": 1, "line_end": 272, "language": "python", "name": "doc_index.py"}, "6bd80aa052fd_func_extract_module_docstring": {"id": "6bd80aa052fd_func_extract_module_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def extract_module_docstring(file_path: Path) -> Optional[str]:\n    \"\"\"Extract module docstring from a Python file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n        return ast.get_docstring(tree)\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 32, "line_end": 40, "language": "python", "name": "extract_module_docstring"}, "6bd80aa052fd_func_extract_docstrings": {"id": "6bd80aa052fd_func_extract_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def extract_docstrings(file_path: Path) -> List[DocItem]:\n    \"\"\"Extract all docstrings from a file.\"\"\"\n    docs = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        tree = ast.parse(source)\n    except Exception:\n        return docs\n\n    # Module docstring\n    module_doc = ast.get_docstring(tree)\n    if module_doc:\n        docs.append(DocItem(\n            type='module',\n            name=file_path.stem,\n            path=str(file_path),\n            summary=module_doc.split('\\n')[0][:100],\n            full_text=module_doc[:500]\n        ))\n\n    # Function and class docstrings\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            doc = ast.get_docstring(node)\n            if doc:\n                docs.append(DocItem(\n                    type='function',\n                    name=node.name,\n                    path=str(file_path),\n                    summary=doc.split('\\n')[0][:100],\n                  ", "chunk_type": "function", "line_start": 43, "line_end": 88, "language": "python", "name": "extract_docstrings"}, "6bd80aa052fd_func_find_readme_files": {"id": "6bd80aa052fd_func_find_readme_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def find_readme_files(root: Path) -> List[Path]:\n    \"\"\"Find README files in project.\"\"\"\n    readmes = []\n    patterns = ['README', 'README.md', 'README.rst', 'README.txt', 'DOCUMENTATION.md']\n\n    for pattern in patterns:\n        for readme in root.rglob(pattern):\n            if '.git' not in str(readme) and 'node_modules' not in str(readme):\n                readmes.append(readme)\n\n    return readmes", "chunk_type": "function", "line_start": 91, "line_end": 101, "language": "python", "name": "find_readme_files"}, "6bd80aa052fd_func_index_readme": {"id": "6bd80aa052fd_func_index_readme", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def index_readme(readme_path: Path) -> DocItem:\n    \"\"\"Index a README file.\"\"\"\n    try:\n        content = readme_path.read_text(encoding='utf-8', errors='ignore')\n\n        # Get first paragraph as summary\n        lines = content.split('\\n')\n        summary_lines = []\n        for line in lines:\n            if line.strip() and not line.startswith('#'):\n                summary_lines.append(line)\n                if len(summary_lines) >= 3:\n                    break\n\n        summary = ' '.join(summary_lines)[:200]\n\n        return DocItem(\n            type='readme',\n            name=readme_path.name,\n            path=str(readme_path),\n            summary=summary,\n            full_text=content[:2000]\n        )\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 104, "line_end": 128, "language": "python", "name": "index_readme"}, "6bd80aa052fd_func_index_documentation": {"id": "6bd80aa052fd_func_index_documentation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def index_documentation(root: Path = None) -> Dict:\n    \"\"\"Build documentation index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Indexing documentation...\")\n\n    index = {\n        \"total_items\": 0,\n        \"by_type\": {\"readme\": 0, \"module\": 0, \"class\": 0, \"function\": 0},\n        \"items\": []\n    }\n\n    # Index READMEs\n    for readme in find_readme_files(root):\n        item = index_readme(readme)\n        if item:\n            index[\"items\"].append({\n                \"type\": item.type,\n                \"name\": item.name,\n                \"path\": str(item.path),\n                \"summary\": item.summary\n            })\n            index[\"by_type\"][\"readme\"] += 1\n            index[\"total_items\"] += 1\n\n    # Index Python docstrings\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    for file_path in find_python_files(root, exclude):\n        docs = extract_docstrings(file_path)\n        for item in docs:\n            index[\"items\"].appen", "chunk_type": "function", "line_start": 131, "line_end": 179, "language": "python", "name": "index_documentation"}, "6bd80aa052fd_func_search_docs": {"id": "6bd80aa052fd_func_search_docs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def search_docs(query: str, root: Path = None) -> List[DocItem]:\n    \"\"\"Search documentation index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    index_path = root / '.mcp' / 'doc_index.json'\n\n    if not index_path.exists():\n        index_documentation(root)\n\n    with open(index_path, 'r') as f:\n        index = json.load(f)\n\n    results = []\n    query_lower = query.lower()\n\n    for item in index.get('items', []):\n        if query_lower in item['name'].lower() or query_lower in item['summary'].lower():\n            results.append(DocItem(\n                type=item['type'],\n                name=item['name'],\n                path=item['path'],\n                summary=item['summary']\n            ))\n\n    return results", "chunk_type": "function", "line_start": 182, "line_end": 205, "language": "python", "name": "search_docs"}, "6bd80aa052fd_func_get_module_summary": {"id": "6bd80aa052fd_func_get_module_summary", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def get_module_summary(module_path: Path) -> str:\n    \"\"\"Get summary of a module.\"\"\"\n    docs = extract_docstrings(module_path)\n\n    lines = [f\"# Module: {module_path.stem}\", \"\"]\n\n    # Module docstring\n    module_docs = [d for d in docs if d.type == 'module']\n    if module_docs:\n        lines.append(module_docs[0].full_text)\n        lines.append(\"\")\n\n    # Classes\n    class_docs = [d for d in docs if d.type == 'class']\n    if class_docs:\n        lines.append(\"## Classes\")\n        for d in class_docs:\n            lines.append(f\"- **{d.name}**: {d.summary}\")\n        lines.append(\"\")\n\n    # Functions\n    func_docs = [d for d in docs if d.type == 'function']\n    if func_docs:\n        lines.append(\"## Functions\")\n        for d in func_docs[:10]:\n            lines.append(f\"- **{d.name}**: {d.summary}\")\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 208, "line_end": 235, "language": "python", "name": "get_module_summary"}, "6bd80aa052fd_func_main": {"id": "6bd80aa052fd_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Documentation Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_documentation(root)\n        return 0\n\n    if '--search' in sys.argv and args:\n        query = args[0]\n        results = search_docs(query, root)\n        Console.info(f\"Found {len(results)} results for '{query}':\")\n        for r in results[:15]:\n            print(f\"  [{r.type}] {r.name}: {r.summary[:50]}...\")\n        return 0\n\n    if args:\n        # Show module summary\n        file_path = Path(args[0])\n        if file_path.exists():\n            summary = get_module_summary(file_path)\n            print(summary)\n    else:\n        # Just index\n        index_documentation(root)\n\n    return 0", "chunk_type": "function", "line_start": 238, "line_end": 267, "language": "python", "name": "main"}, "6bd80aa052fd_class_DocItem": {"id": "6bd80aa052fd_class_DocItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\doc_index.py", "content": "class DocItem:\n    \"\"\"A documentation item.\"\"\"\n    type: str  # 'readme', 'module', 'class', 'function'\n    name: str\n    path: str\n    summary: str\n    full_text: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "DocItem"}, "ff631de15c33_file": {"id": "ff631de15c33_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "\"\"\"\nEmbeddings Generation\n=====================\nGenerate vector embeddings for code semantic search.\nUses sentence-transformers or falls back to TF-IDF.\n\nUsage:\n    from scripts.embeddings import embed_text, embed_code\n\"\"\"\n\nimport sys\nimport re\nimport math\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass\n\nfrom .utils import Console\n\n\n# Try to import sentence-transformers\ntry:\n    from sentence_transformers import SentenceTransformer\n    TRANSFORMERS_AVAILABLE = True\nexcept ImportError:\n    TRANSFORMERS_AVAILABLE = False\n\n# Try to import numpy\ntry:\n    import numpy as np\n    NUMPY_AVAILABLE = True\nexcept ImportError:\n    NUMPY_AVAILABLE = False\n\n\n# Model cache\n_model = None\n_model_name = \"all-MiniLM-L6-v2\"  # 22MB, good quality/speed balance\n\n\ndef get_model():\n    \"\"\"Get or load embedding model.\"\"\"\n    global _model\n\n    if _model is not None:\n        return _model\n\n    if not TRANSFORMERS_AVAILABLE:\n        return None\n\n    try:\n        # Try to load from local cache first\n        _model = SentenceTransformer(_model_name)\n        return _model\n    except Exception as e:\n        Console.warn(f\"Could not load embedding model: {e}\")\n        return None\n\n\ndef embed_text(text: str) -> Optional[List[float]]:\n    \"\"\"Generate embedding for text.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True)\n        return embedding.tolist()\n\n    # Fallback to simple TF-IDF-like embedding\n    return _fallback_embed(text)\n\n\ndef embed_texts(texts: List[str]) -> List[List[float]]:\n    \"\"\"Generate embeddings for multiple texts.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embeddings = model.encode(texts, convert_to_numpy=True)\n        return embeddings.tolist()\n\n    # Fallback\n    return [_fallback_embed(t) for t in texts]\n\n\ndef embed_code(code: str, language: str = \"python\") -> Optional[List[float]]:\n    \"\"\"Generate embedding for code with language-awar", "chunk_type": "file", "line_start": 1, "line_end": 217, "language": "python", "name": "embeddings.py"}, "ff631de15c33_func_get_model": {"id": "ff631de15c33_func_get_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def get_model():\n    \"\"\"Get or load embedding model.\"\"\"\n    global _model\n\n    if _model is not None:\n        return _model\n\n    if not TRANSFORMERS_AVAILABLE:\n        return None\n\n    try:\n        # Try to load from local cache first\n        _model = SentenceTransformer(_model_name)\n        return _model\n    except Exception as e:\n        Console.warn(f\"Could not load embedding model: {e}\")\n        return None", "chunk_type": "function", "line_start": 41, "line_end": 57, "language": "python", "name": "get_model"}, "ff631de15c33_func_embed_text": {"id": "ff631de15c33_func_embed_text", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_text(text: str) -> Optional[List[float]]:\n    \"\"\"Generate embedding for text.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True)\n        return embedding.tolist()\n\n    # Fallback to simple TF-IDF-like embedding\n    return _fallback_embed(text)", "chunk_type": "function", "line_start": 60, "line_end": 69, "language": "python", "name": "embed_text"}, "ff631de15c33_func_embed_texts": {"id": "ff631de15c33_func_embed_texts", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_texts(texts: List[str]) -> List[List[float]]:\n    \"\"\"Generate embeddings for multiple texts.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embeddings = model.encode(texts, convert_to_numpy=True)\n        return embeddings.tolist()\n\n    # Fallback\n    return [_fallback_embed(t) for t in texts]", "chunk_type": "function", "line_start": 72, "line_end": 81, "language": "python", "name": "embed_texts"}, "ff631de15c33_func_embed_code": {"id": "ff631de15c33_func_embed_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_code(code: str, language: str = \"python\") -> Optional[List[float]]:\n    \"\"\"Generate embedding for code with language-aware preprocessing.\"\"\"\n    # Preprocess code for better embeddings\n    processed = _preprocess_code(code, language)\n    return embed_text(processed)", "chunk_type": "function", "line_start": 84, "line_end": 88, "language": "python", "name": "embed_code"}, "ff631de15c33_func__preprocess_code": {"id": "ff631de15c33_func__preprocess_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def _preprocess_code(code: str, language: str) -> str:\n    \"\"\"Preprocess code for embedding.\"\"\"\n    # Remove comments based on language\n    if language in ('python', 'ruby'):\n        code = re.sub(r'#.*$', '', code, flags=re.MULTILINE)\n    elif language in ('javascript', 'typescript', 'java', 'c', 'cpp', 'go', 'rust'):\n        code = re.sub(r'//.*$', '', code, flags=re.MULTILINE)\n        code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n\n    # Normalize whitespace\n    code = ' '.join(code.split())\n\n    # Split camelCase and snake_case for better semantic matching\n    code = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', code)\n    code = code.replace('_', ' ')\n\n    return code.lower()", "chunk_type": "function", "line_start": 91, "line_end": 107, "language": "python", "name": "_preprocess_code"}, "ff631de15c33_func__fallback_embed": {"id": "ff631de15c33_func__fallback_embed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def _fallback_embed(text: str, dim: int = 384) -> List[float]:\n    \"\"\"Simple fallback embedding using hashing + TF-IDF-like approach.\"\"\"\n    # Tokenize\n    tokens = re.findall(r'[a-z0-9]+', text.lower())\n\n    if not tokens:\n        return [0.0] * dim\n\n    # Create embedding via feature hashing\n    embedding = [0.0] * dim\n\n    for token in tokens:\n        # Hash token to get index\n        h = hash(token)\n        idx = abs(h) % dim\n\n        # Add weighted value\n        tf = tokens.count(token) / len(tokens)\n        embedding[idx] += tf\n\n    # Normalize\n    norm = math.sqrt(sum(x * x for x in embedding))\n    if norm > 0:\n        embedding = [x / norm for x in embedding]\n\n    return embedding", "chunk_type": "function", "line_start": 110, "line_end": 135, "language": "python", "name": "_fallback_embed"}, "ff631de15c33_func_cosine_similarity": {"id": "ff631de15c33_func_cosine_similarity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def cosine_similarity(a: List[float], b: List[float]) -> float:\n    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n    if len(a) != len(b):\n        return 0.0\n\n    dot = sum(x * y for x, y in zip(a, b))\n    norm_a = math.sqrt(sum(x * x for x in a))\n    norm_b = math.sqrt(sum(x * x for x in b))\n\n    if norm_a == 0 or norm_b == 0:\n        return 0.0\n\n    return dot / (norm_a * norm_b)", "chunk_type": "function", "line_start": 138, "line_end": 150, "language": "python", "name": "cosine_similarity"}, "ff631de15c33_func_embedding_dimension": {"id": "ff631de15c33_func_embedding_dimension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embedding_dimension() -> int:\n    \"\"\"Get embedding dimension.\"\"\"\n    model = get_model()\n    if model is not None:\n        return model.get_sentence_embedding_dimension()\n    return 384  # Fallback dimension", "chunk_type": "function", "line_start": 153, "line_end": 158, "language": "python", "name": "embedding_dimension"}, "ff631de15c33_func_is_transformers_available": {"id": "ff631de15c33_func_is_transformers_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def is_transformers_available() -> bool:\n    \"\"\"Check if sentence-transformers is available.\"\"\"\n    return TRANSFORMERS_AVAILABLE", "chunk_type": "function", "line_start": 161, "line_end": 163, "language": "python", "name": "is_transformers_available"}, "ff631de15c33_func_embed_with_info": {"id": "ff631de15c33_func_embed_with_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def embed_with_info(text: str) -> EmbeddingResult:\n    \"\"\"Generate embedding with metadata.\"\"\"\n    model = get_model()\n\n    if model is not None:\n        embedding = model.encode(text, convert_to_numpy=True).tolist()\n        return EmbeddingResult(text=text, embedding=embedding, method='transformer')\n\n    embedding = _fallback_embed(text)\n    return EmbeddingResult(text=text, embedding=embedding, method='fallback')", "chunk_type": "function", "line_start": 174, "line_end": 183, "language": "python", "name": "embed_with_info"}, "ff631de15c33_func_main": {"id": "ff631de15c33_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Embedding Generation\")\n\n    if TRANSFORMERS_AVAILABLE:\n        Console.ok(\"sentence-transformers available\")\n        model = get_model()\n        if model:\n            Console.ok(f\"Model: {_model_name}\")\n            Console.ok(f\"Dimension: {embedding_dimension()}\")\n    else:\n        Console.warn(\"sentence-transformers not available, using fallback\")\n        Console.info(f\"Fallback dimension: 384\")\n\n    # Test embedding\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        text = ' '.join(args)\n        Console.info(f\"Embedding: {text[:50]}...\")\n\n        result = embed_with_info(text)\n        Console.ok(f\"Method: {result.method}\")\n        Console.ok(f\"Dimension: {len(result.embedding)}\")\n        Console.ok(f\"Sample values: {result.embedding[:5]}\")\n\n    return 0", "chunk_type": "function", "line_start": 186, "line_end": 212, "language": "python", "name": "main"}, "ff631de15c33_class_EmbeddingResult": {"id": "ff631de15c33_class_EmbeddingResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\embeddings.py", "content": "class EmbeddingResult:\n    \"\"\"Result of embedding generation.\"\"\"\n    text: str\n    embedding: List[float]\n    method: str  # 'transformer' or 'fallback'", "chunk_type": "class", "line_start": 167, "line_end": 171, "language": "python", "name": "EmbeddingResult"}, "6f59d73ae179_file": {"id": "6f59d73ae179_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "\"\"\"\nError Pattern Analyzer\n======================\nAnalyze exception handling and error patterns in code.\n\nUsage:\n    python errors.py [path]\n    python -m scripts.errors src/\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass ErrorPattern:\n    \"\"\"An error handling pattern.\"\"\"\n    path: Path\n    line: int\n    pattern_type: str  # 'bare_except', 'swallowed', 'broad', 'reraise', 'logged'\n    exception_type: Optional[str] = None\n    severity: str = 'medium'\n    description: str = \"\"\n\n\n@dataclass\nclass ErrorReport:\n    \"\"\"Complete error analysis report.\"\"\"\n    patterns: List[ErrorPattern] = field(default_factory=list)\n    exception_usage: Counter = field(default_factory=Counter)\n    total_try_blocks: int = 0\n\n    @property\n    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{exc}` | {count} |\")\n            lines.append(\"\")\n\n        # Issues by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [p for p in self.patterns if p.severity == severity]\n            if not items:\n         ", "chunk_type": "file", "line_start": 1, "line_end": 341, "language": "python", "name": "errors.py"}, "6f59d73ae179_func_analyze_file": {"id": "6f59d73ae179_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "def analyze_file(path: Path) -> Tuple[List[ErrorPattern], Counter, int]:\n    \"\"\"Analyze a file for error patterns.\"\"\"\n    patterns = []\n    exception_usage: Counter = Counter()\n    try_count = 0\n\n    tree = parse_file(path)\n    if tree is None:\n        return patterns, exception_usage, try_count\n\n    # Exception handling analysis\n    exc_analyzer = ExceptionAnalyzer(path)\n    exc_analyzer.visit(tree)\n    patterns.extend(exc_analyzer.patterns)\n    exception_usage.update(exc_analyzer.exception_usage)\n    try_count = exc_analyzer.try_count\n\n    # Raise analysis\n    raise_analyzer = RaiseAnalyzer(path)\n    raise_analyzer.visit(tree)\n    patterns.extend(raise_analyzer.patterns)\n    exception_usage.update(raise_analyzer.exception_usage)\n\n    return patterns, exception_usage, try_count", "chunk_type": "function", "line_start": 254, "line_end": 277, "language": "python", "name": "analyze_file"}, "6f59d73ae179_func_analyze_project": {"id": "6f59d73ae179_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> ErrorReport:\n    \"\"\"Analyze project for error patterns.\"\"\"\n    report = ErrorReport()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        patterns, exc_usage, try_count = analyze_file(path)\n        report.patterns.extend(patterns)\n        report.exception_usage.update(exc_usage)\n        report.total_try_blocks += try_count\n\n    return report", "chunk_type": "function", "line_start": 280, "line_end": 298, "language": "python", "name": "analyze_project"}, "6f59d73ae179_func_main": {"id": "6f59d73ae179_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Error Pattern Analyzer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    issues = report.issues\n    if issues:\n        Console.warn(f\"Found {len(issues)} error handling issues\")\n    else:\n        Console.ok(\"No error handling issues found\")\n\n    Console.info(f\"Analyzed {report.total_try_blocks} try blocks\")\n\n    return 0", "chunk_type": "function", "line_start": 305, "line_end": 336, "language": "python", "name": "main"}, "6f59d73ae179_func_issues": {"id": "6f59d73ae179_func_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]", "chunk_type": "function", "line_start": 46, "line_end": 47, "language": "python", "name": "issues"}, "6f59d73ae179_func_to_markdown": {"id": "6f59d73ae179_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{exc}` | {count} |\")\n            lines.append(\"\")\n\n        # Issues by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [p for p in self.patterns if p.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Severity\")\n            lines.append(\"\")\n\n          ", "chunk_type": "function", "line_start": 49, "line_end": 86, "language": "python", "name": "to_markdown"}, "6f59d73ae179_func___init__": {"id": "6f59d73ae179_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()", "chunk_type": "function", "line_start": 229, "line_end": 232, "language": "python", "name": "__init__"}, "6f59d73ae179_func_visit_Try": {"id": "6f59d73ae179_func_visit_Try", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def visit_Try(self, node: ast.Try):\n        self.try_count += 1\n\n        for handler in node.handlers:\n            self._analyze_handler(handler)\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 113, "line_end": 119, "language": "python", "name": "visit_Try"}, "6f59d73ae179_func__analyze_handler": {"id": "6f59d73ae179_func__analyze_handler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def _analyze_handler(self, handler: ast.ExceptHandler):\n        # Get exception type\n        if handler.type is None:\n            # Bare except\n            self.patterns.append(ErrorPattern(\n                path=self.path,\n                line=handler.lineno,\n                pattern_type='bare_except',\n                severity='high',\n                description=\"Bare 'except:' catches all exceptions including KeyboardInterrupt\"\n            ))\n            self.exception_usage['Exception'] += 1\n        elif isinstance(handler.type, ast.Name):\n            exc_name = handler.type.id\n            self.exception_usage[exc_name] += 1\n\n            # Check for broad exception\n            if exc_name == 'Exception':\n                self.patterns.append(ErrorPattern(\n                    path=self.path,\n                    line=handler.lineno,\n                    pattern_type='broad_exception',\n                    exception_type=exc_name,\n                    severity='medium',\n                ", "chunk_type": "function", "line_start": 121, "line_end": 179, "language": "python", "name": "_analyze_handler"}, "6f59d73ae179_func__is_swallowed": {"id": "6f59d73ae179_func__is_swallowed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def _is_swallowed(self, handler: ast.ExceptHandler) -> bool:\n        \"\"\"Check if exception is swallowed (ignored).\"\"\"\n        if not handler.body:\n            return True\n\n        if len(handler.body) == 1:\n            stmt = handler.body[0]\n            # Just 'pass'\n            if isinstance(stmt, ast.Pass):\n                return True\n            # Just '...'\n            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant):\n                if stmt.value.value is ...:\n                    return True\n\n        # Check if there's any logging or re-raise\n        for node in ast.walk(handler):\n            if isinstance(node, ast.Raise):\n                return False\n            if isinstance(node, ast.Call):\n                func = self._get_func_name(node.func)\n                if any(x in func for x in ['log', 'error', 'warn', 'print', 'logger']):\n                    return False\n\n        return False", "chunk_type": "function", "line_start": 181, "line_end": 205, "language": "python", "name": "_is_swallowed"}, "6f59d73ae179_func__has_logging": {"id": "6f59d73ae179_func__has_logging", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def _has_logging(self, handler: ast.ExceptHandler) -> bool:\n        \"\"\"Check if handler has logging.\"\"\"\n        for node in ast.walk(handler):\n            if isinstance(node, ast.Call):\n                func = self._get_func_name(node.func)\n                if any(x in func for x in ['logging', 'logger', 'log']):\n                    return True\n        return False", "chunk_type": "function", "line_start": 207, "line_end": 214, "language": "python", "name": "_has_logging"}, "6f59d73ae179_func__get_func_name": {"id": "6f59d73ae179_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id.lower()\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\".lower()\n            return node.attr.lower()\n        return \"\"", "chunk_type": "function", "line_start": 216, "line_end": 223, "language": "python", "name": "_get_func_name"}, "6f59d73ae179_func_visit_Raise": {"id": "6f59d73ae179_func_visit_Raise", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "    def visit_Raise(self, node: ast.Raise):\n        if node.exc:\n            if isinstance(node.exc, ast.Call):\n                if isinstance(node.exc.func, ast.Name):\n                    self.exception_usage[node.exc.func.id] += 1\n\n                    # Check for generic Exception raise\n                    if node.exc.func.id == 'Exception':\n                        self.patterns.append(ErrorPattern(\n                            path=self.path,\n                            line=node.lineno,\n                            pattern_type='generic_raise',\n                            exception_type='Exception',\n                            severity='low',\n                            description=\"Raising generic 'Exception', consider using specific exception types\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 234, "line_end": 251, "language": "python", "name": "visit_Raise"}, "6f59d73ae179_class_ErrorPattern": {"id": "6f59d73ae179_class_ErrorPattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "class ErrorPattern:\n    \"\"\"An error handling pattern.\"\"\"\n    path: Path\n    line: int\n    pattern_type: str  # 'bare_except', 'swallowed', 'broad', 'reraise', 'logged'\n    exception_type: Optional[str] = None\n    severity: str = 'medium'\n    description: str = \"\"", "chunk_type": "class", "line_start": 28, "line_end": 35, "language": "python", "name": "ErrorPattern"}, "6f59d73ae179_class_ErrorReport": {"id": "6f59d73ae179_class_ErrorReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "class ErrorReport:\n    \"\"\"Complete error analysis report.\"\"\"\n    patterns: List[ErrorPattern] = field(default_factory=list)\n    exception_usage: Counter = field(default_factory=Counter)\n    total_try_blocks: int = 0\n\n    @property\n    def issues(self) -> List[ErrorPattern]:\n        return [p for p in self.patterns if p.severity in ('high', 'medium')]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Error Handling Analysis\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Try blocks:** {self.total_try_blocks}\",\n            f\"- **Issues found:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        # Exception types used\n        if self.exception_usage:\n            lines.extend([\n                \"## Exception Types Used\",\n                \"\",\n                \"| Exception | Count |\",\n                \"|-----------|-------|\",\n            ])\n            for exc, count in self.exception_usage.most_common(10):\n                lines.append(f\"| `{e", "chunk_type": "class", "line_start": 39, "line_end": 86, "language": "python", "name": "ErrorReport"}, "6f59d73ae179_class_ExceptionAnalyzer": {"id": "6f59d73ae179_class_ExceptionAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "class ExceptionAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze exception handling patterns.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()\n        self.try_count = 0\n\n    def visit_Try(self, node: ast.Try):\n        self.try_count += 1\n\n        for handler in node.handlers:\n            self._analyze_handler(handler)\n\n        self.generic_visit(node)\n\n    def _analyze_handler(self, handler: ast.ExceptHandler):\n        # Get exception type\n        if handler.type is None:\n            # Bare except\n            self.patterns.append(ErrorPattern(\n                path=self.path,\n                line=handler.lineno,\n                pattern_type='bare_except',\n                severity='high',\n                description=\"Bare 'except:' catches all exceptions including KeyboardInterrupt\"\n            ))\n            self.exception_usage['Exception'] += 1\n        elif isinstance(handler.type", "chunk_type": "class", "line_start": 104, "line_end": 223, "language": "python", "name": "ExceptionAnalyzer"}, "6f59d73ae179_class_RaiseAnalyzer": {"id": "6f59d73ae179_class_RaiseAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\errors.py", "content": "class RaiseAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze raise statements.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.patterns: List[ErrorPattern] = []\n        self.exception_usage: Counter = Counter()\n\n    def visit_Raise(self, node: ast.Raise):\n        if node.exc:\n            if isinstance(node.exc, ast.Call):\n                if isinstance(node.exc.func, ast.Name):\n                    self.exception_usage[node.exc.func.id] += 1\n\n                    # Check for generic Exception raise\n                    if node.exc.func.id == 'Exception':\n                        self.patterns.append(ErrorPattern(\n                            path=self.path,\n                            line=node.lineno,\n                            pattern_type='generic_raise',\n                            exception_type='Exception',\n                            severity='low',\n                            description=\"Raising generic 'Exception', consider using specific exception types\"\n   ", "chunk_type": "class", "line_start": 226, "line_end": 251, "language": "python", "name": "RaiseAnalyzer"}, "e407d68ff063_file": {"id": "e407d68ff063_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "\"\"\"\nSmart File Finder\n=================\nFind files by natural language queries and patterns.\n\nUsage:\n    python finder.py \"authentication\" [path]\n    python -m scripts.finder \"database handler\"\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    run_git_command,\n    Console\n)\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result.\"\"\"\n    path: Path\n    score: float\n    match_type: str  # 'filename', 'content', 'import', 'function', 'class'\n    context: str\n    line: Optional[int] = None\n\n\n@dataclass\nclass SearchResults:\n    \"\"\"Collection of search results.\"\"\"\n    query: str\n    results: List[SearchResult] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n            for r in sorted(items, key=lambda x: x.score, reverse=True)[:10]:\n                if r.line:\n                    lines.append(f\"- `{r.path}:{r.line}` (score: {r.score:.2f})\")\n                else:\n                    lines.append(f\"- `{r.path}` (score: {r.score:.2f})\")\n                lines.appen", "chunk_type": "file", "line_start": 1, "line_end": 300, "language": "python", "name": "finder.py"}, "e407d68ff063_func_expand_query": {"id": "e407d68ff063_func_expand_query", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def expand_query(query: str) -> List[str]:\n    \"\"\"Expand query into search terms.\"\"\"\n    terms = re.findall(r'[a-z0-9]+', query.lower())\n    expanded = list(terms)\n\n    for term in terms:\n        if term in QUERY_EXPANSIONS:\n            expanded.extend(QUERY_EXPANSIONS[term])\n\n    return list(set(expanded))", "chunk_type": "function", "line_start": 97, "line_end": 106, "language": "python", "name": "expand_query"}, "e407d68ff063_func_score_filename_match": {"id": "e407d68ff063_func_score_filename_match", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def score_filename_match(filename: str, terms: List[str]) -> float:\n    \"\"\"Score a filename against search terms.\"\"\"\n    name_lower = filename.lower()\n    score = 0.0\n\n    for term in terms:\n        if term in name_lower:\n            # Exact match gets higher score\n            score += 2.0\n            # Even higher if at word boundary\n            if f\"_{term}\" in name_lower or name_lower.startswith(term):\n                score += 1.0\n\n    return score", "chunk_type": "function", "line_start": 109, "line_end": 122, "language": "python", "name": "score_filename_match"}, "e407d68ff063_func_search_file_content": {"id": "e407d68ff063_func_search_file_content", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def search_file_content(\n    path: Path,\n    terms: List[str]\n) -> List[Tuple[int, str, float]]:\n    \"\"\"Search file content for terms.\"\"\"\n    matches = []\n\n    try:\n        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return matches\n\n    for i, line in enumerate(lines, 1):\n        line_lower = line.lower()\n        score = sum(1.0 for term in terms if term in line_lower)\n        if score > 0:\n            matches.append((i, line.strip()[:100], score))\n\n    return matches", "chunk_type": "function", "line_start": 125, "line_end": 144, "language": "python", "name": "search_file_content"}, "e407d68ff063_func_search_module_structure": {"id": "e407d68ff063_func_search_module_structure", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def search_module_structure(\n    path: Path,\n    terms: List[str]\n) -> List[SearchResult]:\n    \"\"\"Search module functions and classes.\"\"\"\n    results = []\n\n    module = analyze_module(path)\n    if module is None:\n        return results\n\n    # Search functions\n    for func in module.functions:\n        name_lower = func.name.lower()\n        score = sum(2.0 for term in terms if term in name_lower)\n\n        # Check docstring\n        if func.docstring:\n            doc_lower = func.docstring.lower()\n            score += sum(0.5 for term in terms if term in doc_lower)\n\n        if score > 0:\n            results.append(SearchResult(\n                path=path,\n                score=score,\n                match_type='function',\n                context=f\"def {func.name}(): {func.docstring or ''}\",\n                line=func.lineno\n            ))\n\n    # Search classes\n    for cls in module.classes:\n        name_lower = cls.name.lower()\n        score = sum(2.0 for term in terms if term in name_lower)", "chunk_type": "function", "line_start": 147, "line_end": 206, "language": "python", "name": "search_module_structure"}, "e407d68ff063_func_find_files": {"id": "e407d68ff063_func_find_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def find_files(\n    query: str,\n    root: Path,\n    limit: int = 20,\n    exclude_patterns: List[str] = None\n) -> SearchResults:\n    \"\"\"Find files matching a query.\"\"\"\n    results = SearchResults(query=query)\n    terms = expand_query(query)\n\n    Console.info(f\"Searching for: '{query}'\")\n    Console.info(f\"Terms: {', '.join(terms)}\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    all_results = []\n\n    for path in files:\n        # Filename match\n        filename_score = score_filename_match(path.name, terms)\n        if filename_score > 0:\n            all_results.append(SearchResult(\n                path=path,\n                score=filename_score,\n                match_type='filename',\n                context=path.name\n            ))\n\n        # Module structure search\n        structure_results = search_module_structure(path, terms)\n        all_results.extend(structure_results)\n\n        # Content search (only if not foun", "chunk_type": "function", "line_start": 209, "line_end": 258, "language": "python", "name": "find_files"}, "e407d68ff063_func_main": {"id": "e407d68ff063_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Smart File Finder\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.fail(\"Usage: mcp find <query> [path]\")\n        print(\"\\nExamples:\")\n        print('  mcp find \"authentication\"')\n        print('  mcp find \"database handler\"')\n        print('  mcp find \"api endpoint\" src/')\n        return 1\n\n    query = args[0]\n\n    if len(args) > 1:\n        path = Path(args[1])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Searching in: {path}\")\n\n    results = find_files(query, path)\n\n    print(results.to_markdown())\n\n    Console.ok(f\"Found {len(results.results)} results\")\n\n    return 0", "chunk_type": "function", "line_start": 261, "line_end": 295, "language": "python", "name": "main"}, "e407d68ff063_func_to_markdown": {"id": "e407d68ff063_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n            for r in sorted(items, key=lambda x: x.score, reverse=True)[:10]:\n                if r.line:\n                    lines.append(f\"- `{r.pat", "chunk_type": "function", "line_start": 43, "line_end": 79, "language": "python", "name": "to_markdown"}, "e407d68ff063_class_SearchResult": {"id": "e407d68ff063_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "class SearchResult:\n    \"\"\"A search result.\"\"\"\n    path: Path\n    score: float\n    match_type: str  # 'filename', 'content', 'import', 'function', 'class'\n    context: str\n    line: Optional[int] = None", "chunk_type": "class", "line_start": 28, "line_end": 34, "language": "python", "name": "SearchResult"}, "e407d68ff063_class_SearchResults": {"id": "e407d68ff063_class_SearchResults", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\finder.py", "content": "class SearchResults:\n    \"\"\"Collection of search results.\"\"\"\n    query: str\n    results: List[SearchResult] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Search: {self.query}\",\n            \"\",\n            f\"**Found:** {len(self.results)} results\",\n            \"\",\n        ]\n\n        if not self.results:\n            lines.append(\"No results found.\")\n            return \"\\n\".join(lines)\n\n        # Group by match type\n        by_type: Dict[str, List[SearchResult]] = {}\n        for r in self.results:\n            if r.match_type not in by_type:\n                by_type[r.match_type] = []\n            by_type[r.match_type].append(r)\n\n        type_order = ['filename', 'function', 'class', 'import', 'content']\n        for match_type in type_order:\n            items = by_type.get(match_type, [])\n            if not items:\n                continue\n\n            lines.append(f\"## {match_type.title()} Matches\")\n            lines.append(\"\")\n\n          ", "chunk_type": "class", "line_start": 38, "line_end": 79, "language": "python", "name": "SearchResults"}, "6d0444adc517_file": {"id": "6d0444adc517_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "\"\"\"\nAuto-Fix Tool\n=============\nAutomatically fix common code issues.\n\nUsage:\n    python fix.py [path] [--lint] [--format] [--imports]\n    python -m scripts.fix src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console\n)\n\n\n@dataclass\nclass FixResult:\n    \"\"\"Result of a fix operation.\"\"\"\n    path: Path\n    fix_type: str\n    original: str\n    fixed: str\n    line: int\n    description: str\n\n\n@dataclass\nclass FixReport:\n    \"\"\"Complete fix report.\"\"\"\n    fixes_applied: List[FixResult] = field(default_factory=list)\n    files_modified: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        return \"\\n\".join(lines)\n\n\ndef sort_imports(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Sort and organize imports.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n\n    # Find import block\n    import_lines = []\n    import_start = None\n    import_end = None\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n        if stripped.startswith('import ') or stripped.startswith('fro", "chunk_type": "file", "line_start": 1, "line_end": 476, "language": "python", "name": "fix.py"}, "6d0444adc517_func_sort_imports": {"id": "6d0444adc517_func_sort_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def sort_imports(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Sort and organize imports.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n\n    # Find import block\n    import_lines = []\n    import_start = None\n    import_end = None\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n        if stripped.startswith('import ') or stripped.startswith('from '):\n            if import_start is None:\n                import_start = i\n            import_end = i\n            import_lines.append((i, line))\n        elif import_start is not None and stripped and not stripped.startswith('#'):\n            break\n\n    if not import_lines:\n        return content, fixes\n\n    # Group imports\n    stdlib = []\n    third_party = []\n    local = []\n\n    STDLIB = {\n        'os', 'sys', 're', 'json', 'pathlib', 'typing', 'collections',\n        'itertools', 'functools', 'datetime', 'time', 'logging', 'ast',\n        'subprocess', 'threading', 'multiprocessing', 'queue', 'socket',\n        'ht", "chunk_type": "function", "line_start": 73, "line_end": 165, "language": "python", "name": "sort_imports"}, "6d0444adc517_func_fix_trailing_whitespace": {"id": "6d0444adc517_func_fix_trailing_whitespace", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_trailing_whitespace(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Remove trailing whitespace.\"\"\"\n    fixes = []\n    lines = content.split('\\n')\n    fixed_lines = []\n\n    for i, line in enumerate(lines):\n        if line != line.rstrip():\n            fixes.append(FixResult(\n                path=Path(''),\n                fix_type='whitespace',\n                original=line,\n                fixed=line.rstrip(),\n                line=i + 1,\n                description='Removed trailing whitespace'\n            ))\n            fixed_lines.append(line.rstrip())\n        else:\n            fixed_lines.append(line)\n\n    return '\\n'.join(fixed_lines), fixes", "chunk_type": "function", "line_start": 168, "line_end": 188, "language": "python", "name": "fix_trailing_whitespace"}, "6d0444adc517_func_fix_blank_lines": {"id": "6d0444adc517_func_fix_blank_lines", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_blank_lines(content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Fix excessive blank lines.\"\"\"\n    fixes = []\n\n    # Replace 3+ blank lines with 2\n    pattern = r'\\n{4,}'\n    if re.search(pattern, content):\n        content = re.sub(pattern, '\\n\\n\\n', content)\n        fixes.append(FixResult(\n            path=Path(''),\n            fix_type='formatting',\n            original='',\n            fixed='',\n            line=0,\n            description='Reduced excessive blank lines'\n        ))\n\n    # Ensure file ends with single newline\n    if content and not content.endswith('\\n'):\n        content += '\\n'\n        fixes.append(FixResult(\n            path=Path(''),\n            fix_type='formatting',\n            original='',\n            fixed='',\n            line=0,\n            description='Added final newline'\n        ))\n\n    return content, fixes", "chunk_type": "function", "line_start": 191, "line_end": 220, "language": "python", "name": "fix_blank_lines"}, "6d0444adc517_func_remove_unused_imports": {"id": "6d0444adc517_func_remove_unused_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def remove_unused_imports(path: Path, content: str) -> Tuple[str, List[FixResult]]:\n    \"\"\"Remove unused imports.\"\"\"\n    fixes = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return content, fixes\n\n    # Find all imports\n    imported_names = {}  # name -> line\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                name = alias.asname or alias.name.split('.')[0]\n                imported_names[name] = node.lineno\n        elif isinstance(node, ast.ImportFrom):\n            for alias in node.names:\n                if alias.name != '*':\n                    name = alias.asname or alias.name\n                    imported_names[name] = node.lineno\n\n    # Find all name usages\n    used_names: Set[str] = set()\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Name):\n            used_names.add(node.id)\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n     ", "chunk_type": "function", "line_start": 223, "line_end": 286, "language": "python", "name": "remove_unused_imports"}, "6d0444adc517_func_fix_file": {"id": "6d0444adc517_func_fix_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_file(\n    path: Path,\n    fix_imports: bool = True,\n    fix_whitespace: bool = True,\n    fix_formatting: bool = True,\n    fix_unused: bool = True,\n    dry_run: bool = False\n) -> List[FixResult]:\n    \"\"\"Fix issues in a single file.\"\"\"\n    all_fixes = []\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            content = f.read()\n    except Exception:\n        return all_fixes\n\n    original = content\n\n    # Apply fixes\n    if fix_imports:\n        content, fixes = sort_imports(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_whitespace:\n        content, fixes = fix_trailing_whitespace(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_formatting:\n        content, fixes = fix_blank_lines(content)\n        for fix in fixes:\n            fix.path = path\n        all_fixes.extend(fixes)\n\n    if fix_unused:\n        content, fixes = remove_unused_imports(path, c", "chunk_type": "function", "line_start": 289, "line_end": 338, "language": "python", "name": "fix_file"}, "6d0444adc517_func_fix_project": {"id": "6d0444adc517_func_fix_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_project(\n    root: Path,\n    fix_imports: bool = True,\n    fix_whitespace: bool = True,\n    fix_formatting: bool = True,\n    fix_unused: bool = True,\n    dry_run: bool = False,\n    exclude_patterns: List[str] = None\n) -> FixReport:\n    \"\"\"Fix issues in a project.\"\"\"\n    report = FixReport()\n\n    Console.info(f\"Fixing issues in {root}...\")\n    if dry_run:\n        Console.warn(\"DRY RUN - no files will be modified\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        fixes = fix_file(\n            path,\n            fix_imports=fix_imports,\n            fix_whitespace=fix_whitespace,\n            fix_formatting=fix_formatting,\n            fix_unused=fix_unused,\n            dry_run=dry_run\n        )\n\n        if fixes:\n            report.files_modified += 1\n            report.fixes_applied.extend(fixes)\n\n    return report", "chunk_type": "function", "line_start": 341, "line_end": 374, "language": "python", "name": "fix_project"}, "6d0444adc517_func_fix_staged_files": {"id": "6d0444adc517_func_fix_staged_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def fix_staged_files(dry_run: bool = False) -> FixReport:\n    \"\"\"Fix only git staged files.\"\"\"\n    import subprocess\n\n    report = FixReport()\n\n    try:\n        result = subprocess.run(\n            ['git', 'diff', '--cached', '--name-only', '--diff-filter=ACM'],\n            capture_output=True, text=True\n        )\n        staged = [f.strip() for f in result.stdout.strip().split('\\n') if f.strip().endswith('.py')]\n    except Exception:\n        return report\n\n    if not staged:\n        return report\n\n    Console.info(f\"Fixing {len(staged)} staged files...\")\n\n    for file_path in staged:\n        path = Path(file_path)\n        if path.exists():\n            fixes = fix_file(path, dry_run=dry_run)\n            if fixes:\n                report.files_modified += 1\n                report.fixes_applied.extend(fixes)\n\n    return report", "chunk_type": "function", "line_start": 377, "line_end": 405, "language": "python", "name": "fix_staged_files"}, "6d0444adc517_func_main": {"id": "6d0444adc517_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Fix Tool\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    dry_run = '--dry-run' in sys.argv\n    safe_only = '--safe' in sys.argv\n    apply_mode = '--apply' in sys.argv\n    staged_only = '--staged' in sys.argv\n\n    # Safe mode: only whitespace, imports, formatting (no complex changes)\n    if safe_only:\n        fix_imports = True\n        fix_format = True\n        fix_lint = False  # Don't remove unused imports in safe mode\n    else:\n        fix_imports = '--imports' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n        fix_format = '--format' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n        fix_lint = '--lint' in sys.argv or not any(\n            a in sys.argv for a in ['--imports', '--lint', '--format']\n        )\n\n    # Apply mode: actually apply fixes (not dry run)\n", "chunk_type": "function", "line_start": 408, "line_end": 470, "language": "python", "name": "main"}, "6d0444adc517_func_to_markdown": {"id": "6d0444adc517_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 43, "line_end": 70, "language": "python", "name": "to_markdown"}, "6d0444adc517_class_FixResult": {"id": "6d0444adc517_class_FixResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "class FixResult:\n    \"\"\"Result of a fix operation.\"\"\"\n    path: Path\n    fix_type: str\n    original: str\n    fixed: str\n    line: int\n    description: str", "chunk_type": "class", "line_start": 27, "line_end": 34, "language": "python", "name": "FixResult"}, "6d0444adc517_class_FixReport": {"id": "6d0444adc517_class_FixReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\fix.py", "content": "class FixReport:\n    \"\"\"Complete fix report.\"\"\"\n    fixes_applied: List[FixResult] = field(default_factory=list)\n    files_modified: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Auto-Fix Report\",\n            \"\",\n            f\"**Files modified:** {self.files_modified}\",\n            f\"**Fixes applied:** {len(self.fixes_applied)}\",\n            \"\",\n        ]\n\n        if not self.fixes_applied:\n            lines.append(\"No fixes needed.\")\n            return \"\\n\".join(lines)\n\n        # Group by file\n        by_file: Dict[Path, List[FixResult]] = {}\n        for fix in self.fixes_applied:\n            if fix.path not in by_file:\n                by_file[fix.path] = []\n            by_file[fix.path].append(fix)\n\n        for path, fixes in by_file.items():\n            lines.append(f\"## {path}\")\n            lines.append(\"\")\n            for fix in fixes:\n                lines.append(f\"- **Line {fix.line}:** {fix.description}\")\n            lines.append(\"\")\n\n        retur", "chunk_type": "class", "line_start": 38, "line_end": 70, "language": "python", "name": "FixReport"}, "9b6c215bead6_file": {"id": "9b6c215bead6_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "\"\"\"\nGit History Index\n=================\nIndex git commits, blame, and file evolution for AI agents.\n\nUsage:\n    python mcp.py git-history [file]\n    python mcp.py blame [file]\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport re\nimport subprocess\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Commit:\n    \"\"\"A git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    email: str\n    date: str\n    message: str\n    files_changed: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass BlameInfo:\n    \"\"\"Blame info for a line.\"\"\"\n    line_num: int\n    commit_hash: str\n    author: str\n    date: str\n    content: str\n\n\n@dataclass\nclass FileHistory:\n    \"\"\"History of a file.\"\"\"\n    path: str\n    commits: List[Commit] = field(default_factory=list)\n    authors: List[str] = field(default_factory=list)\n    first_commit: Optional[str] = None\n    last_commit: Optional[str] = None\n\n\ndef run_git(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"Run git command and return output.\"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd()\n        )\n        if result.returncode == 0:\n            return result.stdout.strip()\n        return None\n    except Exception:\n        return None\n\n\ndef get_commits(\n    path: Path = None,\n    since: str = None,\n    limit: int = 100,\n    file_path: Path = None\n) -> List[Commit]:\n    \"\"\"Get list of commits.\"\"\"\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        '--name-only'\n    ]\n\n    if since:\n        args.append(f'--since={since}')\n\n    if file_path:\n        args.extend(['--', str(file_path)])\n\n    output = run_git(args, path)\n    if not output:\n        return []\n\n    commits = []\n    current_commit = None\n\n    for line in ou", "chunk_type": "file", "line_start": 1, "line_end": 328, "language": "python", "name": "git_index.py"}, "9b6c215bead6_func_run_git": {"id": "9b6c215bead6_func_run_git", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def run_git(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"Run git command and return output.\"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd()\n        )\n        if result.returncode == 0:\n            return result.stdout.strip()\n        return None\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 55, "line_end": 68, "language": "python", "name": "run_git"}, "9b6c215bead6_func_get_commits": {"id": "9b6c215bead6_func_get_commits", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_commits(\n    path: Path = None,\n    since: str = None,\n    limit: int = 100,\n    file_path: Path = None\n) -> List[Commit]:\n    \"\"\"Get list of commits.\"\"\"\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        '--name-only'\n    ]\n\n    if since:\n        args.append(f'--since={since}')\n\n    if file_path:\n        args.extend(['--', str(file_path)])\n\n    output = run_git(args, path)\n    if not output:\n        return []\n\n    commits = []\n    current_commit = None\n\n    for line in output.split('\\n'):\n        if '|' in line and line.count('|') >= 5:\n            # Commit line\n            parts = line.split('|', 5)\n            if current_commit:\n                commits.append(current_commit)\n\n            current_commit = Commit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                email=parts[3],\n                date=parts[4],\n                message=parts[5] if len(parts) > 5 else ", "chunk_type": "function", "line_start": 71, "line_end": 120, "language": "python", "name": "get_commits"}, "9b6c215bead6_func_get_blame": {"id": "9b6c215bead6_func_get_blame", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_blame(file_path: Path, root: Path = None) -> List[BlameInfo]:\n    \"\"\"Get blame info for file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    args = ['blame', '--line-porcelain', str(file_path)]\n    output = run_git(args, root)\n\n    if not output:\n        return []\n\n    blame_info = []\n    current = {}\n    line_num = 0\n\n    for line in output.split('\\n'):\n        if line.startswith('author '):\n            current['author'] = line[7:]\n        elif line.startswith('author-time '):\n            ts = int(line[12:])\n            current['date'] = datetime.fromtimestamp(ts).isoformat()\n        elif line.startswith('\\t'):\n            line_num += 1\n            if 'commit_hash' in current:\n                blame_info.append(BlameInfo(\n                    line_num=line_num,\n                    commit_hash=current.get('commit_hash', ''),\n                    author=current.get('author', 'Unknown'),\n                    date=current.get('date', ''),\n                    content=line", "chunk_type": "function", "line_start": 123, "line_end": 157, "language": "python", "name": "get_blame"}, "9b6c215bead6_func_get_file_history": {"id": "9b6c215bead6_func_get_file_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_file_history(file_path: Path, root: Path = None) -> FileHistory:\n    \"\"\"Get complete history of a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    commits = get_commits(root, file_path=file_path)\n\n    authors = list(set(c.author for c in commits))\n\n    return FileHistory(\n        path=str(file_path),\n        commits=commits,\n        authors=authors,\n        first_commit=commits[-1].short_hash if commits else None,\n        last_commit=commits[0].short_hash if commits else None\n    )", "chunk_type": "function", "line_start": 160, "line_end": 174, "language": "python", "name": "get_file_history"}, "9b6c215bead6_func_get_change_intent": {"id": "9b6c215bead6_func_get_change_intent", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def get_change_intent(file_path: Path, root: Path = None) -> str:\n    \"\"\"Get the intent behind recent changes to a file.\"\"\"\n    history = get_file_history(file_path, root)\n\n    if not history.commits:\n        return \"No git history available\"\n\n    # Summarize recent commits\n    recent = history.commits[:5]\n\n    lines = [f\"Recent changes to {file_path.name}:\", \"\"]\n    for commit in recent:\n        lines.append(f\"- {commit.message} ({commit.author}, {commit.date[:10]})\")\n\n    lines.append(\"\")\n    lines.append(f\"Authors: {', '.join(history.authors[:5])}\")\n    lines.append(f\"Total commits: {len(history.commits)}\")\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 177, "line_end": 195, "language": "python", "name": "get_change_intent"}, "9b6c215bead6_func_search_commits": {"id": "9b6c215bead6_func_search_commits", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def search_commits(query: str, root: Path = None, limit: int = 20) -> List[Commit]:\n    \"\"\"Search commit messages.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    args = [\n        'log',\n        f'-{limit}',\n        '--format=%H|%h|%an|%ae|%aI|%s',\n        f'--grep={query}',\n        '-i'  # Case insensitive\n    ]\n\n    output = run_git(args, root)\n    if not output:\n        return []\n\n    commits = []\n    for line in output.split('\\n'):\n        if '|' in line:\n            parts = line.split('|', 5)\n            commits.append(Commit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                email=parts[3],\n                date=parts[4],\n                message=parts[5] if len(parts) > 5 else \"\"\n            ))\n\n    return commits", "chunk_type": "function", "line_start": 198, "line_end": 227, "language": "python", "name": "search_commits"}, "9b6c215bead6_func_index_git_history": {"id": "9b6c215bead6_func_index_git_history", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def index_git_history(root: Path = None, since: str = \"3 months\") -> Dict:\n    \"\"\"Build git history index.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(f\"Indexing git history (since {since})...\")\n\n    commits = get_commits(root, since=since, limit=500)\n\n    # Build index\n    index = {\n        \"commit_count\": len(commits),\n        \"authors\": {},\n        \"files\": {},\n        \"commits\": []\n    }\n\n    for commit in commits:\n        # Track authors\n        if commit.author not in index[\"authors\"]:\n            index[\"authors\"][commit.author] = 0\n        index[\"authors\"][commit.author] += 1\n\n        # Track files\n        for file in commit.files_changed:\n            if file not in index[\"files\"]:\n                index[\"files\"][file] = []\n            index[\"files\"][file].append(commit.short_hash)\n\n        # Store commit (without files to save space)\n        index[\"commits\"].append({\n            \"hash\": commit.short_hash,\n            \"author\": commit.author,\n       ", "chunk_type": "function", "line_start": 230, "line_end": 275, "language": "python", "name": "index_git_history"}, "9b6c215bead6_func_main": {"id": "9b6c215bead6_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Git History Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        since = \"3 months\"\n        for i, arg in enumerate(sys.argv):\n            if arg == '--since' and i + 1 < len(sys.argv):\n                since = sys.argv[i + 1]\n        index_git_history(root, since)\n        return 0\n\n    if '--search' in sys.argv and args:\n        query = args[0]\n        Console.info(f\"Searching commits: {query}\")\n        commits = search_commits(query, root)\n\n        for commit in commits:\n            print(f\"{commit.short_hash} {commit.message[:60]} ({commit.author})\")\n        return 0\n\n    if '--blame' in sys.argv and args:\n        file_path = Path(args[0])\n        Console.info(f\"Blame: {file_path}\")\n\n        blame = get_blame(file_path, root)\n        for info in blame[:30]:\n            print(f\"{info.line_num:4d} {info.commit_hash[:7]} {info.a", "chunk_type": "function", "line_start": 278, "line_end": 323, "language": "python", "name": "main"}, "9b6c215bead6_class_Commit": {"id": "9b6c215bead6_class_Commit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "class Commit:\n    \"\"\"A git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    email: str\n    date: str\n    message: str\n    files_changed: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 24, "line_end": 32, "language": "python", "name": "Commit"}, "9b6c215bead6_class_BlameInfo": {"id": "9b6c215bead6_class_BlameInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "class BlameInfo:\n    \"\"\"Blame info for a line.\"\"\"\n    line_num: int\n    commit_hash: str\n    author: str\n    date: str\n    content: str", "chunk_type": "class", "line_start": 36, "line_end": 42, "language": "python", "name": "BlameInfo"}, "9b6c215bead6_class_FileHistory": {"id": "9b6c215bead6_class_FileHistory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\git_index.py", "content": "class FileHistory:\n    \"\"\"History of a file.\"\"\"\n    path: str\n    commits: List[Commit] = field(default_factory=list)\n    authors: List[str] = field(default_factory=list)\n    first_commit: Optional[str] = None\n    last_commit: Optional[str] = None", "chunk_type": "class", "line_start": 46, "line_end": 52, "language": "python", "name": "FileHistory"}, "71e99f167f1f_file": {"id": "71e99f167f1f_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "\"\"\"\nImpact Analysis\n================\nAnalyze what breaks when code changes.\n\nUsage:\n    python mcp.py impact [file]\n    python mcp.py impact --test [file]  # Show affected tests\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set, Tuple\nimport ast\nimport json\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass ImpactReport:\n    \"\"\"Report of change impact.\"\"\"\n    file: str\n    direct_dependents: List[str] = field(default_factory=list)  # Files that import this\n    indirect_dependents: List[str] = field(default_factory=list)  # Transitive deps\n    affected_tests: List[str] = field(default_factory=list)\n    total_impact: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n            lines.append(\"## Affected Tests\")\n            for test in self.affected_tests[:10]:\n                lines.append(f\"- {test}\")\n\n        return '\\n'.join(lines)\n\n\nclass DependencyGraph:\n    \"\"\"Graph of file dependencies.\"\"\"\n\n    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path\n\n    def add_file(self, file_path: Path, ro", "chunk_type": "file", "line_start": 1, "line_end": 235, "language": "python", "name": "impact.py"}, "71e99f167f1f_func_build_dependency_graph": {"id": "71e99f167f1f_func_build_dependency_graph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "def build_dependency_graph(root: Path = None) -> DependencyGraph:\n    \"\"\"Build and return dependency graph.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(\"Building dependency graph...\")\n\n    graph = DependencyGraph()\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    graph.build(root, exclude)\n\n    Console.ok(f\"Indexed {len(graph.imports)} files\")\n\n    return graph", "chunk_type": "function", "line_start": 131, "line_end": 143, "language": "python", "name": "build_dependency_graph"}, "71e99f167f1f_func_analyze_impact": {"id": "71e99f167f1f_func_analyze_impact", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "def analyze_impact(file_path: Path, root: Path = None) -> ImpactReport:\n    \"\"\"Analyze impact of changing a file.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    graph = build_dependency_graph(root)\n\n    try:\n        file_key = str(file_path.relative_to(root))\n    except ValueError:\n        file_key = str(file_path)\n\n    direct = list(graph.get_dependents(file_key))\n\n    all_deps = graph.get_transitive_dependents(file_key)\n    indirect = [d for d in all_deps if d not in direct]\n\n    # Find affected tests\n    tests = [d for d in all_deps if 'test' in d.lower() or d.startswith('tests/')]\n\n    return ImpactReport(\n        file=file_key,\n        direct_dependents=direct,\n        indirect_dependents=indirect,\n        affected_tests=tests,\n        total_impact=len(all_deps)\n    )", "chunk_type": "function", "line_start": 146, "line_end": 171, "language": "python", "name": "analyze_impact"}, "71e99f167f1f_func_save_impact_graph": {"id": "71e99f167f1f_func_save_impact_graph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "def save_impact_graph(root: Path = None):\n    \"\"\"Save dependency graph to disk.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    graph = build_dependency_graph(root)\n\n    # Convert to serializable format\n    data = {\n        \"imports\": {k: list(v) for k, v in graph.imports.items()},\n        \"imported_by\": {k: list(v) for k, v in graph.imported_by.items()},\n        \"file_count\": len(graph.imports)\n    }\n\n    index_path = root / '.mcp' / 'impact_graph.json'\n    index_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(index_path, 'w', encoding='utf-8') as f:\n        json.dump(data, f, indent=2)\n\n    Console.ok(f\"Saved impact graph to {index_path}\")", "chunk_type": "function", "line_start": 174, "line_end": 193, "language": "python", "name": "save_impact_graph"}, "71e99f167f1f_func_main": {"id": "71e99f167f1f_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Impact Analysis\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        save_impact_graph(root)\n        return 0\n\n    if not args:\n        Console.info(\"Usage: python impact.py <file>\")\n        Console.info(\"Options:\")\n        Console.info(\"  --index    Save dependency graph\")\n        Console.info(\"  --test     Show only affected tests\")\n        return 1\n\n    file_path = Path(args[0])\n\n    if not file_path.exists():\n        Console.fail(f\"File not found: {file_path}\")\n        return 1\n\n    report = analyze_impact(file_path, root)\n\n    if '--test' in sys.argv:\n        Console.info(f\"Affected tests for {file_path.name}:\")\n        for test in report.affected_tests:\n            print(f\"  - {test}\")\n        print(f\"\\nTotal: {len(report.affected_tests)} tests\")\n    else:\n        print(report.to_markdown())\n\n    return 0", "chunk_type": "function", "line_start": 196, "line_end": 230, "language": "python", "name": "main"}, "71e99f167f1f_func_to_markdown": {"id": "71e99f167f1f_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n            lines.append(\"## Affected Tests\")\n            for test in self.affected_tests[:10]:\n                lines.append(f\"- {test}\")\n\n        return '\\n'.join(lines)", "chunk_type": "function", "line_start": 31, "line_end": 56, "language": "python", "name": "to_markdown"}, "71e99f167f1f_func___init__": {"id": "71e99f167f1f_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path", "chunk_type": "function", "line_start": 62, "line_end": 65, "language": "python", "name": "__init__"}, "71e99f167f1f_func_add_file": {"id": "71e99f167f1f_func_add_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def add_file(self, file_path: Path, root: Path):\n        \"\"\"Add a file's imports to the graph.\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                source = f.read()\n            tree = ast.parse(source)\n        except Exception:\n            return\n\n        file_key = str(file_path.relative_to(root))\n\n        # Register this module\n        module_name = str(file_path.relative_to(root).with_suffix('')).replace('\\\\', '.').replace('/', '.')\n        self.module_to_file[module_name] = file_key\n\n        # Extract imports\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    self.imports[file_key].add(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                if node.module:\n                    self.imports[file_key].add(node.module)", "chunk_type": "function", "line_start": 67, "line_end": 89, "language": "python", "name": "add_file"}, "71e99f167f1f_func_build": {"id": "71e99f167f1f_func_build", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def build(self, root: Path, exclude_patterns: List[str] = None):\n        \"\"\"Build full dependency graph.\"\"\"\n        for file_path in find_python_files(root, exclude_patterns):\n            self.add_file(file_path, root)\n\n        # Build reverse mapping\n        for file_key, imports in self.imports.items():\n            for imp in imports:\n                # Try to resolve import to file\n                if imp in self.module_to_file:\n                    self.imported_by[self.module_to_file[imp]].add(file_key)", "chunk_type": "function", "line_start": 91, "line_end": 101, "language": "python", "name": "build"}, "71e99f167f1f_func_get_dependents": {"id": "71e99f167f1f_func_get_dependents", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_dependents(self, file_path: str) -> Set[str]:\n        \"\"\"Get files that depend on this file.\"\"\"\n        return self.imported_by.get(file_path, set())", "chunk_type": "function", "line_start": 103, "line_end": 105, "language": "python", "name": "get_dependents"}, "71e99f167f1f_func_get_dependencies": {"id": "71e99f167f1f_func_get_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_dependencies(self, file_path: str) -> Set[str]:\n        \"\"\"Get files this file depends on.\"\"\"\n        return self.imports.get(file_path, set())", "chunk_type": "function", "line_start": 107, "line_end": 109, "language": "python", "name": "get_dependencies"}, "71e99f167f1f_func_get_transitive_dependents": {"id": "71e99f167f1f_func_get_transitive_dependents", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "    def get_transitive_dependents(self, file_path: str, visited: Set[str] = None) -> Set[str]:\n        \"\"\"Get all transitive dependents.\"\"\"\n        if visited is None:\n            visited = set()\n\n        if file_path in visited:\n            return set()\n\n        visited.add(file_path)\n\n        all_deps = set()\n        direct = self.get_dependents(file_path)\n        all_deps.update(direct)\n\n        for dep in direct:\n            all_deps.update(self.get_transitive_dependents(dep, visited))\n\n        return all_deps", "chunk_type": "function", "line_start": 111, "line_end": 128, "language": "python", "name": "get_transitive_dependents"}, "71e99f167f1f_class_ImpactReport": {"id": "71e99f167f1f_class_ImpactReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "class ImpactReport:\n    \"\"\"Report of change impact.\"\"\"\n    file: str\n    direct_dependents: List[str] = field(default_factory=list)  # Files that import this\n    indirect_dependents: List[str] = field(default_factory=list)  # Transitive deps\n    affected_tests: List[str] = field(default_factory=list)\n    total_impact: int = 0\n\n    def to_markdown(self) -> str:\n        lines = [\n            f\"# Impact Report: {Path(self.file).name}\",\n            \"\",\n            f\"**Total Impact:** {self.total_impact} files\",\n            \"\",\n        ]\n\n        if self.direct_dependents:\n            lines.append(\"## Direct Dependents\")\n            for dep in self.direct_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.indirect_dependents:\n            lines.append(\"## Indirect Dependents\")\n            for dep in self.indirect_dependents[:10]:\n                lines.append(f\"- {dep}\")\n            lines.append(\"\")\n\n        if self.affected_tests:\n        ", "chunk_type": "class", "line_start": 23, "line_end": 56, "language": "python", "name": "ImpactReport"}, "71e99f167f1f_class_DependencyGraph": {"id": "71e99f167f1f_class_DependencyGraph", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\impact.py", "content": "class DependencyGraph:\n    \"\"\"Graph of file dependencies.\"\"\"\n\n    def __init__(self):\n        self.imports: Dict[str, Set[str]] = defaultdict(set)  # file -> what it imports\n        self.imported_by: Dict[str, Set[str]] = defaultdict(set)  # file -> who imports it\n        self.module_to_file: Dict[str, str] = {}  # module name -> file path\n\n    def add_file(self, file_path: Path, root: Path):\n        \"\"\"Add a file's imports to the graph.\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                source = f.read()\n            tree = ast.parse(source)\n        except Exception:\n            return\n\n        file_key = str(file_path.relative_to(root))\n\n        # Register this module\n        module_name = str(file_path.relative_to(root).with_suffix('')).replace('\\\\', '.').replace('/', '.')\n        self.module_to_file[module_name] = file_key\n\n        # Extract imports\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n           ", "chunk_type": "class", "line_start": 59, "line_end": 128, "language": "python", "name": "DependencyGraph"}, "178d0d034067_file": {"id": "178d0d034067_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\index_all.py", "content": "\"\"\"\nUnified Index Manager\n=====================\nRun all indexes at once for complete codebase intelligence.\n\nUsage:\n    python mcp.py index-all      # Full reindex\n    python mcp.py index-all --what  # Show what's indexed\n\"\"\"\n\nfrom datetime import datetime\nfrom pathlib import Path\nimport json\nimport sys\nimport time\n\nfrom .utils import Console, find_project_root\n\n\ndef run_all_indexes(root: Path = None, verbose: bool = True) -> dict:\n    \"\"\"Run all indexes and return summary.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    if verbose:\n        Console.header(\"Full Index Build\")\n        Console.info(f\"Indexing {root}...\")\n\n    start_time = time.time()\n    results = {}\n\n    # 1. Semantic code index\n    if verbose:\n        Console.info(\"1/7 Semantic code index...\")\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n        count = store.index_codebase(root)\n        results['semantic'] = {'status': 'ok', 'items': count}\n    except Exception as e:\n        results['semantic'] = {'status': 'error', 'error': str(e)}\n\n    # 2. Git history index\n    if verbose:\n        Console.info(\"2/7 Git history index...\")\n    try:\n        from .git_index import index_git_history\n        index = index_git_history(root, since=\"3 months\")\n        results['git'] = {'status': 'ok', 'commits': index.get('commit_count', 0)}\n    except Exception as e:\n        results['git'] = {'status': 'error', 'error': str(e)}\n\n    # 3. TODO/FIXME index\n    if verbose:\n        Console.info(\"3/7 TODO/FIXME index...\")\n    try:\n        from .todo_index import index_todos\n        index = index_todos(root)\n        results['todos'] = {'status': 'ok', 'items': index.get('total', 0)}\n    except Exception as e:\n        results['todos'] = {'status': 'error', 'error': str(e)}\n\n    # 4. Impact graph\n    if verbose:\n        Console.info(\"4/7 Dependency impact graph...\")\n    try:\n        from .impact import save_impact_graph\n        save_impact_graph(r", "chunk_type": "file", "line_start": 1, "line_end": 195, "language": "python", "name": "index_all.py"}, "178d0d034067_func_run_all_indexes": {"id": "178d0d034067_func_run_all_indexes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\index_all.py", "content": "def run_all_indexes(root: Path = None, verbose: bool = True) -> dict:\n    \"\"\"Run all indexes and return summary.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    if verbose:\n        Console.header(\"Full Index Build\")\n        Console.info(f\"Indexing {root}...\")\n\n    start_time = time.time()\n    results = {}\n\n    # 1. Semantic code index\n    if verbose:\n        Console.info(\"1/7 Semantic code index...\")\n    try:\n        from .vector_store import VectorStore\n        store = VectorStore(root / '.mcp' / 'vector_index')\n        count = store.index_codebase(root)\n        results['semantic'] = {'status': 'ok', 'items': count}\n    except Exception as e:\n        results['semantic'] = {'status': 'error', 'error': str(e)}\n\n    # 2. Git history index\n    if verbose:\n        Console.info(\"2/7 Git history index...\")\n    try:\n        from .git_index import index_git_history\n        index = index_git_history(root, since=\"3 months\")\n        results['git'] = {'status': 'ok', 'commits': index.", "chunk_type": "function", "line_start": 20, "line_end": 123, "language": "python", "name": "run_all_indexes"}, "178d0d034067_func_show_index_status": {"id": "178d0d034067_func_show_index_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\index_all.py", "content": "def show_index_status(root: Path = None):\n    \"\"\"Show what's currently indexed.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    mcp_dir = root / '.mcp'\n\n    print(\"\\n## Index Status\")\n    print(\"\")\n\n    indexes = [\n        ('vector_index', 'Semantic Code', 'chunks.json'),\n        ('git_index.json', 'Git History', None),\n        ('todo_index.json', 'TODOs/FIXMEs', None),\n        ('impact_graph.json', 'Impact Graph', None),\n        ('doc_index.json', 'Documentation', None),\n        ('config_index.json', 'Config', None),\n        ('coverage_index.json', 'Coverage', None),\n    ]\n\n    for idx_name, display_name, sub_file in indexes:\n        idx_path = mcp_dir / idx_name\n\n        if sub_file:\n            idx_path = idx_path / sub_file\n\n        if idx_path.exists():\n            size = idx_path.stat().st_size\n            size_str = f\"{size / 1024:.1f}KB\" if size > 1024 else f\"{size}B\"\n            print(f\"  \u2713 {display_name:20} ({size_str})\")\n        else:\n            print(f\"  \u2717 {dis", "chunk_type": "function", "line_start": 126, "line_end": 155, "language": "python", "name": "show_index_status"}, "178d0d034067_func_main": {"id": "178d0d034067_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\index_all.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    root = find_project_root() or Path.cwd()\n\n    if '--what' in sys.argv or '--status' in sys.argv:\n        Console.header(\"Index Status\")\n        show_index_status(root)\n        return 0\n\n    if '--quick' in sys.argv:\n        # Quick mode: only semantic + todos\n        Console.header(\"Quick Index\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(root / '.mcp' / 'vector_index')\n            store.index_codebase(root)\n        except Exception:\n            pass\n\n        try:\n            from .todo_index import index_todos\n            index_todos(root)\n        except Exception:\n            pass\n\n        Console.ok(\"Quick index complete\")\n        return 0\n\n    # Full index\n    run_all_indexes(root, verbose=True)\n\n    return 0", "chunk_type": "function", "line_start": 158, "line_end": 190, "language": "python", "name": "main"}, "4fc79d1c0397_file": {"id": "4fc79d1c0397_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "\"\"\"\nLearning System\n================\nLearn from feedback, preferences, and past mistakes.\n\nUsage:\n    python mcp.py learn --show-patterns\n    python mcp.py learn --from-feedback\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Feedback:\n    \"\"\"A feedback entry.\"\"\"\n    action: str\n    outcome: str  # 'success', 'failure', 'partial'\n    context: str\n    timestamp: str\n    details: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass ErrorPattern:\n    \"\"\"A learned error pattern.\"\"\"\n    error_type: str\n    pattern: str\n    fix: str\n    occurrences: int = 1\n    last_seen: str = \"\"\n    contexts: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Preference:\n    \"\"\"A user preference.\"\"\"\n    key: str\n    value: Any\n    learned_from: str = \"default\"\n    confidence: float = 0.5\n\n\nclass LearningStore:\n    \"\"\"Store for learning data.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()\n\n    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.js", "chunk_type": "file", "line_start": 1, "line_end": 311, "language": "python", "name": "learning.py"}, "4fc79d1c0397_func_get_store": {"id": "4fc79d1c0397_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "def get_store() -> LearningStore:\n    global _store\n    if _store is None:\n        _store = LearningStore()\n    return _store", "chunk_type": "function", "line_start": 248, "line_end": 252, "language": "python", "name": "get_store"}, "4fc79d1c0397_func_record_feedback": {"id": "4fc79d1c0397_func_record_feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def record_feedback(\n        self,\n        action: str,\n        outcome: str,\n        context: str = \"\",\n        details: Dict = None\n    ):\n        \"\"\"Record feedback on an action.\"\"\"\n        fb = Feedback(\n            action=action,\n            outcome=outcome,\n            context=context,\n            timestamp=datetime.utcnow().isoformat() + 'Z',\n            details=details or {}\n        )\n        self.feedback.append(fb)\n        self.save()", "chunk_type": "function", "line_start": 119, "line_end": 135, "language": "python", "name": "record_feedback"}, "4fc79d1c0397_func_record_error": {"id": "4fc79d1c0397_func_record_error", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def record_error(self, error_type: str, pattern: str, fix: str, context: str = \"\"):\n        \"\"\"Record an error and its fix.\"\"\"\n        key = f\"{error_type}:{pattern[:50]}\"\n\n        if key in self.errors:\n            err = self.errors[key]\n            err.occurrences += 1\n            err.last_seen = datetime.utcnow().isoformat() + 'Z'\n            if context and context not in err.contexts:\n                err.contexts.append(context)\n                err.contexts = err.contexts[-5:]  # Keep last 5\n        else:\n            self.errors[key] = ErrorPattern(\n                error_type=error_type,\n                pattern=pattern,\n                fix=fix,\n                last_seen=datetime.utcnow().isoformat() + 'Z',\n                contexts=[context] if context else []\n            )\n\n        self.save()", "chunk_type": "function", "line_start": 137, "line_end": 157, "language": "python", "name": "record_error"}, "4fc79d1c0397_func_suggest_fix": {"id": "4fc79d1c0397_func_suggest_fix", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def suggest_fix(self, error_type: str, pattern: str) -> Optional[str]:\n        \"\"\"Suggest a fix for an error based on patterns.\"\"\"\n        key = f\"{error_type}:{pattern[:50]}\"\n\n        if key in self.errors:\n            return self.errors[key].fix\n\n        # Fuzzy match\n        for k, err in self.errors.items():\n            if error_type in k and pattern[:20] in err.pattern:\n                return err.fix\n\n        return None", "chunk_type": "function", "line_start": 174, "line_end": 186, "language": "python", "name": "suggest_fix"}, "4fc79d1c0397_func_main": {"id": "4fc79d1c0397_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Learning System\")\n\n    store = get_store()\n\n    Console.info(f\"Storage: {store.storage_path}\")\n    Console.info(f\"Feedback entries: {len(store.feedback)}\")\n    Console.info(f\"Error patterns: {len(store.errors)}\")\n    Console.info(f\"Preferences: {len(store.preferences)}\")\n\n    if '--show-patterns' in sys.argv or '--patterns' in sys.argv:\n        analysis = store.analyze_patterns()\n\n        print(\"\\n## Action Outcomes\")\n        for action, data in analysis[\"action_outcomes\"].items():\n            print(f\"  {action}: {data['success_rate']*100:.0f}% success ({data['count']} times)\")\n\n        print(\"\\n## Common Errors\")\n        for err in analysis[\"common_errors\"]:\n            print(f\"  [{err['type']}] {err['pattern']}\")\n            print(f\"    Fix: {err['fix']}\")\n            print(f\"    Occurred: {err['occurrences']} times\")\n\n        return 0\n\n    if '--preferences' in sys.argv:\n        print(\"\\n## Preferences\")\n        for key, pre", "chunk_type": "function", "line_start": 270, "line_end": 306, "language": "python", "name": "main"}, "4fc79d1c0397_func___init__": {"id": "4fc79d1c0397_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()", "chunk_type": "function", "line_start": 55, "line_end": 68, "language": "python", "name": "__init__"}, "4fc79d1c0397_func_load": {"id": "4fc79d1c0397_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.json'\n        if err_path.exists():\n            try:\n                with open(err_path, 'r') as f:\n                    data = json.load(f)\n                    self.errors = {k: ErrorPattern(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n        # Load preferences\n        pref_path = self.storage_path / 'preferences.json'\n        if pref_path.exists():\n            try:\n                with open(pref_path, 'r') as f:\n                    data = json.load(f)\n                    self.preferences = {k: Pr", "chunk_type": "function", "line_start": 70, "line_end": 100, "language": "python", "name": "load"}, "4fc79d1c0397_func_save": {"id": "4fc79d1c0397_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def save(self):\n        \"\"\"Save all learning data.\"\"\"\n        # Save feedback\n        fb_path = self.storage_path / 'feedback.json'\n        with open(fb_path, 'w') as f:\n            json.dump([asdict(fb) for fb in self.feedback[-1000:]], f, indent=2)\n\n        # Save errors\n        err_path = self.storage_path / 'errors.json'\n        with open(err_path, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.errors.items()}, f, indent=2)\n\n        # Save preferences\n        pref_path = self.storage_path / 'preferences.json'\n        with open(pref_path, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.preferences.items()}, f, indent=2)", "chunk_type": "function", "line_start": 102, "line_end": 117, "language": "python", "name": "save"}, "4fc79d1c0397_func_get_preference": {"id": "4fc79d1c0397_func_get_preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_preference(self, key: str, default: Any = None) -> Any:\n        \"\"\"Get a preference value.\"\"\"\n        pref = self.preferences.get(key)\n        return pref.value if pref else default", "chunk_type": "function", "line_start": 159, "line_end": 162, "language": "python", "name": "get_preference"}, "4fc79d1c0397_func_set_preference": {"id": "4fc79d1c0397_func_set_preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def set_preference(self, key: str, value: Any, source: str = \"user\"):\n        \"\"\"Set a preference.\"\"\"\n        self.preferences[key] = Preference(\n            key=key,\n            value=value,\n            learned_from=source,\n            confidence=1.0 if source == \"user\" else 0.7\n        )\n        self.save()", "chunk_type": "function", "line_start": 164, "line_end": 172, "language": "python", "name": "set_preference"}, "4fc79d1c0397_func_get_action_success_rate": {"id": "4fc79d1c0397_func_get_action_success_rate", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_action_success_rate(self, action: str) -> float:\n        \"\"\"Get success rate for an action type.\"\"\"\n        relevant = [fb for fb in self.feedback if fb.action == action]\n        if not relevant:\n            return 0.5  # Unknown\n\n        successes = sum(1 for fb in relevant if fb.outcome == 'success')\n        return successes / len(relevant)", "chunk_type": "function", "line_start": 188, "line_end": 195, "language": "python", "name": "get_action_success_rate"}, "4fc79d1c0397_func_get_common_errors": {"id": "4fc79d1c0397_func_get_common_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def get_common_errors(self, limit: int = 10) -> List[ErrorPattern]:\n        \"\"\"Get most common errors.\"\"\"\n        sorted_errors = sorted(\n            self.errors.values(),\n            key=lambda e: e.occurrences,\n            reverse=True\n        )\n        return sorted_errors[:limit]", "chunk_type": "function", "line_start": 197, "line_end": 204, "language": "python", "name": "get_common_errors"}, "4fc79d1c0397_func_analyze_patterns": {"id": "4fc79d1c0397_func_analyze_patterns", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "    def analyze_patterns(self) -> Dict:\n        \"\"\"Analyze learning patterns.\"\"\"\n        analysis = {\n            \"total_feedback\": len(self.feedback),\n            \"total_errors\": len(self.errors),\n            \"total_preferences\": len(self.preferences),\n            \"action_outcomes\": {},\n            \"common_errors\": []\n        }\n\n        # Analyze action outcomes\n        action_counts = Counter()\n        action_success = Counter()\n\n        for fb in self.feedback:\n            action_counts[fb.action] += 1\n            if fb.outcome == 'success':\n                action_success[fb.action] += 1\n\n        for action, count in action_counts.most_common(10):\n            rate = action_success[action] / count if count > 0 else 0\n            analysis[\"action_outcomes\"][action] = {\n                \"count\": count,\n                \"success_rate\": round(rate, 2)\n            }\n\n        # Common errors\n        for err in self.get_common_errors(5):\n            analysis[\"common_errors\"].append({\n        ", "chunk_type": "function", "line_start": 206, "line_end": 241, "language": "python", "name": "analyze_patterns"}, "4fc79d1c0397_class_Feedback": {"id": "4fc79d1c0397_class_Feedback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "class Feedback:\n    \"\"\"A feedback entry.\"\"\"\n    action: str\n    outcome: str  # 'success', 'failure', 'partial'\n    context: str\n    timestamp: str\n    details: Dict[str, Any] = field(default_factory=dict)", "chunk_type": "class", "line_start": 23, "line_end": 29, "language": "python", "name": "Feedback"}, "4fc79d1c0397_class_ErrorPattern": {"id": "4fc79d1c0397_class_ErrorPattern", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "class ErrorPattern:\n    \"\"\"A learned error pattern.\"\"\"\n    error_type: str\n    pattern: str\n    fix: str\n    occurrences: int = 1\n    last_seen: str = \"\"\n    contexts: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 33, "line_end": 40, "language": "python", "name": "ErrorPattern"}, "4fc79d1c0397_class_Preference": {"id": "4fc79d1c0397_class_Preference", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "class Preference:\n    \"\"\"A user preference.\"\"\"\n    key: str\n    value: Any\n    learned_from: str = \"default\"\n    confidence: float = 0.5", "chunk_type": "class", "line_start": 44, "line_end": 49, "language": "python", "name": "Preference"}, "4fc79d1c0397_class_LearningStore": {"id": "4fc79d1c0397_class_LearningStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\learning.py", "content": "class LearningStore:\n    \"\"\"Store for learning data.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'learning'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.feedback: List[Feedback] = []\n        self.errors: Dict[str, ErrorPattern] = {}\n        self.preferences: Dict[str, Preference] = {}\n\n        self.load()\n\n    def load(self):\n        \"\"\"Load learning data.\"\"\"\n        # Load feedback\n        fb_path = self.storage_path / 'feedback.json'\n        if fb_path.exists():\n            try:\n                with open(fb_path, 'r') as f:\n                    data = json.load(f)\n                    self.feedback = [Feedback(**d) for d in data]\n            except Exception:\n                pass\n\n        # Load error patterns\n        err_path = self.storage_path / 'errors.json'\n        if err_path.ex", "chunk_type": "class", "line_start": 52, "line_end": 241, "language": "python", "name": "LearningStore"}, "1e285ba68b78_file": {"id": "1e285ba68b78_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "\"\"\"\nPersistent Memory System\n========================\nCross-session knowledge base for AI agents.\n\nUsage:\n    python mcp.py remember \"key\" \"value\"\n    python mcp.py recall \"query\"\n    python mcp.py forget \"key\"\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport hashlib\nimport json\nimport sys\n\nfrom .embeddings import embed_text, cosine_similarity\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass Memory:\n    \"\"\"A memory item.\"\"\"\n    key: str\n    value: str\n    tags: List[str] = field(default_factory=list)\n    created: str = \"\"\n    updated: str = \"\"\n    access_count: int = 0\n    embedding: List[float] = field(default_factory=list)\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)\n\n\nclass MemoryStore:\n    \"\"\"Persistent memory storage.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()\n\n    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'\n\n    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}\n\n    def save(self):\n        \"\"\"Save memories to disk.\"\"\"\n        file_path = self._get_file_path()\n        with open(fil", "chunk_type": "file", "line_start": 1, "line_end": 277, "language": "python", "name": "memory.py"}, "1e285ba68b78_func_get_store": {"id": "1e285ba68b78_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "def get_store() -> MemoryStore:\n    \"\"\"Get or create memory store.\"\"\"\n    global _store\n    if _store is None:\n        _store = MemoryStore()\n    return _store", "chunk_type": "function", "line_start": 193, "line_end": 198, "language": "python", "name": "get_store"}, "1e285ba68b78_func_remember": {"id": "1e285ba68b78_func_remember", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def remember(self, key: str, value: str, tags: List[str] = None) -> Memory:\n        \"\"\"Store a memory.\"\"\"\n        now = datetime.utcnow().isoformat() + 'Z'\n\n        # Generate embedding for semantic search\n        combined = f\"{key} {value}\"\n        embedding = embed_text(combined) or []\n\n        if key in self.memories:\n            # Update existing\n            memory = self.memories[key]\n            memory.value = value\n            memory.updated = now\n            memory.tags = tags or memory.tags\n            memory.embedding = embedding\n        else:\n            # Create new\n            memory = Memory(\n                key=key,\n                value=value,\n                tags=tags or [],\n                created=now,\n                updated=now,\n                embedding=embedding\n            )\n\n        self.memories[key] = memory\n        self.save()\n        return memory", "chunk_type": "function", "line_start": 79, "line_end": 107, "language": "python", "name": "remember"}, "1e285ba68b78_func_recall": {"id": "1e285ba68b78_func_recall", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def recall(self, query: str, limit: int = 10) -> List[Memory]:\n        \"\"\"Search memories semantically.\"\"\"\n        if not self.memories:\n            return []\n\n        # Generate query embedding\n        query_emb = embed_text(query)\n\n        results = []\n        for key, memory in self.memories.items():\n            # Update access count\n            memory.access_count += 1\n\n            # Calculate relevance score\n            score = 0.0\n\n            # Exact key match\n            if query.lower() in key.lower():\n                score += 1.0\n\n            # Value match\n            if query.lower() in memory.value.lower():\n                score += 0.5\n\n            # Tag match\n            for tag in memory.tags:\n                if query.lower() in tag.lower():\n                    score += 0.3\n\n            # Semantic similarity\n            if query_emb and memory.embedding:\n                semantic_score = cosine_similarity(query_emb, memory.embedding)\n                score += semantic_s", "chunk_type": "function", "line_start": 109, "line_end": 150, "language": "python", "name": "recall"}, "1e285ba68b78_func_forget": {"id": "1e285ba68b78_func_forget", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def forget(self, key: str) -> bool:\n        \"\"\"Remove a memory.\"\"\"\n        if key in self.memories:\n            del self.memories[key]\n            self.save()\n            return True\n        return False", "chunk_type": "function", "line_start": 152, "line_end": 158, "language": "python", "name": "forget"}, "1e285ba68b78_func_main": {"id": "1e285ba68b78_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Persistent Memory\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    store = get_store()\n\n    Console.info(f\"Memory storage: {store.storage_path}\")\n    Console.info(f\"Total memories: {len(store.memories)}\")\n\n    if len(args) >= 2:\n        key = args[0]\n        value = args[1]\n        tags = args[2:] if len(args) > 2 else []\n\n        memory = store.remember(key, value, tags)\n        Console.ok(f\"Remembered: {key}\")\n        print(f\"  Value: {value}\")\n        if tags:\n            print(f\"  Tags: {', '.join(tags)}\")\n        return 0\n\n    if len(args) == 1:\n        query = args[0]\n\n        if '--forget' in sys.argv or '--delete' in sys.argv:\n            if store.forget(query):\n                Console.ok(f\"Forgot: {query}\")\n            else:\n                Console.warn(f\"Not found: {query}\")\n            return 0\n\n        # Search\n        Console.info(f\"Recalling: {query}\")\n        results = store.recall(query)\n\n   ", "chunk_type": "function", "line_start": 216, "line_end": 272, "language": "python", "name": "main"}, "1e285ba68b78_func_to_dict": {"id": "1e285ba68b78_func_to_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def to_dict(self) -> dict:\n        return asdict(self)", "chunk_type": "function", "line_start": 35, "line_end": 36, "language": "python", "name": "to_dict"}, "1e285ba68b78_func_from_dict": {"id": "1e285ba68b78_func_from_dict", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)", "chunk_type": "function", "line_start": 39, "line_end": 40, "language": "python", "name": "from_dict"}, "1e285ba68b78_func___init__": {"id": "1e285ba68b78_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()", "chunk_type": "function", "line_start": 46, "line_end": 56, "language": "python", "name": "__init__"}, "1e285ba68b78_func__get_file_path": {"id": "1e285ba68b78_func__get_file_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'", "chunk_type": "function", "line_start": 58, "line_end": 59, "language": "python", "name": "_get_file_path"}, "1e285ba68b78_func_load": {"id": "1e285ba68b78_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}", "chunk_type": "function", "line_start": 61, "line_end": 70, "language": "python", "name": "load"}, "1e285ba68b78_func_save": {"id": "1e285ba68b78_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def save(self):\n        \"\"\"Save memories to disk.\"\"\"\n        file_path = self._get_file_path()\n        with open(file_path, 'w', encoding='utf-8') as f:\n            data = {k: v.to_dict() for k, v in self.memories.items()}\n            json.dump(data, f, indent=2)", "chunk_type": "function", "line_start": 72, "line_end": 77, "language": "python", "name": "save"}, "1e285ba68b78_func_list_all": {"id": "1e285ba68b78_func_list_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def list_all(self, tag: str = None) -> List[Memory]:\n        \"\"\"List all memories, optionally filtered by tag.\"\"\"\n        if tag:\n            return [m for m in self.memories.values() if tag in m.tags]\n        return list(self.memories.values())", "chunk_type": "function", "line_start": 160, "line_end": 164, "language": "python", "name": "list_all"}, "1e285ba68b78_func_get_by_key": {"id": "1e285ba68b78_func_get_by_key", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def get_by_key(self, key: str) -> Optional[Memory]:\n        \"\"\"Get memory by exact key.\"\"\"\n        return self.memories.get(key)", "chunk_type": "function", "line_start": 166, "line_end": 168, "language": "python", "name": "get_by_key"}, "1e285ba68b78_func_export_all": {"id": "1e285ba68b78_func_export_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def export_all(self) -> str:\n        \"\"\"Export all memories as JSON.\"\"\"\n        return json.dumps({k: v.to_dict() for k, v in self.memories.items()}, indent=2)", "chunk_type": "function", "line_start": 170, "line_end": 172, "language": "python", "name": "export_all"}, "1e285ba68b78_func_import_memories": {"id": "1e285ba68b78_func_import_memories", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "    def import_memories(self, json_str: str) -> int:\n        \"\"\"Import memories from JSON.\"\"\"\n        try:\n            data = json.loads(json_str)\n            count = 0\n            for key, mem_data in data.items():\n                if key not in self.memories:\n                    self.memories[key] = Memory.from_dict(mem_data)\n                    count += 1\n            self.save()\n            return count\n        except Exception:\n            return 0", "chunk_type": "function", "line_start": 174, "line_end": 186, "language": "python", "name": "import_memories"}, "1e285ba68b78_class_Memory": {"id": "1e285ba68b78_class_Memory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "class Memory:\n    \"\"\"A memory item.\"\"\"\n    key: str\n    value: str\n    tags: List[str] = field(default_factory=list)\n    created: str = \"\"\n    updated: str = \"\"\n    access_count: int = 0\n    embedding: List[float] = field(default_factory=list)\n\n    def to_dict(self) -> dict:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: dict) -> 'Memory':\n        return cls(**data)", "chunk_type": "class", "line_start": 25, "line_end": 40, "language": "python", "name": "Memory"}, "1e285ba68b78_class_MemoryStore": {"id": "1e285ba68b78_class_MemoryStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\memory.py", "content": "class MemoryStore:\n    \"\"\"Persistent memory storage.\"\"\"\n\n    def __init__(self, storage_path: Path = None):\n        if storage_path:\n            self.storage_path = storage_path\n        else:\n            # Use user-level storage for cross-project memory\n            home = Path.home()\n            self.storage_path = home / '.mcp' / 'memory'\n\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n        self.memories: Dict[str, Memory] = {}\n        self.load()\n\n    def _get_file_path(self) -> Path:\n        return self.storage_path / 'knowledge.json'\n\n    def load(self):\n        \"\"\"Load memories from disk.\"\"\"\n        file_path = self._get_file_path()\n        if file_path.exists():\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self.memories = {k: Memory.from_dict(v) for k, v in data.items()}\n            except Exception:\n                self.memories = {}\n\n    def save(self):\n        \"\"\"", "chunk_type": "class", "line_start": 43, "line_end": 186, "language": "python", "name": "MemoryStore"}, "d89a722f5109_file": {"id": "d89a722f5109_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "\"\"\"\nMigration Helper\n================\nAssist with Python version and framework migrations.\n\nUsage:\n    python migrate.py [path] [--target 3.11]\n    python -m scripts.migrate src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass MigrationIssue:\n    \"\"\"A migration issue or suggestion.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'required', 'recommended', 'optional'\n    category: str\n    title: str\n    description: str\n    old_syntax: Optional[str] = None\n    new_syntax: Optional[str] = None\n\n\n@dataclass\nclass MigrationReport:\n    \"\"\"Complete migration report.\"\"\"\n    target_version: str\n    issues: List[MigrationIssue] = field(default_factory=list)\n\n    @property\n    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']\n\n    @property\n    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        for severity in ['required', 'recommended', 'optional']:\n            items = [i for i in self.issues if i.severity == severity]\n            if not items:\n                continue\n\n            lines.extend([f\"## {severity.title()}\", \"\"])\n\n ", "chunk_type": "file", "line_start": 1, "line_end": 360, "language": "python", "name": "migrate.py"}, "d89a722f5109_func_analyze_file": {"id": "d89a722f5109_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "def analyze_file(\n    path: Path,\n    target: str\n) -> List[MigrationIssue]:\n    \"\"\"Analyze a file for migration issues.\"\"\"\n    issues = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues\n\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source_lines = f.readlines()\n    except Exception:\n        return issues\n\n    # Run analyzers\n    deprecation = DeprecationAnalyzer(path, target)\n    deprecation.visit(tree)\n    issues.extend(deprecation.issues)\n\n    modernizer = SyntaxModernizer(path, source_lines, target)\n    modernizer.visit(tree)\n    issues.extend(modernizer.issues)\n\n    string_format = StringFormatAnalyzer(path, source_lines)\n    string_format.visit(tree)\n    issues.extend(string_format.issues)\n\n    return issues", "chunk_type": "function", "line_start": 266, "line_end": 296, "language": "python", "name": "analyze_file"}, "d89a722f5109_func_check_migration": {"id": "d89a722f5109_func_check_migration", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "def check_migration(\n    root: Path,\n    target: str = \"3.11\",\n    exclude_patterns: List[str] = None\n) -> MigrationReport:\n    \"\"\"Check project for migration issues.\"\"\"\n    report = MigrationReport(target_version=target)\n\n    Console.info(f\"Checking migration to Python {target}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        issues = analyze_file(path, target)\n        report.issues.extend(issues)\n\n    return report", "chunk_type": "function", "line_start": 299, "line_end": 316, "language": "python", "name": "check_migration"}, "d89a722f5109_func_main": {"id": "d89a722f5109_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Migration Helper\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    target = \"3.11\"\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--target' and i + 1 < len(sys.argv):\n            target = sys.argv[i + 1]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n    Console.info(f\"Target version: Python {target}\")\n\n    report = check_migration(path, target)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.required:\n        Console.warn(f\"Found {len(report.required)} required changes\")\n    elif report.recommended:\n        Console.info(f\"Found {len(report.recommended)} recommended changes\")\n    else:\n        Console.ok(\"Code is ready for migration\")\n\n    return 0", "chunk_type": "function", "line_start": 319, "line_end": 355, "language": "python", "name": "main"}, "d89a722f5109_func_required": {"id": "d89a722f5109_func_required", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']", "chunk_type": "function", "line_start": 47, "line_end": 48, "language": "python", "name": "required"}, "d89a722f5109_func_recommended": {"id": "d89a722f5109_func_recommended", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']", "chunk_type": "function", "line_start": 51, "line_end": 52, "language": "python", "name": "recommended"}, "d89a722f5109_func_to_markdown": {"id": "d89a722f5109_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        for severity in ['required', 'recommended', 'optional']:\n            items = [i for i in self.issues if i.severity == severity]\n            if not items:\n                continue\n\n            lines.extend([f\"## {severity.title()}\", \"\"])\n\n            for issue in items:\n                lines.append(f\"### {issue.title}\")\n                lines.append(f\"**File:** `{issue.path}:{issue.line}`\")\n                lines.app", "chunk_type": "function", "line_start": 54, "line_end": 96, "language": "python", "name": "to_markdown"}, "d89a722f5109_func___init__": {"id": "d89a722f5109_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.issues: List[MigrationIssue] = []", "chunk_type": "function", "line_start": 243, "line_end": 246, "language": "python", "name": "__init__"}, "d89a722f5109_func_visit_ImportFrom": {"id": "d89a722f5109_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module == 'typing':\n            for alias in node.names:\n                self._typing_imports.add(alias.name)\n\n                # Check deprecated typing imports\n                if alias.name in DEPRECATED_PATTERNS:\n                    new, version, desc = DEPRECATED_PATTERNS[f'typing.{alias.name}']\n                    if self._version_ge(version):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Deprecated: typing.{alias.name}\",\n                            description=desc,\n                            old_syntax=f\"from typing import {alias.name}\",\n                            new_syntax=f\"# Use {new} directly\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 135, "line_end": 155, "language": "python", "name": "visit_ImportFrom"}, "d89a722f5109_func_visit_Subscript": {"id": "d89a722f5109_func_visit_Subscript", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Subscript(self, node: ast.Subscript):\n        # Check for Optional[X] -> X | None\n        if isinstance(node.value, ast.Attribute):\n            if isinstance(node.value.value, ast.Name):\n                if node.value.value.id == 'typing':\n                    attr = node.value.attr\n                    if attr in ('Optional', 'Union') and self._version_ge('3.10+'):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Modernize: typing.{attr}\",\n                            description=f\"Python 3.10+ supports | syntax for unions\",\n                            old_syntax=f\"typing.{attr}[...]\",\n                            new_syntax=\"X | Y | None\"\n                        ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 157, "line_end": 175, "language": "python", "name": "visit_Subscript"}, "d89a722f5109_func_visit_Call": {"id": "d89a722f5109_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Call(self, node: ast.Call):\n        # Check for deprecated function calls\n        func_name = self._get_func_name(node.func)\n\n        # Check for old string formatting\n        if func_name == 'format' or '%' in str(node):\n            pass  # Would need more context\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 177, "line_end": 185, "language": "python", "name": "visit_Call"}, "d89a722f5109_func__get_func_name": {"id": "d89a722f5109_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 187, "line_end": 192, "language": "python", "name": "_get_func_name"}, "d89a722f5109_func__version_ge": {"id": "d89a722f5109_func__version_ge", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def _version_ge(self, version: str) -> bool:\n        \"\"\"Check if target version is >= specified version.\"\"\"\n        target_parts = self.target.split('.')\n        version_parts = version.replace('+', '').split('.')\n\n        try:\n            for t, v in zip(target_parts, version_parts):\n                if int(t) > int(v):\n                    return True\n                elif int(t) < int(v):\n                    return False\n            return True\n        except ValueError:\n            return False", "chunk_type": "function", "line_start": 194, "line_end": 207, "language": "python", "name": "_version_ge"}, "d89a722f5109_func_visit_FunctionDef": {"id": "d89a722f5109_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        # Check for missing type hints\n        if not node.returns and not node.name.startswith('_'):\n            self.issues.append(MigrationIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='optional',\n                category='type_hints',\n                title=f\"Add return type to {node.name}\",\n                description=\"Adding type hints improves code quality and IDE support\"\n            ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 219, "line_end": 231, "language": "python", "name": "visit_FunctionDef"}, "d89a722f5109_func_visit_Assign": {"id": "d89a722f5109_func_visit_Assign", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_Assign(self, node: ast.Assign):\n        # Check for walrus operator opportunities in Python 3.8+\n        pass\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 233, "line_end": 237, "language": "python", "name": "visit_Assign"}, "d89a722f5109_func_visit_BinOp": {"id": "d89a722f5109_func_visit_BinOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "    def visit_BinOp(self, node: ast.BinOp):\n        # Check for % string formatting\n        if isinstance(node.op, ast.Mod):\n            if isinstance(node.left, ast.Constant) and isinstance(node.left.value, str):\n                self.issues.append(MigrationIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='optional',\n                    category='string_format',\n                    title=\"Modernize string formatting\",\n                    description=\"Consider using f-strings for better readability\",\n                    old_syntax='\"%s\" % value',\n                    new_syntax='f\"{value}\"'\n                ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 248, "line_end": 263, "language": "python", "name": "visit_BinOp"}, "d89a722f5109_class_MigrationIssue": {"id": "d89a722f5109_class_MigrationIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class MigrationIssue:\n    \"\"\"A migration issue or suggestion.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'required', 'recommended', 'optional'\n    category: str\n    title: str\n    description: str\n    old_syntax: Optional[str] = None\n    new_syntax: Optional[str] = None", "chunk_type": "class", "line_start": 28, "line_end": 37, "language": "python", "name": "MigrationIssue"}, "d89a722f5109_class_MigrationReport": {"id": "d89a722f5109_class_MigrationReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class MigrationReport:\n    \"\"\"Complete migration report.\"\"\"\n    target_version: str\n    issues: List[MigrationIssue] = field(default_factory=list)\n\n    @property\n    def required(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'required']\n\n    @property\n    def recommended(self) -> List[MigrationIssue]:\n        return [i for i in self.issues if i.severity == 'recommended']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Migration Report\",\n            \"\",\n            f\"**Target Version:** Python {self.target_version}\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"- **Required changes:** {len(self.required)}\",\n            f\"- **Recommended changes:** {len(self.recommended)}\",\n            f\"- **Total issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if not self.issues:\n            lines.append(\"No migration issues found. Code is compatible.\")\n            return \"\\n\".join(lines)\n\n        f", "chunk_type": "class", "line_start": 41, "line_end": 96, "language": "python", "name": "MigrationReport"}, "d89a722f5109_class_DeprecationAnalyzer": {"id": "d89a722f5109_class_DeprecationAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class DeprecationAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for deprecated patterns.\"\"\"\n\n    def __init__(self, path: Path, target: str):\n        self.path = path\n        self.target = target\n        self.issues: List[MigrationIssue] = []\n        self._typing_imports: Set[str] = set()\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module == 'typing':\n            for alias in node.names:\n                self._typing_imports.add(alias.name)\n\n                # Check deprecated typing imports\n                if alias.name in DEPRECATED_PATTERNS:\n                    new, version, desc = DEPRECATED_PATTERNS[f'typing.{alias.name}']\n                    if self._version_ge(version):\n                        self.issues.append(MigrationIssue(\n                            path=self.path,\n                            line=node.lineno,\n                            severity='recommended',\n                            category='typing',\n                            title=f\"Depre", "chunk_type": "class", "line_start": 126, "line_end": 207, "language": "python", "name": "DeprecationAnalyzer"}, "d89a722f5109_class_SyntaxModernizer": {"id": "d89a722f5109_class_SyntaxModernizer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class SyntaxModernizer(ast.NodeVisitor):\n    \"\"\"Suggest syntax modernization.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str], target: str):\n        self.path = path\n        self.source_lines = source_lines\n        self.target = target\n        self.issues: List[MigrationIssue] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        # Check for missing type hints\n        if not node.returns and not node.name.startswith('_'):\n            self.issues.append(MigrationIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='optional',\n                category='type_hints',\n                title=f\"Add return type to {node.name}\",\n                description=\"Adding type hints improves code quality and IDE support\"\n            ))\n\n        self.generic_visit(node)\n\n    def visit_Assign(self, node: ast.Assign):\n        # Check for walrus operator opportunities in Python 3.8+\n        pass\n\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 210, "line_end": 237, "language": "python", "name": "SyntaxModernizer"}, "d89a722f5109_class_StringFormatAnalyzer": {"id": "d89a722f5109_class_StringFormatAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\migrate.py", "content": "class StringFormatAnalyzer(ast.NodeVisitor):\n    \"\"\"Check string formatting patterns.\"\"\"\n\n    def __init__(self, path: Path, source_lines: List[str]):\n        self.path = path\n        self.source_lines = source_lines\n        self.issues: List[MigrationIssue] = []\n\n    def visit_BinOp(self, node: ast.BinOp):\n        # Check for % string formatting\n        if isinstance(node.op, ast.Mod):\n            if isinstance(node.left, ast.Constant) and isinstance(node.left.value, str):\n                self.issues.append(MigrationIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='optional',\n                    category='string_format',\n                    title=\"Modernize string formatting\",\n                    description=\"Consider using f-strings for better readability\",\n                    old_syntax='\"%s\" % value',\n                    new_syntax='f\"{value}\"'\n                ))\n\n        self.generic_visit(node)", "chunk_type": "class", "line_start": 240, "line_end": 263, "language": "python", "name": "StringFormatAnalyzer"}, "7ead9b9630da_file": {"id": "7ead9b9630da_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "#!/usr/bin/env python3\n\"\"\"\nAntigravity Model Priority Manager\nManages model selection based on user preference and availability.\nPriority 1: Gemini 3 Flash\nPriority 2: Claude Opus (Latest/4.5 Thinking)\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\n\n# Configuration Path\nCONFIG_PATH = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules/model_preferences.json\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules/model_preferences.json\")\n\nDEFAULT_PRIORITY = [\n    \"Gemini 3 Flash\",\n    \"Claude Opus (4.5 Thinking)\",\n    \"GPT-4o\"\n]\n\ndef get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n\ndef save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)\n\ndef get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])\n\ndef switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]\n\ndef main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n", "chunk_type": "file", "line_start": 1, "line_end": 73, "language": "python", "name": "model_manager.py"}, "7ead9b9630da_func_get_preferences": {"id": "7ead9b9630da_func_get_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def get_preferences():\n    if CONFIG_PATH.exists():\n        with open(CONFIG_PATH, \"r\") as f:\n            return json.load(f)\n    return {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}", "chunk_type": "function", "line_start": 23, "line_end": 27, "language": "python", "name": "get_preferences"}, "7ead9b9630da_func_save_preferences": {"id": "7ead9b9630da_func_save_preferences", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def save_preferences(prefs):\n    with open(CONFIG_PATH, \"w\") as f:\n        json.dump(prefs, f, indent=2)", "chunk_type": "function", "line_start": 29, "line_end": 31, "language": "python", "name": "save_preferences"}, "7ead9b9630da_func_get_current_model": {"id": "7ead9b9630da_func_get_current_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def get_current_model():\n    prefs = get_preferences()\n    return prefs.get(\"current\", DEFAULT_PRIORITY[0])", "chunk_type": "function", "line_start": 33, "line_end": 35, "language": "python", "name": "get_current_model"}, "7ead9b9630da_func_switch_model": {"id": "7ead9b9630da_func_switch_model", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def switch_model(reason=\"manual\"):\n    prefs = get_preferences()\n    priority = prefs.get(\"priority\", DEFAULT_PRIORITY)\n    current = prefs.get(\"current\", priority[0])\n\n    try:\n        idx = priority.index(current)\n        next_idx = (idx + 1) % len(priority)\n        prefs[\"current\"] = priority[next_idx]\n        save_preferences(prefs)\n        print(f\"[MODEL] Switched to {prefs['current']} (Reason: {reason})\")\n        return prefs[\"current\"]\n    except ValueError:\n        prefs[\"current\"] = priority[0]\n        save_preferences(prefs)\n        return priority[0]", "chunk_type": "function", "line_start": 37, "line_end": 52, "language": "python", "name": "switch_model"}, "7ead9b9630da_func_main": {"id": "7ead9b9630da_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\model_manager.py", "content": "def main():\n    if len(sys.argv) < 2:\n        print(get_current_model())\n        return 0\n\n    cmd = sys.argv[1]\n    if cmd == \"status\":\n        print(f\"Current Priority Model: {get_current_model()}\")\n    elif cmd == \"switch\":\n        reason = sys.argv[2] if len(sys.argv) > 2 else \"limit reached\"\n        switch_model(reason)\n    elif cmd == \"reset\":\n        prefs = {\"priority\": DEFAULT_PRIORITY, \"current\": DEFAULT_PRIORITY[0]}\n        save_preferences(prefs)\n        print(\"[MODEL] Preferences reset to defaults.\")\n    return 0", "chunk_type": "function", "line_start": 54, "line_end": 69, "language": "python", "name": "main"}, "8a074d3363a7_file": {"id": "8a074d3363a7_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "\"\"\"\nMulti-Repo Search\n=================\nSearch across all registered projects.\n\nUsage:\n    python mcp.py search-all \"query\"\n    python mcp.py repos --add /path/to/repo\n\"\"\"\n\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport json\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass RepoInfo:\n    \"\"\"Information about a registered repository.\"\"\"\n    path: str\n    name: str\n    added: str\n    last_indexed: Optional[str] = None\n    file_count: int = 0\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result from multi-repo search.\"\"\"\n    repo: str\n    file: str\n    line: int\n    content: str\n    score: float\n\n\nclass MultiRepoStore:\n    \"\"\"Manage multiple repository indexes.\"\"\"\n\n    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()\n\n    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'\n\n    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)\n\n    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a repository to track.\"\"\"\n        path = path.resolve()\n        if not path.exists():\n            return False\n\n        key = str(path)\n\n        # Count files\n        file_count = sum(1 for _ in path.rglob('*.py'))\n\n        self.repos[key] = RepoInfo(\n            pat", "chunk_type": "file", "line_start": 1, "line_end": 250, "language": "python", "name": "multi_repo.py"}, "8a074d3363a7_func_get_store": {"id": "8a074d3363a7_func_get_store", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "def get_store() -> MultiRepoStore:\n    global _store\n    if _store is None:\n        _store = MultiRepoStore()\n    return _store", "chunk_type": "function", "line_start": 188, "line_end": 192, "language": "python", "name": "get_store"}, "8a074d3363a7_func_main": {"id": "8a074d3363a7_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Multi-Repo Search\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    store = get_store()\n\n    Console.info(f\"Registered repos: {len(store.repos)}\")\n\n    if '--add' in sys.argv and args:\n        path = Path(args[0]).resolve()\n        if store.add_repo(path):\n            Console.ok(f\"Added: {path}\")\n        else:\n            Console.fail(f\"Not found: {path}\")\n        return 0\n\n    if '--remove' in sys.argv and args:\n        if store.remove_repo(args[0]):\n            Console.ok(f\"Removed: {args[0]}\")\n        else:\n            Console.fail(f\"Not found: {args[0]}\")\n        return 0\n\n    if '--list' in sys.argv or not args:\n        repos = store.list_repos()\n        if repos:\n            print(\"\\n## Registered Repositories\")\n            for repo in repos:\n                print(f\"  [{repo.name}] {repo.path}\")\n                print(f\"    Files: {repo.file_count}, Added: {repo.added[:10]}\")\n        else:\n            Co", "chunk_type": "function", "line_start": 195, "line_end": 245, "language": "python", "name": "main"}, "8a074d3363a7_func___init__": {"id": "8a074d3363a7_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()", "chunk_type": "function", "line_start": 44, "line_end": 50, "language": "python", "name": "__init__"}, "8a074d3363a7_func__config_path": {"id": "8a074d3363a7_func__config_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'", "chunk_type": "function", "line_start": 52, "line_end": 53, "language": "python", "name": "_config_path"}, "8a074d3363a7_func_load": {"id": "8a074d3363a7_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass", "chunk_type": "function", "line_start": 55, "line_end": 64, "language": "python", "name": "load"}, "8a074d3363a7_func_save": {"id": "8a074d3363a7_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)", "chunk_type": "function", "line_start": 66, "line_end": 70, "language": "python", "name": "save"}, "8a074d3363a7_func_add_repo": {"id": "8a074d3363a7_func_add_repo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a repository to track.\"\"\"\n        path = path.resolve()\n        if not path.exists():\n            return False\n\n        key = str(path)\n\n        # Count files\n        file_count = sum(1 for _ in path.rglob('*.py'))\n\n        self.repos[key] = RepoInfo(\n            path=key,\n            name=path.name,\n            added=datetime.utcnow().isoformat() + 'Z',\n            file_count=file_count\n        )\n\n        self.save()\n        return True", "chunk_type": "function", "line_start": 72, "line_end": 91, "language": "python", "name": "add_repo"}, "8a074d3363a7_func_remove_repo": {"id": "8a074d3363a7_func_remove_repo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def remove_repo(self, path: str) -> bool:\n        \"\"\"Remove a repository.\"\"\"\n        if path in self.repos:\n            del self.repos[path]\n            self.save()\n            return True\n        return False", "chunk_type": "function", "line_start": 93, "line_end": 99, "language": "python", "name": "remove_repo"}, "8a074d3363a7_func_list_repos": {"id": "8a074d3363a7_func_list_repos", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def list_repos(self) -> List[RepoInfo]:\n        \"\"\"List all registered repos.\"\"\"\n        return list(self.repos.values())", "chunk_type": "function", "line_start": 101, "line_end": 103, "language": "python", "name": "list_repos"}, "8a074d3363a7_func_search_all": {"id": "8a074d3363a7_func_search_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def search_all(self, query: str, limit: int = 20) -> List[SearchResult]:\n        \"\"\"Search across all repos.\"\"\"\n        results = []\n        query_lower = query.lower()\n\n        for repo_path, repo_info in self.repos.items():\n            path = Path(repo_path)\n            if not path.exists():\n                continue\n\n            # Search files\n            for file_path in path.rglob('*.py'):\n                if '.git' in str(file_path) or 'node_modules' in str(file_path):\n                    continue\n\n                try:\n                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                        for i, line in enumerate(f, 1):\n                            if query_lower in line.lower():\n                                results.append(SearchResult(\n                                    repo=repo_info.name,\n                                    file=str(file_path.relative_to(path)),\n                                    line=i,\n                           ", "chunk_type": "function", "line_start": 105, "line_end": 139, "language": "python", "name": "search_all"}, "8a074d3363a7_func_find_similar_code": {"id": "8a074d3363a7_func_find_similar_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "    def find_similar_code(self, code_snippet: str, limit: int = 10) -> List[SearchResult]:\n        \"\"\"Find similar code across repos.\"\"\"\n        results = []\n\n        # Tokenize snippet\n        tokens = set(code_snippet.lower().split())\n        tokens = {t for t in tokens if len(t) > 2}\n\n        if not tokens:\n            return results\n\n        for repo_path, repo_info in self.repos.items():\n            path = Path(repo_path)\n            if not path.exists():\n                continue\n\n            for file_path in path.rglob('*.py'):\n                if '.git' in str(file_path):\n                    continue\n\n                try:\n                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n\n                    # Calculate similarity\n                    file_tokens = set(content.lower().split())\n                    overlap = len(tokens & file_tokens) / len(tokens) if tokens else 0\n\n                    if overlap > 0.3:  ", "chunk_type": "function", "line_start": 141, "line_end": 181, "language": "python", "name": "find_similar_code"}, "8a074d3363a7_class_RepoInfo": {"id": "8a074d3363a7_class_RepoInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class RepoInfo:\n    \"\"\"Information about a registered repository.\"\"\"\n    path: str\n    name: str\n    added: str\n    last_indexed: Optional[str] = None\n    file_count: int = 0", "chunk_type": "class", "line_start": 22, "line_end": 28, "language": "python", "name": "RepoInfo"}, "8a074d3363a7_class_SearchResult": {"id": "8a074d3363a7_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class SearchResult:\n    \"\"\"A search result from multi-repo search.\"\"\"\n    repo: str\n    file: str\n    line: int\n    content: str\n    score: float", "chunk_type": "class", "line_start": 32, "line_end": 38, "language": "python", "name": "SearchResult"}, "8a074d3363a7_class_MultiRepoStore": {"id": "8a074d3363a7_class_MultiRepoStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\multi_repo.py", "content": "class MultiRepoStore:\n    \"\"\"Manage multiple repository indexes.\"\"\"\n\n    def __init__(self):\n        home = Path.home()\n        self.storage_path = home / '.mcp' / 'repos'\n        self.storage_path.mkdir(parents=True, exist_ok=True)\n\n        self.repos: Dict[str, RepoInfo] = {}\n        self.load()\n\n    def _config_path(self) -> Path:\n        return self.storage_path / 'repos.json'\n\n    def load(self):\n        \"\"\"Load repo list.\"\"\"\n        config = self._config_path()\n        if config.exists():\n            try:\n                with open(config, 'r') as f:\n                    data = json.load(f)\n                    self.repos = {k: RepoInfo(**v) for k, v in data.items()}\n            except Exception:\n                pass\n\n    def save(self):\n        \"\"\"Save repo list.\"\"\"\n        config = self._config_path()\n        with open(config, 'w') as f:\n            json.dump({k: asdict(v) for k, v in self.repos.items()}, f, indent=2)\n\n    def add_repo(self, path: Path) -> bool:\n        \"\"\"Add a r", "chunk_type": "class", "line_start": 41, "line_end": 181, "language": "python", "name": "MultiRepoStore"}, "8fb4261bb320_file": {"id": "8fb4261bb320_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "#!/usr/bin/env python3\n\"\"\"\nMCP NSync Module\nProvides real-time cross-device synchronization and remote execution.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import List, Optional\nimport os\nimport subprocess\nimport sys\nimport time\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler\nexcept ImportError:\n    Observer = None\n    FileSystemEventHandler = object\n\n# NSync Configuration\nfrom .utils import find_project_root\n\n# NSync Configuration\n# Enforce containment within the current project\n_project_root = find_project_root() or Path.cwd()\nWINDOWS_NSYNC = _project_root / \".nsync\"\nLINUX_NSYNC = _project_root / \".nsync\"\n\ndef get_remote_peer():\n    import socket\n    host = socket.gethostname()\n    if host.lower() == \"wizardpanda\":\n        return \"quasar\"\n    return \"wizardpanda\"\n\nREMOTE_USER = \"p4nd4pr0t0c01\"\n\nclass NSyncHandler(FileSystemEventHandler):\n    \"\"\"Handles file system events and triggers git sync.\"\"\"\n    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds\n\n    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now\n\n    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle conflicts cleanly\n            subprocess.run([\"git\", \"pull\", \"--rebase\", get_remote_peer(), \"master\"], capture_output=True)\n\n            # Pu", "chunk_type": "file", "line_start": 1, "line_end": 372, "language": "python", "name": "nsync.py"}, "8fb4261bb320_func_get_remote_peer": {"id": "8fb4261bb320_func_get_remote_peer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def get_remote_peer():\n    import socket\n    host = socket.gethostname()\n    if host.lower() == \"wizardpanda\":\n        return \"quasar\"\n    return \"wizardpanda\"", "chunk_type": "function", "line_start": 30, "line_end": 35, "language": "python", "name": "get_remote_peer"}, "8fb4261bb320_func_get_nsync_path": {"id": "8fb4261bb320_func_get_nsync_path", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def get_nsync_path() -> Path:\n    \"\"\"Determine the local NSync path based on OS.\"\"\"\n    if os.name == 'nt':\n        return WINDOWS_NSYNC\n    return LINUX_NSYNC", "chunk_type": "function", "line_start": 106, "line_end": 110, "language": "python", "name": "get_nsync_path"}, "8fb4261bb320_func_show_help": {"id": "8fb4261bb320_func_show_help", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def show_help():\n    print(\"MCP NSync: Real-time synchronization and remote execution\")\n    print(\"Usage: mcp nsync <command> [args]\")\n    print(\"\\nCommands:\")\n    print(\"  watch               Start the real-time sync service\")\n    print(\"  status              Check sync status and peer connectivity\")\n    print(\"  run <file>          Sync and execute a file on wizardpanda\")\n    print(\"  sync                Perform a manual sync cycle\")\n    print(\"  setup               Install Git hooks for sync automation\")\n    print(\"  init-project <name> Initialize a new project folder with MCP links\")", "chunk_type": "function", "line_start": 112, "line_end": 121, "language": "python", "name": "show_help"}, "8fb4261bb320_func_init_project": {"id": "8fb4261bb320_func_init_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def init_project(name: str):\n    \"\"\"Initialize a sub-project within NSync with MCP links.\"\"\"\n    nsync_path = get_nsync_path()\n    project_path = nsync_path / name\n\n    if project_path.exists():\n        print(f\"[FAIL] Project {name} already exists at {project_path}\")\n        return 1\n\n    project_path.mkdir(parents=True)\n    print(f\"[OK] Created project directory: {project_path}\")\n\n    # Create link to mcp-global-rules\n    mcp_source = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules\")\n    mcp_target = project_path / \"mcp-global-rules\"\n\n    try:\n        if os.name == 'nt':\n            # Use Junction for Windows directory link\n            subprocess.run([\"cmd\", \"/c\", \"mklink\", \"/J\", str(mcp_target), str(mcp_source)], check=True)\n        else:\n            os.symlink(mcp_source, mcp_target)\n        print(f\"[OK] Linked mcp-global-rules to {mcp_target}\")\n    except Exception as e:\n        print(f\"[WA", "chunk_type": "function", "line_start": 123, "line_end": 189, "language": "python", "name": "init_project"}, "8fb4261bb320_func_start_watch": {"id": "8fb4261bb320_func_start_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def start_watch():\n    if not Observer:\n        print(\"[FAIL] 'watchdog' package not found. Install with: pip install watchdog\")\n        return 1\n\n    path = get_nsync_path()\n    if not path.exists():\n        print(f\"[FAIL] NSync directory not found at {path}\")\n        return 1\n\n    # [NEW] PID-based singleton protection\n    import tempfile\n    pid_file = Path(tempfile.gettempdir()) / \"nsync_watch.pid\"\n    if pid_file.exists():\n        try:\n            with open(pid_file, \"r\") as f:\n                old_pid = int(f.read().strip())\n                if os.name == 'nt':\n                    # Windows PID check\n                    subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {old_pid}\"], check=True, capture_output=True)\n                else:\n                    # Linux PID check\n                    os.kill(old_pid, 0)\n                print(f\"[NSYNC] Watch service already running (PID {old_pid}). Exiting.\")\n                return 0\n        except:\n            pid_file.unlink()\n\n    with open(pi", "chunk_type": "function", "line_start": 191, "line_end": 262, "language": "python", "name": "start_watch"}, "8fb4261bb320_func_remote_run": {"id": "8fb4261bb320_func_remote_run", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def remote_run(filename: str):\n    \"\"\"Sync and run a script on wizardpanda.\"\"\"\n    local_path = get_nsync_path() / filename\n    if not local_path.exists():\n        print(f\"[FAIL] File {filename} not found in NSync directory.\")\n        return 1\n\n    print(f\"[NSYNC] Syncing {filename} to {get_remote_peer()}...\")\n    # Manual sync before execution\n    handler = NSyncHandler(get_nsync_path())\n    handler.sync()\n\n    remote_cmd = f\"cd ~/Projects/NSync && python3 {filename}\"\n    ssh_cmd = [\"ssh\", f\"{REMOTE_USER}@{get_remote_peer()}\", remote_cmd]\n\n    print(f\"[EXEC] Executing on {get_remote_peer()}...\\n\" + \"-\"*40)\n    subprocess.run(ssh_cmd)\n    print(\"-\"*40 + \"\\n[NSYNC] Remote execution complete.\")\n    return 0", "chunk_type": "function", "line_start": 264, "line_end": 282, "language": "python", "name": "remote_run"}, "8fb4261bb320_func_check_status": {"id": "8fb4261bb320_func_check_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def check_status():\n    \"\"\"Verify connectivity and repo states.\"\"\"\n    path = get_nsync_path()\n    print(f\"Local Path: {path}\")\n    if path.exists():\n        print(\"[OK] Local directory exists.\")\n        os.chdir(path)\n        res = subprocess.run([\"git\", \"status\"], capture_output=True, text=True)\n        if res.returncode == 0:\n            print(\"[OK] Git repository initialized.\")\n        else:\n            print(\"[WARN] Git not initialized in NSync directory.\")\n    else:\n        print(\"[FAIL] Local directory missing.\")\n\n    print(f\"Peer: {get_remote_peer()}\")\n    res = subprocess.run([\"ssh\", f\"{REMOTE_USER}@{get_remote_peer()}\", \"date\"], capture_output=True)\n    if res.returncode == 0:\n        print(\"[OK] Peer reachable via SSH.\")\n    else:\n        print(\"[FAIL] Peer unreachable or SSH failed.\")", "chunk_type": "function", "line_start": 284, "line_end": 304, "language": "python", "name": "check_status"}, "8fb4261bb320_func_setup_hooks": {"id": "8fb4261bb320_func_setup_hooks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def setup_hooks():\n    \"\"\"Install Git hooks for sync automation.\"\"\"\n    path = get_nsync_path()\n    hooks_dir = path / \".git\" / \"hooks\"\n    if not hooks_dir.exists():\n        print(f\"[FAIL] Git hooks directory missing at {hooks_dir}\")\n        return 1\n\n    # Post-commit hook: Trigger sync immediately\n    post_commit_path = hooks_dir / (\"post-commit\" if os.name != 'nt' else \"post-commit\")\n    # Note: On Windows Git Bash uses the same name\n\n    sync_cmd = \"mcp nsync sync\"\n    if os.name == 'nt':\n        # Create a shell script for Git to run\n        with open(post_commit_path, \"w\") as f:\n            f.write(f\"#!/bin/sh\\n{sync_cmd}\\n\")\n    else:\n        with open(post_commit_path, \"w\") as f:\n            f.write(f\"#!/bin/bash\\npython3 /home/p4nd4pr0t0c01/Projects/mcp-global-rules/mcp.py nsync sync\\n\")\n\n    os.chmod(post_commit_path, 0o755)\n    print(f\"[OK] Installed post-commit hook at {post_commit_path}\")\n\n    # Post-merge hook: Re-index context\n    post_merge_path = hooks_dir / \"post-mer", "chunk_type": "function", "line_start": 306, "line_end": 342, "language": "python", "name": "setup_hooks"}, "8fb4261bb320_func_main": {"id": "8fb4261bb320_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "def main():\n    if len(sys.argv) < 2:\n        show_help()\n        return 0\n\n    cmd = sys.argv[1]\n    args = sys.argv[2:]\n\n    if cmd == \"watch\":\n        return start_watch()\n    elif cmd == \"run\" and args:\n        return remote_run(args[0])\n    elif cmd == \"status\":\n        return check_status()\n    elif cmd == \"sync\":\n        handler = NSyncHandler(get_nsync_path())\n        handler.sync()\n        return 0\n    elif cmd == \"setup\":\n        return setup_hooks()\n    elif cmd == \"init-project\" and args:\n        return init_project(args[0])\n    else:\n        show_help()\n    return 0", "chunk_type": "function", "line_start": 344, "line_end": 368, "language": "python", "name": "main"}, "8fb4261bb320_func___init__": {"id": "8fb4261bb320_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds", "chunk_type": "function", "line_start": 41, "line_end": 44, "language": "python", "name": "__init__"}, "8fb4261bb320_func_on_any_event": {"id": "8fb4261bb320_func_on_any_event", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now", "chunk_type": "function", "line_start": 46, "line_end": 53, "language": "python", "name": "on_any_event"}, "8fb4261bb320_func_sync": {"id": "8fb4261bb320_func_sync", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle conflicts cleanly\n            subprocess.run([\"git\", \"pull\", \"--rebase\", get_remote_peer(), \"master\"], capture_output=True)\n\n            # Push to peer\n            subprocess.run([\"git\", \"push\", get_remote_peer(), \"master\"], capture_output=True)\n            print(f\"[NSYNC] Sync complete.\")\n        except Exception as e:\n            print(f\"[FAIL] Sync failed: {e}\")", "chunk_type": "function", "line_start": 55, "line_end": 75, "language": "python", "name": "sync"}, "8fb4261bb320_func_ensure_rules_links": {"id": "8fb4261bb320_func_ensure_rules_links", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def ensure_rules_links(self):\n        \"\"\"Iterate through all projects and ensure mcp-global-rules is linked.\"\"\"\n        mcp_source = Path(\"C:/Users/dbiss/Desktop/Projects/_BLANK_/mcp-global-rules\") if os.name == 'nt' else Path(\"/home/p4nd4pr0t0c01/Projects/mcp-global-rules\")\n\n        for item in self.repo_path.iterdir():\n            if item.is_dir() and not item.name.startswith(\".\"):\n                target = item / \"mcp-global-rules\"\n\n                # If it's a real directory (not a link), remove it to make way for the link\n                if target.exists() and not target.is_symlink():\n                    if os.name != 'nt': # Extra check for Linux directory sync issue\n                         # Only remove if it's not a junction/symlink\n                         import shutil\n                         try:\n                             if target.is_dir() and not target.is_symlink():\n                                 shutil.rmtree(target)\n                         except:\n            ", "chunk_type": "function", "line_start": 77, "line_end": 104, "language": "python", "name": "ensure_rules_links"}, "8fb4261bb320_func_poll_remote": {"id": "8fb4261bb320_func_poll_remote", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "    def poll_remote():\n        while True:\n            time.sleep(30) # Poll every 30 seconds\n            print(\"[NSYNC] Periodic check for remote changes...\")\n            handler.sync()", "chunk_type": "function", "line_start": 230, "line_end": 234, "language": "python", "name": "poll_remote"}, "8fb4261bb320_class_NSyncHandler": {"id": "8fb4261bb320_class_NSyncHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\nsync.py", "content": "class NSyncHandler(FileSystemEventHandler):\n    \"\"\"Handles file system events and triggers git sync.\"\"\"\n    def __init__(self, repo_path: Path):\n        self.repo_path = repo_path\n        self.last_sync = 0\n        self.debounce = 2 # Seconds\n\n    def on_any_event(self, event):\n        if event.is_directory or \".git\" in event.src_path:\n            return\n\n        now = time.time()\n        if now - self.last_sync > self.debounce:\n            self.sync()\n            self.last_sync = now\n\n    def sync(self):\n        \"\"\"Perform a git sync cycle.\"\"\"\n        print(f\"[NSYNC] Change detected. Syncing...\")\n\n        # [NEW] Ensure rules links exist in all projects before sync\n        self.ensure_rules_links()\n\n        try:\n            os.chdir(self.repo_path)\n            # Add and commit\n            subprocess.run([\"git\", \"add\", \"-A\"], capture_output=True)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"nsync: auto-sync\"], capture_output=True)\n\n            # Pull with rebase to handle confli", "chunk_type": "class", "line_start": 39, "line_end": 104, "language": "python", "name": "NSyncHandler"}, "29532227c193_file": {"id": "29532227c193_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "\"\"\"\nBug Prediction\n==============\nPredict bugs before they happen based on code patterns.\n\nUsage:\n    python mcp.py predict-bugs [file]\n    python mcp.py risk-score\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport json\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass BugPrediction:\n    \"\"\"A predicted bug.\"\"\"\n    file: str\n    line: int\n    risk_level: str  # 'high', 'medium', 'low'\n    category: str\n    description: str\n    confidence: float\n    suggestion: str = \"\"\n\n\n@dataclass\nclass RiskReport:\n    \"\"\"Risk assessment report.\"\"\"\n    total_risk_score: float\n    risk_level: str\n    predictions: List[BugPrediction] = field(default_factory=list)\n    hotspots: List[str] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n            lines.append(\"## Hotspots\")\n            for hs in self.hotspots[:5]:\n                lines.append(f\"- {hs}\")\n\n        return '\\n'.join(lines)\n\n\n# Risk patterns\nRISK_PATTERNS = {\n    'complexity': {\n        'threshold': 10,\n        'weight': 2.0,\n        'description': 'High cyclomatic complexity'\n    },\n    'nesting': {\n        'threshold': 4,\n ", "chunk_type": "file", "line_start": 1, "line_end": 367, "language": "python", "name": "predict.py"}, "29532227c193_func_predict_bugs": {"id": "29532227c193_func_predict_bugs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def predict_bugs(file_path: Path) -> List[BugPrediction]:\n    \"\"\"Predict bugs in a file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            source = f.read()\n            lines = source.split('\\n')\n\n        tree = ast.parse(source)\n    except Exception:\n        return []\n\n    predictor = BugPredictor(lines)\n    predictor.current_file = str(file_path)\n    predictor.visit(tree)\n\n    return predictor.predictions", "chunk_type": "function", "line_start": 253, "line_end": 268, "language": "python", "name": "predict_bugs"}, "29532227c193_func_predict_bugs_project": {"id": "29532227c193_func_predict_bugs_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def predict_bugs_project(root: Path) -> List[BugPrediction]:\n    \"\"\"Predict bugs across project.\"\"\"\n    all_predictions = []\n\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n\n    for file_path in find_python_files(root, exclude):\n        predictions = predict_bugs(file_path)\n        all_predictions.extend(predictions)\n\n    # Sort by risk level\n    level_order = {'high': 0, 'medium': 1, 'low': 2}\n    all_predictions.sort(key=lambda p: level_order.get(p.risk_level, 3))\n\n    return all_predictions", "chunk_type": "function", "line_start": 271, "line_end": 285, "language": "python", "name": "predict_bugs_project"}, "29532227c193_func_calculate_risk_score": {"id": "29532227c193_func_calculate_risk_score", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def calculate_risk_score(predictions: List[BugPrediction]) -> float:\n    \"\"\"Calculate overall risk score (0-100).\"\"\"\n    if not predictions:\n        return 0.0\n\n    score = 0.0\n    for pred in predictions:\n        weight = RISK_PATTERNS.get(pred.category, {}).get('weight', 1.0)\n        level_mult = {'high': 3, 'medium': 2, 'low': 1}.get(pred.risk_level, 1)\n        score += weight * level_mult * pred.confidence\n\n    # Normalize to 0-100\n    return min(100, score)", "chunk_type": "function", "line_start": 288, "line_end": 300, "language": "python", "name": "calculate_risk_score"}, "29532227c193_func_get_risk_report": {"id": "29532227c193_func_get_risk_report", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def get_risk_report(root: Path = None) -> RiskReport:\n    \"\"\"Generate risk report for project.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    predictions = predict_bugs_project(root)\n    score = calculate_risk_score(predictions)\n\n    # Determine level\n    if score >= 50:\n        level = 'high'\n    elif score >= 20:\n        level = 'medium'\n    else:\n        level = 'low'\n\n    # Find hotspots (files with most issues)\n    file_counts = Counter(p.file for p in predictions)\n    hotspots = [f\"{path} ({count} issues)\" for path, count in file_counts.most_common(5)]\n\n    return RiskReport(\n        total_risk_score=score,\n        risk_level=level,\n        predictions=predictions,\n        hotspots=hotspots\n    )", "chunk_type": "function", "line_start": 303, "line_end": 327, "language": "python", "name": "get_risk_report"}, "29532227c193_func_main": {"id": "29532227c193_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Bug Prediction\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if args:\n        file_path = Path(args[0])\n        if file_path.exists() and file_path.is_file():\n            Console.info(f\"Analyzing {file_path}...\")\n            predictions = predict_bugs(file_path)\n\n            if predictions:\n                Console.warn(f\"Found {len(predictions)} potential issues\")\n                for pred in predictions:\n                    level_color = {'high': '\\033[91m', 'medium': '\\033[93m', 'low': '\\033[92m'}\n                    nc = '\\033[0m'\n                    print(f\"\\n  {level_color.get(pred.risk_level, '')}{pred.risk_level.upper()}{nc}: {pred.category}\")\n                    print(f\"  Line {pred.line}: {pred.description}\")\n                    if pred.suggestion:\n                        print(f\"  Suggestion: {pred.suggestion}\")\n            else:\n                Conso", "chunk_type": "function", "line_start": 330, "line_end": 362, "language": "python", "name": "main"}, "29532227c193_func_to_markdown": {"id": "29532227c193_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n            lines.append(\"## Hotspots\")\n            for hs in self.hotspots[:5]:\n                lines.append(f\"- {hs}\")\n\n        return '\\n'.join(lines)", "chunk_type": "function", "line_start": 42, "line_end": 66, "language": "python", "name": "to_markdown"}, "29532227c193_func___init__": {"id": "29532227c193_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def __init__(self, source_lines: List[str]):\n        self.predictions: List[BugPrediction] = []\n        self.source_lines = source_lines\n        self.current_file = \"\"", "chunk_type": "function", "line_start": 157, "line_end": 160, "language": "python", "name": "__init__"}, "29532227c193_func_visit_If": {"id": "29532227c193_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_If(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 120, "line_end": 124, "language": "python", "name": "visit_If"}, "29532227c193_func_visit_For": {"id": "29532227c193_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_For(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 126, "line_end": 130, "language": "python", "name": "visit_For"}, "29532227c193_func_visit_While": {"id": "29532227c193_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_While(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()", "chunk_type": "function", "line_start": 132, "line_end": 136, "language": "python", "name": "visit_While"}, "29532227c193_func_visit_ExceptHandler": {"id": "29532227c193_func_visit_ExceptHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_ExceptHandler(self, node):\n        if node.type is None:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high',\n                category='bare_except',\n                description=\"Bare except catches all exceptions\",\n                confidence=0.95,\n                suggestion=\"Specify exception type: except Exception:\"\n            ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 227, "line_end": 238, "language": "python", "name": "visit_ExceptHandler"}, "29532227c193_func_visit_BoolOp": {"id": "29532227c193_func_visit_BoolOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_BoolOp(self, node):\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 142, "line_end": 144, "language": "python", "name": "visit_BoolOp"}, "29532227c193_func__enter_nesting": {"id": "29532227c193_func__enter_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def _enter_nesting(self):\n        self.current_nesting += 1\n        self.max_nesting = max(self.max_nesting, self.current_nesting)", "chunk_type": "function", "line_start": 146, "line_end": 148, "language": "python", "name": "_enter_nesting"}, "29532227c193_func__exit_nesting": {"id": "29532227c193_func__exit_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def _exit_nesting(self):\n        self.current_nesting -= 1", "chunk_type": "function", "line_start": 150, "line_end": 151, "language": "python", "name": "_exit_nesting"}, "29532227c193_func_analyze_function": {"id": "29532227c193_func_analyze_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def analyze_function(self, node: ast.FunctionDef):\n        \"\"\"Analyze a function for bug risks.\"\"\"\n        # Complexity analysis\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        line_count = (node.end_lineno or node.lineno) - node.lineno\n        param_count = len(node.args.args)\n\n        # Check complexity\n        if analyzer.complexity > RISK_PATTERNS['complexity']['threshold']:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high' if analyzer.complexity > 20 else 'medium',\n                category='complexity',\n                description=f\"Cyclomatic complexity {analyzer.complexity} in {node.name}()\",\n                confidence=0.8,\n                suggestion=\"Break into smaller functions\"\n            ))\n\n        # Check nesting\n        if analyzer.max_nesting > RISK_PATTERNS['nesting']['threshold']:\n            self.predictions.append(BugPredicti", "chunk_type": "function", "line_start": 162, "line_end": 217, "language": "python", "name": "analyze_function"}, "29532227c193_func_visit_FunctionDef": {"id": "29532227c193_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_FunctionDef(self, node):\n        self.analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 219, "line_end": 221, "language": "python", "name": "visit_FunctionDef"}, "29532227c193_func_visit_AsyncFunctionDef": {"id": "29532227c193_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_AsyncFunctionDef(self, node):\n        self.analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 223, "line_end": 225, "language": "python", "name": "visit_AsyncFunctionDef"}, "29532227c193_func_visit_Global": {"id": "29532227c193_func_visit_Global", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "    def visit_Global(self, node):\n        self.predictions.append(BugPrediction(\n            file=self.current_file,\n            line=node.lineno,\n            risk_level='medium',\n            category='global_var',\n            description=f\"Global variable: {', '.join(node.names)}\",\n            confidence=0.6,\n            suggestion=\"Consider using a class or passing as parameter\"\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 240, "line_end": 250, "language": "python", "name": "visit_Global"}, "29532227c193_class_BugPrediction": {"id": "29532227c193_class_BugPrediction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "class BugPrediction:\n    \"\"\"A predicted bug.\"\"\"\n    file: str\n    line: int\n    risk_level: str  # 'high', 'medium', 'low'\n    category: str\n    description: str\n    confidence: float\n    suggestion: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 31, "language": "python", "name": "BugPrediction"}, "29532227c193_class_RiskReport": {"id": "29532227c193_class_RiskReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "class RiskReport:\n    \"\"\"Risk assessment report.\"\"\"\n    total_risk_score: float\n    risk_level: str\n    predictions: List[BugPrediction] = field(default_factory=list)\n    hotspots: List[str] = field(default_factory=list)\n\n    def to_markdown(self) -> str:\n        level_label = {'high': '[HIGH]', 'medium': '[MEDIUM]', 'low': '[LOW]'}\n\n        lines = [\n            f\"# Risk Report\",\n            \"\",\n            f\"**Overall Risk:** {level_label.get(self.risk_level, '')} {self.risk_level.upper()} ({self.total_risk_score:.1f}/100)\",\n            \"\",\n        ]\n\n        if self.predictions:\n            lines.append(\"## Predictions\")\n            for pred in self.predictions[:10]:\n                lines.append(f\"- **{pred.category}** ({pred.risk_level}): {pred.description}\")\n                lines.append(f\"  - {pred.file}:{pred.line}\")\n                if pred.suggestion:\n                    lines.append(f\"  - Fix: {pred.suggestion}\")\n            lines.append(\"\")\n\n        if self.hotspots:\n         ", "chunk_type": "class", "line_start": 35, "line_end": 66, "language": "python", "name": "RiskReport"}, "29532227c193_class_ComplexityAnalyzer": {"id": "29532227c193_class_ComplexityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "class ComplexityAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code complexity.\"\"\"\n\n    def __init__(self):\n        self.complexity = 1\n        self.max_nesting = 0\n        self.current_nesting = 0\n        self.function_lines = 0\n        self.param_count = 0\n\n    def visit_If(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_For(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_While(self, node):\n        self.complexity += 1\n        self._enter_nesting()\n        self.generic_visit(node)\n        self._exit_nesting()\n\n    def visit_ExceptHandler(self, node):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_BoolOp(self, node):\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)\n\n    def _enter_nesting(self):\n        self.current_nesting += 1\n ", "chunk_type": "class", "line_start": 110, "line_end": 151, "language": "python", "name": "ComplexityAnalyzer"}, "29532227c193_class_BugPredictor": {"id": "29532227c193_class_BugPredictor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\predict.py", "content": "class BugPredictor(ast.NodeVisitor):\n    \"\"\"Predict bugs in code.\"\"\"\n\n    def __init__(self, source_lines: List[str]):\n        self.predictions: List[BugPrediction] = []\n        self.source_lines = source_lines\n        self.current_file = \"\"\n\n    def analyze_function(self, node: ast.FunctionDef):\n        \"\"\"Analyze a function for bug risks.\"\"\"\n        # Complexity analysis\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        line_count = (node.end_lineno or node.lineno) - node.lineno\n        param_count = len(node.args.args)\n\n        # Check complexity\n        if analyzer.complexity > RISK_PATTERNS['complexity']['threshold']:\n            self.predictions.append(BugPrediction(\n                file=self.current_file,\n                line=node.lineno,\n                risk_level='high' if analyzer.complexity > 20 else 'medium',\n                category='complexity',\n                description=f\"Cyclomatic complexity {analyzer.complexity} in {node.name}()\",\n       ", "chunk_type": "class", "line_start": 154, "line_end": 250, "language": "python", "name": "BugPredictor"}, "3128c7f515a7_file": {"id": "3128c7f515a7_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "\"\"\"\nPerformance Profiler\n====================\nStatic analysis for performance bottlenecks and code complexity.\n\nUsage:\n    python profile.py [path]\n    python -m scripts.profile src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass PerformanceIssue:\n    \"\"\"A performance finding.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'critical', 'high', 'medium', 'low'\n    category: str\n    title: str\n    description: str\n    complexity: Optional[str] = None  # Big-O notation\n    suggestion: Optional[str] = None\n\n\n@dataclass\nclass PerformanceReport:\n    \"\"\"Complete performance analysis report.\"\"\"\n    issues: List[PerformanceIssue] = field(default_factory=list)\n    complexity_scores: Dict[str, int] = field(default_factory=dict)\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f\"| `{name}` | {score} ({status}) |\")\n            lines.append(\"\")\n\n        if self.issues:\n            lines.extend([\"## Issues\", \"\"])\n\n            for issue in sorted(self.issues, key=lambda x: (\n                {'critical': 0, 'high':", "chunk_type": "file", "line_start": 1, "line_end": 441, "language": "python", "name": "profile.py"}, "3128c7f515a7_func_analyze_file": {"id": "3128c7f515a7_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "def analyze_file(path: Path) -> Tuple[List[PerformanceIssue], Dict[str, int]]:\n    \"\"\"Analyze a single file for performance issues.\"\"\"\n    issues = []\n    complexity = {}\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues, complexity\n\n    # Run analyzers\n    perf = PerformanceAnalyzer(path)\n    perf.visit(tree)\n    issues.extend(perf.issues)\n    complexity.update(perf.complexity_scores)\n\n    mem = MemoryAnalyzer(path)\n    mem.visit(tree)\n    issues.extend(mem.issues)\n\n    async_analyzer = AsyncAnalyzer(path)\n    async_analyzer.visit(tree)\n    issues.extend(async_analyzer.issues)\n\n    return issues, complexity", "chunk_type": "function", "line_start": 356, "line_end": 379, "language": "python", "name": "analyze_file"}, "3128c7f515a7_func_analyze_project": {"id": "3128c7f515a7_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> PerformanceReport:\n    \"\"\"Analyze project for performance issues.\"\"\"\n    report = PerformanceReport()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        issues, complexity = analyze_file(path)\n        report.issues.extend(issues)\n        report.complexity_scores.update(complexity)\n\n    return report", "chunk_type": "function", "line_start": 382, "line_end": 399, "language": "python", "name": "analyze_project"}, "3128c7f515a7_func_main": {"id": "3128c7f515a7_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Performance Profiler\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    # Summary\n    high_complexity = sum(1 for s in report.complexity_scores.values() if s > 10)\n\n    if high_complexity > 0:\n        Console.warn(f\"Found {high_complexity} functions with high complexity\")\n\n    Console.info(f\"Found {len(report.issues)} performance issues\")\n\n    return 0", "chunk_type": "function", "line_start": 406, "line_end": 436, "language": "python", "name": "main"}, "3128c7f515a7_func_to_markdown": {"id": "3128c7f515a7_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f\"| `{name}` | {score} ({status}) |\")\n            lines.append(\"\")\n\n        if self.issues:\n            lines.extend([\"## Issues\", \"\"])\n\n            for issue in sorted(self.issues, key=lambda x: (\n          ", "chunk_type": "function", "line_start": 45, "line_end": 90, "language": "python", "name": "to_markdown"}, "3128c7f515a7_func___init__": {"id": "3128c7f515a7_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self._in_async = False", "chunk_type": "function", "line_start": 310, "line_end": 313, "language": "python", "name": "__init__"}, "3128c7f515a7_func_visit_If": {"id": "3128c7f515a7_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_If(self, node: ast.If):\n        self.complexity += 1\n        # Count elif branches\n        for _ in node.orelse:\n            if isinstance(_, ast.If):\n                self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 99, "line_end": 105, "language": "python", "name": "visit_If"}, "3128c7f515a7_func_visit_While": {"id": "3128c7f515a7_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_While(self, node: ast.While):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 107, "line_end": 109, "language": "python", "name": "visit_While"}, "3128c7f515a7_func_visit_For": {"id": "3128c7f515a7_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_For(self, node: ast.For):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 111, "line_end": 113, "language": "python", "name": "visit_For"}, "3128c7f515a7_func_visit_ExceptHandler": {"id": "3128c7f515a7_func_visit_ExceptHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_ExceptHandler(self, node: ast.ExceptHandler):\n        self.complexity += 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 115, "line_end": 117, "language": "python", "name": "visit_ExceptHandler"}, "3128c7f515a7_func_visit_BoolOp": {"id": "3128c7f515a7_func_visit_BoolOp", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_BoolOp(self, node: ast.BoolOp):\n        # Each and/or adds a decision point\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 119, "line_end": 122, "language": "python", "name": "visit_BoolOp"}, "3128c7f515a7_func_visit_comprehension": {"id": "3128c7f515a7_func_visit_comprehension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_comprehension(self, node: ast.comprehension):\n        self.complexity += 1\n        self.complexity += len(node.ifs)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 124, "line_end": 127, "language": "python", "name": "visit_comprehension"}, "3128c7f515a7_func_visit_FunctionDef": {"id": "3128c7f515a7_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 140, "line_end": 142, "language": "python", "name": "visit_FunctionDef"}, "3128c7f515a7_func_visit_AsyncFunctionDef": {"id": "3128c7f515a7_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        old_in_async = self._in_async\n        self._in_async = True\n        self.generic_visit(node)\n        self._in_async = old_in_async", "chunk_type": "function", "line_start": 315, "line_end": 319, "language": "python", "name": "visit_AsyncFunctionDef"}, "3128c7f515a7_func__analyze_function": {"id": "3128c7f515a7_func__analyze_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _analyze_function(self, node):\n        # Calculate complexity\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        func_name = f\"{self.path.stem}.{node.name}\"\n        self.complexity_scores[func_name] = analyzer.complexity\n\n        # Check for high complexity\n        if analyzer.complexity > 15:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='high',\n                category='complexity',\n                title=f\"High cyclomatic complexity: {node.name}\",\n                description=f\"Function has complexity of {analyzer.complexity} (threshold: 15)\",\n                suggestion=\"Break down into smaller functions\"\n            ))\n        elif analyzer.complexity > 10:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='medium',\n                category='complexity',\n              ", "chunk_type": "function", "line_start": 148, "line_end": 190, "language": "python", "name": "_analyze_function"}, "3128c7f515a7_func__check_nested_loops": {"id": "3128c7f515a7_func__check_nested_loops", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_nested_loops(self, node: ast.For, parent_func):\n        \"\"\"Detect nested loops (O(n^2) or worse).\"\"\"\n        nested = 0\n        for child in ast.walk(node):\n            if isinstance(child, ast.For) and child != node:\n                nested += 1\n\n        if nested >= 2:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='high',\n                category='algorithm',\n                title=\"Deeply nested loops\",\n                description=f\"Found {nested + 1} levels of nested loops\",\n                complexity=f\"O(n^{nested + 1})\",\n                suggestion=\"Consider using sets, dicts, or algorithmic optimizations\"\n            ))\n        elif nested == 1:\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='medium',\n                category='algorithm',\n                title=\"Nested loop\",\n        ", "chunk_type": "function", "line_start": 192, "line_end": 220, "language": "python", "name": "_check_nested_loops"}, "3128c7f515a7_func__check_list_comprehension": {"id": "3128c7f515a7_func__check_list_comprehension", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_list_comprehension(self, node: ast.ListComp):\n        \"\"\"Check for expensive list comprehensions.\"\"\"\n        # Check for nested comprehensions\n        for gen in node.generators:\n            if isinstance(gen.iter, ast.ListComp):\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='medium',\n                    category='memory',\n                    title=\"Nested list comprehension\",\n                    description=\"Nested comprehensions create intermediate lists\",\n                    suggestion=\"Consider using generator expressions\"\n                ))", "chunk_type": "function", "line_start": 222, "line_end": 235, "language": "python", "name": "_check_list_comprehension"}, "3128c7f515a7_func__check_expensive_calls": {"id": "3128c7f515a7_func__check_expensive_calls", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _check_expensive_calls(self, node: ast.Call):\n        \"\"\"Check for expensive function calls.\"\"\"\n        func_name = self._get_func_name(node.func)\n\n        # String concatenation in loop\n        if func_name == 'join':\n            pass  # join is good\n\n        # len() in loop condition\n        # (would need more context to detect)\n\n        # Regular expression compilation in loop\n        if func_name in ('re.match', 're.search', 're.findall'):\n            # Check if inside a loop\n            pass  # Would need parent context", "chunk_type": "function", "line_start": 237, "line_end": 251, "language": "python", "name": "_check_expensive_calls"}, "3128c7f515a7_func__get_func_name": {"id": "3128c7f515a7_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\"\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 346, "line_end": 353, "language": "python", "name": "_get_func_name"}, "3128c7f515a7_func_visit_Call": {"id": "3128c7f515a7_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "    def visit_Call(self, node: ast.Call):\n        if self._in_async:\n            func_name = self._get_func_name(node.func)\n\n            # Blocking calls in async code\n            blocking = {\n                'time.sleep': 'asyncio.sleep',\n                'requests.get': 'aiohttp.get',\n                'requests.post': 'aiohttp.post',\n                'open': 'aiofiles.open',\n            }\n\n            if func_name in blocking:\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n                    severity='high',\n                    category='async',\n                    title=f\"Blocking call in async: {func_name}\",\n                    description=f\"{func_name}() blocks the event loop\",\n                    suggestion=f\"Use {blocking[func_name]}() instead\"\n                ))\n\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 321, "line_end": 344, "language": "python", "name": "visit_Call"}, "3128c7f515a7_class_PerformanceIssue": {"id": "3128c7f515a7_class_PerformanceIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceIssue:\n    \"\"\"A performance finding.\"\"\"\n    path: Path\n    line: int\n    severity: str  # 'critical', 'high', 'medium', 'low'\n    category: str\n    title: str\n    description: str\n    complexity: Optional[str] = None  # Big-O notation\n    suggestion: Optional[str] = None", "chunk_type": "class", "line_start": 27, "line_end": 36, "language": "python", "name": "PerformanceIssue"}, "3128c7f515a7_class_PerformanceReport": {"id": "3128c7f515a7_class_PerformanceReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceReport:\n    \"\"\"Complete performance analysis report.\"\"\"\n    issues: List[PerformanceIssue] = field(default_factory=list)\n    complexity_scores: Dict[str, int] = field(default_factory=dict)\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Performance Analysis Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"**Total Issues:** {len(self.issues)}\",\n            \"\",\n        ]\n\n        if self.complexity_scores:\n            lines.extend([\n                \"## Complexity Scores (Cyclomatic)\",\n                \"\",\n                \"| Function | Score |\",\n                \"|----------|-------|\",\n            ])\n            sorted_scores = sorted(\n                self.complexity_scores.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:10]\n            for name, score in sorted_scores:\n                status = \"HIGH\" if score > 10 else \"OK\" if score <= 5 else \"MEDIUM\"\n                lines.append(f", "chunk_type": "class", "line_start": 40, "line_end": 90, "language": "python", "name": "PerformanceReport"}, "3128c7f515a7_class_ComplexityAnalyzer": {"id": "3128c7f515a7_class_ComplexityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class ComplexityAnalyzer(ast.NodeVisitor):\n    \"\"\"Calculate cyclomatic complexity.\"\"\"\n\n    def __init__(self):\n        self.complexity = 1  # Base complexity\n\n    def visit_If(self, node: ast.If):\n        self.complexity += 1\n        # Count elif branches\n        for _ in node.orelse:\n            if isinstance(_, ast.If):\n                self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_While(self, node: ast.While):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_For(self, node: ast.For):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_ExceptHandler(self, node: ast.ExceptHandler):\n        self.complexity += 1\n        self.generic_visit(node)\n\n    def visit_BoolOp(self, node: ast.BoolOp):\n        # Each and/or adds a decision point\n        self.complexity += len(node.values) - 1\n        self.generic_visit(node)\n\n    def visit_comprehension(self, node: ast.comprehension):\n        self.complexity += 1\n        sel", "chunk_type": "class", "line_start": 93, "line_end": 127, "language": "python", "name": "ComplexityAnalyzer"}, "3128c7f515a7_class_PerformanceAnalyzer": {"id": "3128c7f515a7_class_PerformanceAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class PerformanceAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for performance issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self.complexity_scores: Dict[str, int] = {}\n        self._current_function: Optional[str] = None\n        self._loop_depth = 0\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._analyze_function(node)\n        self.generic_visit(node)\n\n    def _analyze_function(self, node):\n        # Calculate complexity\n        analyzer = ComplexityAnalyzer()\n        analyzer.visit(node)\n\n        func_name = f\"{self.path.stem}.{node.name}\"\n        self.complexity_scores[func_name] = analyzer.complexity\n\n        # Check for high complexity\n        if analyzer.complexity > 15:\n            self.issues.append(PerformanceIssue(\n                path", "chunk_type": "class", "line_start": 130, "line_end": 260, "language": "python", "name": "PerformanceAnalyzer"}, "3128c7f515a7_class_MemoryAnalyzer": {"id": "3128c7f515a7_class_MemoryAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class MemoryAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for memory issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n\n    def visit_Call(self, node: ast.Call):\n        func_name = self._get_func_name(node.func)\n\n        # Check for reading entire files\n        if func_name in ('read', 'readlines'):\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n                severity='low',\n                category='memory',\n                title=\"Reading entire file into memory\",\n                description=\"Using read()/readlines() loads entire file\",\n                suggestion=\"Consider iterating line by line for large files\"\n            ))\n\n        # Large list operations\n        if func_name == 'sorted' or func_name == 'list':\n            self.issues.append(PerformanceIssue(\n                path=self.path,\n                line=node.lineno,\n               ", "chunk_type": "class", "line_start": 263, "line_end": 304, "language": "python", "name": "MemoryAnalyzer"}, "3128c7f515a7_class_AsyncAnalyzer": {"id": "3128c7f515a7_class_AsyncAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\profile.py", "content": "class AsyncAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze async code for issues.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[PerformanceIssue] = []\n        self._in_async = False\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        old_in_async = self._in_async\n        self._in_async = True\n        self.generic_visit(node)\n        self._in_async = old_in_async\n\n    def visit_Call(self, node: ast.Call):\n        if self._in_async:\n            func_name = self._get_func_name(node.func)\n\n            # Blocking calls in async code\n            blocking = {\n                'time.sleep': 'asyncio.sleep',\n                'requests.get': 'aiohttp.get',\n                'requests.post': 'aiohttp.post',\n                'open': 'aiofiles.open',\n            }\n\n            if func_name in blocking:\n                self.issues.append(PerformanceIssue(\n                    path=self.path,\n                    line=node.lineno,\n               ", "chunk_type": "class", "line_start": 307, "line_end": 353, "language": "python", "name": "AsyncAnalyzer"}, "f329c62da74a_file": {"id": "f329c62da74a_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "\"\"\"\nContext Recorder\n================\nRecord development actions and context snapshots to memory.\n\nUsage:\n    python mcp.py record \"Action description\"\n    python mcp.py record --snapshot\n\"\"\"\n\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import List, Optional\nimport subprocess\nimport sys\n\nfrom .memory import get_store\nfrom .utils import Console, find_project_root, run_git_command\n\ndef get_git_status(root: Path) -> str:\n    \"\"\"Get concise git status.\"\"\"\n    status = run_git_command(['status', '--short'], cwd=root)\n    if not status:\n        return \"No changes\"\n    return status\n\ndef get_git_diff_stat(root: Path) -> str:\n    \"\"\"Get git diff stats.\"\"\"\n    # Staged changes\n    staged = run_git_command(['diff', '--cached', '--stat'], cwd=root)\n    return staged or \"No staged changes\"\n\ndef analyze_diff(root: Path) -> str:\n    \"\"\"Analyze the staged diff for semantic meaning.\"\"\"\n    diff = run_git_command(['diff', '--cached', '-U0'], cwd=root)\n    if not diff:\n        return \"No staged changes detected.\"\n\n    changes = []\n    current_file = \"\"\n\n    for line in diff.split('\\n'):\n        if line.startswith('diff --git'):\n            # diff --git a/file.py b/file.py\n            parts = line.split()\n            if len(parts) >= 4:\n                current_file = parts[-1].lstrip('b/')\n        elif line.startswith('@@'):\n            # @@ -10,0 +11,5 @@ def new_function():\n            # Try to extract context hint\n            context = line.split('@@')[-1].strip()\n            if context and current_file:\n                changes.append(f\"- {current_file}: {context}\")\n            elif current_file:\n                 changes.append(f\"- {current_file}: (modification)\")\n\n    # Deduplicate and summarize\n    unique_changes = sorted(list(set(changes)))\n    if len(unique_changes) > 10:\n        return \"\\n\".join(unique_changes[:10]) + f\"\\n... ({len(unique_changes) - 10} more changes)\"\n    return \"\\n\".join(unique_changes)\n\ndef record_snapshot(root: Path) -> bool:\n    \"\"\"R", "chunk_type": "file", "line_start": 1, "line_end": 109, "language": "python", "name": "record.py"}, "f329c62da74a_func_get_git_status": {"id": "f329c62da74a_func_get_git_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def get_git_status(root: Path) -> str:\n    \"\"\"Get concise git status.\"\"\"\n    status = run_git_command(['status', '--short'], cwd=root)\n    if not status:\n        return \"No changes\"\n    return status", "chunk_type": "function", "line_start": 20, "line_end": 25, "language": "python", "name": "get_git_status"}, "f329c62da74a_func_get_git_diff_stat": {"id": "f329c62da74a_func_get_git_diff_stat", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def get_git_diff_stat(root: Path) -> str:\n    \"\"\"Get git diff stats.\"\"\"\n    # Staged changes\n    staged = run_git_command(['diff', '--cached', '--stat'], cwd=root)\n    return staged or \"No staged changes\"", "chunk_type": "function", "line_start": 27, "line_end": 31, "language": "python", "name": "get_git_diff_stat"}, "f329c62da74a_func_analyze_diff": {"id": "f329c62da74a_func_analyze_diff", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def analyze_diff(root: Path) -> str:\n    \"\"\"Analyze the staged diff for semantic meaning.\"\"\"\n    diff = run_git_command(['diff', '--cached', '-U0'], cwd=root)\n    if not diff:\n        return \"No staged changes detected.\"\n\n    changes = []\n    current_file = \"\"\n\n    for line in diff.split('\\n'):\n        if line.startswith('diff --git'):\n            # diff --git a/file.py b/file.py\n            parts = line.split()\n            if len(parts) >= 4:\n                current_file = parts[-1].lstrip('b/')\n        elif line.startswith('@@'):\n            # @@ -10,0 +11,5 @@ def new_function():\n            # Try to extract context hint\n            context = line.split('@@')[-1].strip()\n            if context and current_file:\n                changes.append(f\"- {current_file}: {context}\")\n            elif current_file:\n                 changes.append(f\"- {current_file}: (modification)\")\n\n    # Deduplicate and summarize\n    unique_changes = sorted(list(set(changes)))\n    if len(unique_changes) > 10:", "chunk_type": "function", "line_start": 33, "line_end": 61, "language": "python", "name": "analyze_diff"}, "f329c62da74a_func_record_snapshot": {"id": "f329c62da74a_func_record_snapshot", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def record_snapshot(root: Path) -> bool:\n    \"\"\"Record a context snapshot of current state.\"\"\"\n    Console.info(\"Recording context snapshot...\")\n\n    status = get_git_status(root)\n    semantic_summary = analyze_diff(root)\n\n    content = f\"# Context Snapshot\\n\\n## Git Status\\n{status}\\n\\n## Semantic Changes\\n{semantic_summary}\"\n\n    store = get_store()\n    timestamp = datetime.now().isoformat()\n\n    store.remember(\n        key=f\"Snapshot {timestamp}\",\n        value=content,\n        tags=['snapshot', 'auto-context', 'pre-commit']\n    )\n\n    Console.ok(\"Context snapshot recorded\")\n    return True", "chunk_type": "function", "line_start": 63, "line_end": 82, "language": "python", "name": "record_snapshot"}, "f329c62da74a_func_main": {"id": "f329c62da74a_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\record.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--snapshot' in sys.argv:\n        record_snapshot(root)\n        return 0\n\n    if not args:\n        Console.fail(\"Usage: mcp record 'message' OR mcp record --snapshot\")\n        return 1\n\n    message = \" \".join(args)\n    store = get_store()\n    store.remember(\n        key=f\"Action {datetime.now().isoformat()}\",\n        value=message,\n        tags=['user-action']\n    )\n    Console.ok(\"Action recorded\")\n    return 0", "chunk_type": "function", "line_start": 84, "line_end": 105, "language": "python", "name": "main"}, "3ea8ddb137eb_file": {"id": "3ea8ddb137eb_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "\"\"\"\nAuto-Refactorer\n===============\nDetect and suggest code refactorings for improved quality.\n\nUsage:\n    python refactor.py [path] [--apply]\n    python -m scripts.refactor src/\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Set\nimport ast\nimport hashlib\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\n@dataclass\nclass RefactoringSuggestion:\n    \"\"\"A suggested refactoring.\"\"\"\n    path: Path\n    line_start: int\n    line_end: int\n    severity: str  # 'high', 'medium', 'low'\n    category: str  # 'long_function', 'duplicate', 'complex', 'naming'\n    message: str\n    suggestion: str\n\n\n@dataclass\nclass RefactoringReport:\n    \"\"\"Complete refactoring report.\"\"\"\n    suggestions: List[RefactoringSuggestion] = field(default_factory=list)\n\n    @property\n    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n                lines.append(f\"**Suggestion:** {s.suggestion}\")\n                lines.append(\"\")\n\n        return \"\\n\".join(lines)\n\n\nclass LongFunctionDetector(ast.NodeVisitor):\n    \"\"\"Detect functions ", "chunk_type": "file", "line_start": 1, "line_end": 403, "language": "python", "name": "refactor.py"}, "3ea8ddb137eb_func_analyze_file": {"id": "3ea8ddb137eb_func_analyze_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def analyze_file(self, path: Path, tree: ast.Module, source_lines: List[str]):\n        \"\"\"Analyze file for duplicate blocks.\"\"\"\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    start = node.lineno - 1\n                    end = node.end_lineno\n                    if end - start >= self.MIN_LINES:\n                        content = '\\n'.join(source_lines[start:end])\n                        # Normalize whitespace\n                        normalized = ' '.join(content.split())\n                        code_hash = hashlib.md5(normalized.encode()).hexdigest()\n                        self.code_hashes[code_hash].append((path, start + 1, end))", "chunk_type": "function", "line_start": 173, "line_end": 185, "language": "python", "name": "analyze_file"}, "3ea8ddb137eb_func_analyze_project": {"id": "3ea8ddb137eb_func_analyze_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "def analyze_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> RefactoringReport:\n    \"\"\"Analyze project for refactoring opportunities.\"\"\"\n    report = RefactoringReport()\n    duplicate_detector = DuplicateCodeDetector()\n\n    Console.info(f\"Analyzing {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    Console.info(f\"Found {len(files)} Python files\")\n\n    for path in files:\n        # Single file analysis\n        issues = analyze_file(path)\n        report.suggestions.extend(issues)\n\n        # Collect for duplicate detection\n        tree = parse_file(path)\n        if tree:\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    source_lines = f.readlines()\n                duplicate_detector.analyze_file(path, tree, source_lines)\n            except Exception:\n                pass\n\n    # Finalize duplicate detection\n    duplicate_detector.finalize()\n    report.suggestions.extend(duplicate_detector.issues)\n\n", "chunk_type": "function", "line_start": 338, "line_end": 370, "language": "python", "name": "analyze_project"}, "3ea8ddb137eb_func_main": {"id": "3ea8ddb137eb_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Refactorer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Analyzing: {path}\")\n\n    report = analyze_project(path)\n\n    print(report.to_markdown())\n\n    Console.info(f\"Found {len(report.suggestions)} refactoring suggestions\")\n    Console.info(f\"High priority: {len(report.high_priority)}\")\n\n    return 0", "chunk_type": "function", "line_start": 373, "line_end": 398, "language": "python", "name": "main"}, "3ea8ddb137eb_func_high_priority": {"id": "3ea8ddb137eb_func_high_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']", "chunk_type": "function", "line_start": 46, "line_end": 47, "language": "python", "name": "high_priority"}, "3ea8ddb137eb_func_to_markdown": {"id": "3ea8ddb137eb_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n                lines.append(f\"**Suggestion:** {s.suggestion}\")\n                lines.append(\"\")\n\n        return \"\\n\".join(lines)", "chunk_type": "function", "line_start": 49, "line_end": 73, "language": "python", "name": "to_markdown"}, "3ea8ddb137eb_func___init__": {"id": "3ea8ddb137eb_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []", "chunk_type": "function", "line_start": 282, "line_end": 284, "language": "python", "name": "__init__"}, "3ea8ddb137eb_func_visit_FunctionDef": {"id": "3ea8ddb137eb_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 286, "line_end": 288, "language": "python", "name": "visit_FunctionDef"}, "3ea8ddb137eb_func_visit_AsyncFunctionDef": {"id": "3ea8ddb137eb_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 290, "line_end": 292, "language": "python", "name": "visit_AsyncFunctionDef"}, "3ea8ddb137eb_func__check_function": {"id": "3ea8ddb137eb_func__check_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_function(self, node):\n        if node.end_lineno:\n            length = node.end_lineno - node.lineno\n            if length > self.MAX_LINES:\n                self.issues.append(RefactoringSuggestion(\n                    path=self.path,\n                    line_start=node.lineno,\n                    line_end=node.end_lineno,\n                    severity='high' if length > 100 else 'medium',\n                    category='long_function',\n                    message=f\"Function '{node.name}' is {length} lines (max: {self.MAX_LINES})\",\n                    suggestion=f\"Extract helper functions from '{node.name}'\"\n                ))", "chunk_type": "function", "line_start": 93, "line_end": 105, "language": "python", "name": "_check_function"}, "3ea8ddb137eb_func_visit_If": {"id": "3ea8ddb137eb_func_visit_If", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_If(self, node: ast.If):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 127, "line_end": 131, "language": "python", "name": "visit_If"}, "3ea8ddb137eb_func_visit_For": {"id": "3ea8ddb137eb_func_visit_For", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_For(self, node: ast.For):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 133, "line_end": 137, "language": "python", "name": "visit_For"}, "3ea8ddb137eb_func_visit_While": {"id": "3ea8ddb137eb_func_visit_While", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_While(self, node: ast.While):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 139, "line_end": 143, "language": "python", "name": "visit_While"}, "3ea8ddb137eb_func_visit_Try": {"id": "3ea8ddb137eb_func_visit_Try", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_Try(self, node: ast.Try):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1", "chunk_type": "function", "line_start": 145, "line_end": 149, "language": "python", "name": "visit_Try"}, "3ea8ddb137eb_func__check_nesting": {"id": "3ea8ddb137eb_func__check_nesting", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_nesting(self, node):\n        if self._nesting_level >= self.MAX_NESTED:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.end_lineno or node.lineno,\n                severity='high',\n                category='deep_nesting',\n                message=f\"Deeply nested code ({self._nesting_level + 1} levels)\",\n                suggestion=\"Extract nested logic into helper functions\"\n            ))", "chunk_type": "function", "line_start": 151, "line_end": 161, "language": "python", "name": "_check_nesting"}, "3ea8ddb137eb_func_finalize": {"id": "3ea8ddb137eb_func_finalize", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def finalize(self):\n        \"\"\"Generate issues for duplicates.\"\"\"\n        for code_hash, locations in self.code_hashes.items():\n            if len(locations) > 1:\n                files = list(set(str(loc[0]) for loc in locations))\n                for path, start, end in locations:\n                    self.issues.append(RefactoringSuggestion(\n                        path=path,\n                        line_start=start,\n                        line_end=end,\n                        severity='medium',\n                        category='duplicate_code',\n                        message=f\"Duplicate code found in {len(locations)} locations\",\n                        suggestion=f\"Extract common code into shared function\"\n                    ))", "chunk_type": "function", "line_start": 187, "line_end": 201, "language": "python", "name": "finalize"}, "3ea8ddb137eb_func_visit_ClassDef": {"id": "3ea8ddb137eb_func_visit_ClassDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def visit_ClassDef(self, node: ast.ClassDef):\n        self._check_class_name(node)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 215, "line_end": 217, "language": "python", "name": "visit_ClassDef"}, "3ea8ddb137eb_func__check_function_name": {"id": "3ea8ddb137eb_func__check_function_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_function_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for camelCase\n        if any(c.isupper() for c in name[1:]) and '_' not in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' uses camelCase\",\n                suggestion=f\"Rename to snake_case: '{self._to_snake_case(name)}'\"\n            ))\n\n        # Check single letter names (except i, j, k, x, y, z)\n        if len(name) == 1 and name not in 'ijkxyz':\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' has ", "chunk_type": "function", "line_start": 219, "line_end": 246, "language": "python", "name": "_check_function_name"}, "3ea8ddb137eb_func__check_class_name": {"id": "3ea8ddb137eb_func__check_class_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_class_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for snake_case in class names\n        if '_' in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Class '{name}' uses snake_case\",\n                suggestion=f\"Rename to CamelCase: '{self._to_camel_case(name)}'\"\n            ))", "chunk_type": "function", "line_start": 248, "line_end": 263, "language": "python", "name": "_check_class_name"}, "3ea8ddb137eb_func__to_snake_case": {"id": "3ea8ddb137eb_func__to_snake_case", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _to_snake_case(self, name: str) -> str:\n        result = []\n        for i, c in enumerate(name):\n            if c.isupper() and i > 0:\n                result.append('_')\n            result.append(c.lower())\n        return ''.join(result)", "chunk_type": "function", "line_start": 265, "line_end": 271, "language": "python", "name": "_to_snake_case"}, "3ea8ddb137eb_func__to_camel_case": {"id": "3ea8ddb137eb_func__to_camel_case", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _to_camel_case(self, name: str) -> str:\n        return ''.join(word.capitalize() for word in name.split('_'))", "chunk_type": "function", "line_start": 273, "line_end": 274, "language": "python", "name": "_to_camel_case"}, "3ea8ddb137eb_func__check_params": {"id": "3ea8ddb137eb_func__check_params", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "    def _check_params(self, node):\n        # Count params excluding self/cls\n        params = [a for a in node.args.args if a.arg not in ('self', 'cls')]\n        if len(params) > self.MAX_PARAMS:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='medium',\n                category='too_many_params',\n                message=f\"Function '{node.name}' has {len(params)} parameters (max: {self.MAX_PARAMS})\",\n                suggestion=\"Consider using a configuration object or dataclass\"\n            ))", "chunk_type": "function", "line_start": 294, "line_end": 306, "language": "python", "name": "_check_params"}, "3ea8ddb137eb_class_RefactoringSuggestion": {"id": "3ea8ddb137eb_class_RefactoringSuggestion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class RefactoringSuggestion:\n    \"\"\"A suggested refactoring.\"\"\"\n    path: Path\n    line_start: int\n    line_end: int\n    severity: str  # 'high', 'medium', 'low'\n    category: str  # 'long_function', 'duplicate', 'complex', 'naming'\n    message: str\n    suggestion: str", "chunk_type": "class", "line_start": 29, "line_end": 37, "language": "python", "name": "RefactoringSuggestion"}, "3ea8ddb137eb_class_RefactoringReport": {"id": "3ea8ddb137eb_class_RefactoringReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class RefactoringReport:\n    \"\"\"Complete refactoring report.\"\"\"\n    suggestions: List[RefactoringSuggestion] = field(default_factory=list)\n\n    @property\n    def high_priority(self) -> List[RefactoringSuggestion]:\n        return [s for s in self.suggestions if s.severity == 'high']\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Refactoring Suggestions\",\n            \"\",\n            f\"**Total suggestions:** {len(self.suggestions)}\",\n            f\"**High priority:** {len(self.high_priority)}\",\n            \"\",\n        ]\n\n        # Group by severity\n        for severity in ['high', 'medium', 'low']:\n            items = [s for s in self.suggestions if s.severity == severity]\n            if not items:\n                continue\n\n            lines.append(f\"## {severity.upper()} Priority\")\n            lines.append(\"\")\n\n            for s in items:\n                lines.append(f\"### {s.category}: {s.path}:{s.line_start}\")\n                lines.append(f\"**Issue:** {s.message}\")\n", "chunk_type": "class", "line_start": 41, "line_end": 73, "language": "python", "name": "RefactoringReport"}, "3ea8ddb137eb_class_LongFunctionDetector": {"id": "3ea8ddb137eb_class_LongFunctionDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class LongFunctionDetector(ast.NodeVisitor):\n    \"\"\"Detect functions that are too long.\"\"\"\n\n    MAX_LINES = 50\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_function(node)\n        self.generic_visit(node)\n\n    def _check_function(self, node):\n        if node.end_lineno:\n            length = node.end_lineno - node.lineno\n            if length > self.MAX_LINES:\n                self.issues.append(RefactoringSuggestion(\n                    path=self.path,\n                    line_start=node.lineno,\n                    line_end=node.end_lineno,\n                    severity='high' if length > 100 else 'medium',\n                    category='long_function',\n                    message=f\"Function '{node.name}' is {le", "chunk_type": "class", "line_start": 76, "line_end": 105, "language": "python", "name": "LongFunctionDetector"}, "3ea8ddb137eb_class_ComplexityDetector": {"id": "3ea8ddb137eb_class_ComplexityDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class ComplexityDetector(ast.NodeVisitor):\n    \"\"\"Detect overly complex code.\"\"\"\n\n    MAX_NESTED = 4\n    MAX_CONDITIONS = 5\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n        self._nesting_level = 0\n        self._current_function = None\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        old_func = self._current_function\n        self._current_function = node.name\n        self._nesting_level = 0\n        self.generic_visit(node)\n        self._current_function = old_func\n\n    def visit_If(self, node: ast.If):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1\n\n    def visit_For(self, node: ast.For):\n        self._check_nesting(node)\n        self._nesting_level += 1\n        self.generic_visit(node)\n        self._nesting_level -= 1\n\n    def visit_While(self, node: ast.While):\n        self._check_nesting(node)\n        self._ne", "chunk_type": "class", "line_start": 108, "line_end": 161, "language": "python", "name": "ComplexityDetector"}, "3ea8ddb137eb_class_DuplicateCodeDetector": {"id": "3ea8ddb137eb_class_DuplicateCodeDetector", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class DuplicateCodeDetector:\n    \"\"\"Detect duplicate code blocks.\"\"\"\n\n    MIN_LINES = 5\n\n    def __init__(self):\n        self.code_hashes: Dict[str, List[Tuple[Path, int, int]]] = defaultdict(list)\n        self.issues: List[RefactoringSuggestion] = []\n\n    def analyze_file(self, path: Path, tree: ast.Module, source_lines: List[str]):\n        \"\"\"Analyze file for duplicate blocks.\"\"\"\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    start = node.lineno - 1\n                    end = node.end_lineno\n                    if end - start >= self.MIN_LINES:\n                        content = '\\n'.join(source_lines[start:end])\n                        # Normalize whitespace\n                        normalized = ' '.join(content.split())\n                        code_hash = hashlib.md5(normalized.encode()).hexdigest()\n                        self.code_hashes[code_hash].append((path, sta", "chunk_type": "class", "line_start": 164, "line_end": 201, "language": "python", "name": "DuplicateCodeDetector"}, "3ea8ddb137eb_class_NamingConventionChecker": {"id": "3ea8ddb137eb_class_NamingConventionChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class NamingConventionChecker(ast.NodeVisitor):\n    \"\"\"Check naming conventions.\"\"\"\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_function_name(node)\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef):\n        self._check_class_name(node)\n        self.generic_visit(node)\n\n    def _check_function_name(self, node):\n        name = node.name\n        if name.startswith('_'):\n            return\n\n        # Check for camelCase\n        if any(c.isupper() for c in name[1:]) and '_' not in name:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='low',\n                category='naming',\n                message=f\"Function '{name}' uses camelCase\",\n                suggestion=f\"Rename to ", "chunk_type": "class", "line_start": 204, "line_end": 274, "language": "python", "name": "NamingConventionChecker"}, "3ea8ddb137eb_class_ParameterCountChecker": {"id": "3ea8ddb137eb_class_ParameterCountChecker", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\refactor.py", "content": "class ParameterCountChecker(ast.NodeVisitor):\n    \"\"\"Check for functions with too many parameters.\"\"\"\n\n    MAX_PARAMS = 5\n\n    def __init__(self, path: Path):\n        self.path = path\n        self.issues: List[RefactoringSuggestion] = []\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self._check_params(node)\n        self.generic_visit(node)\n\n    def _check_params(self, node):\n        # Count params excluding self/cls\n        params = [a for a in node.args.args if a.arg not in ('self', 'cls')]\n        if len(params) > self.MAX_PARAMS:\n            self.issues.append(RefactoringSuggestion(\n                path=self.path,\n                line_start=node.lineno,\n                line_end=node.lineno,\n                severity='medium',\n                category='too_many_params',\n                message=f\"Function '{node.name}' has {len(params)}", "chunk_type": "class", "line_start": 277, "line_end": 306, "language": "python", "name": "ParameterCountChecker"}, "99a0f68b5a6a_file": {"id": "99a0f68b5a6a_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "\"\"\"\nCode Review Automation\n======================\nPre-commit code review checklist - validates code quality before commit.\n\nUsage:\n    python review.py [path] [--strict]\n    python -m scripts.review [path]\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import List, Dict, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    get_staged_files,\n    analyze_module,\n    Console,\n    format_as_markdown_table\n)\n\n\nclass Severity(Enum):\n    \"\"\"Severity level for review issues.\"\"\"\n    ERROR = \"ERROR\"\n    WARNING = \"WARNING\"\n    INFO = \"INFO\"\n\n\n@dataclass\nclass ReviewIssue:\n    \"\"\"A single code review issue.\"\"\"\n    file: Path\n    line: int\n    severity: Severity\n    category: str\n    message: str\n\n\n@dataclass\nclass ReviewReport:\n    \"\"\"Complete code review report.\"\"\"\n    issues: List[ReviewIssue] = field(default_factory=list)\n    files_reviewed: int = 0\n\n    @property\n    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]\n\n    @property\n    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]\n\n    @property\n    def passed(self) -> bool:\n        return len(self.errors) == 0\n\n\n# Review checks\nclass ReviewChecks:\n    \"\"\"Collection of review check functions.\"\"\"\n\n    @staticmethod\n    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n              ", "chunk_type": "file", "line_start": 1, "line_end": 509, "language": "python", "name": "review.py"}, "99a0f68b5a6a_func_review_file": {"id": "99a0f68b5a6a_func_review_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def review_file(path: Path, strict: bool = False) -> List[ReviewIssue]:\n    \"\"\"\n    Review a single Python file.\n\n    Args:\n        path: Path to file\n        strict: Enable strict mode (more checks)\n\n    Returns:\n        List of review issues\n    \"\"\"\n    issues = []\n\n    tree = parse_file(path)\n    if tree is None:\n        return issues\n\n    # Run all checks\n    issues.extend(ReviewChecks.check_docstrings(path, tree))\n    issues.extend(ReviewChecks.check_todo_fixme(path))\n    issues.extend(ReviewChecks.check_naming_conventions(path, tree))\n    issues.extend(ReviewChecks.check_file_length(path))\n    issues.extend(ReviewChecks.check_function_length(path, tree))\n    issues.extend(ReviewChecks.check_unused_imports(path, tree))\n    issues.extend(ReviewChecks.check_security_issues(path, tree))\n\n    if strict:\n        issues.extend(ReviewChecks.check_type_hints(path, tree))\n\n    return issues", "chunk_type": "function", "line_start": 337, "line_end": 366, "language": "python", "name": "review_file"}, "99a0f68b5a6a_func_review_project": {"id": "99a0f68b5a6a_func_review_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def review_project(\n    root: Path,\n    staged_only: bool = False,\n    strict: bool = False,\n    exclude_patterns: List[str] = None\n) -> ReviewReport:\n    \"\"\"\n    Review a Python project.\n\n    Args:\n        root: Root directory\n        staged_only: Only review staged files\n        strict: Enable strict mode\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        ReviewReport\n    \"\"\"\n    report = ReviewReport()\n\n    if staged_only:\n        Console.info(\"Reviewing staged files only...\")\n        staged = get_staged_files(cwd=root)\n        files = [root / f for f in staged if f.endswith('.py')]\n    else:\n        Console.info(f\"Reviewing all Python files in {root}...\")\n        files = list(find_python_files(root, exclude_patterns))\n\n    Console.info(f\"Found {len(files)} files to review\")\n    report.files_reviewed = len(files)\n\n    for path in files:\n        issues = review_file(path, strict=strict)\n        report.issues.extend(issues)\n\n    return report", "chunk_type": "function", "line_start": 369, "line_end": 404, "language": "python", "name": "review_project"}, "99a0f68b5a6a_func_format_report_console": {"id": "99a0f68b5a6a_func_format_report_console", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def format_report_console(report: ReviewReport) -> None:\n    \"\"\"Print report to console.\"\"\"\n    if not report.issues:\n        Console.ok(\"No issues found\")\n        return\n\n    # Group by file\n    by_file: Dict[Path, List[ReviewIssue]] = {}\n    for issue in report.issues:\n        if issue.file not in by_file:\n            by_file[issue.file] = []\n        by_file[issue.file].append(issue)\n\n    for file, issues in sorted(by_file.items()):\n        print(f\"\\n{file}:\")\n        for issue in sorted(issues, key=lambda x: x.line):\n            severity_color = {\n                Severity.ERROR: Console.fail,\n                Severity.WARNING: Console.warn,\n                Severity.INFO: Console.info\n            }\n            severity_color[issue.severity](f\"  L{issue.line}: [{issue.category}] {issue.message}\")", "chunk_type": "function", "line_start": 407, "line_end": 428, "language": "python", "name": "format_report_console"}, "99a0f68b5a6a_func_format_report_markdown": {"id": "99a0f68b5a6a_func_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def format_report_markdown(report: ReviewReport) -> str:\n    \"\"\"Format report as Markdown.\"\"\"\n    lines = [\n        \"# Code Review Report\",\n        \"\",\n        \"## Summary\",\n        \"\",\n        f\"- **Files Reviewed:** {report.files_reviewed}\",\n        f\"- **Total Issues:** {len(report.issues)}\",\n        f\"- **Errors:** {len(report.errors)}\",\n        f\"- **Warnings:** {len(report.warnings)}\",\n        f\"- **Status:** {'PASSED' if report.passed else 'FAILED'}\",\n        \"\",\n    ]\n\n    if report.errors:\n        lines.extend([\n            \"## Errors (Must Fix)\",\n            \"\",\n        ])\n        rows = [[str(i.file), str(i.line), i.category, i.message] for i in report.errors]\n        lines.append(format_as_markdown_table([\"File\", \"Line\", \"Category\", \"Message\"], rows))\n        lines.append(\"\")\n\n    if report.warnings:\n        lines.extend([\n            \"## Warnings\",\n            \"\",\n        ])\n        rows = [[str(i.file), str(i.line), i.category, i.message] for i in report.warnings]\n       ", "chunk_type": "function", "line_start": 431, "line_end": 464, "language": "python", "name": "format_report_markdown"}, "99a0f68b5a6a_func_main": {"id": "99a0f68b5a6a_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Code Review Automation\")\n\n    # Parse args\n    strict = '--strict' in sys.argv\n    staged_only = '--staged' in sys.argv\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Reviewing: {path}\")\n    Console.info(f\"Mode: {'strict' if strict else 'standard'}\")\n\n    report = review_project(path, staged_only=staged_only, strict=strict)\n\n    print()\n    format_report_console(report)\n    print()\n\n    # Summary\n    Console.info(f\"Reviewed {report.files_reviewed} files\")\n    Console.info(f\"Found {len(report.issues)} issues ({len(report.errors)} errors, {len(report.warnings)} warnings)\")\n\n    if report.passed:\n        Console.ok(\"Code review PASSED\")\n        return 0\n    else:\n        Console.fail(\"Cod", "chunk_type": "function", "line_start": 467, "line_end": 504, "language": "python", "name": "main"}, "99a0f68b5a6a_func_errors": {"id": "99a0f68b5a6a_func_errors", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]", "chunk_type": "function", "line_start": 53, "line_end": 54, "language": "python", "name": "errors"}, "99a0f68b5a6a_func_warnings": {"id": "99a0f68b5a6a_func_warnings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]", "chunk_type": "function", "line_start": 57, "line_end": 58, "language": "python", "name": "warnings"}, "99a0f68b5a6a_func_passed": {"id": "99a0f68b5a6a_func_passed", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def passed(self) -> bool:\n        return len(self.errors) == 0", "chunk_type": "function", "line_start": 61, "line_end": 62, "language": "python", "name": "passed"}, "99a0f68b5a6a_func_check_docstrings": {"id": "99a0f68b5a6a_func_check_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.WARNING,\n                        category=\"documentation\",\n                        message=f\"Function '{node.name}' is missing a docstring\"\n                    ))\n\n            elif isinstance(node, ast.ClassDef):\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        ", "chunk_type": "function", "line_start": 70, "line_end": 102, "language": "python", "name": "check_docstrings"}, "99a0f68b5a6a_func_check_type_hints": {"id": "99a0f68b5a6a_func_check_type_hints", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_type_hints(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing type hints.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                # Check return type\n                if node.returns is None and node.name != '__init__':\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.INFO,\n                        category=\"types\",\n                        message=f\"Function '{node.name}' is missing return type hint\"\n                    ))\n\n                # Check argument types\n                for arg in node.args.args:\n                    if arg.arg not in ('self', 'cls') and arg.annotation is None:\n                        issue", "chunk_type": "function", "line_start": 105, "line_end": 136, "language": "python", "name": "check_type_hints"}, "99a0f68b5a6a_func_check_todo_fixme": {"id": "99a0f68b5a6a_func_check_todo_fixme", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_todo_fixme(path: Path) -> List[ReviewIssue]:\n        \"\"\"Check for TODO/FIXME comments.\"\"\"\n        issues = []\n\n        try:\n            with open(path, 'r', encoding='utf-8') as f:\n                for i, line in enumerate(f, 1):\n                    line_upper = line.upper()\n                    if 'TODO' in line_upper:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=i,\n                            severity=Severity.INFO,\n                            category=\"todo\",\n                            message=f\"TODO comment found: {line.strip()[:50]}...\"\n                        ))\n                    elif 'FIXME' in line_upper:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=i,\n                            severity=Severity.WARNING,\n                            category=\"fixme\",\n                            message=f\"FIXME comment found: ", "chunk_type": "function", "line_start": 139, "line_end": 174, "language": "python", "name": "check_todo_fixme"}, "99a0f68b5a6a_func_check_naming_conventions": {"id": "99a0f68b5a6a_func_check_naming_conventions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_naming_conventions(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check naming conventions.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            # Classes should be CamelCase\n            if isinstance(node, ast.ClassDef):\n                if not node.name[0].isupper() or '_' in node.name:\n                    if not node.name.startswith('_'):\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.WARNING,\n                            category=\"naming\",\n                            message=f\"Class '{node.name}' should use CamelCase\"\n                        ))\n\n            # Functions should be snake_case\n            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if not node.name.startswith('_'):\n                    # Check for camelCase (has lowercase followed by uppercase)\n           ", "chunk_type": "function", "line_start": 177, "line_end": 208, "language": "python", "name": "check_naming_conventions"}, "99a0f68b5a6a_func_check_file_length": {"id": "99a0f68b5a6a_func_check_file_length", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_file_length(path: Path, max_lines: int = 500) -> List[ReviewIssue]:\n        \"\"\"Check file length.\"\"\"\n        issues = []\n\n        try:\n            with open(path, 'r', encoding='utf-8') as f:\n                line_count = sum(1 for _ in f)\n\n            if line_count > max_lines:\n                issues.append(ReviewIssue(\n                    file=path,\n                    line=1,\n                    severity=Severity.WARNING,\n                    category=\"complexity\",\n                    message=f\"File has {line_count} lines (max recommended: {max_lines})\"\n                ))\n        except Exception:\n            pass\n\n        return issues", "chunk_type": "function", "line_start": 211, "line_end": 230, "language": "python", "name": "check_file_length"}, "99a0f68b5a6a_func_check_function_length": {"id": "99a0f68b5a6a_func_check_function_length", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_function_length(path: Path, tree: ast.Module, max_lines: int = 50) -> List[ReviewIssue]:\n        \"\"\"Check function length.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                if node.end_lineno:\n                    length = node.end_lineno - node.lineno\n                    if length > max_lines:\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.WARNING,\n                            category=\"complexity\",\n                            message=f\"Function '{node.name}' is {length} lines (max: {max_lines})\"\n                        ))\n\n        return issues", "chunk_type": "function", "line_start": 233, "line_end": 250, "language": "python", "name": "check_function_length"}, "99a0f68b5a6a_func_check_unused_imports": {"id": "99a0f68b5a6a_func_check_unused_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_unused_imports(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for potentially unused imports.\"\"\"\n        issues = []\n\n        # Collect imports\n        imports = {}\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name.split('.')[0]\n                    imports[name] = node.lineno\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    if alias.name != '*':\n                        name = alias.asname or alias.name\n                        imports[name] = node.lineno\n\n        # Collect all used names\n        used_names = set()\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Name):\n                used_names.add(node.id)\n            elif isinstance(node, ast.Attribute):\n                if isinstance(node.value, ast.Name):\n                    used_names.add", "chunk_type": "function", "line_start": 253, "line_end": 290, "language": "python", "name": "check_unused_imports"}, "99a0f68b5a6a_func_check_security_issues": {"id": "99a0f68b5a6a_func_check_security_issues", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "    def check_security_issues(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for common security issues.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            # Check for eval/exec\n            if isinstance(node, ast.Call):\n                if isinstance(node.func, ast.Name):\n                    if node.func.id in ('eval', 'exec'):\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.ERROR,\n                            category=\"security\",\n                            message=f\"Use of '{node.func.id}' is a security risk\"\n                        ))\n                    elif node.func.id == 'input':\n                        issues.append(ReviewIssue(\n                            file=path,\n                            line=node.lineno,\n                            severity=Severity.INFO,\n                            category=\"secu", "chunk_type": "function", "line_start": 293, "line_end": 334, "language": "python", "name": "check_security_issues"}, "99a0f68b5a6a_class_Severity": {"id": "99a0f68b5a6a_class_Severity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "class Severity(Enum):\n    \"\"\"Severity level for review issues.\"\"\"\n    ERROR = \"ERROR\"\n    WARNING = \"WARNING\"\n    INFO = \"INFO\"", "chunk_type": "class", "line_start": 29, "line_end": 33, "language": "python", "name": "Severity"}, "99a0f68b5a6a_class_ReviewIssue": {"id": "99a0f68b5a6a_class_ReviewIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewIssue:\n    \"\"\"A single code review issue.\"\"\"\n    file: Path\n    line: int\n    severity: Severity\n    category: str\n    message: str", "chunk_type": "class", "line_start": 37, "line_end": 43, "language": "python", "name": "ReviewIssue"}, "99a0f68b5a6a_class_ReviewReport": {"id": "99a0f68b5a6a_class_ReviewReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewReport:\n    \"\"\"Complete code review report.\"\"\"\n    issues: List[ReviewIssue] = field(default_factory=list)\n    files_reviewed: int = 0\n\n    @property\n    def errors(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.ERROR]\n\n    @property\n    def warnings(self) -> List[ReviewIssue]:\n        return [i for i in self.issues if i.severity == Severity.WARNING]\n\n    @property\n    def passed(self) -> bool:\n        return len(self.errors) == 0", "chunk_type": "class", "line_start": 47, "line_end": 62, "language": "python", "name": "ReviewReport"}, "99a0f68b5a6a_class_ReviewChecks": {"id": "99a0f68b5a6a_class_ReviewChecks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\review.py", "content": "class ReviewChecks:\n    \"\"\"Collection of review check functions.\"\"\"\n\n    @staticmethod\n    def check_docstrings(path: Path, tree: ast.Module) -> List[ReviewIssue]:\n        \"\"\"Check for missing docstrings.\"\"\"\n        issues = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                # Skip private and dunder methods\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_docstring(node):\n                    issues.append(ReviewIssue(\n                        file=path,\n                        line=node.lineno,\n                        severity=Severity.WARNING,\n                        category=\"documentation\",\n                        message=f\"Function '{node.name}' is missing a docstring\"\n                    ))\n\n            elif isinstance(node, ast.ClassDef):\n                if node.name.startswith('_'):\n                    continue\n\n                if not ast.get_d", "chunk_type": "class", "line_start": 66, "line_end": 334, "language": "python", "name": "ReviewChecks"}, "3fec6b2527c5_file": {"id": "3fec6b2527c5_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "\"\"\"\nSecurity Auditor\n================\nDeep security analysis for Python code - OWASP, secrets, injection detection.\n\nUsage:\n    python security.py [path] [--strict]\n    python -m scripts.security src/\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set\nimport ast\nimport re\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    parse_file,\n    Console,\n    format_as_markdown_table\n)\n\n\nclass Severity(Enum):\n    CRITICAL = \"CRITICAL\"\n    HIGH = \"HIGH\"\n    MEDIUM = \"MEDIUM\"\n    LOW = \"LOW\"\n    INFO = \"INFO\"\n\n\n@dataclass\nclass SecurityIssue:\n    \"\"\"A security finding.\"\"\"\n    path: Path\n    line: int\n    severity: Severity\n    category: str\n    title: str\n    description: str\n    cwe: Optional[str] = None  # CWE identifier\n    fix: Optional[str] = None\n\n\n@dataclass\nclass SecurityReport:\n    \"\"\"Complete security audit report.\"\"\"\n    issues: List[SecurityIssue] = field(default_factory=list)\n    files_scanned: int = 0\n\n    @property\n    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]\n\n    @property\n    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n            return \"\\n\".join(lines)\n\n        # Group by severity\n        for sev in Severity:\n            items = [i f", "chunk_type": "file", "line_start": 1, "line_end": 411, "language": "python", "name": "security.py"}, "3fec6b2527c5_func_check_secrets": {"id": "3fec6b2527c5_func_check_secrets", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def check_secrets(path: Path, source: str) -> List[SecurityIssue]:\n    \"\"\"Check for hardcoded secrets.\"\"\"\n    issues = []\n    lines = source.split('\\n')\n\n    for i, line in enumerate(lines, 1):\n        # Skip comments\n        stripped = line.strip()\n        if stripped.startswith('#'):\n            continue\n\n        for pattern, title in SECRET_PATTERNS:\n            if re.search(pattern, line):\n                # Exclude obvious non-secrets\n                if 'example' in line.lower() or 'test' in line.lower():\n                    continue\n                if '\"\"' in line or \"''\" in line:  # Empty strings\n                    continue\n                if 'os.environ' in line or 'getenv' in line:\n                    continue\n\n                issues.append(SecurityIssue(\n                    path=path,\n                    line=i,\n                    severity=Severity.CRITICAL,\n                    category=\"Hardcoded Secret\",\n                    title=title,\n                    description=f\"Po", "chunk_type": "function", "line_start": 263, "line_end": 296, "language": "python", "name": "check_secrets"}, "3fec6b2527c5_func_check_sql_injection": {"id": "3fec6b2527c5_func_check_sql_injection", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def check_sql_injection(path: Path, source: str) -> List[SecurityIssue]:\n    \"\"\"Check for SQL injection patterns.\"\"\"\n    issues = []\n    lines = source.split('\\n')\n\n    for i, line in enumerate(lines, 1):\n        for pattern in SQL_INJECTION_PATTERNS:\n            if re.search(pattern, line, re.IGNORECASE):\n                issues.append(SecurityIssue(\n                    path=path,\n                    line=i,\n                    severity=Severity.HIGH,\n                    category=\"SQL Injection\",\n                    title=\"Potential SQL injection\",\n                    description=\"SQL query appears to use string formatting instead of parameterization\",\n                    cwe=\"CWE-89\",\n                    fix=\"Use parameterized queries with placeholders\"\n                ))\n                break\n\n    return issues", "chunk_type": "function", "line_start": 299, "line_end": 319, "language": "python", "name": "check_sql_injection"}, "3fec6b2527c5_func_audit_file": {"id": "3fec6b2527c5_func_audit_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def audit_file(path: Path) -> List[SecurityIssue]:\n    \"\"\"Audit a single file for security issues.\"\"\"\n    issues = []\n\n    try:\n        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n            source = f.read()\n    except Exception:\n        return issues\n\n    # AST-based analysis\n    tree = parse_file(path)\n    if tree:\n        analyzer = SecurityAnalyzer(path, source)\n        analyzer.visit(tree)\n        issues.extend(analyzer.issues)\n\n    # Pattern-based checks\n    issues.extend(check_secrets(path, source))\n    issues.extend(check_sql_injection(path, source))\n\n    return issues", "chunk_type": "function", "line_start": 322, "line_end": 343, "language": "python", "name": "audit_file"}, "3fec6b2527c5_func_security_audit": {"id": "3fec6b2527c5_func_security_audit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def security_audit(\n    root: Path,\n    strict: bool = False,\n    exclude_patterns: List[str] = None\n) -> SecurityReport:\n    \"\"\"Perform security audit on a project.\"\"\"\n    report = SecurityReport()\n\n    Console.info(f\"Security audit of {root}...\")\n\n    files = list(find_python_files(root, exclude_patterns))\n    report.files_scanned = len(files)\n    Console.info(f\"Scanning {len(files)} files...\")\n\n    for path in files:\n        issues = audit_file(path)\n\n        # In strict mode, include all issues; otherwise filter INFO\n        if strict:\n            report.issues.extend(issues)\n        else:\n            report.issues.extend([i for i in issues if i.severity != Severity.INFO])\n\n    return report", "chunk_type": "function", "line_start": 346, "line_end": 369, "language": "python", "name": "security_audit"}, "3fec6b2527c5_func_main": {"id": "3fec6b2527c5_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Security Auditor\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    strict = '--strict' in sys.argv\n\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        return 1\n\n    Console.info(f\"Auditing: {path}\")\n    Console.info(f\"Mode: {'strict' if strict else 'standard'}\")\n\n    report = security_audit(path, strict=strict)\n\n    print(report.to_markdown())\n\n    # Summary\n    if report.critical:\n        Console.fail(f\"CRITICAL: {len(report.critical)} critical issues found!\")\n    elif report.high:\n        Console.warn(f\"HIGH: {len(report.high)} high severity issues found\")\n    elif report.issues:\n        Console.warn(f\"Found {len(report.issues)} security issues\")\n    else:\n        Console.ok(\"No security issues found\")\n\n    return 1 if report.critical or report.high else 0", "chunk_type": "function", "line_start": 372, "line_end": 406, "language": "python", "name": "main"}, "3fec6b2527c5_func_critical": {"id": "3fec6b2527c5_func_critical", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]", "chunk_type": "function", "line_start": 56, "line_end": 57, "language": "python", "name": "critical"}, "3fec6b2527c5_func_high": {"id": "3fec6b2527c5_func_high", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]", "chunk_type": "function", "line_start": 60, "line_end": 61, "language": "python", "name": "high"}, "3fec6b2527c5_func_to_markdown": {"id": "3fec6b2527c5_func_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n            return \"\\n\".join(lines)\n\n        # Group by severity\n        for sev in Severity:\n            items = [i for i in self.issues if i.severity == sev]\n            if not items:\n                continue\n\n            lines.extend([f\"## {sev.value}\", \"\"])\n\n            for issue in items:\n                lines.append(f\"### {issue.category}: {issue.title}\")\n                lines.append(f\"**File:** `{issue.path}:{is", "chunk_type": "function", "line_start": 63, "line_end": 104, "language": "python", "name": "to_markdown"}, "3fec6b2527c5_func___init__": {"id": "3fec6b2527c5_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def __init__(self, path: Path, source: str):\n        self.path = path\n        self.source = source\n        self.source_lines = source.split('\\n')\n        self.issues: List[SecurityIssue] = []\n        self._imports: Set[str] = set()", "chunk_type": "function", "line_start": 165, "line_end": 170, "language": "python", "name": "__init__"}, "3fec6b2527c5_func_visit_Import": {"id": "3fec6b2527c5_func_visit_Import", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self._imports.add(alias.name)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 172, "line_end": 175, "language": "python", "name": "visit_Import"}, "3fec6b2527c5_func_visit_ImportFrom": {"id": "3fec6b2527c5_func_visit_ImportFrom", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self._imports.add(node.module)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 177, "line_end": 180, "language": "python", "name": "visit_ImportFrom"}, "3fec6b2527c5_func_visit_Call": {"id": "3fec6b2527c5_func_visit_Call", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Call(self, node: ast.Call):\n        # Check for dangerous function calls\n        func_name = self._get_func_name(node.func)\n\n        if func_name in DANGEROUS_FUNCTIONS:\n            # Special case: Allow subprocess.Popen/call/run if shell=False is explicit\n            if func_name in ('subprocess.Popen', 'subprocess.call', 'subprocess.run'):\n                is_safe = False\n                for keyword in node.keywords:\n                    if keyword.arg == 'shell':\n                         if isinstance(keyword.value, ast.Constant) and keyword.value.value is False:\n                             is_safe = True\n                if is_safe:\n                    self.generic_visit(node)\n                    return\n\n            title, severity, cwe, desc = DANGEROUS_FUNCTIONS[func_name]\n            self.issues.append(SecurityIssue(\n                path=self.path,\n                line=node.lineno,\n                severity=severity,\n                category=\"Dangerous Function\",\n    ", "chunk_type": "function", "line_start": 182, "line_end": 238, "language": "python", "name": "visit_Call"}, "3fec6b2527c5_func_visit_Assert": {"id": "3fec6b2527c5_func_visit_Assert", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def visit_Assert(self, node: ast.Assert):\n        # Asserts are removed in optimized bytecode\n        self.issues.append(SecurityIssue(\n            path=self.path,\n            line=node.lineno,\n            severity=Severity.LOW,\n            category=\"Security Control\",\n            title=\"Assert used for security check\",\n            description=\"Assert statements are removed when Python runs with -O flag\",\n            fix=\"Use proper if/raise for security checks\"\n        ))\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 240, "line_end": 251, "language": "python", "name": "visit_Assert"}, "3fec6b2527c5_func__get_func_name": {"id": "3fec6b2527c5_func__get_func_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "    def _get_func_name(self, node) -> str:\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            if isinstance(node.value, ast.Name):\n                return f\"{node.value.id}.{node.attr}\"\n            return node.attr\n        return \"\"", "chunk_type": "function", "line_start": 253, "line_end": 260, "language": "python", "name": "_get_func_name"}, "3fec6b2527c5_class_Severity": {"id": "3fec6b2527c5_class_Severity", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "class Severity(Enum):\n    CRITICAL = \"CRITICAL\"\n    HIGH = \"HIGH\"\n    MEDIUM = \"MEDIUM\"\n    LOW = \"LOW\"\n    INFO = \"INFO\"", "chunk_type": "class", "line_start": 28, "line_end": 33, "language": "python", "name": "Severity"}, "3fec6b2527c5_class_SecurityIssue": {"id": "3fec6b2527c5_class_SecurityIssue", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityIssue:\n    \"\"\"A security finding.\"\"\"\n    path: Path\n    line: int\n    severity: Severity\n    category: str\n    title: str\n    description: str\n    cwe: Optional[str] = None  # CWE identifier\n    fix: Optional[str] = None", "chunk_type": "class", "line_start": 37, "line_end": 46, "language": "python", "name": "SecurityIssue"}, "3fec6b2527c5_class_SecurityReport": {"id": "3fec6b2527c5_class_SecurityReport", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityReport:\n    \"\"\"Complete security audit report.\"\"\"\n    issues: List[SecurityIssue] = field(default_factory=list)\n    files_scanned: int = 0\n\n    @property\n    def critical(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.CRITICAL]\n\n    @property\n    def high(self) -> List[SecurityIssue]:\n        return [i for i in self.issues if i.severity == Severity.HIGH]\n\n    def to_markdown(self) -> str:\n        lines = [\n            \"# Security Audit Report\",\n            \"\",\n            \"## Summary\",\n            \"\",\n            f\"| Severity | Count |\",\n            f\"|----------|-------|\",\n        ]\n\n        for sev in Severity:\n            count = len([i for i in self.issues if i.severity == sev])\n            if count > 0:\n                lines.append(f\"| {sev.value} | {count} |\")\n\n        lines.extend([\"\", f\"**Files Scanned:** {self.files_scanned}\", \"\"])\n\n        if not self.issues:\n            lines.append(\"No security issues found.\")\n  ", "chunk_type": "class", "line_start": 50, "line_end": 104, "language": "python", "name": "SecurityReport"}, "3fec6b2527c5_class_SecurityAnalyzer": {"id": "3fec6b2527c5_class_SecurityAnalyzer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\security.py", "content": "class SecurityAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze code for security issues.\"\"\"\n\n    def __init__(self, path: Path, source: str):\n        self.path = path\n        self.source = source\n        self.source_lines = source.split('\\n')\n        self.issues: List[SecurityIssue] = []\n        self._imports: Set[str] = set()\n\n    def visit_Import(self, node: ast.Import):\n        for alias in node.names:\n            self._imports.add(alias.name)\n        self.generic_visit(node)\n\n    def visit_ImportFrom(self, node: ast.ImportFrom):\n        if node.module:\n            self._imports.add(node.module)\n        self.generic_visit(node)\n\n    def visit_Call(self, node: ast.Call):\n        # Check for dangerous function calls\n        func_name = self._get_func_name(node.func)\n\n        if func_name in DANGEROUS_FUNCTIONS:\n            # Special case: Allow subprocess.Popen/call/run if shell=False is explicit\n            if func_name in ('subprocess.Popen', 'subprocess.call', 'subprocess.run'):\n         ", "chunk_type": "class", "line_start": 162, "line_end": 260, "language": "python", "name": "SecurityAnalyzer"}, "191ce15091f4_file": {"id": "191ce15091f4_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "\"\"\"\nMCP Setup Commands\n==================\nInstall hooks, profiles, and configure MCP.\n\nUsage:\n    python mcp.py setup --hooks     # Install git hooks\n    python mcp.py setup --profile   # Install shell profile\n    python mcp.py setup --all       # Full setup\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport shutil\nimport subprocess\nimport sys\n\nfrom .utils import Console, find_project_root, get_package_root\nimport importlib\nimport stat\n\n\ndef install_dependencies() -> int:\n    \"\"\"Install required Python dependencies.\"\"\"\n    Console.info(\"Checking dependencies...\")\n\n    # Detect NVIDIA GPU\n    has_gpu = False\n    try:\n        subprocess.run(['nvidia-smi'], capture_output=True, check=True)\n        has_gpu = True\n        Console.ok(\"NVIDIA GPU detected, will use faiss-gpu\")\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        Console.info(\"No NVIDIA GPU detected, using faiss-cpu fallback\")\n\n    faiss_pkg = 'faiss-gpu' if has_gpu else 'faiss-cpu'\n    dependencies = [faiss_pkg, 'watchdog']\n\n    for dep in dependencies:\n        # Check for faiss generically but verify GPU support if needed\n        is_faiss = 'faiss' in dep\n        check_name = 'faiss' if is_faiss else dep.replace('-', '_')\n\n        try:\n            # Check if already installed\n            module = importlib.import_module(check_name)\n\n            # Special check for FAISS GPU support\n            if dep == 'faiss-gpu':\n                try:\n                    import faiss\n                    if faiss.get_num_gpus() > 0:\n                        Console.ok(f\"Dependency already satisfied: {dep} (GPU support verified)\")\n                        continue\n                    else:\n                        Console.warn(\"FAISS installed but NO GPU support found. Upgrading to faiss-gpu...\")\n                        raise ImportError(\"No GPU support\")\n                except Exception:\n                    raise ImportError(\"FAISS GPU check failed\")\n            else:\n                Console.ok(f\"Dependency al", "chunk_type": "file", "line_start": 1, "line_end": 272, "language": "python", "name": "setup.py"}, "191ce15091f4_func_install_dependencies": {"id": "191ce15091f4_func_install_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def install_dependencies() -> int:\n    \"\"\"Install required Python dependencies.\"\"\"\n    Console.info(\"Checking dependencies...\")\n\n    # Detect NVIDIA GPU\n    has_gpu = False\n    try:\n        subprocess.run(['nvidia-smi'], capture_output=True, check=True)\n        has_gpu = True\n        Console.ok(\"NVIDIA GPU detected, will use faiss-gpu\")\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        Console.info(\"No NVIDIA GPU detected, using faiss-cpu fallback\")\n\n    faiss_pkg = 'faiss-gpu' if has_gpu else 'faiss-cpu'\n    dependencies = [faiss_pkg, 'watchdog']\n\n    for dep in dependencies:\n        # Check for faiss generically but verify GPU support if needed\n        is_faiss = 'faiss' in dep\n        check_name = 'faiss' if is_faiss else dep.replace('-', '_')\n\n        try:\n            # Check if already installed\n            module = importlib.import_module(check_name)\n\n            # Special check for FAISS GPU support\n            if dep == 'faiss-gpu':\n                try:\n   ", "chunk_type": "function", "line_start": 23, "line_end": 85, "language": "python", "name": "install_dependencies"}, "191ce15091f4_func_install_git_hooks": {"id": "191ce15091f4_func_install_git_hooks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def install_git_hooks(project_root: Path = None) -> int:\n    \"\"\"Install MCP git hooks to a project.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    # Find MCP installation\n    # Find MCP installation\n    mcp_root = get_package_root()\n    hooks_source = mcp_root / '.git-hooks'\n\n    if not hooks_source.exists():\n        Console.fail(f\"Hooks not found: {hooks_source}\")\n        return 1\n\n    # Target\n    git_hooks = project_root / '.git' / 'hooks'\n\n    if not (project_root / '.git').exists():\n        Console.fail(\"Not a git repository\")\n        return 1\n\n    git_hooks.mkdir(parents=True, exist_ok=True)\n\n    # Copy hooks\n    hooks = ['pre-commit', 'post-commit', 'commit-msg', 'pre-push', 'post-checkout', 'post-merge']\n    installed = 0\n\n    for hook in hooks:\n        source = hooks_source / hook\n        target = git_hooks / hook\n\n        if source.exists():\n            shutil.copy2(source, target)\n            # Make executable\n            target.chmod(target.sta", "chunk_type": "function", "line_start": 88, "line_end": 126, "language": "python", "name": "install_git_hooks"}, "191ce15091f4_func_install_shell_profile": {"id": "191ce15091f4_func_install_shell_profile", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def install_shell_profile() -> int:\n    \"\"\"Install shell startup script to user profile.\"\"\"\n    mcp_root = get_package_root()\n\n    home = Path.home()\n\n    # Detect shell\n    if os.name == 'nt':\n        # PowerShell\n        ps_profile = home / 'Documents' / 'PowerShell' / 'Microsoft.PowerShell_profile.ps1'\n        ps_profile.parent.mkdir(parents=True, exist_ok=True)\n\n        startup_script = mcp_root / 'scripts' / 'mcp-startup.ps1'\n\n        if startup_script.exists():\n            # Add source line to profile\n            source_line = f'. \"{startup_script}\"'\n\n            existing = ps_profile.read_text() if ps_profile.exists() else \"\"\n            if source_line not in existing:\n                with open(ps_profile, 'a') as f:\n                    f.write(f\"\\n# MCP Integration\\n{source_line}\\n\")\n                Console.ok(f\"Added to PowerShell profile: {ps_profile}\")\n            else:\n                Console.ok(\"PowerShell profile already configured\")\n    else:\n        # Bash/Zsh\n        s", "chunk_type": "function", "line_start": 129, "line_end": 169, "language": "python", "name": "install_shell_profile"}, "191ce15091f4_func_install_ci_cd": {"id": "191ce15091f4_func_install_ci_cd", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def install_ci_cd(project_root: Path = None) -> int:\n    \"\"\"Auto-create CI/CD if not exists.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    # Check if CI already exists\n    github_ci = project_root / '.github' / 'workflows' / 'ci.yml'\n    gitlab_ci = project_root / '.gitlab-ci.yml'\n\n    if github_ci.exists() or gitlab_ci.exists():\n        Console.ok(\"CI/CD already configured\")\n        return 0\n\n    # Check for .git\n    if not (project_root / '.git').exists():\n        Console.warn(\"Not a git repository, skipping CI setup\")\n        return 0\n\n    # Generate GitHub Action\n    try:\n        from .cicd import write_github_action\n        path = write_github_action(project_root)\n        Console.ok(f\"Created: {path}\")\n    except Exception as e:\n        Console.warn(f\"Could not create CI: {e}\")\n\n    return 0", "chunk_type": "function", "line_start": 172, "line_end": 197, "language": "python", "name": "install_ci_cd"}, "191ce15091f4_func_full_setup": {"id": "191ce15091f4_func_full_setup", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def full_setup(project_root: Path = None) -> int:\n    \"\"\"Run full MCP setup.\"\"\"\n    project_root = project_root or find_project_root() or Path.cwd()\n\n    Console.header(\"MCP Full Setup\")\n\n    # 0. Install dependencies\n    Console.info(\"Verifying dependencies...\")\n    if install_dependencies() != 0:\n        Console.fail(\"Dependency installation failed, aborting setup.\")\n        return 1\n\n    # 1. Install hooks\n    Console.info(\"Installing git hooks...\")\n    install_git_hooks(project_root)\n\n    # 2. Install shell profile\n    Console.info(\"Installing shell profile...\")\n    install_shell_profile()\n\n    # 3. Create CI/CD\n    Console.info(\"Setting up CI/CD...\")\n    install_ci_cd(project_root)\n\n    # 4. Initial index\n    Console.info(\"Building initial index...\")\n    try:\n        from .index_all import run_all_indexes\n        run_all_indexes(project_root, verbose=False)\n    except Exception:\n        Console.warn(\"Could not build initial index\")\n\n    # 5. Create .mcp directory\n    mcp_dir = pro", "chunk_type": "function", "line_start": 200, "line_end": 242, "language": "python", "name": "full_setup"}, "191ce15091f4_func_main": {"id": "191ce15091f4_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\setup.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"MCP Setup\")\n\n    if '--hooks' in sys.argv:\n        return install_git_hooks()\n\n    if '--profile' in sys.argv:\n        return install_shell_profile()\n\n    if '--ci' in sys.argv or '--cicd' in sys.argv:\n        return install_ci_cd()\n\n    if '--all' in sys.argv or len(sys.argv) <= 1:\n        return full_setup()\n\n    Console.info(\"Usage:\")\n    Console.info(\"  mcp setup --hooks     Install git hooks\")\n    Console.info(\"  mcp setup --profile   Install shell profile\")\n    Console.info(\"  mcp setup --ci        Create CI/CD pipeline\")\n    Console.info(\"  mcp setup --all       Full setup\")\n\n    return 0", "chunk_type": "function", "line_start": 245, "line_end": 267, "language": "python", "name": "main"}, "6a1e2f6689ab_file": {"id": "6a1e2f6689ab_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "\"\"\"\nCodebase Summarizer\n===================\nGenerate context summaries for AI agents to quickly understand codebases.\n\nUsage:\n    python summarize.py [path] [--output CODEBASE_SUMMARY.md]\n    python -m scripts.summarize [path]\n\"\"\"\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport datetime\nimport sys\n\nfrom .utils import (\n    find_python_files,\n    find_project_root,\n    analyze_module,\n    get_git_log,\n    get_changed_files,\n    ModuleInfo,\n    Console,\n    format_as_json\n)\n\n\n@dataclass\nclass CodebaseSummary:\n    \"\"\"Summary of an entire codebase.\"\"\"\n    root: Path\n    total_files: int = 0\n    total_lines: int = 0\n    total_functions: int = 0\n    total_classes: int = 0\n\n    # Structure\n    directory_tree: Dict[str, Any] = field(default_factory=dict)\n    modules: List[ModuleInfo] = field(default_factory=list)\n\n    # Dependencies\n    external_deps: List[str] = field(default_factory=list)\n    internal_deps: Dict[str, List[str]] = field(default_factory=dict)\n\n    # Entry points\n    entry_points: List[str] = field(default_factory=list)\n\n    # Patterns\n    patterns: List[str] = field(default_factory=list)\n\n    # Recent changes\n    recent_changes: List[str] = field(default_factory=list)\n\n\ndef count_lines(path: Path) -> int:\n    \"\"\"Count non-empty lines in a file.\"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            return sum(1 for line in f if line.strip())\n    except Exception:\n        return 0\n\n\ndef build_directory_tree(root: Path, files: List[Path]) -> Dict[str, Any]:\n    \"\"\"\n    Build a hierarchical directory tree structure.\n\n    Args:\n        root: Root directory\n        files: List of file paths\n\n    Returns:\n        Nested dictionary representing directory structure\n    \"\"\"\n    tree: Dict[str, Any] = {}\n\n    for file in files:\n        try:\n            relative = file.relative_to(root)\n            parts = relative.parts\n        except Value", "chunk_type": "file", "line_start": 1, "line_end": 448, "language": "python", "name": "summarize.py"}, "6a1e2f6689ab_func_count_lines": {"id": "6a1e2f6689ab_func_count_lines", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def count_lines(path: Path) -> int:\n    \"\"\"Count non-empty lines in a file.\"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            return sum(1 for line in f if line.strip())\n    except Exception:\n        return 0", "chunk_type": "function", "line_start": 57, "line_end": 63, "language": "python", "name": "count_lines"}, "6a1e2f6689ab_func_build_directory_tree": {"id": "6a1e2f6689ab_func_build_directory_tree", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def build_directory_tree(root: Path, files: List[Path]) -> Dict[str, Any]:\n    \"\"\"\n    Build a hierarchical directory tree structure.\n\n    Args:\n        root: Root directory\n        files: List of file paths\n\n    Returns:\n        Nested dictionary representing directory structure\n    \"\"\"\n    tree: Dict[str, Any] = {}\n\n    for file in files:\n        try:\n            relative = file.relative_to(root)\n            parts = relative.parts\n        except ValueError:\n            parts = file.parts\n\n        current = tree\n        for part in parts[:-1]:\n            if part not in current:\n                current[part] = {}\n            current = current[part]\n\n        # Add file with info\n        current[parts[-1]] = {\n            '_type': 'file',\n            '_lines': count_lines(file)\n        }\n\n    return tree", "chunk_type": "function", "line_start": 66, "line_end": 98, "language": "python", "name": "build_directory_tree"}, "6a1e2f6689ab_func_format_tree_ascii": {"id": "6a1e2f6689ab_func_format_tree_ascii", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def format_tree_ascii(tree: Dict[str, Any], prefix: str = \"\", is_last: bool = True) -> str:\n    \"\"\"Format directory tree as ASCII art.\"\"\"\n    lines = []\n\n    items = sorted(tree.items(), key=lambda x: (x[1].get('_type') != 'file' if isinstance(x[1], dict) else 0, x[0]))\n\n    for i, (name, value) in enumerate(items):\n        if name.startswith('_'):\n            continue\n\n        is_last_item = i == len(items) - 1\n        connector = \"\u2514\u2500\u2500 \" if is_last_item else \"\u251c\u2500\u2500 \"\n\n        if isinstance(value, dict) and value.get('_type') == 'file':\n            line_count = value.get('_lines', 0)\n            lines.append(f\"{prefix}{connector}{name} ({line_count} lines)\")\n        elif isinstance(value, dict):\n            lines.append(f\"{prefix}{connector}{name}/\")\n            extension = \"    \" if is_last_item else \"\u2502   \"\n            lines.append(format_tree_ascii(value, prefix + extension, is_last_item))\n        else:\n            lines.append(f\"{prefix}{connector}{name}\")\n\n    return \"\\n\".join(filter", "chunk_type": "function", "line_start": 101, "line_end": 124, "language": "python", "name": "format_tree_ascii"}, "6a1e2f6689ab_func_detect_patterns": {"id": "6a1e2f6689ab_func_detect_patterns", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def detect_patterns(modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Detect common patterns in the codebase.\"\"\"\n    patterns = []\n\n    # Check for common patterns\n    all_decorators = set()\n    all_bases = set()\n    all_imports = set()\n\n    for module in modules:\n        for func in module.functions:\n            all_decorators.update(func.decorators)\n        for cls in module.classes:\n            all_bases.update(cls.bases)\n            all_decorators.update(cls.decorators)\n        all_imports.update(module.imports)\n        for mod, names in module.from_imports:\n            all_imports.add(mod)\n\n    # Detect patterns\n    if 'dataclass' in all_decorators or 'dataclasses' in all_imports:\n        patterns.append(\"Uses dataclasses for data structures\")\n\n    if 'pytest' in all_imports or 'unittest' in all_imports:\n        patterns.append(\"Has test infrastructure\")\n\n    if 'flask' in all_imports or 'fastapi' in all_imports:\n        patterns.append(\"Web application (Flask/FastAPI)\")\n\n    if 'dj", "chunk_type": "function", "line_start": 127, "line_end": 180, "language": "python", "name": "detect_patterns"}, "6a1e2f6689ab_func_find_entry_points": {"id": "6a1e2f6689ab_func_find_entry_points", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def find_entry_points(root: Path, modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Find likely entry points in the codebase.\"\"\"\n    entry_points = []\n\n    for module in modules:\n        # Check for if __name__ == '__main__'\n        try:\n            with open(module.path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                if \"if __name__\" in content and \"__main__\" in content:\n                    relative = module.path.relative_to(root) if module.path.is_relative_to(root) else module.path\n                    entry_points.append(str(relative))\n        except Exception:\n            pass\n\n    # Check for common entry point files\n    common_entry_points = ['main.py', 'app.py', 'cli.py', 'run.py', '__main__.py', 'manage.py']\n    for ep in common_entry_points:\n        for module in modules:\n            if module.path.name == ep:\n                relative = module.path.relative_to(root) if module.path.is_relative_to(root) else module.path\n                if str(relati", "chunk_type": "function", "line_start": 183, "line_end": 207, "language": "python", "name": "find_entry_points"}, "6a1e2f6689ab_func_extract_external_deps": {"id": "6a1e2f6689ab_func_extract_external_deps", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def extract_external_deps(modules: List[ModuleInfo]) -> List[str]:\n    \"\"\"Extract external dependencies from imports.\"\"\"\n    stdlib_modules = {\n        'os', 'sys', 're', 'json', 'pathlib', 'typing', 'collections',\n        'itertools', 'functools', 'datetime', 'time', 'logging', 'ast',\n        'subprocess', 'threading', 'multiprocessing', 'queue', 'socket',\n        'http', 'urllib', 'email', 'html', 'xml', 'configparser',\n        'argparse', 'io', 'string', 'textwrap', 'copy', 'pprint',\n        'dataclasses', 'abc', 'contextlib', 'warnings', 'traceback',\n        'unittest', 'doctest', 'sqlite3', 'csv', 'pickle', 'shelve',\n        'hashlib', 'hmac', 'secrets', 'random', 'math', 'statistics',\n        'fractions', 'decimal', 'struct', 'codecs', 'unicodedata',\n        'locale', 'gettext', 'operator', 'enum', 'graphlib', 'bisect',\n        'heapq', 'array', 'weakref', 'types', 'inspect', 'dis',\n        'gc', 'atexit', 'builtins', 'tempfile', 'shutil', 'glob',\n        'fnmatch', 'linecache', ", "chunk_type": "function", "line_start": 210, "line_end": 241, "language": "python", "name": "extract_external_deps"}, "6a1e2f6689ab_func_summarize_codebase": {"id": "6a1e2f6689ab_func_summarize_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def summarize_codebase(root: Path, exclude_patterns: List[str] = None) -> CodebaseSummary:\n    \"\"\"\n    Generate a comprehensive summary of a codebase.\n\n    Args:\n        root: Root directory\n        exclude_patterns: Patterns to exclude\n\n    Returns:\n        CodebaseSummary object\n    \"\"\"\n    summary = CodebaseSummary(root=root)\n\n    Console.info(f\"Scanning {root}...\")\n\n    # Find all Python files\n    files = list(find_python_files(root, exclude_patterns))\n    summary.total_files = len(files)\n\n    Console.info(f\"Found {len(files)} Python files\")\n\n    # Build directory tree\n    summary.directory_tree = build_directory_tree(root, files)\n\n    # Analyze each module\n    for path in files:\n        module_info = analyze_module(path)\n        if module_info:\n            summary.modules.append(module_info)\n            summary.total_lines += count_lines(path)\n            summary.total_functions += len(module_info.functions)\n            summary.total_classes += len(module_info.classes)\n\n    Consol", "chunk_type": "function", "line_start": 244, "line_end": 292, "language": "python", "name": "summarize_codebase"}, "6a1e2f6689ab_func_format_summary_markdown": {"id": "6a1e2f6689ab_func_format_summary_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def format_summary_markdown(summary: CodebaseSummary) -> str:\n    \"\"\"Format summary as Markdown.\"\"\"\n\n    lines = [\n        \"# Codebase Summary\",\n        \"\",\n        f\"**Root:** `{summary.root}`\",\n        f\"**Generated:** {datetime.datetime.now().isoformat()}\",\n        \"\",\n        \"## Overview\",\n        \"\",\n        f\"| Metric | Value |\",\n        f\"|--------|-------|\",\n        f\"| Python Files | {summary.total_files} |\",\n        f\"| Total Lines | {summary.total_lines:,} |\",\n        f\"| Functions | {summary.total_functions} |\",\n        f\"| Classes | {summary.total_classes} |\",\n        \"\",\n    ]\n\n    # Directory Structure\n    if summary.directory_tree:\n        lines.extend([\n            \"## Directory Structure\",\n            \"\",\n            \"```\",\n            format_tree_ascii(summary.directory_tree),\n            \"```\",\n            \"\",\n        ])\n\n    # Entry Points\n    if summary.entry_points:\n        lines.extend([\n            \"## Entry Points\",\n            \"\",\n        ])\n        for ep i", "chunk_type": "function", "line_start": 295, "line_end": 399, "language": "python", "name": "format_summary_markdown"}, "6a1e2f6689ab_func_main": {"id": "6a1e2f6689ab_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Codebase Summarizer\")\n\n    # Parse args\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    output_file = None\n\n    for i, arg in enumerate(sys.argv):\n        if arg == '--output' and i + 1 < len(sys.argv):\n            output_file = Path(sys.argv[i + 1])\n\n    # Get path\n    if args:\n        path = Path(args[0])\n    else:\n        path = find_project_root() or Path.cwd()\n\n    if not path.exists():\n        Console.fail(f\"Path not found: {path}\")\n        sys.exit(1)\n\n    Console.info(f\"Analyzing: {path}\")\n\n    summary = summarize_codebase(path)\n    markdown = format_summary_markdown(summary)\n\n    # Output\n    if output_file:\n        with open(output_file, 'w', encoding='utf-8') as f:\n            f.write(markdown)\n        Console.ok(f\"Summary written to: {output_file}\")\n    else:\n        # Handle Windows encoding issues\n        try:\n            print(markdown)\n        except UnicodeEncodeError:\n            # Fallback: ", "chunk_type": "function", "line_start": 402, "line_end": 443, "language": "python", "name": "main"}, "6a1e2f6689ab_class_CodebaseSummary": {"id": "6a1e2f6689ab_class_CodebaseSummary", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\summarize.py", "content": "class CodebaseSummary:\n    \"\"\"Summary of an entire codebase.\"\"\"\n    root: Path\n    total_files: int = 0\n    total_lines: int = 0\n    total_functions: int = 0\n    total_classes: int = 0\n\n    # Structure\n    directory_tree: Dict[str, Any] = field(default_factory=dict)\n    modules: List[ModuleInfo] = field(default_factory=list)\n\n    # Dependencies\n    external_deps: List[str] = field(default_factory=list)\n    internal_deps: Dict[str, List[str]] = field(default_factory=dict)\n\n    # Entry points\n    entry_points: List[str] = field(default_factory=list)\n\n    # Patterns\n    patterns: List[str] = field(default_factory=list)\n\n    # Recent changes\n    recent_changes: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 31, "line_end": 54, "language": "python", "name": "CodebaseSummary"}, "44d4301193f6_file": {"id": "44d4301193f6_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "#!/usr/bin/env python3\n\"\"\"\nTelegram C2 Bridge\nPolls Telegram for user instructions and dispatches them to active agents.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nimport os\nimport sys\nimport time\n\nimport requests\n\n# MCP Path Resolution\nSCRIPTS_DIR = Path(__file__).resolve().parent\nsys.path.append(str(SCRIPTS_DIR))\n\ntry:\n    import agent_comms\nexcept ImportError:\n    pass\n\nCONFIG_FILE = Path(__file__).resolve().parent / \"telegram_config.json\"\n\ndef get_config():\n    if not CONFIG_FILE.exists():\n        return None\n    with open(CONFIG_FILE, \"r\") as f:\n        return json.load(f)\n\ndef poll_telegram(config):\n    # Only the primary host should poll for updates to avoid 409 Conflict\n    # We'll designate Quasar (Windows) as primary, WizardPanda as fallback.\n    hostname = agent_comms.get_hostname().lower()\n    is_windows = os.name == 'nt'\n\n    # Simple logic: If we are on Linux and a Windows agent was seen recently, don't poll.\n    if not is_windows:\n        remotes = agent_comms.AgentPresence.get_remote_status()\n        for host, data in remotes.items():\n            if data.get('hostname', '').lower() == 'quasar' or 'window' in host.lower():\n                age = time.time() - data.get('timestamp', 0)\n                if age < 120: # Quasar was seen in the last 2 minutes\n                    return\n\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    last_update = config.get(\"last_update_id\", 0)\n\n    url = f\"https://api.telegram.org/bot{token}/getUpdates?offset={last_update + 1}&timeout=10\"\n    try:\n        r = requests.get(url, timeout=15)\n        if r.status_code == 200:\n            updates = r.json().get(\"result\", [])\n            for update in updates:\n                last_update = update[\"update_id\"]\n                msg = update.get(\"message\", {})\n                text = msg.get(\"text\", \"\")\n                from_id = msg.get(\"from\", {}).get(\"id\")\n\n                if str(from_id) == str(chat_id):\n                    handle_instruction(text)\n\n      ", "chunk_type": "file", "line_start": 1, "line_end": 195, "language": "python", "name": "telegram_bridge.py"}, "44d4301193f6_func_get_config": {"id": "44d4301193f6_func_get_config", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def get_config():\n    if not CONFIG_FILE.exists():\n        return None\n    with open(CONFIG_FILE, \"r\") as f:\n        return json.load(f)", "chunk_type": "function", "line_start": 26, "line_end": 30, "language": "python", "name": "get_config"}, "44d4301193f6_func_poll_telegram": {"id": "44d4301193f6_func_poll_telegram", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def poll_telegram(config):\n    # Only the primary host should poll for updates to avoid 409 Conflict\n    # We'll designate Quasar (Windows) as primary, WizardPanda as fallback.\n    hostname = agent_comms.get_hostname().lower()\n    is_windows = os.name == 'nt'\n\n    # Simple logic: If we are on Linux and a Windows agent was seen recently, don't poll.\n    if not is_windows:\n        remotes = agent_comms.AgentPresence.get_remote_status()\n        for host, data in remotes.items():\n            if data.get('hostname', '').lower() == 'quasar' or 'window' in host.lower():\n                age = time.time() - data.get('timestamp', 0)\n                if age < 120: # Quasar was seen in the last 2 minutes\n                    return\n\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    last_update = config.get(\"last_update_id\", 0)\n\n    url = f\"https://api.telegram.org/bot{token}/getUpdates?offset={last_update + 1}&timeout=10\"\n    try:\n        r = requests.get(url, timeout=15)\n ", "chunk_type": "function", "line_start": 32, "line_end": 72, "language": "python", "name": "poll_telegram"}, "44d4301193f6_func_handle_instruction": {"id": "44d4301193f6_func_handle_instruction", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def handle_instruction(text):\n    print(f\"[BRIDGE] Received instruction: {text}\")\n    target_host = agent_comms.get_hostname().lower()\n\n    if text.lower().startswith(\"to \"):\n        parts = text.split(\":\", 1)\n        if len(parts) == 2:\n            target_host = parts[0].replace(\"to \", \"\").strip().lower()\n            text = parts[1].strip()\n\n    inbox = agent_comms.get_telegram_inbox_dir()\n    msg_id = int(time.time() * 1000)\n\n    # If the user says \"to antigravity\", \"to assistant\", or just \"to me\"\n    if text.lower().startswith(\"to antigravity\") or text.lower().startswith(\"to assistant\"):\n         target_host = \"Antigravity\"\n         if \":\" in text:\n             text = text.split(\":\", 1)[1].strip()\n\n    msg_file = inbox / f\"{target_host}_{msg_id}.json\"\n\n    with open(msg_file, \"w\") as f:\n        json.dump({\"text\": text, \"timestamp\": time.time()}, f, indent=2)", "chunk_type": "function", "line_start": 74, "line_end": 96, "language": "python", "name": "handle_instruction"}, "44d4301193f6_func_check_outbox": {"id": "44d4301193f6_func_check_outbox", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def check_outbox(config):\n    token = config.get(\"bot_token\")\n    chat_id = config.get(\"chat_id\")\n    outbox = agent_comms.get_comms_dir() / \"telegram_outbox\"\n\n    if not outbox.exists():\n        return\n\n    # Use a temp directory outside of the NSync synced tree for processing\n    import tempfile\n    buffer_dir = Path(tempfile.gettempdir()) / \"mcp_telegram_buffer\"\n    if not buffer_dir.exists():\n        buffer_dir.mkdir(parents=True, exist_ok=True)\n\n    for f in outbox.glob(\"*.json\"):\n        if f.is_dir() or f.name.startswith(\".\"): continue\n        try:\n            # Move to local temp buffer first (breaks sync lock)\n            target = buffer_dir / f.name\n            try:\n                # Force replace if target exists (stale)\n                if target.exists(): os.remove(target)\n                os.rename(str(f), str(target))\n            except OSError:\n                continue # Still locked by NSync or Git\n\n            with open(target, \"r\") as mf:\n                data = json.lo", "chunk_type": "function", "line_start": 98, "line_end": 148, "language": "python", "name": "check_outbox"}, "44d4301193f6_func_main": {"id": "44d4301193f6_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\telegram_bridge.py", "content": "def main():\n    print(\"--- Telegram C2 Bridge ---\")\n\n    # [NEW] PID-based singleton protection\n    import tempfile\n    pid_file = Path(tempfile.gettempdir()) / \"telegram_bridge.pid\"\n    if pid_file.exists():\n        try:\n            with open(pid_file, \"r\") as f:\n                old_pid = int(f.read().strip())\n                if os.name == 'nt':\n                    subprocess.run([\"tasklist\", \"/FI\", f\"PID eq {old_pid}\"], check=True, capture_output=True)\n                else:\n                    os.kill(old_pid, 0)\n                print(f\"[BRIDGE] Service already running (PID {old_pid}). Exiting.\")\n                return 0\n        except:\n            pid_file.unlink()\n\n    with open(pid_file, \"w\") as f:\n        f.write(str(os.getpid()))\n\n    try:\n        config = get_config()\n        if not config:\n            print(\"[FAIL] telegram_config.json missing. Please create it with bot_token and chat_id.\")\n            return 1\n\n        print(f\"[BRIDGE] Configuration loaded. Chat ID: {config.g", "chunk_type": "function", "line_start": 150, "line_end": 191, "language": "python", "name": "main"}, "238801ee63f5_file": {"id": "238801ee63f5_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "\"\"\"\nAuto-Test Implementation Generator\n==================================\nGenerate actual test implementations, not just stubs.\n\nUsage:\n    python mcp.py test-gen [file] --impl\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport ast\nimport sys\n\nfrom .utils import Console, find_project_root\n\n\n@dataclass\nclass FunctionSignature:\n    \"\"\"Function signature info.\"\"\"\n    name: str\n    args: List[Tuple[str, Optional[str]]]  # (name, type_hint)\n    return_type: Optional[str]\n    decorators: List[str]\n    docstring: Optional[str]\n    is_async: bool\n    line_num: int\n\n\nclass SignatureExtractor(ast.NodeVisitor):\n    \"\"\"Extract function signatures.\"\"\"\n\n    def __init__(self):\n        self.functions: List[FunctionSignature] = []\n\n    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)\n\n    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = ast.unparse(node.returns)\n\n        # Get decorators\n        decorators = []\n        for dec in node.decorator_list:\n            if isinstance(dec, ast.Name):\n                decorators.append(dec.id)\n            elif isinstance(dec, ast.Attribute):\n                decorators.append(dec.attr)\n\n        self.functions.append(FunctionSignature(\n            name=node.name", "chunk_type": "file", "line_start": 1, "line_end": 297, "language": "python", "name": "test_gen.py"}, "238801ee63f5_func_get_test_value": {"id": "238801ee63f5_func_get_test_value", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def get_test_value(type_hint: Optional[str]) -> str:\n    \"\"\"Get example test value for a type.\"\"\"\n    if not type_hint:\n        return '\"test_value\"'\n\n    type_lower = type_hint.lower()\n\n    if 'int' in type_lower:\n        return '42'\n    elif 'float' in type_lower:\n        return '3.14'\n    elif 'str' in type_lower:\n        return '\"test_string\"'\n    elif 'bool' in type_lower:\n        return 'True'\n    elif 'list' in type_lower:\n        return '[]'\n    elif 'dict' in type_lower:\n        return '{}'\n    elif 'none' in type_lower:\n        return 'None'\n    elif 'path' in type_lower:\n        return 'Path(\".\")'\n    elif 'optional' in type_lower:\n        return 'None'\n    else:\n        return 'None  # TODO: provide test value'", "chunk_type": "function", "line_start": 83, "line_end": 109, "language": "python", "name": "get_test_value"}, "238801ee63f5_func_get_assertion": {"id": "238801ee63f5_func_get_assertion", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def get_assertion(return_type: Optional[str]) -> str:\n    \"\"\"Get appropriate assertion for return type.\"\"\"\n    if not return_type:\n        return 'assert result is not None'\n\n    type_lower = return_type.lower()\n\n    if 'bool' in type_lower:\n        return 'assert isinstance(result, bool)'\n    elif 'int' in type_lower:\n        return 'assert isinstance(result, int)'\n    elif 'float' in type_lower:\n        return 'assert isinstance(result, (int, float))'\n    elif 'str' in type_lower:\n        return 'assert isinstance(result, str)'\n    elif 'list' in type_lower:\n        return 'assert isinstance(result, list)'\n    elif 'dict' in type_lower:\n        return 'assert isinstance(result, dict)'\n    elif 'none' in type_lower:\n        return 'assert result is None'\n    else:\n        return 'assert result is not None'", "chunk_type": "function", "line_start": 112, "line_end": 134, "language": "python", "name": "get_assertion"}, "238801ee63f5_func_generate_test_impl": {"id": "238801ee63f5_func_generate_test_impl", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_test_impl(func: FunctionSignature, module_name: str) -> str:\n    \"\"\"Generate full test implementation for a function.\"\"\"\n    lines = []\n\n    # Test function signature\n    async_prefix = 'async ' if func.is_async else ''\n    lines.append(f'{async_prefix}def test_{func.name}():')\n\n    # Docstring\n    if func.docstring:\n        lines.append(f'    \"\"\"Test {func.name}: {func.docstring[:50]}...\"\"\"')\n    else:\n        lines.append(f'    \"\"\"Test {func.name} function.\"\"\"')\n\n    # Arrange\n    lines.append('    # Arrange')\n    args_call = []\n    for arg_name, arg_type in func.args:\n        value = get_test_value(arg_type)\n        lines.append(f'    {arg_name} = {value}')\n        args_call.append(arg_name)\n\n    lines.append('')\n    lines.append('    # Act')\n\n    args_str = ', '.join(args_call)\n    if func.is_async:\n        lines.append(f'    result = await {func.name}({args_str})')\n    else:\n        lines.append(f'    result = {func.name}({args_str})')\n\n    lines.append('')\n    lines.", "chunk_type": "function", "line_start": 137, "line_end": 172, "language": "python", "name": "generate_test_impl"}, "238801ee63f5_func_generate_edge_case_tests": {"id": "238801ee63f5_func_generate_edge_case_tests", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_edge_case_tests(func: FunctionSignature) -> List[str]:\n    \"\"\"Generate edge case tests.\"\"\"\n    tests = []\n\n    for arg_name, arg_type in func.args:\n        if not arg_type:\n            continue\n\n        type_lower = arg_type.lower()\n\n        # None tests for Optional types\n        if 'optional' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_none():\n    \"\"\"Test {func.name} with {arg_name}=None.\"\"\"\n    result = {func.name}({arg_name}=None)\n    assert result is not None or True  # Handle None case'''\n            tests.append(test)\n\n        # Empty tests for collections\n        if 'list' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_empty():\n    \"\"\"Test {func.name} with empty list.\"\"\"\n    result = {func.name}({arg_name}=[])\n    assert result is not None'''\n            tests.append(test)\n\n        if 'str' in type_lower:\n            test = f'''def test_{func.name}_{arg_name}_empty_string():\n    \"\"\"Test {func.name} with empty string.", "chunk_type": "function", "line_start": 175, "line_end": 221, "language": "python", "name": "generate_edge_case_tests"}, "238801ee63f5_func_generate_test_file": {"id": "238801ee63f5_func_generate_test_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def generate_test_file(file_path: Path) -> str:\n    \"\"\"Generate full test file for a module.\"\"\"\n    try:\n        source = file_path.read_text(encoding='utf-8')\n        tree = ast.parse(source)\n    except Exception as e:\n        return f\"# Error parsing {file_path}: {e}\"\n\n    extractor = SignatureExtractor()\n    extractor.visit(tree)\n\n    module_name = file_path.stem\n\n    lines = [\n        '\"\"\"',\n        f'Auto-generated tests for {module_name}',\n        '\"\"\"',\n        '',\n        'import pytest',\n        f'from {module_name} import *',\n        '',\n        '',\n    ]\n\n    for func in extractor.functions:\n        # Main test\n        lines.append(generate_test_impl(func, module_name))\n        lines.append('')\n        lines.append('')\n\n        # Edge case tests\n        edge_tests = generate_edge_case_tests(func)\n        for test in edge_tests[:2]:  # Limit edge cases\n            lines.append(test)\n            lines.append('')\n            lines.append('')\n\n    return '\\n'.join(lines)", "chunk_type": "function", "line_start": 224, "line_end": 261, "language": "python", "name": "generate_test_file"}, "238801ee63f5_func_main": {"id": "238801ee63f5_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Auto-Test Generator (Full Implementation)\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.info(\"Usage: mcp test-gen <file.py> [--impl]\")\n        return 1\n\n    file_path = Path(args[0])\n\n    if not file_path.exists():\n        Console.fail(f\"File not found: {file_path}\")\n        return 1\n\n    Console.info(f\"Generating tests for: {file_path}\")\n\n    test_code = generate_test_file(file_path)\n\n    if '--impl' in sys.argv or '--write' in sys.argv:\n        # Write to test file\n        test_file = file_path.parent / f'test_{file_path.name}'\n        test_file.write_text(test_code)\n        Console.ok(f\"Written to: {test_file}\")\n    else:\n        print(test_code)\n\n    return 0", "chunk_type": "function", "line_start": 264, "line_end": 292, "language": "python", "name": "main"}, "238801ee63f5_func___init__": {"id": "238801ee63f5_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def __init__(self):\n        self.functions: List[FunctionSignature] = []", "chunk_type": "function", "line_start": 34, "line_end": 35, "language": "python", "name": "__init__"}, "238801ee63f5_func_visit_FunctionDef": {"id": "238801ee63f5_func_visit_FunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 37, "line_end": 39, "language": "python", "name": "visit_FunctionDef"}, "238801ee63f5_func_visit_AsyncFunctionDef": {"id": "238801ee63f5_func_visit_AsyncFunctionDef", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)", "chunk_type": "function", "line_start": 41, "line_end": 43, "language": "python", "name": "visit_AsyncFunctionDef"}, "238801ee63f5_func__extract": {"id": "238801ee63f5_func__extract", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = ast.unparse(node.returns)\n\n        # Get decorators\n        decorators = []\n        for dec in node.decorator_list:\n            if isinstance(dec, ast.Name):\n                decorators.append(dec.id)\n            elif isinstance(dec, ast.Attribute):\n                decorators.append(dec.attr)\n\n        self.functions.append(FunctionSignature(\n            name=node.name,\n            args=args,\n      ", "chunk_type": "function", "line_start": 45, "line_end": 80, "language": "python", "name": "_extract"}, "238801ee63f5_class_FunctionSignature": {"id": "238801ee63f5_class_FunctionSignature", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "class FunctionSignature:\n    \"\"\"Function signature info.\"\"\"\n    name: str\n    args: List[Tuple[str, Optional[str]]]  # (name, type_hint)\n    return_type: Optional[str]\n    decorators: List[str]\n    docstring: Optional[str]\n    is_async: bool\n    line_num: int", "chunk_type": "class", "line_start": 20, "line_end": 28, "language": "python", "name": "FunctionSignature"}, "238801ee63f5_class_SignatureExtractor": {"id": "238801ee63f5_class_SignatureExtractor", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\test_gen.py", "content": "class SignatureExtractor(ast.NodeVisitor):\n    \"\"\"Extract function signatures.\"\"\"\n\n    def __init__(self):\n        self.functions: List[FunctionSignature] = []\n\n    def visit_FunctionDef(self, node):\n        self._extract(node, is_async=False)\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node):\n        self._extract(node, is_async=True)\n        self.generic_visit(node)\n\n    def _extract(self, node, is_async: bool):\n        # Skip private and magic methods (except __init__)\n        if node.name.startswith('_') and not node.name == '__init__':\n            return\n\n        # Get args with type hints\n        args = []\n        for arg in node.args.args:\n            if arg.arg != 'self':\n                type_hint = None\n                if arg.annotation:\n                    type_hint = ast.unparse(arg.annotation)\n                args.append((arg.arg, type_hint))\n\n        # Get return type\n        return_type = None\n        if node.returns:\n            return_type = a", "chunk_type": "class", "line_start": 31, "line_end": 80, "language": "python", "name": "SignatureExtractor"}, "29f7afddb6c3_file": {"id": "29f7afddb6c3_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "\"\"\"\nTODO/FIXME Index\n================\nScan and index all TODOs, FIXMEs, HACKs, and NOTEs in code.\n\nUsage:\n    python mcp.py todos\n    python mcp.py todos --priority high\n\"\"\"\n\nfrom collections import Counter\nfrom dataclasses import dataclass, field, asdict\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport re\nimport sys\n\nfrom .utils import Console, find_python_files, find_project_root\n\n\n@dataclass\nclass TodoItem:\n    \"\"\"A TODO/FIXME item.\"\"\"\n    type: str  # TODO, FIXME, HACK, XXX, NOTE\n    message: str\n    file: str\n    line: int\n    author: Optional[str] = None\n    priority: int = 2  # 1=high, 2=medium, 3=low\n    context: str = \"\"\n\n\n# Patterns to detect\nTODO_PATTERNS = [\n    (r'#\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)$', 'python'),\n    (r'//\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)$', 'js'),\n    (r'/\\*\\s*(TODO|FIXME|HACK|XXX|NOTE)(?:\\(([^)]+)\\))?:\\s*(.+?)\\*/', 'block'),\n]\n\nPRIORITY_MAP = {\n    'FIXME': 1,\n    'XXX': 1,\n    'HACK': 2,\n    'TODO': 2,\n    'NOTE': 3,\n}\n\nPRIORITY_KEYWORDS = {\n    'urgent': 1,\n    'critical': 1,\n    'important': 1,\n    'P0': 1, 'P1': 1,\n    'P2': 2, 'P3': 3,\n    'low': 3,\n    'minor': 3,\n}\n\n\ndef detect_priority(todo_type: str, message: str, author: str = None) -> int:\n    \"\"\"Detect priority from type and message.\"\"\"\n    priority = PRIORITY_MAP.get(todo_type, 2)\n\n    # Check for priority keywords\n    text = (message + (author or '')).lower()\n    for keyword, p in PRIORITY_KEYWORDS.items():\n        if keyword.lower() in text:\n            priority = min(priority, p)\n            break\n\n    # ! at end indicates high priority\n    if message.rstrip().endswith('!'):\n        priority = 1\n\n    return priority\n\n\ndef scan_file(file_path: Path) -> List[TodoItem]:\n    \"\"\"Scan a file for TODOs.\"\"\"\n    todos = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return todos\n\n    for i, li", "chunk_type": "file", "line_start": 1, "line_end": 260, "language": "python", "name": "todo_index.py"}, "29f7afddb6c3_func_detect_priority": {"id": "29f7afddb6c3_func_detect_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def detect_priority(todo_type: str, message: str, author: str = None) -> int:\n    \"\"\"Detect priority from type and message.\"\"\"\n    priority = PRIORITY_MAP.get(todo_type, 2)\n\n    # Check for priority keywords\n    text = (message + (author or '')).lower()\n    for keyword, p in PRIORITY_KEYWORDS.items():\n        if keyword.lower() in text:\n            priority = min(priority, p)\n            break\n\n    # ! at end indicates high priority\n    if message.rstrip().endswith('!'):\n        priority = 1\n\n    return priority", "chunk_type": "function", "line_start": 60, "line_end": 75, "language": "python", "name": "detect_priority"}, "29f7afddb6c3_func_scan_file": {"id": "29f7afddb6c3_func_scan_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def scan_file(file_path: Path) -> List[TodoItem]:\n    \"\"\"Scan a file for TODOs.\"\"\"\n    todos = []\n\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            lines = f.readlines()\n    except Exception:\n        return todos\n\n    for i, line in enumerate(lines, 1):\n        for pattern, _ in TODO_PATTERNS:\n            match = re.search(pattern, line, re.IGNORECASE)\n            if match:\n                todo_type = match.group(1).upper()\n                author = match.group(2) if match.lastindex >= 2 else None\n                message = match.group(3) if match.lastindex >= 3 else match.group(2)\n\n                if message:\n                    # Get context (surrounding lines)\n                    context_start = max(0, i - 2)\n                    context_end = min(len(lines), i + 2)\n                    context = ''.join(lines[context_start:context_end])\n\n                    todos.append(TodoItem(\n                        type=todo_type,\n                    ", "chunk_type": "function", "line_start": 78, "line_end": 113, "language": "python", "name": "scan_file"}, "29f7afddb6c3_func_scan_project": {"id": "29f7afddb6c3_func_scan_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def scan_project(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> List[TodoItem]:\n    \"\"\"Scan entire project for TODOs.\"\"\"\n    all_todos = []\n\n    # Find all code files\n    extensions = ['.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.go', '.rs', '.c', '.cpp', '.h']\n\n    for ext in extensions:\n        for file_path in root.rglob(f'*{ext}'):\n            # Skip excluded\n            if exclude_patterns:\n                skip = False\n                for pattern in exclude_patterns:\n                    if pattern in str(file_path):\n                        skip = True\n                        break\n                if skip:\n                    continue\n\n            todos = scan_file(file_path)\n            all_todos.extend(todos)\n\n    return all_todos", "chunk_type": "function", "line_start": 116, "line_end": 141, "language": "python", "name": "scan_project"}, "29f7afddb6c3_func_group_by_priority": {"id": "29f7afddb6c3_func_group_by_priority", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def group_by_priority(todos: List[TodoItem]) -> Dict[int, List[TodoItem]]:\n    \"\"\"Group TODOs by priority.\"\"\"\n    groups = {1: [], 2: [], 3: []}\n    for todo in todos:\n        groups[todo.priority].append(todo)\n    return groups", "chunk_type": "function", "line_start": 144, "line_end": 149, "language": "python", "name": "group_by_priority"}, "29f7afddb6c3_func_group_by_type": {"id": "29f7afddb6c3_func_group_by_type", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def group_by_type(todos: List[TodoItem]) -> Dict[str, List[TodoItem]]:\n    \"\"\"Group TODOs by type.\"\"\"\n    groups = {}\n    for todo in todos:\n        if todo.type not in groups:\n            groups[todo.type] = []\n        groups[todo.type].append(todo)\n    return groups", "chunk_type": "function", "line_start": 152, "line_end": 159, "language": "python", "name": "group_by_type"}, "29f7afddb6c3_func_index_todos": {"id": "29f7afddb6c3_func_index_todos", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def index_todos(root: Path = None) -> Dict:\n    \"\"\"Build TODO index and save to disk.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.info(f\"Scanning for TODOs in {root}...\")\n\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    todos = scan_project(root, exclude)\n\n    # Build index\n    index = {\n        \"total\": len(todos),\n        \"by_type\": {},\n        \"by_priority\": {1: 0, 2: 0, 3: 0},\n        \"by_file\": {},\n        \"items\": []\n    }\n\n    for todo in todos:\n        # Count by type\n        if todo.type not in index[\"by_type\"]:\n            index[\"by_type\"][todo.type] = 0\n        index[\"by_type\"][todo.type] += 1\n\n        # Count by priority\n        index[\"by_priority\"][todo.priority] += 1\n\n        # Count by file\n        if todo.file not in index[\"by_file\"]:\n            index[\"by_file\"][todo.file] = 0\n        index[\"by_file\"][todo.file] += 1\n\n        # Store item\n        index[\"items\"].append(asdict(todo))\n\n    # Save index\n    inde", "chunk_type": "function", "line_start": 162, "line_end": 206, "language": "python", "name": "index_todos"}, "29f7afddb6c3_func_main": {"id": "29f7afddb6c3_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"TODO/FIXME Index\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n    root = find_project_root() or Path.cwd()\n\n    if '--index' in sys.argv:\n        index_todos(root)\n        return 0\n\n    # Scan and display\n    exclude = ['node_modules', 'venv', '.venv', '__pycache__', '.git', 'vendor']\n    todos = scan_project(root, exclude)\n\n    if not todos:\n        Console.ok(\"No TODOs found!\")\n        return 0\n\n    # Filter by priority\n    if '--high' in sys.argv or '--priority' in sys.argv:\n        todos = [t for t in todos if t.priority == 1]\n\n    # Filter by type\n    for todo_type in ['TODO', 'FIXME', 'HACK', 'NOTE']:\n        if f'--{todo_type.lower()}' in sys.argv:\n            todos = [t for t in todos if t.type == todo_type]\n\n    # Group by priority\n    by_priority = group_by_priority(todos)\n\n    # Display\n    priority_names = {1: 'HIGH', 2: 'MEDIUM', 3: 'LOW'}\n    priority_colors = {1: '\\033[91m', 2: '\\033[93m', 3: ", "chunk_type": "function", "line_start": 209, "line_end": 255, "language": "python", "name": "main"}, "29f7afddb6c3_class_TodoItem": {"id": "29f7afddb6c3_class_TodoItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\todo_index.py", "content": "class TodoItem:\n    \"\"\"A TODO/FIXME item.\"\"\"\n    type: str  # TODO, FIXME, HACK, XXX, NOTE\n    message: str\n    file: str\n    line: int\n    author: Optional[str] = None\n    priority: int = 2  # 1=high, 2=medium, 3=low\n    context: str = \"\"", "chunk_type": "class", "line_start": 23, "line_end": 31, "language": "python", "name": "TodoItem"}, "d6ce97822756_file": {"id": "d6ce97822756_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "\"\"\"\nTree-sitter Utilities\n=====================\nMulti-language code parsing using tree-sitter.\nSupports Python, JavaScript, TypeScript, Go, Rust, Java, C, C++, and more.\n\nUsage:\n    from scripts.treesitter_utils import parse_file, get_functions, get_classes\n\"\"\"\n\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Iterator, Callable\nfrom dataclasses import dataclass, field\n\n# Try to import tree-sitter, fall back gracefully\ntry:\n    import tree_sitter\n    from tree_sitter import Language, Parser, Tree, Node\n    TREE_SITTER_AVAILABLE = True\nexcept ImportError:\n    TREE_SITTER_AVAILABLE = False\n    Tree = Any\n    Node = Any\n\nfrom .utils import Console\n\n\n@dataclass\nclass CodeItem:\n    \"\"\"A code item (function, class, etc).\"\"\"\n    name: str\n    item_type: str  # 'function', 'class', 'method', 'import', 'variable'\n    line_start: int\n    line_end: int\n    signature: str = \"\"\n    docstring: Optional[str] = None\n    language: str = \"\"\n    children: List['CodeItem'] = field(default_factory=list)\n\n\n@dataclass\nclass ParsedFile:\n    \"\"\"Result of parsing a file.\"\"\"\n    path: Path\n    language: str\n    tree: Optional[Any] = None\n    source: bytes = b\"\"\n    functions: List[CodeItem] = field(default_factory=list)\n    classes: List[CodeItem] = field(default_factory=list)\n    imports: List[str] = field(default_factory=list)\n    error: Optional[str] = None\n\n\n# Language detection by extension\nLANGUAGE_MAP = {\n    '.py': 'python',\n    '.js': 'javascript',\n    '.jsx': 'javascript',\n    '.ts': 'typescript',\n    '.tsx': 'typescript',\n    '.go': 'go',\n    '.rs': 'rust',\n    '.java': 'java',\n    '.c': 'c',\n    '.h': 'c',\n    '.cpp': 'cpp',\n    '.cc': 'cpp',\n    '.cxx': 'cpp',\n    '.hpp': 'cpp',\n    '.cs': 'c_sharp',\n    '.rb': 'ruby',\n    '.php': 'php',\n    '.swift': 'swift',\n    '.kt': 'kotlin',\n    '.scala': 'scala',\n    '.lua': 'lua',\n    '.sh': 'bash',\n    '.bash': 'bash',\n    '.json': 'json',\n    '.yaml': 'yaml',\n    '.yml': 'yaml',\n    '.html': 'html',\n    ", "chunk_type": "file", "line_start": 1, "line_end": 432, "language": "python", "name": "treesitter_utils.py"}, "d6ce97822756_func_detect_language": {"id": "d6ce97822756_func_detect_language", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def detect_language(path: Path) -> Optional[str]:\n    \"\"\"Detect language from file extension.\"\"\"\n    return LANGUAGE_MAP.get(path.suffix.lower())", "chunk_type": "function", "line_start": 128, "line_end": 130, "language": "python", "name": "detect_language"}, "d6ce97822756_func_get_parser": {"id": "d6ce97822756_func_get_parser", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def get_parser(language: str) -> Optional[Any]:\n    \"\"\"Get or create parser for language.\"\"\"\n    if not TREE_SITTER_AVAILABLE:\n        return None\n\n    if language in _parsers:\n        return _parsers[language]\n\n    try:\n        # Try to load language\n        import importlib\n        lang_module = importlib.import_module(f'tree_sitter_{language}')\n        if hasattr(lang_module, 'language'):\n            lang = Language(lang_module.language())\n            parser = Parser(lang)\n            _parsers[language] = parser\n            _languages[language] = lang\n            return parser\n    except ImportError:\n        pass\n    except Exception as e:\n        Console.warn(f\"Could not load tree-sitter-{language}: {e}\")\n\n    return None", "chunk_type": "function", "line_start": 133, "line_end": 156, "language": "python", "name": "get_parser"}, "d6ce97822756_func_parse_source": {"id": "d6ce97822756_func_parse_source", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def parse_source(source: bytes, language: str) -> Optional[Tree]:\n    \"\"\"Parse source code into tree.\"\"\"\n    parser = get_parser(language)\n    if parser is None:\n        return None\n\n    return parser.parse(source)", "chunk_type": "function", "line_start": 159, "line_end": 165, "language": "python", "name": "parse_source"}, "d6ce97822756_func_parse_file": {"id": "d6ce97822756_func_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def parse_file(path: Path) -> ParsedFile:\n    \"\"\"Parse a source file.\"\"\"\n    result = ParsedFile(path=path, language=\"\")\n\n    # Detect language\n    language = detect_language(path)\n    if not language:\n        result.error = f\"Unknown language for {path.suffix}\"\n        return result\n\n    result.language = language\n\n    # Read file\n    try:\n        with open(path, 'rb') as f:\n            source = f.read()\n        result.source = source\n    except Exception as e:\n        result.error = f\"Could not read file: {e}\"\n        return result\n\n    # Parse with tree-sitter if available\n    if TREE_SITTER_AVAILABLE:\n        tree = parse_source(source, language)\n        if tree:\n            result.tree = tree\n            result.functions = extract_functions(tree, language, source)\n            result.classes = extract_classes(tree, language, source)\n            result.imports = extract_imports(tree, language, source)\n            return result\n\n    # Fallback to Python's ast for Python files\n    if ", "chunk_type": "function", "line_start": 168, "line_end": 203, "language": "python", "name": "parse_file"}, "d6ce97822756_func__parse_python_fallback": {"id": "d6ce97822756_func__parse_python_fallback", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _parse_python_fallback(path: Path, source: bytes, result: ParsedFile) -> ParsedFile:\n    \"\"\"Fallback parser for Python using stdlib ast.\"\"\"\n    import ast\n\n    try:\n        tree = ast.parse(source.decode('utf-8', errors='ignore'))\n\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                item = CodeItem(\n                    name=node.name,\n                    item_type='function',\n                    line_start=node.lineno,\n                    line_end=node.end_lineno or node.lineno,\n                    docstring=ast.get_docstring(node),\n                    language='python'\n                )\n                result.functions.append(item)\n\n            elif isinstance(node, ast.ClassDef):\n                item = CodeItem(\n                    name=node.name,\n                    item_type='class',\n                    line_start=node.lineno,\n                    line_end=node.end_lineno or node.lineno,\n                  ", "chunk_type": "function", "line_start": 206, "line_end": 247, "language": "python", "name": "_parse_python_fallback"}, "d6ce97822756_func_extract_functions": {"id": "d6ce97822756_func_extract_functions", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_functions(tree: Tree, language: str, source: bytes) -> List[CodeItem]:\n    \"\"\"Extract functions from tree.\"\"\"\n    functions = []\n    func_types = FUNCTION_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in func_types:\n            name = _get_node_name(node, language)\n            if name:\n                item = CodeItem(\n                    name=name,\n                    item_type='function',\n                    line_start=node.start_point[0] + 1,\n                    line_end=node.end_point[0] + 1,\n                    signature=_get_signature(node, source),\n                    language=language\n                )\n                functions.append(item)\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return functions", "chunk_type": "function", "line_start": 250, "line_end": 275, "language": "python", "name": "extract_functions"}, "d6ce97822756_func_extract_classes": {"id": "d6ce97822756_func_extract_classes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_classes(tree: Tree, language: str, source: bytes) -> List[CodeItem]:\n    \"\"\"Extract classes from tree.\"\"\"\n    classes = []\n    class_types = CLASS_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in class_types:\n            name = _get_node_name(node, language)\n            if name:\n                item = CodeItem(\n                    name=name,\n                    item_type='class',\n                    line_start=node.start_point[0] + 1,\n                    line_end=node.end_point[0] + 1,\n                    language=language\n                )\n                classes.append(item)\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return classes", "chunk_type": "function", "line_start": 278, "line_end": 302, "language": "python", "name": "extract_classes"}, "d6ce97822756_func_extract_imports": {"id": "d6ce97822756_func_extract_imports", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def extract_imports(tree: Tree, language: str, source: bytes) -> List[str]:\n    \"\"\"Extract imports from tree.\"\"\"\n    imports = []\n    import_types = IMPORT_TYPES.get(language, [])\n\n    def visit(node: Node):\n        if node.type in import_types:\n            # Get the import text\n            import_text = source[node.start_byte:node.end_byte].decode('utf-8', errors='ignore')\n            imports.append(import_text.strip())\n\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return imports", "chunk_type": "function", "line_start": 305, "line_end": 322, "language": "python", "name": "extract_imports"}, "d6ce97822756_func__get_node_name": {"id": "d6ce97822756_func__get_node_name", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _get_node_name(node: Node, language: str) -> Optional[str]:\n    \"\"\"Extract name from node.\"\"\"\n    # Look for identifier child\n    for child in node.children:\n        if child.type in ('identifier', 'name', 'property_identifier'):\n            return child.text.decode('utf-8', errors='ignore')\n    return None", "chunk_type": "function", "line_start": 325, "line_end": 331, "language": "python", "name": "_get_node_name"}, "d6ce97822756_func__get_signature": {"id": "d6ce97822756_func__get_signature", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def _get_signature(node: Node, source: bytes) -> str:\n    \"\"\"Get function/method signature.\"\"\"\n    # Get first line\n    start = node.start_byte\n    end = node.end_byte\n    text = source[start:end].decode('utf-8', errors='ignore')\n    first_line = text.split('\\n')[0]\n    return first_line[:100]", "chunk_type": "function", "line_start": 334, "line_end": 341, "language": "python", "name": "_get_signature"}, "d6ce97822756_func_walk_tree": {"id": "d6ce97822756_func_walk_tree", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def walk_tree(tree: Tree, callback: Callable[[Node], None]):\n    \"\"\"Walk entire tree calling callback on each node.\"\"\"\n    def visit(node: Node):\n        callback(node)\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)", "chunk_type": "function", "line_start": 344, "line_end": 352, "language": "python", "name": "walk_tree"}, "d6ce97822756_func_find_nodes": {"id": "d6ce97822756_func_find_nodes", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def find_nodes(tree: Tree, node_types: List[str]) -> List[Node]:\n    \"\"\"Find all nodes of given types.\"\"\"\n    results = []\n\n    def visit(node: Node):\n        if node.type in node_types:\n            results.append(node)\n        for child in node.children:\n            visit(child)\n\n    if tree and tree.root_node:\n        visit(tree.root_node)\n\n    return results", "chunk_type": "function", "line_start": 355, "line_end": 368, "language": "python", "name": "find_nodes"}, "d6ce97822756_func_get_node_text": {"id": "d6ce97822756_func_get_node_text", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def get_node_text(node: Node, source: bytes) -> str:\n    \"\"\"Get text content of node.\"\"\"\n    return source[node.start_byte:node.end_byte].decode('utf-8', errors='ignore')", "chunk_type": "function", "line_start": 371, "line_end": 373, "language": "python", "name": "get_node_text"}, "d6ce97822756_func_supported_languages": {"id": "d6ce97822756_func_supported_languages", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def supported_languages() -> List[str]:\n    \"\"\"Get list of supported languages.\"\"\"\n    return list(LANGUAGE_MAP.values())", "chunk_type": "function", "line_start": 376, "line_end": 378, "language": "python", "name": "supported_languages"}, "d6ce97822756_func_is_tree_sitter_available": {"id": "d6ce97822756_func_is_tree_sitter_available", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def is_tree_sitter_available() -> bool:\n    \"\"\"Check if tree-sitter is available.\"\"\"\n    return TREE_SITTER_AVAILABLE", "chunk_type": "function", "line_start": 381, "line_end": 383, "language": "python", "name": "is_tree_sitter_available"}, "d6ce97822756_func_main": {"id": "d6ce97822756_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Tree-sitter Utilities\")\n\n    if not TREE_SITTER_AVAILABLE:\n        Console.warn(\"tree-sitter not installed, using Python ast fallback\")\n    else:\n        Console.ok(\"tree-sitter available\")\n\n    # Parse arguments\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if not args:\n        Console.info(\"Supported languages:\")\n        for ext, lang in sorted(LANGUAGE_MAP.items()):\n            Console.info(f\"  {ext} -> {lang}\")\n        return 0\n\n    path = Path(args[0])\n    if not path.exists():\n        Console.fail(f\"File not found: {path}\")\n        return 1\n\n    result = parse_file(path)\n\n    print(f\"\\nFile: {result.path}\")\n    print(f\"Language: {result.language}\")\n    print(f\"Functions: {len(result.functions)}\")\n    print(f\"Classes: {len(result.classes)}\")\n    print(f\"Imports: {len(result.imports)}\")\n\n    if result.functions:\n        print(\"\\n## Functions\")\n        for f in result.functions[:10]:\n            print(f\"", "chunk_type": "function", "line_start": 386, "line_end": 427, "language": "python", "name": "main"}, "d6ce97822756_func_visit": {"id": "d6ce97822756_func_visit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "    def visit(node: Node):\n        if node.type in node_types:\n            results.append(node)\n        for child in node.children:\n            visit(child)", "chunk_type": "function", "line_start": 359, "line_end": 363, "language": "python", "name": "visit"}, "d6ce97822756_class_CodeItem": {"id": "d6ce97822756_class_CodeItem", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "class CodeItem:\n    \"\"\"A code item (function, class, etc).\"\"\"\n    name: str\n    item_type: str  # 'function', 'class', 'method', 'import', 'variable'\n    line_start: int\n    line_end: int\n    signature: str = \"\"\n    docstring: Optional[str] = None\n    language: str = \"\"\n    children: List['CodeItem'] = field(default_factory=list)", "chunk_type": "class", "line_start": 30, "line_end": 39, "language": "python", "name": "CodeItem"}, "d6ce97822756_class_ParsedFile": {"id": "d6ce97822756_class_ParsedFile", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\treesitter_utils.py", "content": "class ParsedFile:\n    \"\"\"Result of parsing a file.\"\"\"\n    path: Path\n    language: str\n    tree: Optional[Any] = None\n    source: bytes = b\"\"\n    functions: List[CodeItem] = field(default_factory=list)\n    classes: List[CodeItem] = field(default_factory=list)\n    imports: List[str] = field(default_factory=list)\n    error: Optional[str] = None", "chunk_type": "class", "line_start": 43, "line_end": 52, "language": "python", "name": "ParsedFile"}, "ff331eef4c1b_file": {"id": "ff331eef4c1b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\trigger_loop.py", "content": "\"\"\"\nAuto-Dev Loop Trigger\n=====================\nTriggers the autonomous development loop if enabled by the user.\n\"\"\"\n\nfrom pathlib import Path\nimport sys\n\nfrom .utils import Console, find_project_root\nimport config.loop_config as loop_config\n\ndef main():\n    \"\"\"Check config and trigger loop if enabled.\"\"\"\n    if not loop_config.ENABLE_AUTO_LOOP:\n        Console.info(\"Auto-Dev Loop: Disabled (User controllable via mcp-global-rules/config/loop_config.py)\")\n        return 0\n\n    # Locate the prompt file\n    root = find_project_root() or Path.cwd()\n    # Check standard location first\n    prompt_path = root / \"mcp-global-rules\" / \"prompts\" / \"auto_dev.md\"\n\n    if not prompt_path.exists():\n        # Fallback to the user's legacy temp file as requested (but preferring permanent)\n        fallback = root / \"ai-script-to-make-it-continue-development.md\"\n        if fallback.exists():\n            prompt_path = fallback\n        else:\n            Console.warn(\"Auto-Dev Loop: Enabled but prompt file not found.\")\n            return 1\n\n    try:\n        content = prompt_path.read_text(encoding='utf-8').strip()\n        Console.header(\"AUTO-DEV LOOP TRIGGERED\")\n        print(\"\\n\" + \"=\"*40)\n        print(\">>> INJECTION START >>>\")\n        print(content)\n        print(\"<<< INJECTION END <<<\")\n        print(\"=\"*40 + \"\\n\")\n        Console.ok(\"Prompt sent to agent stream.\")\n    except Exception as e:\n        Console.fail(f\"Failed to read prompt: {e}\")\n        return 1\n\n    return 0\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n", "chunk_type": "file", "line_start": 1, "line_end": 50, "language": "python", "name": "trigger_loop.py"}, "ff331eef4c1b_func_main": {"id": "ff331eef4c1b_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\trigger_loop.py", "content": "def main():\n    \"\"\"Check config and trigger loop if enabled.\"\"\"\n    if not loop_config.ENABLE_AUTO_LOOP:\n        Console.info(\"Auto-Dev Loop: Disabled (User controllable via mcp-global-rules/config/loop_config.py)\")\n        return 0\n\n    # Locate the prompt file\n    root = find_project_root() or Path.cwd()\n    # Check standard location first\n    prompt_path = root / \"mcp-global-rules\" / \"prompts\" / \"auto_dev.md\"\n\n    if not prompt_path.exists():\n        # Fallback to the user's legacy temp file as requested (but preferring permanent)\n        fallback = root / \"ai-script-to-make-it-continue-development.md\"\n        if fallback.exists():\n            prompt_path = fallback\n        else:\n            Console.warn(\"Auto-Dev Loop: Enabled but prompt file not found.\")\n            return 1\n\n    try:\n        content = prompt_path.read_text(encoding='utf-8').strip()\n        Console.header(\"AUTO-DEV LOOP TRIGGERED\")\n        print(\"\\n\" + \"=\"*40)\n        print(\">>> INJECTION START >>>\")\n        print", "chunk_type": "function", "line_start": 13, "line_end": 46, "language": "python", "name": "main"}, "9fd29e1766c5_file": {"id": "9fd29e1766c5_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "\"\"\"\nMCP Global Rules - Shared Utilities\n====================================\nCore utility functions used by all AI agent enhancement tools.\n\nPython 3.11+ compatible, uses only stdlib.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Iterator, Tuple\nimport ast\nimport json\nimport os\nimport subprocess\n\n\n# =============================================================================\n# DATA CLASSES\n# =============================================================================\n\n@dataclass\nclass FunctionInfo:\n    \"\"\"Information about a Python function.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    args: List[str]\n    arg_types: Dict[str, str]\n    return_type: Optional[str]\n    docstring: Optional[str]\n    is_async: bool = False\n    is_method: bool = False\n    decorators: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ClassInfo:\n    \"\"\"Information about a Python class.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    docstring: Optional[str]\n    methods: List[FunctionInfo] = field(default_factory=list)\n    bases: List[str] = field(default_factory=list)\n    decorators: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ModuleInfo:\n    \"\"\"Information about a Python module.\"\"\"\n    path: Path\n    docstring: Optional[str]\n    imports: List[str] = field(default_factory=list)\n    from_imports: List[Tuple[str, List[str]]] = field(default_factory=list)\n    functions: List[FunctionInfo] = field(default_factory=list)\n    classes: List[ClassInfo] = field(default_factory=list)\n    global_vars: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass GitCommit:\n    \"\"\"Information about a git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    date: str\n    message: str\n    body: str = \"\"\n    files_changed: List[str] = field(default_factory=list)\n\n\n# =============================================================================\n# FILE DISC", "chunk_type": "file", "line_start": 1, "line_end": 659, "language": "python", "name": "utils.py"}, "9fd29e1766c5_func_find_python_files": {"id": "9fd29e1766c5_func_find_python_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def find_python_files(\n    root: Path,\n    exclude_patterns: List[str] = None\n) -> Iterator[Path]:\n    \"\"\"\n    Find all Python files in a directory tree.\n\n    Args:\n        root: Root directory to search\n        exclude_patterns: Patterns to exclude (e.g., ['__pycache__', '.venv'])\n\n    Yields:\n        Path objects for each Python file found\n    \"\"\"\n    if exclude_patterns is None:\n        exclude_patterns = [\n            '__pycache__', '.venv', 'venv', '.git', 'node_modules',\n            '.eggs', '*.egg-info', 'dist', 'build', '.tox', '.pytest_cache'\n        ]\n\n    root = Path(root)\n    if not root.exists():\n        return\n\n    for item in root.rglob('*.py'):\n        # Check if any parent directory matches exclude patterns\n        skip = False\n        for part in item.parts:\n            for pattern in exclude_patterns:\n                if pattern.startswith('*'):\n                    if part.endswith(pattern[1:]):\n                        skip = True\n                        break\n       ", "chunk_type": "function", "line_start": 78, "line_end": 118, "language": "python", "name": "find_python_files"}, "9fd29e1766c5_func_find_project_root": {"id": "9fd29e1766c5_func_find_project_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def find_project_root(start: Path = None) -> Optional[Path]:\n    \"\"\"\n    Find the project root by looking for common markers.\n\n    Args:\n        start: Starting directory (defaults to cwd)\n\n    Returns:\n        Project root path or None\n    \"\"\"\n    # 1. Try environment variable set by mcp.py\n    mcp_root_env = os.environ.get('MCP_ROOT')\n\n    if start is None:\n        start = Path.cwd()\n\n    markers = ['.git', 'pyproject.toml', 'setup.py', 'setup.cfg', '.mcp']\n\n    # helper to check markers\n    def check_dir(d: Path) -> bool:\n        for marker in markers:\n            if (d / marker).exists():\n                return True\n        return False\n\n    # A. Search up from the MCP package location first (Strongest signal)\n    # If mcp-global-rules is inside a project, that's likely the project we want.\n    if mcp_root_env:\n        mcp_root = Path(mcp_root_env).resolve()\n\n        # Check parent of mcp-global-rules (common case)\n        if check_dir(mcp_root.parent):\n            return mcp_root.", "chunk_type": "function", "line_start": 121, "line_end": 176, "language": "python", "name": "find_project_root"}, "9fd29e1766c5_func_get_package_root": {"id": "9fd29e1766c5_func_get_package_root", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_package_root() -> Path:\n    \"\"\"Get the absolute path to the mcp-global-rules package directory.\"\"\"\n    mcp_root_env = os.environ.get('MCP_ROOT')\n    if mcp_root_env:\n        return Path(mcp_root_env).resolve()\n\n    # Fallback to __file__ resolution\n    return Path(__file__).resolve().parent.parent", "chunk_type": "function", "line_start": 179, "line_end": 186, "language": "python", "name": "get_package_root"}, "9fd29e1766c5_func_parse_file": {"id": "9fd29e1766c5_func_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def parse_file(path: Path) -> Optional[ast.Module]:\n    \"\"\"\n    Parse a Python file into an AST.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        AST module or None if parsing fails\n    \"\"\"\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            source = f.read()\n        return ast.parse(source, filename=str(path))\n    except (SyntaxError, UnicodeDecodeError, FileNotFoundError):\n        return None", "chunk_type": "function", "line_start": 193, "line_end": 208, "language": "python", "name": "parse_file"}, "9fd29e1766c5_func_get_type_annotation": {"id": "9fd29e1766c5_func_get_type_annotation", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_type_annotation(node: ast.expr) -> str:\n    \"\"\"Convert an AST type annotation to a string.\"\"\"\n    if node is None:\n        return \"\"\n\n    if isinstance(node, ast.Name):\n        return node.id\n    elif isinstance(node, ast.Constant):\n        return repr(node.value)\n    elif isinstance(node, ast.Subscript):\n        base = get_type_annotation(node.value)\n        if isinstance(node.slice, ast.Tuple):\n            args = ', '.join(get_type_annotation(e) for e in node.slice.elts)\n        else:\n            args = get_type_annotation(node.slice)\n        return f\"{base}[{args}]\"\n    elif isinstance(node, ast.Attribute):\n        return f\"{get_type_annotation(node.value)}.{node.attr}\"\n    elif isinstance(node, ast.BinOp) and isinstance(node.op, ast.BitOr):\n        # Union type with | operator\n        left = get_type_annotation(node.left)\n        right = get_type_annotation(node.right)\n        return f\"{left} | {right}\"\n    else:\n        return ast.unparse(node) if hasattr(ast, 'unparse') e", "chunk_type": "function", "line_start": 211, "line_end": 235, "language": "python", "name": "get_type_annotation"}, "9fd29e1766c5_func_extract_function_info": {"id": "9fd29e1766c5_func_extract_function_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def extract_function_info(node: ast.FunctionDef | ast.AsyncFunctionDef) -> FunctionInfo:\n    \"\"\"\n    Extract information from a function definition node.\n\n    Args:\n        node: AST function definition node\n\n    Returns:\n        FunctionInfo dataclass\n    \"\"\"\n    # Get arguments\n    args = []\n    arg_types = {}\n\n    for arg in node.args.args:\n        arg_name = arg.arg\n        args.append(arg_name)\n        if arg.annotation:\n            arg_types[arg_name] = get_type_annotation(arg.annotation)\n\n    # Get return type\n    return_type = None\n    if node.returns:\n        return_type = get_type_annotation(node.returns)\n\n    # Get docstring\n    docstring = ast.get_docstring(node)\n\n    # Get decorators\n    decorators = []\n    for dec in node.decorator_list:\n        if isinstance(dec, ast.Name):\n            decorators.append(dec.id)\n        elif isinstance(dec, ast.Attribute):\n            decorators.append(f\"{get_type_annotation(dec.value)}.{dec.attr}\")\n        elif isinstance(dec, ast.Call):", "chunk_type": "function", "line_start": 238, "line_end": 289, "language": "python", "name": "extract_function_info"}, "9fd29e1766c5_func_extract_class_info": {"id": "9fd29e1766c5_func_extract_class_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def extract_class_info(node: ast.ClassDef) -> ClassInfo:\n    \"\"\"\n    Extract information from a class definition node.\n\n    Args:\n        node: AST class definition node\n\n    Returns:\n        ClassInfo dataclass\n    \"\"\"\n    # Get methods\n    methods = []\n    for item in node.body:\n        if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            func_info = extract_function_info(item)\n            func_info.is_method = True\n            methods.append(func_info)\n\n    # Get base classes\n    bases = [get_type_annotation(base) for base in node.bases]\n\n    # Get decorators\n    decorators = []\n    for dec in node.decorator_list:\n        if isinstance(dec, ast.Name):\n            decorators.append(dec.id)\n\n    return ClassInfo(\n        name=node.name,\n        lineno=node.lineno,\n        end_lineno=node.end_lineno or node.lineno,\n        docstring=ast.get_docstring(node),\n        methods=methods,\n        bases=bases,\n        decorators=decorators\n    )", "chunk_type": "function", "line_start": 292, "line_end": 327, "language": "python", "name": "extract_class_info"}, "9fd29e1766c5_func_analyze_module": {"id": "9fd29e1766c5_func_analyze_module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def analyze_module(path: Path) -> Optional[ModuleInfo]:\n    \"\"\"\n    Analyze a Python module and extract all information.\n\n    Args:\n        path: Path to Python file\n\n    Returns:\n        ModuleInfo dataclass or None if parsing fails\n    \"\"\"\n    tree = parse_file(path)\n    if tree is None:\n        return None\n\n    info = ModuleInfo(\n        path=path,\n        docstring=ast.get_docstring(tree)\n    )\n\n    for node in ast.walk(tree):\n        # Imports\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                info.imports.append(alias.name)\n        elif isinstance(node, ast.ImportFrom):\n            if node.module:\n                names = [alias.name for alias in node.names]\n                info.from_imports.append((node.module, names))\n\n    # Top-level items only\n    for node in tree.body:\n        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            info.functions.append(extract_function_info(node))\n        elif isinstance(node, ast.", "chunk_type": "function", "line_start": 330, "line_end": 370, "language": "python", "name": "analyze_module"}, "9fd29e1766c5_func_run_git_command": {"id": "9fd29e1766c5_func_run_git_command", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def run_git_command(args: List[str], cwd: Path = None) -> Optional[str]:\n    \"\"\"\n    Run a git command and return output.\n\n    Args:\n        args: Git command arguments\n        cwd: Working directory\n\n    Returns:\n        Command output or None if failed\n    \"\"\"\n    try:\n        result = subprocess.run(\n            ['git'] + args,\n            capture_output=True,\n            text=True,\n            cwd=cwd or Path.cwd(),\n            timeout=30\n        )\n        if result and result.returncode == 0:\n            return (result.stdout or \"\").strip()\n        return None\n    except Exception:\n        return None", "chunk_type": "function", "line_start": 377, "line_end": 400, "language": "python", "name": "run_git_command"}, "9fd29e1766c5_func_get_git_log": {"id": "9fd29e1766c5_func_get_git_log", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_git_log(\n    count: int = 50,\n    cwd: Path = None\n) -> List[GitCommit]:\n    \"\"\"\n    Get recent git commits.\n\n    Args:\n        count: Number of commits to retrieve\n        cwd: Working directory\n\n    Returns:\n        List of GitCommit objects\n    \"\"\"\n    # Use a delimiter that won't appear in commit messages\n    delimiter = \"---COMMIT_DELIMITER---\"\n    format_str = f\"%H{delimiter}%h{delimiter}%an{delimiter}%ai{delimiter}%s{delimiter}%b\"\n\n    output = run_git_command(\n        ['log', f'-{count}', f'--format={format_str}'],\n        cwd=cwd\n    )\n\n    if not output:\n        return []\n\n    commits = []\n    for entry in output.split('\\n'):\n        if not entry.strip():\n            continue\n\n        parts = entry.split(delimiter)\n        if len(parts) >= 5:\n            commits.append(GitCommit(\n                hash=parts[0],\n                short_hash=parts[1],\n                author=parts[2],\n                date=parts[3],\n                message=parts[4],\n                body=part", "chunk_type": "function", "line_start": 403, "line_end": 445, "language": "python", "name": "get_git_log"}, "9fd29e1766c5_func_get_changed_files": {"id": "9fd29e1766c5_func_get_changed_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_changed_files(since_commit: str = \"HEAD~1\", cwd: Path = None) -> List[str]:\n    \"\"\"\n    Get list of files changed since a commit.\n\n    Args:\n        since_commit: Git reference to compare against\n        cwd: Working directory\n\n    Returns:\n        List of changed file paths\n    \"\"\"\n    output = run_git_command(\n        ['diff', '--name-only', since_commit],\n        cwd=cwd\n    )\n\n    if not output:\n        return []\n\n    return [f for f in output.split('\\n') if f.strip()]", "chunk_type": "function", "line_start": 448, "line_end": 467, "language": "python", "name": "get_changed_files"}, "9fd29e1766c5_func_get_staged_files": {"id": "9fd29e1766c5_func_get_staged_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_staged_files(cwd: Path = None) -> List[str]:\n    \"\"\"Get list of staged files.\"\"\"\n    output = run_git_command(['diff', '--cached', '--name-only'], cwd=cwd)\n    return [f for f in (output or '').split('\\n') if f.strip()]", "chunk_type": "function", "line_start": 470, "line_end": 473, "language": "python", "name": "get_staged_files"}, "9fd29e1766c5_func_format_as_json": {"id": "9fd29e1766c5_func_format_as_json", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def format_as_json(data: Any, indent: int = 2) -> str:\n    \"\"\"Format data as JSON string.\"\"\"\n    def default_serializer(obj):\n        if isinstance(obj, Path):\n            return str(obj)\n        if hasattr(obj, '__dataclass_fields__'):\n            return {k: getattr(obj, k) for k in obj.__dataclass_fields__}\n        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n\n    return json.dumps(data, indent=indent, default=default_serializer)", "chunk_type": "function", "line_start": 480, "line_end": 489, "language": "python", "name": "format_as_json"}, "9fd29e1766c5_func_format_as_markdown_table": {"id": "9fd29e1766c5_func_format_as_markdown_table", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def format_as_markdown_table(\n    headers: List[str],\n    rows: List[List[str]]\n) -> str:\n    \"\"\"Format data as a Markdown table.\"\"\"\n    if not headers or not rows:\n        return \"\"\n\n    # Calculate column widths\n    widths = [len(h) for h in headers]\n    for row in rows:\n        for i, cell in enumerate(row):\n            if i < len(widths):\n                widths[i] = max(widths[i], len(str(cell)))\n\n    # Format header\n    header_row = \"| \" + \" | \".join(h.ljust(widths[i]) for i, h in enumerate(headers)) + \" |\"\n    separator = \"|\" + \"|\".join(\"-\" * (w + 2) for w in widths) + \"|\"\n\n    # Format rows\n    data_rows = []\n    for row in rows:\n        cells = []\n        for i, cell in enumerate(row):\n            width = widths[i] if i < len(widths) else len(str(cell))\n            cells.append(str(cell).ljust(width))\n        data_rows.append(\"| \" + \" | \".join(cells) + \" |\")\n\n    return \"\\n\".join([header_row, separator] + data_rows)", "chunk_type": "function", "line_start": 492, "line_end": 520, "language": "python", "name": "format_as_markdown_table"}, "9fd29e1766c5_func_get_mcp_data_dir": {"id": "9fd29e1766c5_func_get_mcp_data_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def get_mcp_data_dir() -> Optional[Path]:\n    \"\"\"Find the .mcp directory.\"\"\"\n    project_root = find_project_root()\n    if project_root:\n        mcp_dir = project_root / '.mcp'\n        if mcp_dir.exists():\n            return mcp_dir\n    return None", "chunk_type": "function", "line_start": 527, "line_end": 534, "language": "python", "name": "get_mcp_data_dir"}, "9fd29e1766c5_func_record_to_memory": {"id": "9fd29e1766c5_func_record_to_memory", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "def record_to_memory(\n    entry_type: str,\n    content: str,\n    tags: List[str] = None,\n    metadata: Dict[str, Any] = None\n) -> bool:\n    \"\"\"\n    Record an entry to MCP memory.\n\n    Args:\n        entry_type: Type of entry (action, decision, todo, etc.)\n        content: Content of the entry\n        tags: Optional tags\n        metadata: Optional metadata\n\n    Returns:\n        True if successful\n    \"\"\"\n    mcp_data = get_mcp_data_dir()\n    if not mcp_data:\n        return False\n\n    memory_dir = mcp_data / 'memory'\n    if not memory_dir.exists():\n        memory_dir.mkdir(parents=True)\n\n    # Map entry types to files\n    type_files = {\n        'action': 'actions.json',\n        'decision': 'decisions.json',\n        'todo': 'todos.json',\n        'milestone': 'milestones.json',\n        'session': 'sessions.json'\n    }\n\n    filename = type_files.get(entry_type, 'actions.json')\n    filepath = memory_dir / filename\n\n    # Load existing entries\n    entries = []\n    if filepath.exists():\n       ", "chunk_type": "function", "line_start": 537, "line_end": 602, "language": "python", "name": "record_to_memory"}, "9fd29e1766c5_func_check_dir": {"id": "9fd29e1766c5_func_check_dir", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def check_dir(d: Path) -> bool:\n        for marker in markers:\n            if (d / marker).exists():\n                return True\n        return False", "chunk_type": "function", "line_start": 140, "line_end": 144, "language": "python", "name": "check_dir"}, "9fd29e1766c5_func_default_serializer": {"id": "9fd29e1766c5_func_default_serializer", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def default_serializer(obj):\n        if isinstance(obj, Path):\n            return str(obj)\n        if hasattr(obj, '__dataclass_fields__'):\n            return {k: getattr(obj, k) for k in obj.__dataclass_fields__}\n        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")", "chunk_type": "function", "line_start": 482, "line_end": 487, "language": "python", "name": "default_serializer"}, "9fd29e1766c5_func__supports_color": {"id": "9fd29e1766c5_func__supports_color", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def _supports_color(cls) -> bool:\n        \"\"\"Check if terminal supports color.\"\"\"\n        import sys\n        return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()", "chunk_type": "function", "line_start": 623, "line_end": 626, "language": "python", "name": "_supports_color"}, "9fd29e1766c5_func__color": {"id": "9fd29e1766c5_func__color", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def _color(cls, text: str, color: str) -> str:\n        \"\"\"Apply color to text.\"\"\"\n        if not cls._supports_color():\n            return text\n        return f\"{cls.COLORS.get(color, '')}{text}{cls.COLORS['reset']}\"", "chunk_type": "function", "line_start": 629, "line_end": 633, "language": "python", "name": "_color"}, "9fd29e1766c5_func_info": {"id": "9fd29e1766c5_func_info", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def info(cls, msg: str):\n        \"\"\"Print info message.\"\"\"\n        print(f\"{cls._color('[INFO]', 'blue')} {msg}\")", "chunk_type": "function", "line_start": 636, "line_end": 638, "language": "python", "name": "info"}, "9fd29e1766c5_func_ok": {"id": "9fd29e1766c5_func_ok", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def ok(cls, msg: str):\n        \"\"\"Print success message.\"\"\"\n        print(f\"{cls._color('[OK]', 'green')} {msg}\")", "chunk_type": "function", "line_start": 641, "line_end": 643, "language": "python", "name": "ok"}, "9fd29e1766c5_func_warn": {"id": "9fd29e1766c5_func_warn", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def warn(cls, msg: str):\n        \"\"\"Print warning message.\"\"\"\n        print(f\"{cls._color('[WARNING]', 'yellow')} {msg}\")", "chunk_type": "function", "line_start": 646, "line_end": 648, "language": "python", "name": "warn"}, "9fd29e1766c5_func_fail": {"id": "9fd29e1766c5_func_fail", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def fail(cls, msg: str):\n        \"\"\"Print failure message.\"\"\"\n        print(f\"{cls._color('[FAIL]', 'red')} {msg}\")", "chunk_type": "function", "line_start": 651, "line_end": 653, "language": "python", "name": "fail"}, "9fd29e1766c5_func_header": {"id": "9fd29e1766c5_func_header", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "    def header(cls, msg: str):\n        \"\"\"Print header.\"\"\"\n        print(f\"\\n{cls._color('=== ' + msg + ' ===', 'cyan')}\\n\")", "chunk_type": "function", "line_start": 656, "line_end": 658, "language": "python", "name": "header"}, "9fd29e1766c5_class_FunctionInfo": {"id": "9fd29e1766c5_class_FunctionInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class FunctionInfo:\n    \"\"\"Information about a Python function.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    args: List[str]\n    arg_types: Dict[str, str]\n    return_type: Optional[str]\n    docstring: Optional[str]\n    is_async: bool = False\n    is_method: bool = False\n    decorators: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 24, "line_end": 35, "language": "python", "name": "FunctionInfo"}, "9fd29e1766c5_class_ClassInfo": {"id": "9fd29e1766c5_class_ClassInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class ClassInfo:\n    \"\"\"Information about a Python class.\"\"\"\n    name: str\n    lineno: int\n    end_lineno: int\n    docstring: Optional[str]\n    methods: List[FunctionInfo] = field(default_factory=list)\n    bases: List[str] = field(default_factory=list)\n    decorators: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 39, "line_end": 47, "language": "python", "name": "ClassInfo"}, "9fd29e1766c5_class_ModuleInfo": {"id": "9fd29e1766c5_class_ModuleInfo", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class ModuleInfo:\n    \"\"\"Information about a Python module.\"\"\"\n    path: Path\n    docstring: Optional[str]\n    imports: List[str] = field(default_factory=list)\n    from_imports: List[Tuple[str, List[str]]] = field(default_factory=list)\n    functions: List[FunctionInfo] = field(default_factory=list)\n    classes: List[ClassInfo] = field(default_factory=list)\n    global_vars: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 51, "line_end": 59, "language": "python", "name": "ModuleInfo"}, "9fd29e1766c5_class_GitCommit": {"id": "9fd29e1766c5_class_GitCommit", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class GitCommit:\n    \"\"\"Information about a git commit.\"\"\"\n    hash: str\n    short_hash: str\n    author: str\n    date: str\n    message: str\n    body: str = \"\"\n    files_changed: List[str] = field(default_factory=list)", "chunk_type": "class", "line_start": 63, "line_end": 71, "language": "python", "name": "GitCommit"}, "9fd29e1766c5_class_Console": {"id": "9fd29e1766c5_class_Console", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\utils.py", "content": "class Console:\n    \"\"\"Simple console output with colors.\"\"\"\n\n    COLORS = {\n        'red': '\\033[0;31m',\n        'green': '\\033[0;32m',\n        'yellow': '\\033[1;33m',\n        'blue': '\\033[0;34m',\n        'cyan': '\\033[0;36m',\n        'bold': '\\033[1m',\n        'reset': '\\033[0m'\n    }\n\n    @classmethod\n    def _supports_color(cls) -> bool:\n        \"\"\"Check if terminal supports color.\"\"\"\n        import sys\n        return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()\n\n    @classmethod\n    def _color(cls, text: str, color: str) -> str:\n        \"\"\"Apply color to text.\"\"\"\n        if not cls._supports_color():\n            return text\n        return f\"{cls.COLORS.get(color, '')}{text}{cls.COLORS['reset']}\"\n\n    @classmethod\n    def info(cls, msg: str):\n        \"\"\"Print info message.\"\"\"\n        print(f\"{cls._color('[INFO]', 'blue')} {msg}\")\n\n    @classmethod\n    def ok(cls, msg: str):\n        \"\"\"Print success message.\"\"\"\n        print(f\"{cls._color('[OK]', 'green')} {msg}\")\n\n    @cla", "chunk_type": "class", "line_start": 609, "line_end": 658, "language": "python", "name": "Console"}, "22f491db1ab2_file": {"id": "22f491db1ab2_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "\"\"\"\nVector Store\n=============\nLocal FAISS-based vector database for semantic code search.\n\nUsage:\n    from scripts.vector_store import VectorStore\n\n    store = VectorStore(path)\n    store.index_codebase(root)\n    results = store.search(\"authentication handler\", k=10)\n\"\"\"\n\nimport json\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass, field, asdict\nimport hashlib\n\nfrom .utils import Console, find_python_files, find_project_root\nfrom .embeddings import embed_text, embed_texts, cosine_similarity, embedding_dimension\n\n\n# Try to import FAISS\ntry:\n    import faiss\n    FAISS_AVAILABLE = True\nexcept ImportError:\n    FAISS_AVAILABLE = False\n\n# Try numpy\ntry:\n    import numpy as np\n    NUMPY_AVAILABLE = True\nexcept ImportError:\n    NUMPY_AVAILABLE = False\n\n\n@dataclass\nclass CodeChunk:\n    \"\"\"A chunk of code with metadata.\"\"\"\n    id: str\n    path: str\n    content: str\n    chunk_type: str  # 'function', 'class', 'file', 'block'\n    line_start: int\n    line_end: int\n    language: str = \"\"\n    name: str = \"\"\n\n\n@dataclass\nclass SearchResult:\n    \"\"\"A search result.\"\"\"\n    chunk: CodeChunk\n    score: float\n    rank: int\n\n\nclass VectorStore:\n    \"\"\"Local vector store for semantic code search.\"\"\"\n\n    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}\n\n    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n", "chunk_type": "file", "line_start": 1, "line_end": 386, "language": "python", "name": "vector_store.py"}, "22f491db1ab2_func_main": {"id": "22f491db1ab2_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"Vector Store\")\n\n    if FAISS_AVAILABLE:\n        Console.ok(\"FAISS available\")\n    else:\n        Console.warn(\"FAISS not available, using brute force search\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if len(args) < 1:\n        Console.info(\"Usage: python vector_store.py <command> [args]\")\n        Console.info(\"Commands:\")\n        Console.info(\"  index <path>     Index codebase\")\n        Console.info(\"  search <query>   Search index\")\n        return 1\n\n    command = args[0]\n    store = VectorStore()\n\n    if command == 'index':\n        root = find_project_root() or Path.cwd()\n        path = Path(args[1]) if len(args) > 1 else root\n        store.index_codebase(path)\n\n    elif command == 'search':\n        query = ' '.join(args[1:]) if len(args) > 1 else ''\n        if not query:\n            Console.fail(\"No query provided\")\n            return 1\n\n        # Load existing index\n        if not store.load():\n    ", "chunk_type": "function", "line_start": 336, "line_end": 381, "language": "python", "name": "main"}, "22f491db1ab2_func___init__": {"id": "22f491db1ab2_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}", "chunk_type": "function", "line_start": 64, "line_end": 75, "language": "python", "name": "__init__"}, "22f491db1ab2_func_index_codebase": {"id": "22f491db1ab2_func_index_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n        Console.info(f\"Found {len(files)} files\")\n\n        chunks = []\n        for path in files:\n            file_chunks = self._extract_chunks(path)\n            chunks.extend(file_chunks)\n\n        Console.info(f\"Extracted {len(chunks)} code chunks\")\n\n        if not chunks:\n            return 0\n\n        # Generate embeddings\n        Console.info(\"Generating embeddings...\")\n        texts = [c.content[:1000] for c in chunks]  # Limit text length\n        embeddings = embed_texts(texts)\n\n        # Store chunks and embeddings\n        for chunk, emb in zip(chunks, embeddings):\n            self.chunks[chunk.id] = chunk\n            self.embeddings[chunk.id] = emb\n\n        # Build FAISS index if available\n        if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n  ", "chunk_type": "function", "line_start": 77, "line_end": 112, "language": "python", "name": "index_codebase"}, "22f491db1ab2_func__extract_chunks": {"id": "22f491db1ab2_func__extract_chunks", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _extract_chunks(self, path: Path) -> List[CodeChunk]:\n        \"\"\"Extract code chunks from file.\"\"\"\n        chunks = []\n\n        try:\n            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n                content = f.read()\n        except Exception:\n            return chunks\n\n        # Detect language\n        ext = path.suffix.lower()\n        lang_map = {'.py': 'python', '.js': 'javascript', '.ts': 'typescript',\n                    '.go': 'go', '.rs': 'rust', '.java': 'java'}\n        language = lang_map.get(ext, 'unknown')\n\n        # Create file-level chunk\n        file_id = hashlib.md5(str(path).encode()).hexdigest()[:12]\n        chunks.append(CodeChunk(\n            id=f\"{file_id}_file\",\n            path=str(path),\n            content=content[:2000],  # First 2000 chars\n            chunk_type='file',\n            line_start=1,\n            line_end=content.count('\\n') + 1,\n            language=language,\n            name=path.name\n        ))\n\n        # Try to ex", "chunk_type": "function", "line_start": 114, "line_end": 179, "language": "python", "name": "_extract_chunks"}, "22f491db1ab2_func__build_faiss_index": {"id": "22f491db1ab2_func__build_faiss_index", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _build_faiss_index(self):\n        \"\"\"Build FAISS index from embeddings.\"\"\"\n        if not self.embeddings:\n            return\n\n        dim = len(next(iter(self.embeddings.values())))\n\n        # Create index\n        self._faiss_index = faiss.IndexFlatIP(dim)  # Inner product = cosine for normalized\n\n        # Add vectors\n        ids = list(self.embeddings.keys())\n        vectors = np.array([self.embeddings[id] for id in ids], dtype='float32')\n\n        # Normalize for cosine similarity\n        faiss.normalize_L2(vectors)\n\n        self._faiss_index.add(vectors)\n\n        # Build ID mappings\n        for idx, id in enumerate(ids):\n            self._id_to_idx[id] = idx\n            self._idx_to_id[idx] = id", "chunk_type": "function", "line_start": 181, "line_end": 203, "language": "python", "name": "_build_faiss_index"}, "22f491db1ab2_func_search": {"id": "22f491db1ab2_func_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def search(self, query: str, k: int = 10) -> List[SearchResult]:\n        \"\"\"Search for code matching query.\"\"\"\n        if not self.embeddings:\n            return []\n\n        # Generate query embedding\n        query_emb = embed_text(query)\n        if query_emb is None:\n            return []\n\n        # Use FAISS if available\n        if self._faiss_index is not None and NUMPY_AVAILABLE:\n            return self._faiss_search(query_emb, k)\n\n        # Fallback to brute force\n        return self._brute_force_search(query_emb, k)", "chunk_type": "function", "line_start": 205, "line_end": 220, "language": "python", "name": "search"}, "22f491db1ab2_func__faiss_search": {"id": "22f491db1ab2_func__faiss_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _faiss_search(self, query_emb: List[float], k: int) -> List[SearchResult]:\n        \"\"\"Search using FAISS.\"\"\"\n        query_vec = np.array([query_emb], dtype='float32')\n        faiss.normalize_L2(query_vec)\n\n        k = min(k, len(self.embeddings))\n        distances, indices = self._faiss_index.search(query_vec, k)\n\n        results = []\n        for rank, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n            if idx < 0:\n                continue\n            chunk_id = self._idx_to_id.get(int(idx))\n            if chunk_id and chunk_id in self.chunks:\n                results.append(SearchResult(\n                    chunk=self.chunks[chunk_id],\n                    score=float(dist),\n                    rank=rank + 1\n                ))\n\n        return results", "chunk_type": "function", "line_start": 222, "line_end": 242, "language": "python", "name": "_faiss_search"}, "22f491db1ab2_func__brute_force_search": {"id": "22f491db1ab2_func__brute_force_search", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def _brute_force_search(self, query_emb: List[float], k: int) -> List[SearchResult]:\n        \"\"\"Brute force cosine similarity search.\"\"\"\n        scores = []\n\n        for chunk_id, emb in self.embeddings.items():\n            score = cosine_similarity(query_emb, emb)\n            scores.append((chunk_id, score))\n\n        # Sort by score descending\n        scores.sort(key=lambda x: x[1], reverse=True)\n\n        results = []\n        for rank, (chunk_id, score) in enumerate(scores[:k]):\n            if chunk_id in self.chunks:\n                results.append(SearchResult(\n                    chunk=self.chunks[chunk_id],\n                    score=score,\n                    rank=rank + 1\n                ))\n\n        return results", "chunk_type": "function", "line_start": 244, "line_end": 264, "language": "python", "name": "_brute_force_search"}, "22f491db1ab2_func_save": {"id": "22f491db1ab2_func_save", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def save(self):\n        \"\"\"Save index to disk.\"\"\"\n        self.index_path.mkdir(parents=True, exist_ok=True)\n\n        # Save chunks\n        chunks_file = self.index_path / \"chunks.json\"\n        with open(chunks_file, 'w', encoding='utf-8') as f:\n            json.dump({k: asdict(v) for k, v in self.chunks.items()}, f)\n\n        # Save embeddings\n        emb_file = self.index_path / \"embeddings.json\"\n        with open(emb_file, 'w', encoding='utf-8') as f:\n            json.dump(self.embeddings, f)\n\n        Console.ok(f\"Index saved to {self.index_path}\")", "chunk_type": "function", "line_start": 266, "line_end": 280, "language": "python", "name": "save"}, "22f491db1ab2_func_load": {"id": "22f491db1ab2_func_load", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def load(self) -> bool:\n        \"\"\"Load index from disk.\"\"\"\n        chunks_file = self.index_path / \"chunks.json\"\n        emb_file = self.index_path / \"embeddings.json\"\n\n        if not chunks_file.exists() or not emb_file.exists():\n            return False\n\n        try:\n            with open(chunks_file, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                self.chunks = {k: CodeChunk(**v) for k, v in data.items()}\n\n            with open(emb_file, 'r', encoding='utf-8') as f:\n                self.embeddings = json.load(f)\n\n            if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n                self._build_faiss_index()\n\n            Console.ok(f\"Loaded {len(self.chunks)} chunks from index\")\n            return True\n\n        except Exception as e:\n            Console.warn(f\"Could not load index: {e}\")\n            return False", "chunk_type": "function", "line_start": 282, "line_end": 306, "language": "python", "name": "load"}, "22f491db1ab2_func_update": {"id": "22f491db1ab2_func_update", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "    def update(self, changed_files: List[Path]):\n        \"\"\"Update index for changed files.\"\"\"\n        for path in changed_files:\n            # Remove old chunks for this file\n            to_remove = [k for k, v in self.chunks.items() if v.path == str(path)]\n            for k in to_remove:\n                del self.chunks[k]\n                if k in self.embeddings:\n                    del self.embeddings[k]\n\n            # Re-index file\n            if path.exists():\n                new_chunks = self._extract_chunks(path)\n                if new_chunks:\n                    texts = [c.content[:1000] for c in new_chunks]\n                    embeddings = embed_texts(texts)\n\n                    for chunk, emb in zip(new_chunks, embeddings):\n                        self.chunks[chunk.id] = chunk\n                        self.embeddings[chunk.id] = emb\n\n        # Rebuild FAISS index\n        if FAISS_AVAILABLE and NUMPY_AVAILABLE:\n            self._build_faiss_index()\n\n        self.save()", "chunk_type": "function", "line_start": 308, "line_end": 333, "language": "python", "name": "update"}, "22f491db1ab2_class_CodeChunk": {"id": "22f491db1ab2_class_CodeChunk", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "class CodeChunk:\n    \"\"\"A chunk of code with metadata.\"\"\"\n    id: str\n    path: str\n    content: str\n    chunk_type: str  # 'function', 'class', 'file', 'block'\n    line_start: int\n    line_end: int\n    language: str = \"\"\n    name: str = \"\"", "chunk_type": "class", "line_start": 41, "line_end": 50, "language": "python", "name": "CodeChunk"}, "22f491db1ab2_class_SearchResult": {"id": "22f491db1ab2_class_SearchResult", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "class SearchResult:\n    \"\"\"A search result.\"\"\"\n    chunk: CodeChunk\n    score: float\n    rank: int", "chunk_type": "class", "line_start": 54, "line_end": 58, "language": "python", "name": "SearchResult"}, "22f491db1ab2_class_VectorStore": {"id": "22f491db1ab2_class_VectorStore", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\vector_store.py", "content": "class VectorStore:\n    \"\"\"Local vector store for semantic code search.\"\"\"\n\n    def __init__(self, index_path: Optional[Path] = None):\n        if index_path is None:\n            root = find_project_root() or Path.cwd()\n            self.index_path = root / \".mcp\" / \"vector_index\"\n        else:\n            self.index_path = Path(index_path)\n\n        self.chunks: Dict[str, CodeChunk] = {}\n        self.embeddings: Dict[str, List[float]] = {}\n        self._faiss_index = None\n        self._id_to_idx: Dict[str, int] = {}\n        self._idx_to_id: Dict[int, str] = {}\n\n    def index_codebase(self, root: Path, exclude_patterns: List[str] = None) -> int:\n        \"\"\"Index all code files in directory.\"\"\"\n        Console.info(f\"Indexing {root}...\")\n\n        files = list(find_python_files(root, exclude_patterns))\n        Console.info(f\"Found {len(files)} files\")\n\n        chunks = []\n        for path in files:\n            file_chunks = self._extract_chunks(path)\n            chunks.extend(file_chunks)\n\n ", "chunk_type": "class", "line_start": 61, "line_end": 333, "language": "python", "name": "VectorStore"}, "317b12cd2b19_file": {"id": "317b12cd2b19_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\warm.py", "content": "\"\"\"\nWarm-Up Command\n===============\nPre-warm all indexes for faster AI agent responses.\n\nUsage:\n    python mcp.py warm\n\"\"\"\n\nfrom pathlib import Path\nimport sys\nimport time\n\nfrom .utils import Console, find_project_root\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n\ndef warm_all(root: Path = None) -> dict:\n    \"\"\"Pre-warm all indexes and caches.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.header(\"Warming Indexes\")\n    Console.info(f\"Project: {root}\")\n\n    start_time = time.time()\n    results = {}\n\n    # Define warm-up tasks\n    tasks = {\n        'semantic': ('vector_store', 'VectorStore', 'index_codebase'),\n        'todos': ('todo_index', 'index_todos', None),\n        'impact': ('impact', 'save_impact_graph', None),\n        'docs': ('doc_index', 'index_documentation', None),\n        'config': ('config_index', 'index_configs', None),\n        'context': ('autocontext', 'warm_context', None),\n    }\n\n    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' / 'vector_index')\n                getattr(instance, method)(root)\n            else:\n                # Direct function\n                func = getattr(module, func_or_class)\n                func(root)\n\n            return name, 'ok', None\n        except Exception as e:\n            return name, 'error', str(e)\n\n    # Run tasks in parallel\n    Console.info(\"Running warm-up tasks...\")\n\n    with ThreadPoolExecutor(max_workers=4) as executor:\n        futures = {}\n        for name, (module, func, method) in tasks.items():\n            future = executor.submit(run_task, name, module, func, method)\n            futures[future] = name\n\n        for future in as_completed(futures):\n            name, status, error = future.", "chunk_type": "file", "line_start": 1, "line_end": 117, "language": "python", "name": "warm.py"}, "317b12cd2b19_func_warm_all": {"id": "317b12cd2b19_func_warm_all", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\warm.py", "content": "def warm_all(root: Path = None) -> dict:\n    \"\"\"Pre-warm all indexes and caches.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    Console.header(\"Warming Indexes\")\n    Console.info(f\"Project: {root}\")\n\n    start_time = time.time()\n    results = {}\n\n    # Define warm-up tasks\n    tasks = {\n        'semantic': ('vector_store', 'VectorStore', 'index_codebase'),\n        'todos': ('todo_index', 'index_todos', None),\n        'impact': ('impact', 'save_impact_graph', None),\n        'docs': ('doc_index', 'index_documentation', None),\n        'config': ('config_index', 'index_configs', None),\n        'context': ('autocontext', 'warm_context', None),\n    }\n\n    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' /", "chunk_type": "function", "line_start": 18, "line_end": 83, "language": "python", "name": "warm_all"}, "317b12cd2b19_func_main": {"id": "317b12cd2b19_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\warm.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    root = find_project_root() or Path.cwd()\n\n    if '--quick' in sys.argv:\n        # Quick warm - just semantic and todos\n        Console.header(\"Quick Warm\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(root / '.mcp' / 'vector_index')\n            store.index_codebase(root)\n            Console.ok(\"Semantic index warmed\")\n        except Exception:\n            pass\n\n        try:\n            from .todo_index import index_todos\n            index_todos(root)\n            Console.ok(\"TODO index warmed\")\n        except Exception:\n            pass\n\n        return 0\n\n    warm_all(root)\n    return 0", "chunk_type": "function", "line_start": 86, "line_end": 112, "language": "python", "name": "main"}, "317b12cd2b19_func_run_task": {"id": "317b12cd2b19_func_run_task", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\warm.py", "content": "    def run_task(name, module_name, func_or_class, method):\n        try:\n            import importlib\n            module = importlib.import_module(f\"scripts.{module_name}\")\n\n            if method:\n                # Class with method\n                cls = getattr(module, func_or_class)\n                instance = cls(root / '.mcp' / 'vector_index')\n                getattr(instance, method)(root)\n            else:\n                # Direct function\n                func = getattr(module, func_or_class)\n                func(root)\n\n            return name, 'ok', None\n        except Exception as e:\n            return name, 'error', str(e)", "chunk_type": "function", "line_start": 38, "line_end": 55, "language": "python", "name": "run_task"}, "ec6c3e36af4b_file": {"id": "ec6c3e36af4b_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "\"\"\"\nFile System Watcher\n===================\nBackground process for live semantic index updates.\n\nUsage:\n    python mcp.py watch           # Start watching\n    python mcp.py watch --stop    # Stop watching\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, Set, Optional\nimport hashlib\nimport json\nimport os\nimport sys\nimport time\n\nfrom .utils import Console, find_python_files, find_project_root\nimport signal\n\n\n# Try watchdog for efficient file watching\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileModifiedEvent\n    WATCHDOG_AVAILABLE = True\nexcept ImportError:\n    WATCHDOG_AVAILABLE = False\n\n\n@dataclass\nclass WatcherState:\n    \"\"\"State of the file watcher.\"\"\"\n    pid_file: Path\n    index_path: Path\n    debounce_ms: int = 500\n    save_interval_s: int = 30\n    running: bool = False\n\n\nclass CodeChangeHandler:\n    \"\"\"Handles file changes for indexing.\"\"\"\n\n    def __init__(self, root: Path, state: WatcherState):\n        self.root = root\n        self.state = state\n        self.pending_files: Set[Path] = set()\n        self.last_change_time: float = 0\n        self.file_hashes: Dict[str, str] = {}\n\n    def on_modified(self, path: Path):\n        \"\"\"Handle file modification.\"\"\"\n        if not path.suffix == '.py':\n            return\n\n        # Check if file actually changed (not just touched)\n        current_hash = self._get_file_hash(path)\n        if self.file_hashes.get(str(path)) == current_hash:\n            return\n\n        self.file_hashes[str(path)] = current_hash\n        self.pending_files.add(path)\n        self.last_change_time = time.time()\n\n    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n            return \"\"\n\n    def process_pending(self) -> int:\n        \"\"\"Process ", "chunk_type": "file", "line_start": 1, "line_end": 291, "language": "python", "name": "watcher.py"}, "ec6c3e36af4b_func_poll_watch": {"id": "ec6c3e36af4b_func_poll_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def poll_watch(root: Path, state: WatcherState):\n    \"\"\"Polling-based file watcher (fallback).\"\"\"\n    handler = CodeChangeHandler(root, state)\n    last_save = time.time()\n\n    # Initial scan\n    Console.info(\"Initial file scan...\")\n    for path in find_python_files(root):\n        handler.file_hashes[str(path)] = handler._get_file_hash(path)\n    Console.ok(f\"Tracking {len(handler.file_hashes)} files\")\n\n    Console.info(f\"Watching {root} (polling mode)...\")\n    Console.info(\"Press Ctrl+C to stop\")\n\n    while state.running:\n        # Check for changes\n        for path in find_python_files(root):\n            current_hash = handler._get_file_hash(path)\n            if handler.file_hashes.get(str(path)) != current_hash:\n                handler.on_modified(path)\n\n        # Process pending\n        handler.process_pending()\n\n        # Periodic save\n        if time.time() - last_save > state.save_interval_s:\n            last_save = time.time()\n\n        time.sleep(1)", "chunk_type": "function", "line_start": 120, "line_end": 148, "language": "python", "name": "poll_watch"}, "ec6c3e36af4b_func_watchdog_watch": {"id": "ec6c3e36af4b_func_watchdog_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def watchdog_watch(root: Path, state: WatcherState):\n    \"\"\"Watchdog-based efficient file watching.\"\"\"\n    handler = CodeChangeHandler(root, state)\n    watchdog_handler = WatchdogHandler(handler)\n\n    observer = Observer()\n    observer.schedule(watchdog_handler, str(root), recursive=True)\n    observer.start()\n\n    Console.info(f\"Watching {root} (watchdog mode)...\")\n    Console.info(\"Press Ctrl+C to stop\")\n\n    try:\n        while state.running:\n            handler.process_pending()\n            time.sleep(0.5)\n    finally:\n        observer.stop()\n        observer.join()", "chunk_type": "function", "line_start": 151, "line_end": 169, "language": "python", "name": "watchdog_watch"}, "ec6c3e36af4b_func_start_watch": {"id": "ec6c3e36af4b_func_start_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def start_watch(root: Path = None, background: bool = False):\n    \"\"\"Start the file watcher.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n\n    mcp_dir = root / '.mcp'\n    mcp_dir.mkdir(exist_ok=True)\n\n    state = WatcherState(\n        pid_file=mcp_dir / 'watcher.pid',\n        index_path=mcp_dir / 'vector_index',\n        running=True\n    )\n\n    # Check if already running\n    if state.pid_file.exists():\n        try:\n            pid = int(state.pid_file.read_text().strip())\n            # Check if process exists\n            os.kill(pid, 0)\n            Console.warn(f\"Watcher already running (PID {pid})\")\n            return 1\n        except (ProcessLookupError, ValueError):\n            state.pid_file.unlink()\n\n    # Write PID\n    state.pid_file.write_text(str(os.getpid()))\n\n    # Handle shutdown\n    def shutdown(signum, frame):\n        Console.info(\"Stopping watcher...\")\n        state.running = False\n        if state.pid_file.exists():\n            state.pid_file.unlink()\n\n    sign", "chunk_type": "function", "line_start": 172, "line_end": 219, "language": "python", "name": "start_watch"}, "ec6c3e36af4b_func_stop_watch": {"id": "ec6c3e36af4b_func_stop_watch", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def stop_watch(root: Path = None):\n    \"\"\"Stop the file watcher.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    pid_file = root / '.mcp' / 'watcher.pid'\n\n    if not pid_file.exists():\n        Console.warn(\"No watcher running\")\n        return 1\n\n    try:\n        pid = int(pid_file.read_text().strip())\n        os.kill(pid, signal.SIGTERM)\n        Console.ok(f\"Stopped watcher (PID {pid})\")\n        pid_file.unlink()\n        return 0\n    except ProcessLookupError:\n        Console.warn(\"Watcher process not found\")\n        pid_file.unlink()\n        return 1\n    except Exception as e:\n        Console.fail(f\"Could not stop watcher: {e}\")\n        return 1", "chunk_type": "function", "line_start": 222, "line_end": 243, "language": "python", "name": "stop_watch"}, "ec6c3e36af4b_func_get_watch_status": {"id": "ec6c3e36af4b_func_get_watch_status", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def get_watch_status(root: Path = None) -> Optional[int]:\n    \"\"\"Get watcher PID if running.\"\"\"\n    root = root or find_project_root() or Path.cwd()\n    pid_file = root / '.mcp' / 'watcher.pid'\n\n    if not pid_file.exists():\n        return None\n\n    try:\n        pid = int(pid_file.read_text().strip())\n        os.kill(pid, 0)  # Check if process exists\n        return pid\n    except (ProcessLookupError, ValueError):\n        return None", "chunk_type": "function", "line_start": 246, "line_end": 259, "language": "python", "name": "get_watch_status"}, "ec6c3e36af4b_func_main": {"id": "ec6c3e36af4b_func_main", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "def main():\n    \"\"\"CLI entry point.\"\"\"\n    Console.header(\"File Watcher\")\n\n    if WATCHDOG_AVAILABLE:\n        Console.ok(\"watchdog available (efficient mode)\")\n    else:\n        Console.warn(\"watchdog not installed, using polling\")\n\n    args = [a for a in sys.argv[1:] if not a.startswith('-')]\n\n    if '--stop' in sys.argv:\n        return stop_watch()\n\n    if '--status' in sys.argv:\n        pid = get_watch_status()\n        if pid:\n            Console.ok(f\"Watcher running (PID {pid})\")\n        else:\n            Console.info(\"Watcher not running\")\n        return 0\n\n    # Start watching\n    path = Path(args[0]) if args else None\n    return start_watch(path)", "chunk_type": "function", "line_start": 262, "line_end": 286, "language": "python", "name": "main"}, "ec6c3e36af4b_func___init__": {"id": "ec6c3e36af4b_func___init__", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "        def __init__(self, change_handler: CodeChangeHandler):\n            self.change_handler = change_handler", "chunk_type": "function", "line_start": 108, "line_end": 109, "language": "python", "name": "__init__"}, "ec6c3e36af4b_func_on_modified": {"id": "ec6c3e36af4b_func_on_modified", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "        def on_modified(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "function", "line_start": 111, "line_end": 113, "language": "python", "name": "on_modified"}, "ec6c3e36af4b_func__get_file_hash": {"id": "ec6c3e36af4b_func__get_file_hash", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n            return \"\"", "chunk_type": "function", "line_start": 68, "line_end": 74, "language": "python", "name": "_get_file_hash"}, "ec6c3e36af4b_func_process_pending": {"id": "ec6c3e36af4b_func_process_pending", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "    def process_pending(self) -> int:\n        \"\"\"Process pending files if debounce period passed.\"\"\"\n        if not self.pending_files:\n            return 0\n\n        # Check debounce\n        elapsed_ms = (time.time() - self.last_change_time) * 1000\n        if elapsed_ms < self.state.debounce_ms:\n            return 0\n\n        # Process files\n        files = list(self.pending_files)\n        self.pending_files.clear()\n\n        Console.info(f\"Updating index for {len(files)} files...\")\n\n        try:\n            from .vector_store import VectorStore\n            store = VectorStore(self.state.index_path)\n            store.load()\n            store.update(files)\n            Console.ok(f\"Index updated\")\n            return len(files)\n        except Exception as e:\n            Console.warn(f\"Index update failed: {e}\")\n            return 0", "chunk_type": "function", "line_start": 76, "line_end": 101, "language": "python", "name": "process_pending"}, "ec6c3e36af4b_func_shutdown": {"id": "ec6c3e36af4b_func_shutdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "    def shutdown(signum, frame):\n        Console.info(\"Stopping watcher...\")\n        state.running = False\n        if state.pid_file.exists():\n            state.pid_file.unlink()", "chunk_type": "function", "line_start": 200, "line_end": 204, "language": "python", "name": "shutdown"}, "ec6c3e36af4b_func_on_created": {"id": "ec6c3e36af4b_func_on_created", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "        def on_created(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "function", "line_start": 115, "line_end": 117, "language": "python", "name": "on_created"}, "ec6c3e36af4b_class_WatcherState": {"id": "ec6c3e36af4b_class_WatcherState", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "class WatcherState:\n    \"\"\"State of the file watcher.\"\"\"\n    pid_file: Path\n    index_path: Path\n    debounce_ms: int = 500\n    save_interval_s: int = 30\n    running: bool = False", "chunk_type": "class", "line_start": 35, "line_end": 41, "language": "python", "name": "WatcherState"}, "ec6c3e36af4b_class_CodeChangeHandler": {"id": "ec6c3e36af4b_class_CodeChangeHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "class CodeChangeHandler:\n    \"\"\"Handles file changes for indexing.\"\"\"\n\n    def __init__(self, root: Path, state: WatcherState):\n        self.root = root\n        self.state = state\n        self.pending_files: Set[Path] = set()\n        self.last_change_time: float = 0\n        self.file_hashes: Dict[str, str] = {}\n\n    def on_modified(self, path: Path):\n        \"\"\"Handle file modification.\"\"\"\n        if not path.suffix == '.py':\n            return\n\n        # Check if file actually changed (not just touched)\n        current_hash = self._get_file_hash(path)\n        if self.file_hashes.get(str(path)) == current_hash:\n            return\n\n        self.file_hashes[str(path)] = current_hash\n        self.pending_files.add(path)\n        self.last_change_time = time.time()\n\n    def _get_file_hash(self, path: Path) -> str:\n        \"\"\"Get hash of file contents.\"\"\"\n        try:\n            with open(path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()\n        except Exception:\n  ", "chunk_type": "class", "line_start": 44, "line_end": 101, "language": "python", "name": "CodeChangeHandler"}, "ec6c3e36af4b_class_WatchdogHandler": {"id": "ec6c3e36af4b_class_WatchdogHandler", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\watcher.py", "content": "    class WatchdogHandler(FileSystemEventHandler):\n        \"\"\"Watchdog event handler.\"\"\"\n\n        def __init__(self, change_handler: CodeChangeHandler):\n            self.change_handler = change_handler\n\n        def on_modified(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))\n\n        def on_created(self, event):\n            if not event.is_directory:\n                self.change_handler.on_modified(Path(event.src_path))", "chunk_type": "class", "line_start": 105, "line_end": 117, "language": "python", "name": "WatchdogHandler"}, "b9b2018b4178_file": {"id": "b9b2018b4178_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\scripts\\__init__.py", "content": "\"\"\"\nMCP Global Rules - Scripts Package\n==================================\nAI Agent Enhancement Tools for autonomous development.\n\"\"\"\n\nfrom .utils import (\n    FunctionInfo,\n    ClassInfo,\n    ModuleInfo,\n    GitCommit,\n    find_python_files,\n    find_project_root,\n    parse_file,\n    analyze_module,\n    get_git_log,\n    get_changed_files,\n    get_staged_files,\n    format_as_json,\n    format_as_markdown_table,\n    record_to_memory,\n    Console\n)\n\n__version__ = \"2.0.0\"\n__all__ = [\n    'FunctionInfo',\n    'ClassInfo',\n    'ModuleInfo',\n    'GitCommit',\n    'find_python_files',\n    'find_project_root',\n    'parse_file',\n    'analyze_module',\n    'get_git_log',\n    'get_changed_files',\n    'get_staged_files',\n    'format_as_json',\n    'format_as_markdown_table',\n    'record_to_memory',\n    'Console'\n]\n", "chunk_type": "file", "line_start": 1, "line_end": 43, "language": "python", "name": "__init__.py"}, "06faef5dcecf_file": {"id": "06faef5dcecf_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "\"\"\"\nTests for MCP Global Rules Scripts\n==================================\nComprehensive test suite for all AI agent enhancement tools.\n\"\"\"\n\nfrom pathlib import Path\nimport os\nimport tempfile\n\nimport pytest\n\n# Create a sample Python file for testing\nSAMPLE_PYTHON_CODE = '''\n\"\"\"Sample module for testing.\"\"\"\n\nimport os\nimport sys\nfrom pathlib import Path\n\n\nclass SampleClass:\n    \"\"\"A sample class.\"\"\"\n\n    def __init__(self, name: str):\n        self.name = name\n\n    def get_name(self) -> str:\n        \"\"\"Get the name.\"\"\"\n        return self.name\n\n\ndef sample_function(arg1: str, arg2: int = 10) -> bool:\n    \"\"\"\n    Sample function with docstring.\n\n    Args:\n        arg1: First argument\n        arg2: Second argument\n\n    Returns:\n        True if successful\n    \"\"\"\n    return True\n\n\ndef undocumented_function(x, y):\n    # This function has no docstring\n    return x + y\n\n\nCONSTANT_VALUE = 42\nunused_variable = \"not used\"\n'''\n\nSAMPLE_CODE_NO_DOCS = '''\nimport json\n\nclass NoDocClass:\n    def __init__(self):\n        self.value = 1\n\n    def method(self):\n        return self.value\n\ndef no_doc_function():\n    return True\n'''\n\n\n@pytest.fixture\ndef temp_project():\n    \"\"\"Create a temporary project directory with sample files.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        project_dir = Path(tmpdir)\n\n        # Create sample files\n        (project_dir / \"sample.py\").write_text(SAMPLE_PYTHON_CODE)\n        (project_dir / \"no_docs.py\").write_text(SAMPLE_CODE_NO_DOCS)\n\n        # Create src directory\n        (project_dir / \"src\").mkdir()\n        (project_dir / \"src\" / \"__init__.py\").write_text(\"\")\n        (project_dir / \"src\" / \"module.py\").write_text(SAMPLE_PYTHON_CODE)\n\n        yield project_dir\n\n\nclass TestUtils:\n    \"\"\"Tests for utils.py module.\"\"\"\n\n    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >=", "chunk_type": "file", "line_start": 1, "line_end": 330, "language": "python", "name": "test_scripts.py"}, "06faef5dcecf_func_temp_project": {"id": "06faef5dcecf_func_temp_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "def temp_project():\n    \"\"\"Create a temporary project directory with sample files.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        project_dir = Path(tmpdir)\n\n        # Create sample files\n        (project_dir / \"sample.py\").write_text(SAMPLE_PYTHON_CODE)\n        (project_dir / \"no_docs.py\").write_text(SAMPLE_CODE_NO_DOCS)\n\n        # Create src directory\n        (project_dir / \"src\").mkdir()\n        (project_dir / \"src\" / \"__init__.py\").write_text(\"\")\n        (project_dir / \"src\" / \"module.py\").write_text(SAMPLE_PYTHON_CODE)\n\n        yield project_dir", "chunk_type": "function", "line_start": 72, "line_end": 86, "language": "python", "name": "temp_project"}, "06faef5dcecf_func_test_find_python_files": {"id": "06faef5dcecf_func_test_find_python_files", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >= 2:\n            raise AssertionError(\"Should have found at least 2 files\")\n        if not any(f.name == \"sample.py\" for f in files):\n            raise AssertionError(\"Should have found sample.py\")", "chunk_type": "function", "line_start": 92, "line_end": 100, "language": "python", "name": "test_find_python_files"}, "06faef5dcecf_func_test_parse_file": {"id": "06faef5dcecf_func_test_parse_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_file(self, temp_project):\n        \"\"\"Test parsing Python file.\"\"\"\n        from scripts.utils import parse_file\n\n        tree = parse_file(temp_project / \"sample.py\")\n        if tree is None:\n            raise AssertionError(\"Tree should not be None\")", "chunk_type": "function", "line_start": 102, "line_end": 108, "language": "python", "name": "test_parse_file"}, "06faef5dcecf_func_test_analyze_module": {"id": "06faef5dcecf_func_test_analyze_module", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_module(self, temp_project):\n        \"\"\"Test analyzing module.\"\"\"\n        from scripts.utils import analyze_module\n\n        info = analyze_module(temp_project / \"sample.py\")\n        if info is None:\n            raise AssertionError(\"Info should not be None\")\n        if not len(info.functions) >= 2:\n            raise AssertionError(\"Should identify at least 2 functions\")\n        if not len(info.classes) >= 1:\n            raise AssertionError(\"Should identify at least 1 class\")", "chunk_type": "function", "line_start": 110, "line_end": 120, "language": "python", "name": "test_analyze_module"}, "06faef5dcecf_func_test_format_as_markdown_table": {"id": "06faef5dcecf_func_test_format_as_markdown_table", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_as_markdown_table(self):\n        \"\"\"Test markdown table formatting.\"\"\"\n        from scripts.utils import format_as_markdown_table\n\n        table = format_as_markdown_table(\n            [\"Name\", \"Value\"],\n            [[\"foo\", \"bar\"], [\"baz\", \"qux\"]]\n        )\n        if \"Name\" not in table:\n            raise AssertionError(\"Table should contain header 'Name'\")\n        if \"foo\" not in table:\n            raise AssertionError(\"Table should contain value 'foo'\")", "chunk_type": "function", "line_start": 122, "line_end": 133, "language": "python", "name": "test_format_as_markdown_table"}, "06faef5dcecf_func_test_detect_dead_code": {"id": "06faef5dcecf_func_test_detect_dead_code", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_detect_dead_code(self, temp_project):\n        \"\"\"Test dead code detection.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not report.total_issues >= 0:\n            raise AssertionError(\"Total issues should be non-negative\")", "chunk_type": "function", "line_start": 139, "line_end": 147, "language": "python", "name": "test_detect_dead_code"}, "06faef5dcecf_func_test_report_to_markdown": {"id": "06faef5dcecf_func_test_report_to_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_report_to_markdown(self, temp_project):\n        \"\"\"Test report conversion to markdown.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        markdown = report.to_markdown()\n        if \"Dead Code Report\" not in markdown:\n            raise AssertionError(\"Markdown should contain 'Dead Code Report'\")", "chunk_type": "function", "line_start": 149, "line_end": 156, "language": "python", "name": "test_report_to_markdown"}, "06faef5dcecf_func_test_analyze_file_for_docstrings": {"id": "06faef5dcecf_func_test_analyze_file_for_docstrings", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_file_for_docstrings(self, temp_project):\n        \"\"\"Test docstring analysis.\"\"\"\n        from scripts.auto_docs import analyze_file_for_docstrings\n\n        suggestions = analyze_file_for_docstrings(temp_project / \"no_docs.py\")\n        if not len(suggestions) >= 2:\n            raise AssertionError(\"Should find at least 2 suggestions\")", "chunk_type": "function", "line_start": 162, "line_end": 168, "language": "python", "name": "test_analyze_file_for_docstrings"}, "06faef5dcecf_func_test_generate_function_docstring": {"id": "06faef5dcecf_func_test_generate_function_docstring", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_generate_function_docstring(self):\n        \"\"\"Test docstring generation.\"\"\"\n        from scripts.auto_docs import generate_function_docstring\n        from scripts.utils import FunctionInfo\n        import ast\n\n        # Create a mock function node\n        code = \"def test_func(arg1: str, arg2: int) -> bool: pass\"\n        tree = ast.parse(code)\n        node = tree.body[0]\n\n        docstring = generate_function_docstring(node, \"    \")\n        if '\"\"\"' not in docstring:\n            raise AssertionError(\"Docstring should contain quotes\")\n        if 'Args:' not in docstring:\n            raise AssertionError(\"Docstring should contain Args section\")", "chunk_type": "function", "line_start": 170, "line_end": 185, "language": "python", "name": "test_generate_function_docstring"}, "06faef5dcecf_func_test_generate_test_function": {"id": "06faef5dcecf_func_test_generate_test_function", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_generate_test_function(self):\n        \"\"\"Test test function generation.\"\"\"\n        from scripts.auto_test import generate_test_function\n        from scripts.utils import FunctionInfo\n\n        func = FunctionInfo(\n            name=\"my_function\",\n            lineno=1,\n            end_lineno=10,\n            args=[\"arg1\", \"arg2\"],\n            arg_types={\"arg1\": \"str\", \"arg2\": \"int\"},\n            return_type=\"bool\",\n            docstring=\"Test function.\"\n        )\n\n        test_code = generate_test_function(func, \"mymodule\")\n        if \"def test_my_function\" not in test_code:\n            raise AssertionError(\"Should generate test function definition\")\n        if \"assert\" not in test_code:\n            raise AssertionError(\"Should contain assertion in generated code\")", "chunk_type": "function", "line_start": 191, "line_end": 210, "language": "python", "name": "test_generate_test_function"}, "06faef5dcecf_func_test_summarize_codebase": {"id": "06faef5dcecf_func_test_summarize_codebase", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_summarize_codebase(self, temp_project):\n        \"\"\"Test codebase summarization.\"\"\"\n        from scripts.summarize import summarize_codebase\n\n        summary = summarize_codebase(temp_project)\n        if not summary.total_files >= 2:\n            raise AssertionError(\"Should handle at least 2 files\")\n        if not summary.total_functions >= 2:\n            raise AssertionError(\"Should handle at least 2 functions\")", "chunk_type": "function", "line_start": 216, "line_end": 224, "language": "python", "name": "test_summarize_codebase"}, "06faef5dcecf_func_test_format_summary_markdown": {"id": "06faef5dcecf_func_test_format_summary_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_summary_markdown(self, temp_project):\n        \"\"\"Test summary markdown formatting.\"\"\"\n        from scripts.summarize import summarize_codebase, format_summary_markdown\n\n        summary = summarize_codebase(temp_project)\n        markdown = format_summary_markdown(summary)\n        if \"# Codebase Summary\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "function", "line_start": 226, "line_end": 233, "language": "python", "name": "test_format_summary_markdown"}, "06faef5dcecf_func_test_parse_commit_message": {"id": "06faef5dcecf_func_test_parse_commit_message", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_commit_message(self):\n        \"\"\"Test commit message parsing.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat(auth): add login functionality\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.commit_type != \"feat\":\n            raise AssertionError(\"Commit type should be feat\")\n        if entry.scope != \"auth\":\n            raise AssertionError(\"Scope should be auth\")\n        if \"login\" not in entry.description:\n            raise AssertionError(\"Description should contain login\")", "chunk_type": "function", "line_start": 239, "line_end": 251, "language": "python", "name": "test_parse_commit_message"}, "06faef5dcecf_func_test_parse_commit_message_breaking": {"id": "06faef5dcecf_func_test_parse_commit_message_breaking", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_parse_commit_message_breaking(self):\n        \"\"\"Test breaking change detection.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat!: breaking change\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.breaking != True:\n            raise AssertionError(\"Should detect breaking change\")", "chunk_type": "function", "line_start": 253, "line_end": 261, "language": "python", "name": "test_parse_commit_message_breaking"}, "06faef5dcecf_func_test_analyze_dependencies": {"id": "06faef5dcecf_func_test_analyze_dependencies", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_analyze_dependencies(self, temp_project):\n        \"\"\"Test dependency analysis.\"\"\"\n        from scripts.deps import analyze_dependencies\n\n        report = analyze_dependencies(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not len(report.modules) >= 2:\n            raise AssertionError(\"Should find at least 2 modules\")", "chunk_type": "function", "line_start": 267, "line_end": 275, "language": "python", "name": "test_analyze_dependencies"}, "06faef5dcecf_func_test_format_report_markdown": {"id": "06faef5dcecf_func_test_format_report_markdown", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_format_report_markdown(self, temp_project):\n        \"\"\"Test dependency report markdown.\"\"\"\n        from scripts.deps import analyze_dependencies, format_report_markdown\n\n        report = analyze_dependencies(temp_project)\n        markdown = format_report_markdown(report)\n        if \"# Dependency Analysis\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "function", "line_start": 277, "line_end": 284, "language": "python", "name": "test_format_report_markdown"}, "06faef5dcecf_func_test_review_file": {"id": "06faef5dcecf_func_test_review_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_review_file(self, temp_project):\n        \"\"\"Test file review.\"\"\"\n        from scripts.review import review_file\n\n        issues = review_file(temp_project / \"no_docs.py\")\n        if not len(issues) >= 1:\n            raise AssertionError(\"Should find missing docstrings\")", "chunk_type": "function", "line_start": 290, "line_end": 296, "language": "python", "name": "test_review_file"}, "06faef5dcecf_func_test_review_project": {"id": "06faef5dcecf_func_test_review_project", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_review_project(self, temp_project):\n        \"\"\"Test project review.\"\"\"\n        from scripts.review import review_project\n\n        report = review_project(temp_project)\n        if not report.files_reviewed >= 2:\n            raise AssertionError(\"Should review at least 2 files\")", "chunk_type": "function", "line_start": 298, "line_end": 304, "language": "python", "name": "test_review_project"}, "06faef5dcecf_func_test_security_check": {"id": "06faef5dcecf_func_test_security_check", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "    def test_security_check(self):\n        \"\"\"Test security issue detection.\"\"\"\n        from scripts.review import ReviewChecks\n        import ast\n\n        code = '''\ntest_val = \"mock\" + \"_\" + \"credential\"\neval(user_input)\n'''\n        tree = ast.parse(code)\n\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write(code)\n            f.flush()\n\n            issues = ReviewChecks.check_security_issues(Path(f.name), tree)\n            if not len(issues) >= 1:\n                raise AssertionError(\"Should find security issue\")\n\n            os.unlink(f.name)", "chunk_type": "function", "line_start": 306, "line_end": 325, "language": "python", "name": "test_security_check"}, "06faef5dcecf_class_TestUtils": {"id": "06faef5dcecf_class_TestUtils", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestUtils:\n    \"\"\"Tests for utils.py module.\"\"\"\n\n    def test_find_python_files(self, temp_project):\n        \"\"\"Test finding Python files.\"\"\"\n        from scripts.utils import find_python_files\n\n        files = list(find_python_files(temp_project))\n        if not len(files) >= 2:\n            raise AssertionError(\"Should have found at least 2 files\")\n        if not any(f.name == \"sample.py\" for f in files):\n            raise AssertionError(\"Should have found sample.py\")\n\n    def test_parse_file(self, temp_project):\n        \"\"\"Test parsing Python file.\"\"\"\n        from scripts.utils import parse_file\n\n        tree = parse_file(temp_project / \"sample.py\")\n        if tree is None:\n            raise AssertionError(\"Tree should not be None\")\n\n    def test_analyze_module(self, temp_project):\n        \"\"\"Test analyzing module.\"\"\"\n        from scripts.utils import analyze_module\n\n        info = analyze_module(temp_project / \"sample.py\")\n        if info is None:\n            raise AssertionEr", "chunk_type": "class", "line_start": 89, "line_end": 133, "language": "python", "name": "TestUtils"}, "06faef5dcecf_class_TestDeadCode": {"id": "06faef5dcecf_class_TestDeadCode", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestDeadCode:\n    \"\"\"Tests for dead_code.py module.\"\"\"\n\n    def test_detect_dead_code(self, temp_project):\n        \"\"\"Test dead code detection.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not report.total_issues >= 0:\n            raise AssertionError(\"Total issues should be non-negative\")\n\n    def test_report_to_markdown(self, temp_project):\n        \"\"\"Test report conversion to markdown.\"\"\"\n        from scripts.dead_code import detect_dead_code\n\n        report = detect_dead_code(temp_project)\n        markdown = report.to_markdown()\n        if \"Dead Code Report\" not in markdown:\n            raise AssertionError(\"Markdown should contain 'Dead Code Report'\")", "chunk_type": "class", "line_start": 136, "line_end": 156, "language": "python", "name": "TestDeadCode"}, "06faef5dcecf_class_TestAutoDocs": {"id": "06faef5dcecf_class_TestAutoDocs", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestAutoDocs:\n    \"\"\"Tests for auto_docs.py module.\"\"\"\n\n    def test_analyze_file_for_docstrings(self, temp_project):\n        \"\"\"Test docstring analysis.\"\"\"\n        from scripts.auto_docs import analyze_file_for_docstrings\n\n        suggestions = analyze_file_for_docstrings(temp_project / \"no_docs.py\")\n        if not len(suggestions) >= 2:\n            raise AssertionError(\"Should find at least 2 suggestions\")\n\n    def test_generate_function_docstring(self):\n        \"\"\"Test docstring generation.\"\"\"\n        from scripts.auto_docs import generate_function_docstring\n        from scripts.utils import FunctionInfo\n        import ast\n\n        # Create a mock function node\n        code = \"def test_func(arg1: str, arg2: int) -> bool: pass\"\n        tree = ast.parse(code)\n        node = tree.body[0]\n\n        docstring = generate_function_docstring(node, \"    \")\n        if '\"\"\"' not in docstring:\n            raise AssertionError(\"Docstring should contain quotes\")\n        if 'Args:' not in doc", "chunk_type": "class", "line_start": 159, "line_end": 185, "language": "python", "name": "TestAutoDocs"}, "06faef5dcecf_class_TestAutoTest": {"id": "06faef5dcecf_class_TestAutoTest", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestAutoTest:\n    \"\"\"Tests for auto_test.py module.\"\"\"\n\n    def test_generate_test_function(self):\n        \"\"\"Test test function generation.\"\"\"\n        from scripts.auto_test import generate_test_function\n        from scripts.utils import FunctionInfo\n\n        func = FunctionInfo(\n            name=\"my_function\",\n            lineno=1,\n            end_lineno=10,\n            args=[\"arg1\", \"arg2\"],\n            arg_types={\"arg1\": \"str\", \"arg2\": \"int\"},\n            return_type=\"bool\",\n            docstring=\"Test function.\"\n        )\n\n        test_code = generate_test_function(func, \"mymodule\")\n        if \"def test_my_function\" not in test_code:\n            raise AssertionError(\"Should generate test function definition\")\n        if \"assert\" not in test_code:\n            raise AssertionError(\"Should contain assertion in generated code\")", "chunk_type": "class", "line_start": 188, "line_end": 210, "language": "python", "name": "TestAutoTest"}, "06faef5dcecf_class_TestSummarize": {"id": "06faef5dcecf_class_TestSummarize", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestSummarize:\n    \"\"\"Tests for summarize.py module.\"\"\"\n\n    def test_summarize_codebase(self, temp_project):\n        \"\"\"Test codebase summarization.\"\"\"\n        from scripts.summarize import summarize_codebase\n\n        summary = summarize_codebase(temp_project)\n        if not summary.total_files >= 2:\n            raise AssertionError(\"Should handle at least 2 files\")\n        if not summary.total_functions >= 2:\n            raise AssertionError(\"Should handle at least 2 functions\")\n\n    def test_format_summary_markdown(self, temp_project):\n        \"\"\"Test summary markdown formatting.\"\"\"\n        from scripts.summarize import summarize_codebase, format_summary_markdown\n\n        summary = summarize_codebase(temp_project)\n        markdown = format_summary_markdown(summary)\n        if \"# Codebase Summary\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "class", "line_start": 213, "line_end": 233, "language": "python", "name": "TestSummarize"}, "06faef5dcecf_class_TestChangelog": {"id": "06faef5dcecf_class_TestChangelog", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestChangelog:\n    \"\"\"Tests for changelog.py module.\"\"\"\n\n    def test_parse_commit_message(self):\n        \"\"\"Test commit message parsing.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat(auth): add login functionality\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entry.commit_type != \"feat\":\n            raise AssertionError(\"Commit type should be feat\")\n        if entry.scope != \"auth\":\n            raise AssertionError(\"Scope should be auth\")\n        if \"login\" not in entry.description:\n            raise AssertionError(\"Description should contain login\")\n\n    def test_parse_commit_message_breaking(self):\n        \"\"\"Test breaking change detection.\"\"\"\n        from scripts.changelog import parse_commit_message\n\n        entry = parse_commit_message(\"feat!: breaking change\")\n        if entry is None:\n            raise AssertionError(\"Entry should not be None\")\n        if entr", "chunk_type": "class", "line_start": 236, "line_end": 261, "language": "python", "name": "TestChangelog"}, "06faef5dcecf_class_TestDeps": {"id": "06faef5dcecf_class_TestDeps", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestDeps:\n    \"\"\"Tests for deps.py module.\"\"\"\n\n    def test_analyze_dependencies(self, temp_project):\n        \"\"\"Test dependency analysis.\"\"\"\n        from scripts.deps import analyze_dependencies\n\n        report = analyze_dependencies(temp_project)\n        if report is None:\n            raise AssertionError(\"Report should not be None\")\n        if not len(report.modules) >= 2:\n            raise AssertionError(\"Should find at least 2 modules\")\n\n    def test_format_report_markdown(self, temp_project):\n        \"\"\"Test dependency report markdown.\"\"\"\n        from scripts.deps import analyze_dependencies, format_report_markdown\n\n        report = analyze_dependencies(temp_project)\n        markdown = format_report_markdown(report)\n        if \"# Dependency Analysis\" not in markdown:\n            raise AssertionError(\"Markdown should contain header\")", "chunk_type": "class", "line_start": 264, "line_end": 284, "language": "python", "name": "TestDeps"}, "06faef5dcecf_class_TestReview": {"id": "06faef5dcecf_class_TestReview", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\test_scripts.py", "content": "class TestReview:\n    \"\"\"Tests for review.py module.\"\"\"\n\n    def test_review_file(self, temp_project):\n        \"\"\"Test file review.\"\"\"\n        from scripts.review import review_file\n\n        issues = review_file(temp_project / \"no_docs.py\")\n        if not len(issues) >= 1:\n            raise AssertionError(\"Should find missing docstrings\")\n\n    def test_review_project(self, temp_project):\n        \"\"\"Test project review.\"\"\"\n        from scripts.review import review_project\n\n        report = review_project(temp_project)\n        if not report.files_reviewed >= 2:\n            raise AssertionError(\"Should review at least 2 files\")\n\n    def test_security_check(self):\n        \"\"\"Test security issue detection.\"\"\"\n        from scripts.review import ReviewChecks\n        import ast\n\n        code = '''\ntest_val = \"mock\" + \"_\" + \"credential\"\neval(user_input)\n'''\n        tree = ast.parse(code)\n\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write(co", "chunk_type": "class", "line_start": 287, "line_end": 325, "language": "python", "name": "TestReview"}, "8b6833a45942_file": {"id": "8b6833a45942_file", "path": "C:\\Users\\dbiss\\Desktop\\Projects\\Personal\\Cerebrum-3\\mcp-global\\mcp-global-rules\\tests\\__init__.py", "content": "\"\"\"Tests package.\"\"\"\n", "chunk_type": "file", "line_start": 1, "line_end": 2, "language": "python", "name": "__init__.py"}}